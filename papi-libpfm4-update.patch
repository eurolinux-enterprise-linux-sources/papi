From 9f688c4593e3005165de3e66c71ccb275e345880 Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Wed, 29 May 2013 11:29:30 -0400
Subject: [PATCH 01/24] Update libpfm4

commit 6e150ca2e55b71afcba7bcdbaa9233ea1e5afa85
Author: Stephane Eranian <eranian@gmail.com>
Date:   Sun Mar 24 16:55:21 2013 +0100

    add Intel Haswell core PMU support

    Add Intel Haswell (model 60) core PMU support.

    Based on SDM Vol 3b March 2013.

diff --git a/src/libpfm4/docs/Makefile b/src/libpfm4/docs/Makefile
index 25aaa29..2e29b05 100644
--- a/src/libpfm4/docs/Makefile
+++ b/src/libpfm4/docs/Makefile
@@ -44,6 +44,7 @@ ARCH_MAN=libpfm_intel_core.3	\
 	 libpfm_intel_snb.3	\
 	 libpfm_intel_snb_unc.3 \
 	 libpfm_intel_ivb.3	\
+	 libpfm_intel_hsw.3	\
 	 libpfm_intel_snbep_unc_cbo.3 \
 	 libpfm_intel_snbep_unc_ha.3 \
 	 libpfm_intel_snbep_unc_imc.3 \
diff --git a/src/libpfm4/docs/man3/libpfm_intel_hsw.3 b/src/libpfm4/docs/man3/libpfm_intel_hsw.3
new file mode 100644
index 0000000..913577d
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_intel_hsw.3
@@ -0,0 +1,97 @@
+.TH LIBPFM 3  "April, 2013" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_intel_hsw - support for Intel Haswell core PMU
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: hsw
+.B PMU desc: Intel Haswell
+.sp
+.SH DESCRIPTION
+The library supports the Intel Haswell core PMU. It should be noted that
+this PMU model only covers each core's PMU and not the socket level
+PMU.
+
+On Haswell, the number of generic counters depends on the Hyperthreading (HT) mode.
+When HT is on, then only 4 generic counters are available. When HT is off, then 8 generic
+counters are available. The \fBpfm_get_pmu_info()\fR function returns the maximum number
+of generic counters in \fBnum_cntrs\fr.
+
+.SH MODIFIERS
+The following modifiers are supported on Intel Haswell processors:
+.TP
+.B u
+Measure at user level which includes privilege levels 1, 2, 3. This corresponds to \fBPFM_PLM3\fR.
+This is a boolean modifier.
+.TP
+.B k
+Measure at kernel level which includes privilege level 0. This corresponds to \fBPFM_PLM0\fR.
+This is a boolean modifier.
+.TP
+.B i
+Invert the meaning of the event. The counter will now count cycles in which the event is \fBnot\fR
+occurring. This is a boolean modifier
+.TP
+.B e
+Enable edge detection, i.e., count only when there is a state transition from no occurrence of the event
+to at least one occurrence. This modifier must be combined with a counter mask modifier (m) with a value greater or equal to one.
+This is a boolean modifier.
+.TP
+.B c
+Set the counter mask value. The mask acts as a threshold. The counter will count the number of cycles
+in which the number of occurrences of the event is greater or equal to the threshold. This is an integer
+modifier with values in the range [0:255].
+.TP
+.B t
+Measure on both threads at the same time assuming hyper-threading is enabled. This is a boolean modifier.
+.TP
+.B ldlat
+Pass a latency threshold to the MEM_TRANS_RETIRED:LOAD_LATENCY event.
+This is an integer attribute that must be in the range [3:65535]. It is required
+for this event.  Note that the event must be used with precise sampling (PEBS).
+
+.SH OFFCORE_RESPONSE events
+Intel Haswell provides two offcore_response events. They are called OFFCORE_RESPONSE_0 and OFFCORE_RESPONSE_1.
+
+Those events need special treatment in the performance monitoring infrastructure
+because each event uses an extra register to store some settings. Thus, in
+case multiple offcore_response events are monitored simultaneously, the kernel needs
+to manage the sharing of that extra register.
+
+The offcore_response events are exposed as a normal events by the library. The extra
+settings are exposed as regular umasks. The library takes care of encoding the
+events according to the underlying kernel interface.
+
+On Intel Haswell, the umasks are divided into three categories: request, supplier
+and snoop. The user must provide at least one umask for each category. The categories
+are shown in the umask descriptions.
+
+There is also the special response umask called \fBANY_RESPONSE\fR. When this umask
+is used then it overrides any supplier and snoop umasks. In other words, users can
+specify either \fBANY_RESPONSE\fR \fBOR\fR any combinations of supplier + snoops.
+
+In case no supplier or snoop is specified, the library defaults to using
+\fBANY_RESPONSE\fR.
+
+For instance, the following are valid event selections:
+.TP
+.B OFFCORE_RESPONSE_0:DMND_DATA_RD:ANY_RESPONSE
+.TP
+.B OFFCORE_RESPONSE_0:ANY_REQUEST
+.TP
+.B OFFCORE_RESPONSE_0:ANY_RFO:LLC_HITM:SNOOP_ANY
+
+.P
+But the following are illegal:
+
+.TP
+.B OFFCORE_RESPONSE_0:ANY_RFO:LLC_HITM:ANY_RESPONSE
+.TP
+.B OFFCORE_RESPONSE_0:ANY_RFO:LLC_HITM:SNOOP_ANY:ANY_RESPONSE
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.PP
diff --git a/src/libpfm4/include/perfmon/pfmlib.h b/src/libpfm4/include/perfmon/pfmlib.h
index fe488f7..de99684 100644
--- a/src/libpfm4/include/perfmon/pfmlib.h
+++ b/src/libpfm4/include/perfmon/pfmlib.h
@@ -183,6 +183,7 @@ typedef enum {
 	PFM_PMU_ARM_1176,		/* ARM 1176 */
 
 	PFM_PMU_INTEL_IVB_EP,		/* Intel IvyBridge EP */
+	PFM_PMU_INTEL_HSW,		/* Intel Haswell */
 
 	/* MUST ADD NEW PMU MODELS HERE */
 
diff --git a/src/libpfm4/lib/Makefile b/src/libpfm4/lib/Makefile
index 0c288d3..84248dd 100644
--- a/src/libpfm4/lib/Makefile
+++ b/src/libpfm4/lib/Makefile
@@ -59,6 +59,7 @@ SRCS   += pfmlib_amd64.c pfmlib_intel_core.c pfmlib_intel_x86.c \
 	  pfmlib_intel_wsm.c  \
 	  pfmlib_intel_snb.c pfmlib_intel_snb_unc.c \
 	  pfmlib_intel_ivb.c \
+	  pfmlib_intel_hsw.c \
 	  pfmlib_intel_snbep_unc.c \
 	  pfmlib_intel_snbep_unc_cbo.c \
 	  pfmlib_intel_snbep_unc_ha.c \
@@ -205,6 +206,7 @@ INC_X86= pfmlib_intel_x86_priv.h	\
 	events/intel_snbep_events.h	\
 	events/intel_snb_unc_events.h	\
 	events/intel_ivb_events.h	\
+	events/intel_hsw_events.h	\
 	pfmlib_intel_snbep_unc_priv.h	\
 	events/intel_snbep_unc_cbo_events.h \
 	events/intel_snbep_unc_ha_events.h \
diff --git a/src/libpfm4/lib/events/intel_hsw_events.h b/src/libpfm4/lib/events/intel_hsw_events.h
new file mode 100644
index 0000000..bc0549e
--- /dev/null
+++ b/src/libpfm4/lib/events/intel_hsw_events.h
@@ -0,0 +1,2332 @@
+/*
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * This file is part of libpfm, a performance monitoring support library for
+ * applications on Linux.
+ *
+ * PMU: hsw (Intel Haswell)
+ */
+
+static const intel_x86_umask_t hsw_baclears[]={
+  { .uname = "ANY",
+    .udesc  = "NUmber of front-end re-steers due to BPU misprediction",
+    .ucode  = 0x1f00,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t hsw_br_inst_exec[]={
+  { .uname = "NONTAKEN_CONDITIONAL",
+    .udesc  = "All macro conditional nontaken branch instructions",
+    .ucode  = 0x4100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "TAKEN_CONDITIONAL",
+    .udesc  = "Taken speculative and retired macro-conditional branches",
+    .ucode  = 0x8100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "TAKEN_DIRECT_JUMP",
+    .udesc  = "Taken speculative and retired macro-conditional branch instructions excluding calls and indirects",
+    .ucode  = 0x8200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "TAKEN_INDIRECT_JUMP_NON_CALL_RET",
+    .udesc  = "Taken speculative and retired indirect branches excluding calls and returns",
+    .ucode  = 0x8400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "TAKEN_INDIRECT_NEAR_RETURN",
+    .udesc  = "Taken speculative and retired indirect branches with return mnemonic",
+    .ucode  = 0x8800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "TAKEN_DIRECT_NEAR_CALL",
+    .udesc  = "Taken speculative and retired direct near calls",
+    .ucode  = 0x9000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "TAKEN_INDIRECT_NEAR_CALL",
+    .udesc  = "All taken indirect calls, including both register and memory indirect",
+    .ucode  = 0xa000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_CONDITIONAL",
+    .udesc  = "Speculative and retired macro-conditional branches",
+    .ucode  = 0xc100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_DIRECT_JMP",
+    .udesc  = "Speculative and retired macro-unconditional branches excluding calls and indirects",
+    .ucode  = 0xc200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_INDIRECT_JUMP_NON_CALL_RET",
+    .udesc  = "Speculative and retired indirect branches excluding calls and returns",
+    .ucode  = 0xc400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_INDIRECT_NEAR_RETURN",
+    .udesc  = "Speculative and retired indirect return branches",
+    .ucode  = 0xc800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_DIRECT_NEAR_CALL",
+    .udesc  = "Speculative and retired direct near calls",
+    .ucode  = 0xd000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ANY_INDIRECT_NEAR_CALL",
+    .udesc  = "All indirect calls, including both register and memory indirect",
+    .ucode  = 0xe000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_BRANCHES",
+    .udesc  = "All branch instructions executed",
+    .ucode  = 0xff00,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t hsw_br_inst_retired[]={
+  { .uname = "CONDITIONAL",
+    .udesc  = "Counts all taken and not taken macro conditional branch instructions",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "NEAR_CALL",
+    .udesc  = "Counts all macro direct and indirect near calls",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "ALL_BRANCHES",
+    .udesc  = "Counts all taken and not taken macro branches including far branches (architectural event)",
+    .ucode  = 0x0,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL | INTEL_X86_PEBS,
+  },
+  { .uname = "NEAR_RETURN",
+    .udesc  = "Counts the number of near ret instructions retired",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "NOT_TAKEN",
+    .udesc  = "Counts all not taken macro branch instructions retired",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "NEAR_TAKEN",
+    .udesc  = "Counts the number of near branch taken instructions retired",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "FAR_BRANCH",
+    .udesc  = "Counts the number of far branch instructions retired",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+};
+
+static const intel_x86_umask_t hsw_br_misp_exec[]={
+  { .uname = "NONTAKEN_CONDITIONAL",
+    .udesc  = "Not taken speculative and retired mispredicted macro conditional branches",
+    .ucode  = 0x4100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "TAKEN_CONDITIONAL",
+    .udesc  = "Taken speculative and retired mispredicted macro conditional branches",
+    .ucode  = 0x8100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "TAKEN_INDIRECT_JUMP_NON_CALL_RET",
+    .udesc  = "Taken speculative and retired mispredicted indirect branches excluding calls and returns",
+    .ucode  = 0x8400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "TAKEN_RETURN_NEAR",
+    .udesc  = "Taken speculative and retired mispredicted indirect branches with return mnemonic",
+    .ucode  = 0x8800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_CONDITIONAL",
+    .udesc  = "Speculative and retired mispredicted macro conditional branches",
+    .ucode  = 0xc100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_INDIRECT_JUMP_NON_CALL_RET",
+    .udesc  = "All mispredicted indirect branches that are not calls nor returns",
+    .ucode  = 0xc400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ANY_RETURN_NEAR",
+    .udesc  = "Speculative and retired mispredicted indirect branches with return mnemonic",
+    .ucode  = 0xc800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ANY_INDIRECT_NEAR_CALL",
+    .udesc  = "All mispredicted indirect calls, including both register and memory indirect",
+    .ucode  = 0xe000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_BRANCHES",
+    .udesc  = "Speculative and retired mispredicted macro conditional branches",
+    .ucode  = 0xff00,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "TAKEN_INDIRECT_NEAR_CALL",
+    .udesc  = "Taken speculative and retired mispredicted indirect calls",
+    .ucode  = 0xa000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_br_misp_retired[]={
+  { .uname = "CONDITIONAL",
+    .udesc  = "All mispredicted macro conditional branch instructions",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "ALL_BRANCHES",
+    .udesc  = "All mispredicted macro branches (architectural event)",
+    .ucode  = 0x0, /* architectural encoding */
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_DFL,
+  },
+  { .uname = "NEAR_TAKEN",
+    .udesc  = "number of near branch instructions retired that were mispredicted and taken",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+};
+
+static const intel_x86_umask_t hsw_cpl_cycles[]={
+  { .uname = "RING0",
+    .udesc  = "Unhalted core cycles when the thread is in ring 0",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RING123",
+    .udesc  = "Unhalted core cycles when thread is in rings 1, 2, or 3",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RING0_TRANS",
+    .udesc  = "Number of intervals between processor halts while thread is in ring 0",
+    .ucode  = 0x100 | INTEL_X86_MOD_EDGE | (1 << INTEL_X86_CMASK_BIT), /* edge=1 cnt=1 */
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_E | _INTEL_X86_ATTR_C,
+  },
+};
+
+static const intel_x86_umask_t hsw_cpu_clk_thread_unhalted[]={
+  { .uname = "REF_XCLK",
+    .udesc  = "Cases when the core is unhalted at 100Mhz",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname  = "THREAD_P",
+    .udesc  = "Cycles when thread is not halted",
+    .ucode = 0x000,
+    .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t hsw_cycle_activity[]={
+   { .uname  = "CYCLES_L2_PENDING",
+     .udesc  = "Cycles with pending L2 miss loads (must use with HT off only)",
+     .ucode  = 0x0100 | (0x1 << INTEL_X86_CMASK_BIT),
+     .uflags = INTEL_X86_NCOMBO,
+     .ucntmsk= 0xf,
+   },
+   { .uname  = "CYCLES_LDM_PENDING",
+     .udesc  = "Cycles with pending memory loads",
+     .ucode  = 0x0200 | (0x2 << INTEL_X86_CMASK_BIT),
+     .uflags = INTEL_X86_NCOMBO,
+   },
+   { .uname  = "CYCLES_L1D_PENDING",
+     .udesc  = "Cycles with pending L1D load cache misses",
+     .ucode  = 0x0800 | (0x8 << INTEL_X86_CMASK_BIT),
+     .ucntmsk= 0x4,
+     .uflags = INTEL_X86_NCOMBO,
+   },
+   { .uname  = "STALLS_L2_PENDING",
+     .udesc  = "Execution stalls due to L2 pending loads (must use with HT off only)",
+     .ucode  = 0x0500 | (0x5 << INTEL_X86_CMASK_BIT),
+     .ucntmsk= 0xf,
+     .uflags = INTEL_X86_NCOMBO,
+   },
+};
+
+static const intel_x86_umask_t hsw_dtlb_load_misses[]={
+  { .uname = "MISS_CAUSES_A_WALK",
+    .udesc  = "Misses in all DTLB levels that cause page walks",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WALK_COMPLETED_4K",
+    .udesc  = "Misses in all TLB levels causes a page walk that completes (4K)",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WALK_COMPLETED_2M_4M",
+    .udesc  = "Misses in all TLB levels causes a page walk that completes (2M/4M)",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WALK_COMPLETED",
+    .udesc  = "Misses in all TLB levels causes a page walk of any page size that completes",
+    .ucode  = 0xe00,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WALK_DURATION",
+    .udesc  = "Cycles when PMH is busy with page walks",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "STLB_HIT_4K",
+    .udesc  = "Misses that miss the DTLB and hit the STLB (4K)",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "STLB_HIT_2M",
+    .udesc  = "Misses that miss the DTLB and hit the STLB (2M)",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "STLB_HIT",
+    .udesc  = "Number of cache load STLB hits. No page walk",
+    .ucode  = 0x6000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "PDE_CACHE_MISS",
+    .udesc  = "DTLB misses with low part of linear-to-physical address translation missed",
+    .ucode  = 0x8000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_itlb_misses[]={
+  { .uname = "MISS_CAUSES_A_WALK",
+    .udesc  = "Misses in all DTLB levels that cause page walks",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WALK_COMPLETED_4K",
+    .udesc  = "Misses in all TLB levels causes a page walk that completes (4K)",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WALK_COMPLETED_2M_4M",
+    .udesc  = "Misses in all TLB levels causes a page walk that completes (2M/4M)",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WALK_COMPLETED",
+    .udesc  = "Misses in all TLB levels causes a page walk of any page size that completes",
+    .ucode  = 0xe00,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WALK_DURATION",
+    .udesc  = "Cycles when PMH is busy with page walks",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "STLB_HIT_4K",
+    .udesc  = "Misses that miss the DTLB and hit the STLB (4K)",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "STLB_HIT_2M",
+    .udesc  = "Misses that miss the DTLB and hit the STLB (2M)",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "STLB_HIT",
+    .udesc  = "Number of cache load STLB hits. No page walk",
+    .ucode  = 0x6000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_fp_assist[]={
+  { .uname = "X87_OUTPUT",
+    .udesc  = "Number of X87 FP assists due to output values",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "X87_INPUT",
+    .udesc  = "Number of X87 FP assists due to input values",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SIMD_OUTPUT",
+    .udesc  = "Number of SIMD FP assists due to output values",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SIMD_INPUT",
+    .udesc  = "Number of SIMD FP assists due to input values",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ANY",
+    .udesc  = "Cycles with any input/output SEE or FP assists",
+    .ucode  = 0x1e00 | (1 << INTEL_X86_CMASK_BIT), /* cnt=1 */
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "ALL",
+    .udesc  = "Cycles with any input and output SSE or FP assist",
+    .ucode  = 0x1e00 | (1 << INTEL_X86_CMASK_BIT), /* cnt=1 */
+    .uequiv = "ANY",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+};
+
+static const intel_x86_umask_t hsw_icache[]={
+  { .uname = "MISSES",
+    .udesc  = "Number of Instruction Cache, Streaming Buffer and Victim Cache Misses. Includes Uncacheable accesses",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t hsw_idq[]={
+  { .uname = "EMPTY",
+    .udesc  = "Cycles the Instruction Decode Queue (IDQ) is empty",
+    .ucode  = 0x200,
+    .ucntmsk= 0xf,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MITE_UOPS",
+    .udesc  = "Number of uops delivered to Instruction Decode Queue (IDQ) from MITE path",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "DSB_UOPS",
+    .udesc  = "Number of uops delivered to Instruction Decode Queue (IDQ) from Decode Stream Buffer (DSB) path",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MS_DSB_UOPS",
+    .udesc  = "Uops initiated by Decode Stream Buffer (DSB) that are being delivered to Instruction Decode Queue (IDQ) while Microcode Sequenser (MS) is busy",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MS_MITE_UOPS",
+    .udesc  = "Uops initiated by MITE and delivered to Instruction Decode Queue (IDQ) while Microcode Sequenser (MS) is busy",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MS_UOPS",
+    .udesc  = "Number of Uops were delivered into Instruction Decode Queue (IDQ) from MS, initiated by Decode Stream Buffer (DSB) or MITE",
+    .ucode  = 0x3000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MS_UOPS_CYCLES",
+    .udesc  = "Number of cycles that Uops were delivered into Instruction Decode Queue (IDQ) when MS_Busy, initiated by Decode Stream Buffer (DSB) or MITE",
+    .ucode  = 0x3000 | (1 << INTEL_X86_CMASK_BIT), /* cnt=1 */
+    .uequiv = "MS_UOPS:c=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "MITE_UOPS_CYCLES",
+    .udesc  = "Cycles when uops are being delivered to Instruction Decode Queue (IDQ) from MITE path",
+    .ucode  = 0x400 | (1 << INTEL_X86_CMASK_BIT), /* cnt=1 */
+    .uequiv = "MITE_UOPS:c=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "DSB_UOPS_CYCLES",
+    .udesc  = "Cycles when uops are being delivered to Instruction Decode Queue (IDQ) from Decode Stream Buffer (DSB) path",
+    .ucode  = 0x800 | (1 << INTEL_X86_CMASK_BIT), /* cnt=1 */
+    .uequiv = "DSB_UOPS:c=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "MS_DSB_UOPS_CYCLES",
+    .udesc  = "Cycles when uops initiated by Decode Stream Buffer (DSB) are being delivered to Instruction Decode Queue (IDQ) while Microcode Sequenser (MS) is busy",
+    .ucode  = 0x1000 | (1 << INTEL_X86_CMASK_BIT), /* cnt=1 */
+    .uequiv = "MS_DSB_UOPS:c=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "MS_DSB_OCCUR",
+    .udesc  = "Deliveries to Instruction Decode Queue (IDQ) initiated by Decode Stream Buffer (DSB) while Microcode Sequenser (MS) is busy",
+    .ucode  = 0x1000 | INTEL_X86_MOD_EDGE | (1 << INTEL_X86_CMASK_BIT), /* edge=1 cnt=1 */
+    .uequiv = "MS_DSB_UOPS:c=1:e=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_E | _INTEL_X86_ATTR_C,
+  },
+  { .uname = "ALL_DSB_CYCLES_4_UOPS",
+    .udesc  = "Cycles Decode Stream Buffer (DSB) is delivering 4 Uops",
+    .ucode  = 0x1800 | (4 << INTEL_X86_CMASK_BIT), /* cnt=4 */
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "ALL_DSB_CYCLES_ANY_UOPS",
+    .udesc  = "Cycles Decode Stream Buffer (DSB) is delivering any Uop",
+    .ucode  = 0x1800 | (1 << INTEL_X86_CMASK_BIT), /* cnt=1 */
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "ALL_MITE_CYCLES_4_UOPS",
+    .udesc  = "Cycles MITE is delivering 4 Uops",
+    .ucode  = 0x2400 | (4 << INTEL_X86_CMASK_BIT), /* cnt=4 */
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "ALL_MITE_CYCLES_ANY_UOPS",
+    .udesc  = "Cycles MITE is delivering any Uop",
+    .ucode  = 0x2400 | (1 << INTEL_X86_CMASK_BIT), /* cnt=1 */
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "ALL_MITE_UOPS",
+    .udesc  = "Number of uops delivered to Instruction Decode Queue (IDQ) from any path",
+    .ucode  = 0x3c00,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_idq_uops_not_delivered[]={
+  { .uname = "CORE",
+    .udesc  = "Count number of non-delivered uops to Resource Allocation Table (RAT)",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t hsw_inst_retired[]={
+  { .uname = "ANY_P",
+    .udesc  = "Number of instructions retired. General Counter - architectural event",
+    .ucode  = 0x000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "ALL",
+    .udesc  = "Precise instruction retired event with HW to reduce effect of PEBS shadow in IP distribution (Precise Event)",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "TOTAL_CYCLES",
+    .udesc  = "Number of cycles using always true condition",
+    .ucode  = 0x100 | INTEL_X86_MOD_INV | (10 << INTEL_X86_CMASK_BIT), /* inv=1 cnt=10 */
+    .uequiv = "ALL:i=1:c=10",
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+    .modhw  = _INTEL_X86_ATTR_I | _INTEL_X86_ATTR_C,
+  },
+  { .uname = "PREC_DIST",
+    .udesc  = "Precise instruction retired event with HW to reduce effect of PEBS shadow in IP distribution",
+    .ucode  = 0x100,
+    .uequiv = "ALL",
+    .ucntmsk= 0x2,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+};
+
+static const intel_x86_umask_t hsw_int_misc[]={
+  { .uname = "RECOVERY_CYCLES",
+    .udesc  = "Number of cycles waiting for Machine Clears  except JEClear",
+    .ucode  = 0x300,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RECOVERY_STALLS_COUNT",
+    .udesc  = "Number of occurrences waiting for Machine Clears",
+    .ucode  = 0x300 | INTEL_X86_MOD_EDGE | (1 << INTEL_X86_CMASK_BIT), /* edge=1 cnt=1 */
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_E | _INTEL_X86_ATTR_C,
+  },
+};
+
+static const intel_x86_umask_t hsw_itlb[]={
+  { .uname = "ITLB_FLUSH",
+    .udesc  = "Flushing of the Instruction TLB (ITLB) pages independent of page size",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t hsw_l1d[]={
+  { .uname = "REPLACEMENT",
+    .udesc  = "L1D Data line replacements",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t hsw_l1d_pend_miss[]={
+  { .uname = "PENDING",
+    .udesc  = "Cycles with L1D load misses outstanding",
+    .ucode  = 0x100,
+    .ucntmsk = 0x4,
+    .uflags = INTEL_X86_DFL,
+  },
+  { .uname = "PENDING_CYCLES",
+    .udesc  = "Cycles with L1D load misses outstanding",
+    .ucode  = 0x100 | (1 << INTEL_X86_CMASK_BIT), /* cnt=1 */
+    .uequiv = "PENDING:c=1",
+    .ucntmsk = 0x4,
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "OCCURRENCES",
+    .udesc  = "Number L1D miss outstanding",
+    .ucode  = 0x100 | INTEL_X86_MOD_EDGE | (1 << INTEL_X86_CMASK_BIT), /* edge=1 cnt=1 */
+    .uequiv = "PENDING:c=1:e=1",
+    .ucntmsk = 0x4,
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_E | _INTEL_X86_ATTR_C,
+  },
+};
+
+static const intel_x86_umask_t hsw_l2_demand_rqsts[]={
+  { .uname = "WB_HIT",
+    .udesc  = "WB requests that hit L2 cache",
+    .ucode  = 0x5000,
+    .uflags = INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t hsw_l2_lines_in[]={
+  { .uname = "I",
+    .udesc  = "L2 cache lines in I state filling L2",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "S",
+    .udesc  = "L2 cache lines in S state filling L2",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "E",
+    .udesc  = "L2 cache lines in E state filling L2",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL",
+    .udesc  = "L2 cache lines filling L2",
+    .ucode  = 0x700,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "ANY",
+    .udesc  = "L2 cache lines filling L2",
+    .uequiv = "ALL",
+    .ucode  = 0x700,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_l2_lines_out[]={
+  { .uname = "DEMAND_CLEAN",
+    .udesc  = "Number of clean L2 cachelines evicted by demand",
+    .ucode  = 0x500,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "DEMAND_DIRTY",
+    .udesc  = "Number of dirty L2 cachelines evicted by demand",
+    .ucode  = 0x600,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_l2_rqsts[]={
+  { .uname = "DEMAND_DATA_RD_MISS",
+    .udesc  = "Demand Data Read requests that miss L2 cache",
+    .ucode  = 0x2100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "DEMAND_DATA_RD_HIT",
+    .udesc  = "Demand Data Read requests that hit L2 cache",
+    .ucode  = 0x4100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "DEMAND_RFO_MISS",
+    .udesc  = "RFO requests that miss L2 cache",
+    .ucode  = 0x2200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "DEMAND_RFO_HIT",
+    .udesc  = "RFO requests that hit L2 cache",
+    .ucode  = 0x4200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "CODE_RD_MISS",
+    .udesc  = "L2 cache misses when fetching instructions",
+    .ucode  = 0x2400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_DEMAND_MISS",
+    .udesc  = "All demand requests that miss the L2 cache",
+    .ucode  = 0x2700,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "CODE_RD_HIT",
+    .udesc  = "L2 cache hits when fetching instructions, code reads",
+    .ucode  = 0x4400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "L2_PF_MISS",
+    .udesc  = "Requests from the L2 hardware prefetchers that miss L2 cache",
+    .ucode  = 0x3000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MISS",
+    .udesc  = "All requests that miss the L2 cache",
+    .ucode  = 0x3f00,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "L2_PF_HIT",
+    .udesc  = "Requests from the L2 hardware prefetchers that hit L2 cache",
+    .ucode  = 0x5000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_DEMAND_DATA_RD",
+    .udesc  = "Any data read request to L2 cache",
+    .ucode  = 0xe100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_RFO",
+    .udesc  = "Any data RFO request to L2 cache",
+    .ucode  = 0xe200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_CODE_RD",
+    .udesc  = "Any code read request to L2 cache",
+    .ucode  = 0xe400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_DEMAND_REFERENCES",
+    .udesc  = "All demand requests to L2 cache ",
+    .ucode  = 0xe700,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_PF",
+    .udesc  = "Any L2 HW prefetch request to L2 cache",
+    .ucode  = 0xf800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "REFERENCES",
+    .udesc  = "All requests to L2 cache",
+    .ucode  = 0xff00,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t hsw_l2_trans[]={
+  { .uname = "DEMAND_DATA_RD",
+    .udesc  = "Demand Data Read requests that access L2 cache",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RFO",
+    .udesc  = "RFO requests that access L2 cache",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "CODE_RD",
+    .udesc  = "L2 cache accesses when fetching instructions",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_PF",
+    .udesc  = "L2 or L3 HW prefetches that access L2 cache, including rejects",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "L1D_WB",
+    .udesc  = "L1D writebacks that access L2 cache",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "L2_FILL",
+    .udesc  = "L2 fill requests that access L2 cache",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "L2_WB",
+    .udesc  = "L2 writebacks that access L2 cache",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_REQUESTS",
+    .udesc  = "Transactions accessing L2 pipe",
+    .ucode  = 0x8000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t hsw_ld_blocks[]={
+  { .uname = "STORE_FORWARD",
+    .udesc  = "Counts the number of loads blocked by overlapping with store buffer entries that cannot be forwarded",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NO_SR",
+    .udesc  = "number of times that split load operations are temporarily blocked because all resources for handling the split accesses are in use",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_ld_blocks_partial[]={
+  { .uname = "ADDRESS_ALIAS",
+    .udesc  = "False dependencies in MOB due to partial compare on address",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t hsw_load_hit_pre[]={
+  { .uname = "SW_PF",
+    .udesc  = "Non software-prefetch load dispatches that hit FB allocated for software prefetch",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "HW_PF",
+    .udesc  = "Non software-prefetch load dispatches that hit FB allocated for hardware prefetch",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_lock_cycles[]={
+  { .uname = "SPLIT_LOCK_UC_LOCK_DURATION",
+    .udesc  = "Cycles in which the L1D and L2 are locked, due to a UC lock or split lock",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "CACHE_LOCK_DURATION",
+    .udesc  = "cycles that the L1D is locked",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_longest_lat_cache[]={
+  { .uname = "MISS",
+    .udesc  = "Core-originated cacheable demand requests missed LLC - architectural event",
+    .ucode  = 0x4100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "REFERENCE",
+    .udesc  = "Core-originated cacheable demand requests that refer to LLC - architectural event",
+    .ucode  = 0x4f00,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_machine_clears[]={
+  { .uname = "MEMORY_ORDERING",
+    .udesc  = "Number of Memory Ordering Machine Clears detected",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SMC",
+    .udesc  = "Number of Self-modifying code (SMC) Machine Clears detected",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MASKMOV",
+    .udesc  = "This event counts the number of executed Intel AVX masked load operations that refer to an illegal address range with the mask bits set to 0",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_mem_load_uops_l3_hit_retired[]={
+  { .uname = "XSNP_MISS",
+    .udesc  = "Retired load uops which data sources were L3 hit and cross-core snoop missed in on-pkg core cache",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "XSNP_HIT",
+    .udesc  = "Retired load uops which data sources were L3 and cross-core snoop hits in on-pkg core cache",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "XSNP_HITM",
+    .udesc  = "Load had HitM Response from a core on same socket (shared L3). (Non PEBS",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "XSNP_NONE",
+    .udesc  = "Retired load uops which data sources were hits in L3 without snoops required",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+};
+
+static const intel_x86_umask_t hsw_mem_load_uops_l3_miss_retired[]={
+  { .uname = "LOCAL_DRAM",
+    .udesc  = "Retired load uops missing L3 cache but hitting local memory",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t hsw_mem_load_uops_retired[]={
+  { .uname = "L1_HIT",
+    .udesc  = "Retired load uops with L1 cache hits as data source",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "L2_HIT",
+    .udesc  = "Retired load uops with L2 cache hits as data source",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "L3_HIT",
+    .udesc  = "Retired load uops with L3 cache hits as data source",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "L1_MISS",
+    .udesc  = "Retired load uops which missed the L1D",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "L2_MISS",
+    .udesc  = "Retired load uops which missed the L2. Unknown data source excluded",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "L3_MISS",
+    .udesc  = "Retired load uops which missed the L3",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "HIT_LFB",
+    .udesc  = "Retired load uops which missed L1 but hit line fill buffer (LFB)",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+};
+
+static const intel_x86_umask_t hsw_mem_trans_retired[]={
+  { .uname  = "LOAD_LATENCY",
+    .udesc  = "Memory load instructions retired above programmed clocks, minimum threshold value is 3 (Precise Event and ldlat required)",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_LDLAT | INTEL_X86_DFL,
+  },
+  { .uname  = "LATENCY_ABOVE_THRESHOLD",
+    .udesc  = "Memory load instructions retired above programmed clocks, minimum threshold value is 3 (Precise Event and ldlat required)",
+    .ucode  = 0x100,
+    .uequiv = "LOAD_LATENCY",
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_LDLAT | INTEL_X86_NO_AUTOENCODE,
+  },
+};
+
+static const intel_x86_umask_t hsw_mem_uops_retired[]={
+  { .uname = "STLB_MISS_LOADS",
+    .udesc  = "Load uops with true STLB miss retired to architected path",
+    .ucode  = 0x1100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "STLB_MISS_STORES",
+    .udesc  = "Store uops with true STLB miss retired to architected path",
+    .ucode  = 0x1200,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "LOCK_LOADS",
+    .udesc  = "Load uops with locked access retired",
+    .ucode  = 0x2100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "LOCK_STORES",
+    .udesc  = "Store uops with locked access retired",
+    .ucode  = 0x2200,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "SPLIT_LOADS",
+    .udesc  = "Line-splitted load uops retired",
+    .ucode  = 0x4100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "SPLIT_STORES",
+    .udesc  = "Line-splitted store uops retired",
+    .ucode  = 0x4200,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "ALL_LOADS",
+    .udesc  = "All load uops retired",
+    .ucode  = 0x8100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "ALL_STORES",
+    .udesc  = "All store uops retired",
+    .ucode  = 0x8200,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+};
+
+static const intel_x86_umask_t hsw_misalign_mem_ref[]={
+  { .uname = "LOADS",
+    .udesc  = "Speculative cache-line split load uops dispatched to the L1D",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "STORES",
+    .udesc  = "Speculative cache-line split store-address uops dispatched to L1D",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_move_elimination[]={
+  { .uname = "INT_ELIMINATED",
+    .udesc  = "Number of integer Move Elimination candidate uops that were eliminated",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SIMD_ELIMINATED",
+    .udesc  = "Number of SIMD Move Elimination candidate uops that were eliminated",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "INT_NOT_ELIMINATED",
+    .udesc  = "Number of integer Move Elimination candidate uops that were not eliminated",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SIMD_NOT_ELIMINATED",
+    .udesc  = "Number of SIMD Move Elimination candidate uops that were not eliminated",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_offcore_requests[]={
+  { .uname  = "DEMAND_DATA_RD",
+    .udesc  = "Demand data read requests sent to uncore (use with HT off only)",
+    .ucode = 0x100,
+    .uflags= INTEL_X86_NCOMBO,
+  },
+  { .uname = "DEMAND_CODE_RD",
+    .udesc  = "Demand code read requests sent to uncore (use with HT off only)",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "DEMAND_RFO",
+    .udesc  = "Demand RFOs requests sent to uncore (use with HT off only)",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_DATA_RD",
+    .udesc  = "Data read requests sent to uncore (use with HT off only)",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_other_assists[]={
+  { .uname = "AVX_TO_SSE",
+    .udesc  = "Number of transitions from AVX-256 to legacy SSE when penalty applicable",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SSE_TO_AVX",
+    .udesc  = "Number of transitions from legacy SSE to AVX-256 when penalty applicable",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ANY_WB_ASSIST",
+    .udesc  = "Number of times any microcode assist is invoked by HW upon uop writeback",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_resource_stalls[]={
+  { .uname = "ANY",
+    .udesc  = "Cycles Allocation is stalled due to Resource Related reason",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "ALL",
+    .udesc  = "Cycles Allocation is stalled due to Resource Related reason",
+    .ucode  = 0x100,
+    .uequiv = "ANY",
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RS",
+    .udesc  = "Stall cycles caused by absence of eligible entries in Reservation Station (RS)",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SB",
+    .udesc  = "Cycles Allocator is stalled due to Store Buffer full (not including draining from synch)",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ROB",
+    .udesc  = "ROB full stall cycles",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_rob_misc_events[]={
+  { .uname = "LBR_INSERTS",
+    .udesc  = "Count each time an new Last Branch Record (LBR) is inserted",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t hsw_rs_events[]={
+  { .uname = "EMPTY_CYCLES",
+    .udesc  = "Cycles the Reservation Station (RS) is empty for this thread",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t hsw_tlb_flush[]={
+  { .uname = "DTLB_THREAD",
+    .udesc  = "Count number of DTLB flushes of thread-specific entries",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "STLB_ANY",
+    .udesc  = "Count number of any STLB flushes",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_uops_executed[]={
+  { .uname = "CORE",
+    .udesc  = "Number of uops executed from any thread",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t hsw_uops_executed_port[]={
+  { .uname = "PORT_0",
+    .udesc  = "Cycles which a Uop is executed on port 0",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "PORT_1",
+    .udesc  = "Cycles which a Uop is executed on port 1",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "PORT_2",
+    .udesc  = "Cycles which a Uop is executed on port 2",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "PORT_3",
+    .udesc  = "Cycles which a Uop is executed on port 3",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "PORT_4",
+    .udesc  = "Cycles which a Uop is executed on port 4",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "PORT_5",
+    .udesc  = "Cycles which a Uop is executed on port 5",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "PORT_6",
+    .udesc  = "Cycles which a Uop is executed on port 6",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "PORT_7",
+    .udesc  = "Cycles which a Uop is executed on port 7",
+    .ucode  = 0x8000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "PORT_0_CORE",
+    .udesc  = "tbd",
+    .ucode  = 0x100 | INTEL_X86_MOD_ANY, /* any=1 */
+    .uequiv = "PORT_0:t=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_T,
+  },
+  { .uname = "PORT_1_CORE",
+    .udesc  = "tbd",
+    .ucode  = 0x200 | INTEL_X86_MOD_ANY, /* any=1 */
+    .uequiv = "PORT_1:t=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_T,
+  },
+  { .uname = "PORT_2_CORE",
+    .udesc  = "tbd",
+    .ucode  = 0x400 | INTEL_X86_MOD_ANY, /* any=1 */
+    .uequiv = "PORT_2:t=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_T,
+  },
+  { .uname = "PORT_3_CORE",
+    .udesc  = "tbd",
+    .ucode  = 0x800 | INTEL_X86_MOD_ANY, /* any=1 */
+    .uequiv = "PORT_3:t=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_T,
+  },
+  { .uname = "PORT_4_CORE",
+    .udesc  = "tbd",
+    .ucode  = 0x1000 | INTEL_X86_MOD_ANY, /* any=1 */
+    .uequiv = "PORT_4:t=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_T,
+  },
+  { .uname = "PORT_5_CORE",
+    .udesc  = "tbd",
+    .ucode  = 0x2000 | INTEL_X86_MOD_ANY, /* any=1 */
+    .uequiv = "PORT_5:t=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_T,
+  },
+  { .uname = "PORT_6_CORE",
+    .udesc  = "tbd",
+    .ucode  = 0x4000 | INTEL_X86_MOD_ANY, /* any=1 */
+    .uequiv = "PORT_6:t=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_T,
+  },
+  { .uname = "PORT_7_CORE",
+    .udesc  = "tbd",
+    .ucode  = 0x8000 | INTEL_X86_MOD_ANY, /* any=1 */
+    .uequiv = "PORT_7:t=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_T,
+  },
+};
+
+static const intel_x86_umask_t hsw_uops_issued[]={
+  { .uname = "ANY",
+    .udesc  = "Number of Uops issued by the Resource Allocation Table (RAT) to the Reservation Station (RS)",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "ALL",
+    .udesc  = "Number of Uops issued by the Resource Allocation Table (RAT) to the Reservation Station (RS)",
+    .ucode  = 0x100,
+    .uequiv = "ANY",
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "FLAGS_MERGE",
+    .udesc  = "Number of flags-merge uops being allocated. Such uops adds delay",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SLOW_LEA",
+    .udesc  = "Number of slow LEA or similar uops allocated. Such uop has 3 sources regardless if result of LEA instruction or not",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SINGLE_MUL",
+    .udesc  = "Number of Multiply packed/scalar single precision uops allocated",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "STALL_CYCLES",
+    .udesc  = "Counts the number of cycles no uops issued by this thread",
+    .ucode  = 0x100 | INTEL_X86_MOD_INV | (1 << INTEL_X86_CMASK_BIT), /* inv=1 cnt=1 */
+    .uequiv = "ANY:c=1:i=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .ucntmsk = 0xf,
+    .modhw  = _INTEL_X86_ATTR_I | _INTEL_X86_ATTR_C,
+  },
+  { .uname = "CORE_STALL_CYCLES",
+    .udesc  = "Counts the number of cycles no uops issued on this core",
+    .ucode  = 0x100 | INTEL_X86_MOD_ANY | INTEL_X86_MOD_INV | (1 << INTEL_X86_CMASK_BIT), /* any=1 inv=1 cnt=1 */
+    .uequiv = "ANY:c=1:i=1:t=1",
+    .ucntmsk = 0xf,
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_T | _INTEL_X86_ATTR_I | _INTEL_X86_ATTR_C,
+  },
+};
+
+static const intel_x86_umask_t hsw_uops_retired[]={
+  { .uname = "ALL",
+    .udesc  = "All uops that actually retired",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_DFL,
+  },
+  { .uname = "ANY",
+    .udesc  = "All uops that actually retired",
+    .ucode  = 0x100,
+    .uequiv = "ALL",
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "RETIRE_SLOTS",
+    .udesc  = "number of retirement slots used non PEBS",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "STALL_CYCLES",
+    .udesc  = "Cycles no executable uops retired (Precise Event)",
+    .ucode  = 0x100 | INTEL_X86_MOD_INV | (1 << INTEL_X86_CMASK_BIT), /* inv=1 cnt=1 */
+    .uequiv = "ALL:i=1:c=1",
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+    .modhw  = _INTEL_X86_ATTR_I | _INTEL_X86_ATTR_C,
+  },
+  { .uname = "TOTAL_CYCLES",
+    .udesc  = "Number of cycles using always true condition applied to PEBS uops retired event",
+    .ucode  = 0x100 | INTEL_X86_MOD_INV | (10 << INTEL_X86_CMASK_BIT), /* inv=1 cnt=10 */
+    .uequiv = "ALL:i=1:c=10",
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+    .modhw  = _INTEL_X86_ATTR_I | _INTEL_X86_ATTR_C,
+  },
+  { .uname = "CORE_STALL_CYCLES",
+    .udesc  = "Cycles no executable uops retired on core (Precise Event)",
+    .ucode  = 0x100 | INTEL_X86_MOD_INV | (1 << INTEL_X86_CMASK_BIT), /* inv=1 cnt=1 */
+    .uequiv = "ALL:i=1:c=1:t=1",
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+    .modhw  = _INTEL_X86_ATTR_I | _INTEL_X86_ATTR_C,
+  },
+  { .uname = "STALL_OCCURRENCES",
+    .udesc  = "Number of transitions from stalled to unstalled execution (Precise Event)",
+    .ucode  = 0x100 | INTEL_X86_MOD_INV | INTEL_X86_MOD_EDGE| (1 << INTEL_X86_CMASK_BIT), /* inv=1 edge=1 cnt=1 */
+    .uequiv = "ALL:c=1:i=1:e=1",
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+    .modhw  = _INTEL_X86_ATTR_I | _INTEL_X86_ATTR_C | _INTEL_X86_ATTR_E,
+  },
+};
+
+static const intel_x86_umask_t hsw_offcore_response[]={
+   { .uname  = "DMND_DATA_RD",
+     .udesc  = "Request: number of demand and DCU prefetch data reads of full and partial cachelines as well as demand data page table entry cacheline reads. Does not count L2 data read prefetches or instruction fetches",
+     .ucode = 1ULL << (0 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "DMND_RFO",
+     .udesc  = "Request: number of demand and DCU prefetch reads for ownership (RFO) requests generated by a write to data cacheline. Does not count L2 RFO prefetches",
+     .ucode = 1ULL << (1 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "DMND_IFETCH",
+     .udesc  = "Request: number of demand and DCU prefetch instruction cacheline reads. Does not count L2 code read prefetches",
+     .ucode = 1ULL << (2 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "WB",
+     .udesc  = "Request: number of writebacks (modified to exclusive) transactions",
+     .ucode = 1ULL << (3 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PF_DATA_RD",
+     .udesc  = "Request: number of data cacheline reads generated by L2 prefetchers",
+     .ucode = 1ULL << (4 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PF_RFO",
+     .udesc  = "Request: number of RFO requests generated by L2 prefetchers",
+     .ucode = 1ULL << (5 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PF_IFETCH",
+     .udesc  = "Request: number of code reads generated by L2 prefetchers",
+     .ucode = 1ULL << (6 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PF_LLC_DATA_RD",
+     .udesc  = "Request: number of L3 prefetcher requests to L2 for loads",
+     .ucode = 1ULL << (7 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PF_LLC_RFO",
+     .udesc  = "Request: number of RFO requests generated by L2 prefetcher",
+     .ucode = 1ULL << (8 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PF_LLC_IFETCH",
+     .udesc  = "Request: number of L2 prefetcher requests to L3 for instruction fetches",
+     .ucode = 1ULL << (9 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "BUS_LOCKS",
+     .udesc  = "Request: number bus lock and split lock requests",
+     .ucode = 1ULL << (10 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "STRM_ST",
+     .udesc  = "Request: number of streaming store requests",
+     .ucode = 1ULL << (11 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "OTHER",
+     .udesc  = "Request: counts one of the following transaction types, including L3 invalidate, I/O, full or partial writes, WC or non-temporal stores, CLFLUSH, Fences, lock, unlock, split lock",
+     .ucode = 1ULL << (15+8),
+     .grpid = 0,
+   },
+   { .uname  = "ANY_IFETCH",
+     .udesc  = "Request: combination of PF_IFETCH | DMND_IFETCH | PF_LLC_IFETCH",
+     .uequiv = "PF_IFETCH:DMND_IFETCH:PF_LLC_IFETCH",
+     .ucode = 0x24100,
+     .grpid = 0,
+   },
+   { .uname  = "ANY_REQUEST",
+     .udesc  = "Request: combination of all request umasks",
+     .uequiv = "DMND_DATA_RD:DMND_RFO:DMND_IFETCH:WB:PF_DATA_RD:PF_RFO:PF_IFETCH:PF_LLC_DATA_RD:PF_LLC_RFO:PF_LLC_IFETCH:BUS_LOCKS:STRM_ST:OTHER",
+     .ucode = 0x8fff00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+     .grpid = 0,
+   },
+   { .uname  = "ANY_DATA",
+     .udesc  = "Request: combination of DMND_DATA | PF_DATA_RD | PF_LLC_DATA_RD",
+     .uequiv = "DMND_DATA_RD:PF_DATA_RD:PF_LLC_DATA_RD",
+     .ucode = 0x9100,
+     .grpid = 0,
+   },
+   { .uname  = "ANY_RFO",
+     .udesc  = "Request: combination of DMND_RFO | PF_RFO | PF_LLC_RFO",
+     .uequiv = "DMND_RFO:PF_RFO:PF_LLC_RFO",
+     .ucode = 0x10300,
+     .grpid = 0,
+   },
+
+   { .uname  = "ANY_RESPONSE",
+     .udesc  = "Response: count any response type",
+     .ucode = 1ULL << (16+8),
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL | INTEL_X86_EXCL_GRP_GT,
+     .grpid = 1,
+   },
+   { .uname  = "NO_SUPP",
+     .udesc  = "Supplier: counts number of times supplier information is not available",
+     .ucode = 1ULL << (17+8),
+     .grpid = 1,
+   },
+   { .uname  = "LLC_HITM",
+     .udesc  = "Supplier: counts L3 hits in M-state (initial lookup)",
+     .ucode = 1ULL << (18+8),
+     .grpid = 1,
+   },
+   { .uname  = "LLC_HITE",
+     .udesc  = "Supplier: counts L3 hits in E-state",
+     .ucode = 1ULL << (19+8),
+     .grpid = 1,
+   },
+   { .uname  = "LLC_HITS",
+     .udesc  = "Supplier: counts L3 hits in S-state",
+     .ucode = 1ULL << (20+8),
+     .grpid = 1,
+   },
+   { .uname  = "LLC_HITF",
+     .udesc  = "Supplier: counts L3 hits in F-state",
+     .ucode = 1ULL << (21+8),
+     .grpid = 1,
+   },
+   { .uname  = "LLC_MISS_LOCAL",
+     .udesc  = "Supplier: counts L3 misses to local DRAM",
+     .ucode = 1ULL << (22+8),
+     .grpid = 1,
+   },
+   { .uname  = "LLC_HITMESF",
+     .udesc  = "Supplier: counts L3 hits in any state (M, E, S, F)",
+     .ucode  = 0xfULL << (18+8),
+     .uequiv = "LLC_HITM:LLC_HITE:LLC_HITS:LLC_HITF",
+     .grpid  = 1,
+   },
+   { .uname  = "SNP_NONE",
+     .udesc  = "Snoop: counts number of times no snoop-related information is available",
+     .ucode = 1ULL << (31+8),
+     .grpid = 2,
+   },
+   { .uname  = "SNP_NOT_NEEDED",
+     .udesc  = "Snoop: counts the number of times no snoop was needed to satisfy the request",
+     .ucode = 1ULL << (32+8),
+     .grpid = 2,
+   },
+   { .uname  = "SNP_MISS",
+     .udesc  = "Snoop: counts number of times a snoop was needed and it missed all snooped caches",
+     .ucode = 1ULL << (33+8),
+     .grpid = 2,
+   },
+   { .uname  = "SNP_NO_FWD",
+     .udesc  = "Snoop: counts number of times a snoop was needed and it hit in at leas one snooped cache",
+     .ucode = 1ULL << (34+8),
+     .grpid = 2,
+   },
+   { .uname  = "SNP_FWD",
+     .udesc  = "Snoop: counts number of times a snoop was needed and data was forwarded from a remote socket",
+     .ucode = 1ULL << (35+8),
+     .grpid = 2,
+   },
+   { .uname  = "HITM",
+     .udesc  = "Snoop: counts number of times a snoop was needed and it hitM-ed in local or remote cache",
+     .ucode = 1ULL << (36+8),
+     .grpid = 2,
+   },
+   { .uname  = "NON_DRAM",
+     .udesc  = "Snoop:  counts number of times target was a non-DRAM system address. This includes MMIO transactions",
+     .ucode = 1ULL << (37+8),
+     .grpid = 2,
+   },
+   { .uname  = "SNP_ANY",
+     .udesc  = "Snoop: any snoop reason",
+     .ucode = 0x7fULL << (31+8),
+     .uequiv = "SNP_NONE:SNP_NOT_NEEDED:SNP_MISS:SNP_NO_FWD:SNP_FWD:HITM:NON_DRAM",
+     .uflags= INTEL_X86_DFL,
+     .grpid = 2,
+   },
+};
+
+static const intel_x86_umask_t hsw_hle_retired[]={
+  { .uname = "START",
+    .udesc  = "Number of times an HLE execution started",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "COMMIT",
+    .udesc  = "Number of times an HLE execution successfully committed",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED",
+    .udesc  = "Number of times an HLE execution aborted due to any reasons (multiple categories may count as one) (Precise Event)",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "ABORTED_MISC1",
+    .udesc  = "Number of times an HLE execution aborted due to various memory events",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED_MISC2",
+    .udesc  = "Number of times an HLE execution aborted due to uncommon conditions",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED_MISC3",
+    .udesc  = "Number of times an HLE execution aborted due to HLE-unfriendly instructions",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED_MISC4",
+    .udesc  = "Number of times an HLE execution aborted due to incomptaible memory type",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED_MISC5",
+    .udesc  = "Number of times an HLE execution aborted due to none of the other 4 reasons (e.g., interrupt)",
+    .ucode  = 0x8000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_rtm_retired[]={
+  { .uname = "START",
+    .udesc  = "Number of times an RTM execution started",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "COMMIT",
+    .udesc  = "Number of times an RTM execution successfully committed",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED",
+    .udesc  = "Number of times an RTM execution aborted due to any reasons (multiple categories may count as one) (Precise Event)",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "ABORTED_MISC1",
+    .udesc  = "Number of times an RTM execution aborted due to various memory events",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED_MISC2",
+    .udesc  = "Number of times an RTM execution aborted due to uncommon conditions",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED_MISC3",
+    .udesc  = "Number of times an RTM execution aborted due to RTM-unfriendly instructions",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED_MISC4",
+    .udesc  = "Number of times an RTM execution aborted due to incomptaible memory type",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED_MISC5",
+    .udesc  = "Number of times an RTM execution aborted due to none of the other 4 reasons (e.g., interrupt)",
+    .ucode  = 0x8000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_tx_mem[]={
+  { .uname = "ABORT_CONFLICT",
+    .udesc  = "Number of times a transactional abort was signaled due to data conflict on a transactionally accessed address",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORT_CAPACITY",
+    .udesc  = "Number of times a transactional abort was signaled due to data capacity limitation",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORT_HLE_STORE_TO_ELIDED_LOCK",
+    .udesc  = "Number of times a HLE transactional execution aborted due to a non xrelease prefixed instruction writing to an elided lock in the elision buffer",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORT_HLE_ELISION_BUFFER_NOT_EMPTY",
+    .udesc  = "Number of times a HLE transactional execution aborted due to NoAllocatedElisionBuffer being non-zero",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORT_HLE_ELISION_BUFFER_MISMATCH",
+    .udesc  = "Number of times a HLE transaction execution aborted due to xrelease lock not satisfying the address and value requirements in the elision buffer",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORT_HLE_ELISION_BUFFER_UNSUPPORTED_ALIGNMENT",
+    .udesc  = "Number of times a HLE transaction execution aborted due to an unsupported read alignment from the elision buffer",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORT_HLE_ELISION_BUFFER_FULL",
+    .udesc  = "Number of times a HLE clock could not be elided due to ElisionBufferAvailable being zero",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_tx_exec[]={
+  { .uname = "MISC1",
+    .udesc  = "Number of times a class of instructions that may cause a transactional abort was executed. Since this is the count of execution, it may not always cause a transactional abort",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MISC2",
+    .udesc  = "Number of times a class of instructions that may cause a transactional abort was executed inside a transactional region",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MISC3",
+    .udesc  = "Number of times an instruction execution caused the supported nest count to be exceeded",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MISC4",
+    .udesc  = "Number of times an instruction with HLE xacquire prefix was executed inside a RTM transactional region",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t hsw_offcore_requests_outstanding[]={
+   { .uname  = "ALL_DATA_RD_CYCLES",
+     .udesc  = "Cycles with cacheable data read transactions in the superQ (use with HT off only)",
+     .uequiv = "ALL_DATA_RD:c=1",
+     .ucode = 0x800 | (0x1 << INTEL_X86_CMASK_BIT),
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "DEMAND_CODE_RD_CYCLES",
+     .udesc  = "Cycles with demand code reads transactions in the superQ (use with HT off only)",
+     .uequiv = "DEMAND_CODE_RD:c=1",
+     .ucode = 0x200 | (0x1 << INTEL_X86_CMASK_BIT),
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "DEMAND_DATA_RD_CYCLES",
+     .udesc  = "Cycles with demand data read transactions in the superQ (use with HT off only)",
+     .uequiv = "DEMAND_DATA_RD:c=1",
+     .ucode = 0x100 | (0x1 << INTEL_X86_CMASK_BIT),
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "ALL_DATA_RD",
+     .udesc  = "Cacheable data read transactions in the superQ every cycle (use with HT off only)",
+     .ucode = 0x800,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "DEMAND_CODE_RD",
+     .udesc  = "Code read transactions in the superQ every cycle (use with HT off only)",
+     .ucode = 0x200,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "DEMAND_DATA_RD",
+     .udesc  = "Demand data read transactions in the superQ every cycle (use with HT off only)",
+     .ucode = 0x100,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "DEMAND_RFO",
+     .udesc  = "Outstanding RFO (store) transactions in the superQ every cycle (use with HT off only)",
+     .ucode = 0x400,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "DEMAND_RFO_CYCLES",
+     .udesc  = "Cycles with outstanding RFO (store) transactions in the superQ (use with HT off only)",
+     .uequiv = "DEMAND_RFO:c=1",
+     .ucode = 0x400 | (0x1 << INTEL_X86_CMASK_BIT),
+     .uflags= INTEL_X86_NCOMBO,
+   },
+};
+
+static const intel_x86_umask_t hsw_ild_stall[]={
+   { .uname  = "LCP",
+     .udesc  = "Stall caused by changing prefix length of the instruction",
+     .ucode = 0x100,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "IQ_FULL",
+     .udesc  = "Stall cycles due to IQ full",
+     .ucode = 0x400,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+};
+
+static const intel_x86_umask_t hsw_page_walker_loads[]={
+   { .uname  = "DTLB_L1",
+     .udesc  = "Number of DTLB page walker loads that hit in the L1D and line fill buffer",
+     .ucode = 0x1100,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "ITLB_L1",
+     .udesc  = "Number of ITLB page walker loads that hit in the L1I and line fill buffer",
+     .ucode = 0x2100,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "DTLB_L2",
+     .udesc  = "Number of DTLB page walker loads that hit in the L2",
+     .ucode = 0x1200,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "ITLB_L2",
+     .udesc  = "Number of ITLB page walker loads that hit in the L2",
+     .ucode = 0x2200,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "DTLB_L3",
+     .udesc  = "Number of DTLB page walker loads that hit in the L3",
+     .ucode = 0x1400,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "ITLB_L3",
+     .udesc  = "Number of ITLB page walker loads that hit in the L3",
+     .ucode = 0x2400,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "DTLB_MEMORY",
+     .udesc  = "Number of DTLB page walker loads that hit memory",
+     .ucode = 0x1800,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "ITLB_MEMORY",
+     .udesc  = "Number of ITLB page walker loads that hit memory",
+     .ucode = 0x2800,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+};
+
+static const intel_x86_umask_t hsw_lsd[]={
+   { .uname  = "UOPS",
+     .udesc  = "Number of uops delivered by the Loop Stream Detector (LSD)",
+     .ucode = 0x100,
+     .uflags= INTEL_X86_DFL,
+   },
+};
+
+static const intel_x86_entry_t intel_hsw_pe[]={
+  { .name   = "UNHALTED_CORE_CYCLES",
+    .desc   = "Count core clock cycles whenever the clock signal on the specific core is running (not halted)",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0x20000000full,
+    .code = 0x3c,
+  },
+  { .name   = "UNHALTED_REFERENCE_CYCLES",
+    .desc   = "Unhalted reference cycles",
+    .modmsk = INTEL_FIXED3_ATTRS,
+    .cntmsk = 0x400000000ull,
+    .code = 0x0300, /* pseudo encoding */
+    .flags = INTEL_X86_FIXED,
+  },
+  { .name   = "INSTRUCTION_RETIRED",
+    .desc   = "Number of instructions at retirement",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0x10000000full,
+    .code = 0xc0,
+  },
+  { .name   = "INSTRUCTIONS_RETIRED",
+    .desc   = "This is an alias for INSTRUCTION_RETIRED",
+    .modmsk = INTEL_V4_ATTRS,
+    .equiv = "INSTRUCTION_RETIRED",
+    .cntmsk = 0x10000000full,
+    .code = 0xc0,
+  },
+  { .name   = "BRANCH_INSTRUCTIONS_RETIRED",
+    .desc   = "Count branch instructions at retirement. Specifically, this event counts the retirement of the last micro-op of a branch instruction",
+    .modmsk = INTEL_V4_ATTRS,
+    .equiv = "BR_INST_RETIRED:ALL_BRANCHES",
+    .cntmsk = 0xff,
+    .code = 0xc4,
+  },
+  { .name   = "MISPREDICTED_BRANCH_RETIRED",
+    .desc   = "Count mispredicted branch instructions at retirement. Specifically, this event counts at retirement of the last micro-op of a branch instruction in the architectural path of the execution and experienced misprediction in the branch prediction hardware",
+    .modmsk = INTEL_V4_ATTRS,
+    .equiv = "BR_MISP_RETIRED:ALL_BRANCHES",
+    .cntmsk = 0xff,
+    .code = 0xc5,
+  },
+  { .name = "BACLEARS",
+    .desc   = "Branch resteered",
+    .code = 0xe6,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_baclears),
+    .umasks  = hsw_baclears
+  },
+  { .name = "BR_INST_EXEC",
+    .desc   = "Branch instructions executed",
+    .code = 0x88,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_br_inst_exec),
+    .umasks  = hsw_br_inst_exec
+  },
+  { .name = "BR_INST_RETIRED",
+    .desc   = "Branch instructions retired (Precise Event)",
+    .code = 0xc4,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_br_inst_retired),
+    .umasks  = hsw_br_inst_retired
+  },
+  { .name = "BR_MISP_EXEC",
+    .desc   = "Mispredicted branches executed",
+    .code = 0x89,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_br_misp_exec),
+    .umasks  = hsw_br_misp_exec
+  },
+  { .name = "BR_MISP_RETIRED",
+    .desc   = "Mispredicted retired branches (Precise Event)",
+    .code = 0xc5,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_br_misp_retired),
+    .umasks  = hsw_br_misp_retired
+  },
+  { .name = "CPL_CYCLES",
+    .desc   = "Unhalted core cycles at a specific ring level",
+    .code = 0x5c,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_cpl_cycles),
+    .umasks  = hsw_cpl_cycles
+  },
+  { .name = "CPU_CLK_THREAD_UNHALTED",
+    .desc   = "Count core clock cycles whenever the clock signal on the specific core is running (not halted)",
+    .code = 0x3c,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_cpu_clk_thread_unhalted),
+    .umasks  = hsw_cpu_clk_thread_unhalted
+  },
+  { .name = "CPU_CLK_UNHALTED",
+    .desc   = "Count core clock cycles whenever the clock signal on the specific core is running (not halted)",
+    .code = 0x3c,
+    .cntmsk = 0xff,
+    .modmsk = INTEL_V4_ATTRS,
+    .equiv = "CPU_CLK_THREAD_UNHALTED",
+  },
+  { .name = "CYCLE_ACTIVITY",
+    .desc   = "Stalled cycles",
+    .code = 0xa3,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = INTEL_V3_ATTRS & ~_INTEL_X86_ATTR_C,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_cycle_activity),
+    .umasks  = hsw_cycle_activity
+  },
+  { .name = "DTLB_LOAD_MISSES",
+    .desc   = "Data TLB load misses",
+    .code = 0x8,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_dtlb_load_misses),
+    .umasks  = hsw_dtlb_load_misses
+  },
+  { .name = "DTLB_STORE_MISSES",
+    .desc = "Data TLB store misses",
+    .code = 0x49,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_dtlb_load_misses),
+    .umasks  = hsw_dtlb_load_misses /* shared */
+  },
+  { .name = "FP_ASSIST",
+    .desc = "X87 floating-point assists",
+    .code = 0xca,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_fp_assist),
+    .umasks  = hsw_fp_assist
+  },
+  { .name = "HLE_RETIRED",
+    .desc = "HLE execution (Precise Event)",
+    .code = 0xc8,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_hle_retired),
+    .umasks  = hsw_hle_retired
+  },
+  { .name = "ICACHE",
+    .desc = "Instruction Cache",
+    .code = 0x80,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_icache),
+    .umasks  = hsw_icache
+  },
+  { .name = "IDQ",
+    .desc   = "IDQ operations",
+    .code = 0x79,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_idq),
+    .umasks  = hsw_idq
+  },
+  { .name = "IDQ_UOPS_NOT_DELIVERED",
+    .desc   = "Uops not delivered",
+    .code = 0x9c,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_idq_uops_not_delivered),
+    .umasks  = hsw_idq_uops_not_delivered
+  },
+  { .name = "INST_RETIRED",
+    .desc = "Number of instructions retired (Precise Event)",
+    .code = 0xc0,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_inst_retired),
+    .umasks  = hsw_inst_retired
+  },
+  { .name = "INT_MISC",
+    .desc = "Miscelleanous interruptions",
+    .code = 0xd,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_int_misc),
+    .umasks  = hsw_int_misc
+  },
+  { .name = "ITLB",
+    .desc   = "Instruction TLB",
+    .code = 0xae,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_itlb),
+    .umasks  = hsw_itlb
+  },
+  { .name = "ITLB_MISSES",
+    .desc = "Instruction TLB misses",
+    .code = 0x85,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_itlb_misses),
+    .umasks  = hsw_itlb_misses
+  },
+  { .name = "L1D",
+    .desc   = "L1D cache",
+    .code = 0x51,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_l1d),
+    .umasks  = hsw_l1d
+  },
+  { .name = "L1D_PEND_MISS",
+    .desc   = "L1D pending misses",
+    .code = 0x48,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_l1d_pend_miss),
+    .umasks  = hsw_l1d_pend_miss
+  },
+  { .name = "L2_DEMAND_RQSTS",
+    .desc = "Demand Data Read requests to L2",
+    .code = 0x27,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_l2_demand_rqsts),
+    .umasks  = hsw_l2_demand_rqsts
+  },
+  { .name = "L2_LINES_IN",
+    .desc   = "L2 lines allocated",
+    .code = 0xf1,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_l2_lines_in),
+    .umasks  = hsw_l2_lines_in
+  },
+  { .name = "L2_LINES_OUT",
+    .desc   = "L2 lines evicted",
+    .code = 0xf2,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_l2_lines_out),
+    .umasks  = hsw_l2_lines_out
+  },
+  { .name = "L2_RQSTS",
+    .desc   = "L2 requests",
+    .code = 0x24,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_l2_rqsts),
+    .umasks  = hsw_l2_rqsts
+  },
+  { .name = "L2_TRANS",
+    .desc   = "L2 transactions",
+    .code = 0xf0,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_l2_trans),
+    .umasks  = hsw_l2_trans
+  },
+  { .name = "LD_BLOCKS",
+    .desc   = "Blocking loads",
+    .code = 0x3,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_ld_blocks),
+    .umasks  = hsw_ld_blocks
+  },
+  { .name = "LD_BLOCKS_PARTIAL",
+    .desc   = "Partial load blocks",
+    .code = 0x7,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_ld_blocks_partial),
+    .umasks  = hsw_ld_blocks_partial
+  },
+  { .name = "LOAD_HIT_PRE",
+    .desc   = "Load dispatches",
+    .code = 0x4c,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_load_hit_pre),
+    .umasks  = hsw_load_hit_pre
+  },
+  { .name = "LOCK_CYCLES",
+    .desc   = "Locked cycles in L1D and L2",
+    .code = 0x63,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_lock_cycles),
+    .umasks  = hsw_lock_cycles
+  },
+  { .name = "LONGEST_LAT_CACHE",
+    .desc   = "L3 cache",
+    .code = 0x2e,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_longest_lat_cache),
+    .umasks  = hsw_longest_lat_cache
+  },
+  { .name = "MACHINE_CLEARS",
+    .desc   = "Machine clear asserted",
+    .code = 0xc3,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_machine_clears),
+    .umasks  = hsw_machine_clears
+  },
+  { .name = "MEM_LOAD_UOPS_L3_HIT_RETIRED",
+  .desc   = "L3 hit load uops retired (Precise Event)",
+    .code = 0xd2,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_mem_load_uops_l3_hit_retired),
+    .umasks  = hsw_mem_load_uops_l3_hit_retired
+  },
+  { .name = "MEM_LOAD_UOPS_L3_MISS_RETIRED",
+    .desc   = "Load uops retired that missed the L3 (Precise Event)",
+    .code = 0xd3,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_mem_load_uops_l3_miss_retired),
+    .umasks  = hsw_mem_load_uops_l3_miss_retired
+  },
+  { .name = "MEM_LOAD_UOPS_RETIRED",
+    .desc = "Retired load uops (Precise Event)",
+    .code = 0xd1,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_mem_load_uops_retired),
+    .umasks  = hsw_mem_load_uops_retired
+  },
+  { .name = "MEM_TRANS_RETIRED",
+    .desc   = "Memory transactions retired (Precise Event)",
+    .code = 0xcd,
+    .cntmsk = 0x8,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS | _INTEL_X86_ATTR_LDLAT,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_mem_trans_retired),
+    .umasks  = hsw_mem_trans_retired
+  },
+  { .name = "MEM_UOPS_RETIRED",
+    .desc = "Memory uops retired (Precise Event)",
+    .code = 0xd0,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_mem_uops_retired),
+    .umasks  = hsw_mem_uops_retired
+  },
+  { .name = "MISALIGN_MEM_REF",
+    .desc = "Misaligned memory references",
+    .code = 0x5,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_misalign_mem_ref),
+    .umasks  = hsw_misalign_mem_ref
+  },
+  { .name = "MOVE_ELIMINATION",
+    .desc = "Move Elimination",
+    .code = 0x58,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_move_elimination),
+    .umasks  = hsw_move_elimination
+  },
+  { .name = "OFFCORE_REQUESTS",
+    .desc = "Demand Data Read requests sent to uncore",
+    .code = 0xb0,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_offcore_requests),
+    .umasks  = hsw_offcore_requests
+  },
+  { .name = "OTHER_ASSISTS",
+    .desc = "Software assist",
+    .code = 0xc1,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_other_assists),
+    .umasks  = hsw_other_assists
+  },
+  { .name = "RESOURCE_STALLS",
+    .desc = "Cycles Allocation is stalled due to Resource Related reason",
+    .code = 0xa2,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_resource_stalls),
+    .umasks  = hsw_resource_stalls
+  },
+  { .name = "ROB_MISC_EVENTS",
+    .desc = "ROB miscellaneous events",
+    .code = 0xcc,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_rob_misc_events),
+    .umasks  = hsw_rob_misc_events
+  },
+  { .name = "RS_EVENTS",
+    .desc = "Reservation Station",
+    .code = 0x5e,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_rs_events),
+    .umasks  = hsw_rs_events
+  },
+  { .name = "RTM_RETIRED",
+    .desc = "Restricted Transaction Memory execution (Precise Event)",
+    .code = 0xc9,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_rtm_retired),
+    .umasks  = hsw_rtm_retired
+  },
+  { .name = "TLB_FLUSH",
+    .desc   = "TLB flushes",
+    .code = 0xbd,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_tlb_flush),
+    .umasks  = hsw_tlb_flush
+  },
+  { .name = "UOPS_EXECUTED",
+    .desc   = "Uops executed",
+    .code = 0xb1,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_uops_executed),
+    .umasks  = hsw_uops_executed
+  },
+  { .name = "LSD",
+    .desc   = "Loop stream detector",
+    .code = 0xa0,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_lsd),
+    .umasks  = hsw_lsd,
+  },
+
+  { .name = "UOPS_EXECUTED_PORT",
+    .desc   = "Uops dispatch to specific ports",
+    .code = 0xa1,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_uops_executed_port),
+    .umasks  = hsw_uops_executed_port
+  },
+  { .name = "UOPS_ISSUED",
+    .desc   = "Uops issued",
+    .code = 0xe,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_uops_issued),
+    .umasks  = hsw_uops_issued
+  },
+  { .name = "UOPS_RETIRED",
+    .desc = "Uops retired (Precise Event)",
+    .code = 0xc2,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_uops_retired),
+    .umasks  = hsw_uops_retired
+  },
+  { .name = "TX_MEM",
+    .desc = "Transactional memory aborts",
+    .code = 0x54,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_tx_mem),
+    .umasks  = hsw_tx_mem,
+  },
+  { .name = "TX_EXEC",
+    .desc = "Transactional execution",
+    .code = 0x5d,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_tx_exec),
+    .umasks  = hsw_tx_exec
+  },
+  { .name   = "OFFCORE_REQUESTS_OUTSTANDING",
+    .desc   = "Outstanding offcore requests",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0xff,
+    .code = 0x60,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_offcore_requests_outstanding),
+    .ngrp = 1,
+    .umasks = hsw_offcore_requests_outstanding,
+  },
+  { .name   = "ILD_STALL",
+    .desc   = "Instruction Length Decoder stalls",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0xff,
+    .code = 0x87,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_ild_stall),
+    .ngrp = 1,
+    .umasks = hsw_ild_stall,
+  },
+  { .name   = "PAGE_WALKER_LOADS",
+    .desc   = "Page walker loads",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0xff,
+    .code = 0xbc,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_page_walker_loads),
+    .ngrp = 1,
+    .umasks = hsw_page_walker_loads,
+  },
+  { .name   = "OFFCORE_RESPONSE_0",
+    .desc   = "Offcore response event (must provide at least one request type and either any_response or any combination of supplier + snoop)",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0xf,
+    .code = 0x1b7,
+    .flags= INTEL_X86_NHM_OFFCORE,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_offcore_response),
+    .ngrp = 3,
+    .umasks = hsw_offcore_response,
+  },
+  { .name   = "OFFCORE_RESPONSE_1",
+    .desc   = "Offcore response event (must provide at least one request type and either any_response or any combination of supplier + snoop)",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0xf,
+    .code = 0x1bb,
+    .flags= INTEL_X86_NHM_OFFCORE,
+    .numasks =  LIBPFM_ARRAY_SIZE(hsw_offcore_response),
+    .ngrp = 3,
+    .umasks = hsw_offcore_response, /* identical to actual umasks list for this event */
+  },
+};
diff --git a/src/libpfm4/lib/events/intel_ivb_events.h b/src/libpfm4/lib/events/intel_ivb_events.h
index 194772d..e473756 100644
--- a/src/libpfm4/lib/events/intel_ivb_events.h
+++ b/src/libpfm4/lib/events/intel_ivb_events.h
@@ -1003,7 +1003,7 @@ static const intel_x86_umask_t ivb_mem_trans_retired[]={
    { .uname  = "LATENCY_ABOVE_THRESHOLD",
      .udesc  = "Memory load instructions retired above programmed clocks, minimum threshold value is 3 (Precise Event and ldlat required)",
      .ucode = 0x100,
-     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_LDLAT | INTEL_X86_NO_AUTOENCODE,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_LDLAT,
    },
    { .uname  = "PRECISE_STORE",
      .udesc  = "Capture where stores occur, must use with PEBS (Precise Event required)",
diff --git a/src/libpfm4/lib/events/intel_nhm_events.h b/src/libpfm4/lib/events/intel_nhm_events.h
index 11a1adf..e47068f 100644
--- a/src/libpfm4/lib/events/intel_nhm_events.h
+++ b/src/libpfm4/lib/events/intel_nhm_events.h
@@ -1079,7 +1079,7 @@ static const intel_x86_umask_t nhm_mem_inst_retired[]={
    { .uname  = "LATENCY_ABOVE_THRESHOLD",
      .udesc  = "Memory instructions retired above programmed clocks, minimum threshold value is 3, (Precise Event and ldlat required)",
      .ucode = 0x1000,
-     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_LDLAT | INTEL_X86_NO_AUTOENCODE,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_LDLAT,
    },
    { .uname  = "LOADS",
      .udesc  = "Instructions retired which contains a load (Precise Event)",
diff --git a/src/libpfm4/lib/events/intel_snb_events.h b/src/libpfm4/lib/events/intel_snb_events.h
index ee97604..68e8d2d 100644
--- a/src/libpfm4/lib/events/intel_snb_events.h
+++ b/src/libpfm4/lib/events/intel_snb_events.h
@@ -1037,13 +1037,18 @@ static const intel_x86_umask_t snb_mem_load_uops_retired[]={
      .ucode = 0x400,
      .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
    },
+   { .uname  = "L3_MISS",
+     .udesc  = "Retired load uops which data sources were data missed LLC (excluding unknown data source)",
+     .ucode = 0x2000,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
 };
 
 static const intel_x86_umask_t snb_mem_trans_retired[]={
    { .uname  = "LATENCY_ABOVE_THRESHOLD",
      .udesc  = "Memory load instructions retired above programmed clocks, minimum threshold value is 3 (Precise Event and ldlat required)",
      .ucode = 0x100,
-     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_LDLAT | INTEL_X86_NO_AUTOENCODE,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_LDLAT,
    },
    { .uname  = "PRECISE_STORE",
      .udesc  = "Capture where stores occur, must use with PEBS (Precise Event required)",
diff --git a/src/libpfm4/lib/events/intel_snbep_events.h b/src/libpfm4/lib/events/intel_snbep_events.h
index 616c903..0df2b5c 100644
--- a/src/libpfm4/lib/events/intel_snbep_events.h
+++ b/src/libpfm4/lib/events/intel_snbep_events.h
@@ -1050,6 +1050,11 @@ static const intel_x86_umask_t snbep_mem_load_uops_retired[]={
      .ucode = 0x400,
      .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
    },
+   { .uname  = "L3_MISS",
+     .udesc  = "Retired load uops which data sources were data missed LLC (excluding unknown data source)",
+     .ucode = 0x2000,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
 };
 
 static const intel_x86_umask_t snbep_mem_trans_retired[]={
diff --git a/src/libpfm4/lib/events/intel_wsm_events.h b/src/libpfm4/lib/events/intel_wsm_events.h
index eb12258..07dffb0 100644
--- a/src/libpfm4/lib/events/intel_wsm_events.h
+++ b/src/libpfm4/lib/events/intel_wsm_events.h
@@ -536,7 +536,7 @@ static const intel_x86_umask_t wsm_mem_inst_retired[]={
    { .uname  = "LATENCY_ABOVE_THRESHOLD",
      .udesc  = "Memory instructions retired above programmed clocks, minimum threshold value is 3, (Precise Event and ldlat required)",
      .ucode = 0x1000,
-     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_LDLAT | INTEL_X86_NO_AUTOENCODE,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_LDLAT,
    },
    { .uname  = "LOADS",
      .udesc  = "Instructions retired which contains a load (Precise Event)",
diff --git a/src/libpfm4/lib/pfmlib_common.c b/src/libpfm4/lib/pfmlib_common.c
index 4522fab..d4aa142 100644
--- a/src/libpfm4/lib/pfmlib_common.c
+++ b/src/libpfm4/lib/pfmlib_common.c
@@ -92,6 +92,7 @@ static pfmlib_pmu_t *pfmlib_pmus[]=
 	&intel_snb_ep_support,
 	&intel_ivb_support,
 	&intel_ivb_ep_support,
+	&intel_hsw_support,
 	&intel_snbep_unc_cb0_support,
 	&intel_snbep_unc_cb1_support,
 	&intel_snbep_unc_cb2_support,
diff --git a/src/libpfm4/lib/pfmlib_intel_hsw.c b/src/libpfm4/lib/pfmlib_intel_hsw.c
new file mode 100644
index 0000000..7d01ff1
--- /dev/null
+++ b/src/libpfm4/lib/pfmlib_intel_hsw.c
@@ -0,0 +1,84 @@
+/*
+ * pfmlib_intel_hsw.c : Intel Haswell core PMU
+ *
+ * Copyright (c) 2012 Google, Inc
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+/* private headers */
+#include "pfmlib_priv.h"
+#include "pfmlib_intel_x86_priv.h"
+#include "events/intel_hsw_events.h"
+
+static int
+pfm_hsw_detect(void *this)
+{
+	int ret;
+
+	ret = pfm_intel_x86_detect();
+	if (ret != PFM_SUCCESS)
+		return ret;
+
+	if (pfm_intel_x86_cfg.family != 6)
+		return PFM_ERR_NOTSUPP;
+
+	switch (pfm_intel_x86_cfg.model) {
+		case 60: /* Haswell */
+			break;
+		default:
+			return PFM_ERR_NOTSUPP;
+	}
+	return PFM_SUCCESS;
+}
+
+static int
+pfm_hsw_init(void *this)
+{
+	pfm_intel_x86_cfg.arch_version = 4;
+	return PFM_SUCCESS;
+}
+
+pfmlib_pmu_t intel_hsw_support={
+	.desc			= "Intel Haswell",
+	.name			= "hsw",
+	.pmu			= PFM_PMU_INTEL_HSW,
+	.pme_count		= LIBPFM_ARRAY_SIZE(intel_hsw_pe),
+	.type			= PFM_PMU_TYPE_CORE,
+	.supported_plm		= INTEL_X86_PLM,
+	.num_cntrs		= 8, /* consider with HT off by default */
+	.num_fixed_cntrs	= 3,
+	.max_encoding		= 2, /* offcore_response */
+	.pe			= intel_hsw_pe,
+	.atdesc			= intel_x86_mods,
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK
+				| INTEL_X86_PMU_FL_ECMASK,
+	.pmu_detect		= pfm_hsw_detect,
+	.pmu_init		= pfm_hsw_init,
+	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding,
+	 PFMLIB_ENCODE_PERF(pfm_intel_x86_get_perf_encoding),
+	.get_event_first	= pfm_intel_x86_get_event_first,
+	.get_event_next		= pfm_intel_x86_get_event_next,
+	.event_is_valid		= pfm_intel_x86_event_is_valid,
+	.validate_table		= pfm_intel_x86_validate_table,
+	.get_event_info		= pfm_intel_x86_get_event_info,
+	.get_event_attr_info	= pfm_intel_x86_get_event_attr_info,
+	 PFMLIB_VALID_PERF_PATTRS(pfm_intel_x86_perf_validate_pattrs),
+	.get_event_nattrs	= pfm_intel_x86_get_event_nattrs,
+	.can_auto_encode	= pfm_intel_x86_can_auto_encode,
+};
diff --git a/src/libpfm4/lib/pfmlib_intel_x86.c b/src/libpfm4/lib/pfmlib_intel_x86.c
index d50d7d0..f069317 100644
--- a/src/libpfm4/lib/pfmlib_intel_x86.c
+++ b/src/libpfm4/lib/pfmlib_intel_x86.c
@@ -564,9 +564,12 @@ pfm_intel_x86_encode_gen(void *this, pfmlib_event_desc_t *e)
 		return PFM_ERR_ATTR;
 	}
 
+	/*
+	 * force a default ldlat (will not appear in display_reg)
+	 */
 	if (ldlat_um && !ldlat) {
-		DPRINT("missing ldlat= for umask\n");
-		return PFM_ERR_ATTR;
+		DPRINT("missing ldlat= for umask, forcing to default %d cycles\n", INTEL_X86_LDLAT_DEFAULT);
+		ldlat = INTEL_X86_LDLAT_DEFAULT;
 	}
 
 	if (ldlat && ldlat_um) {
diff --git a/src/libpfm4/lib/pfmlib_intel_x86_priv.h b/src/libpfm4/lib/pfmlib_intel_x86_priv.h
index 39f96ea..ce369bc 100644
--- a/src/libpfm4/lib/pfmlib_intel_x86_priv.h
+++ b/src/libpfm4/lib/pfmlib_intel_x86_priv.h
@@ -166,6 +166,7 @@ typedef union pfm_intel_x86_reg {
 #define INTEL_FIXED2_ATTRS	(_INTEL_X86_ATTR_U|_INTEL_X86_ATTR_K)
 #define INTEL_FIXED3_ATTRS	(INTEL_FIXED2_ATTRS|_INTEL_X86_ATTR_T)
 #define INTEL_V3_ATTRS 		(INTEL_V2_ATTRS|_INTEL_X86_ATTR_T)
+#define INTEL_V4_ATTRS 		(INTEL_V3_ATTRS)
 
 /* let's define some handy shortcuts! */
 #define sel_event_select perfevtsel.sel_event_select
@@ -200,6 +201,11 @@ typedef union pfm_intel_x86_reg {
  */
 #define INTEL_X86_PMU_FL_ECMASK 0x10000	/* edge requires cmask >=1 */
 
+/*
+ * default ldlat value for PEBS-LL events. Used when ldlat= is missing
+ */
+#define INTEL_X86_LDLAT_DEFAULT	3 /* default ldlat value in core cycles */
+
 typedef struct {
 	unsigned int version:8;
 	unsigned int num_cnt:8;
diff --git a/src/libpfm4/lib/pfmlib_priv.h b/src/libpfm4/lib/pfmlib_priv.h
index 66d9c16..209c445 100644
--- a/src/libpfm4/lib/pfmlib_priv.h
+++ b/src/libpfm4/lib/pfmlib_priv.h
@@ -231,6 +231,7 @@ extern pfmlib_pmu_t intel_snb_unc_cbo3_support;
 extern pfmlib_pmu_t intel_snb_ep_support;
 extern pfmlib_pmu_t intel_ivb_support;
 extern pfmlib_pmu_t intel_ivb_ep_support;
+extern pfmlib_pmu_t intel_hsw_support;
 extern pfmlib_pmu_t intel_snbep_unc_cb0_support;
 extern pfmlib_pmu_t intel_snbep_unc_cb1_support;
 extern pfmlib_pmu_t intel_snbep_unc_cb2_support;
diff --git a/src/libpfm4/tests/validate_x86.c b/src/libpfm4/tests/validate_x86.c
index 85d9458..9c2ab0e 100644
--- a/src/libpfm4/tests/validate_x86.c
+++ b/src/libpfm4/tests/validate_x86.c
@@ -1688,7 +1688,11 @@ static const test_event_t x86_test_events[]={
 	},
 	{ SRC_LINE,
 	  .name = "snb_ep::mem_trans_retired:latency_above_threshold",
-	  .ret = PFM_ERR_ATTR,
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0]=0x5301cd,
+	  .codes[1] = 3,
+	  .fstr = "snb_ep::MEM_TRANS_RETIRED:LATENCY_ABOVE_THRESHOLD:k=1:u=1:e=0:i=0:c=0:t=0:ldlat=3",
 	},
 	{ SRC_LINE,
 	  .name = "snb_ep::mem_trans_retired:latency_above_threshold:ldlat=2",
@@ -1708,7 +1712,11 @@ static const test_event_t x86_test_events[]={
 	},
 	{ SRC_LINE,
 	  .name = "snb::mem_trans_retired:latency_above_threshold",
-	  .ret = PFM_ERR_ATTR,
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5301cd,
+	  .codes[1] = 3,
+	  .fstr = "snb::MEM_TRANS_RETIRED:LATENCY_ABOVE_THRESHOLD:k=1:u=1:e=0:i=0:c=0:t=0:ldlat=3",
 	},
 	{ SRC_LINE,
 	  .name = "snb::mem_trans_retired:latency_above_threshold:ldlat=2",
@@ -1728,7 +1736,11 @@ static const test_event_t x86_test_events[]={
 	},
 	{ SRC_LINE,
 	  .name = "ivb::mem_trans_retired:latency_above_threshold",
-	  .ret = PFM_ERR_ATTR,
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5301cd,
+	  .codes[1] = 3,
+	  .fstr = "ivb::MEM_TRANS_RETIRED:LATENCY_ABOVE_THRESHOLD:k=1:u=1:e=0:i=0:c=0:t=0:ldlat=3",
 	},
 	{ SRC_LINE,
 	  .name = "ivb::mem_trans_retired:latency_above_threshold:ldlat=2",
@@ -1748,7 +1760,11 @@ static const test_event_t x86_test_events[]={
 	},
 	{ SRC_LINE,
 	  .name = "nhm::mem_inst_retired:latency_above_threshold",
-	  .ret = PFM_ERR_ATTR,
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x53100b,
+	  .codes[1] = 3,
+	  .fstr = "nhm::MEM_INST_RETIRED:LATENCY_ABOVE_THRESHOLD:k=1:u=1:e=0:i=0:c=0:t=0:ldlat=3",
 	},
 	{ SRC_LINE,
 	  .name = "nhm::mem_inst_retired:latency_above_threshold:ldlat=2",
@@ -1768,7 +1784,11 @@ static const test_event_t x86_test_events[]={
 	},
 	{ SRC_LINE,
 	  .name = "wsm::mem_inst_retired:latency_above_threshold",
-	  .ret = PFM_ERR_ATTR,
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x53100b,
+	  .codes[1] = 3,
+	  .fstr = "wsm::MEM_INST_RETIRED:LATENCY_ABOVE_THRESHOLD:k=1:u=1:e=0:i=0:c=0:t=0:ldlat=3",
 	},
 	{ SRC_LINE,
 	  .name = "wsm::mem_inst_retired:latency_above_threshold:ldlat=2",
@@ -1865,6 +1885,59 @@ static const test_event_t x86_test_events[]={
 	  .codes[1] = 0x3fff808fffULL,
 	  .fstr = "ivb_ep::OFFCORE_RESPONSE_0:DMND_DATA_RD:DMND_RFO:DMND_IFETCH:WB:PF_DATA_RD:PF_RFO:PF_IFETCH:PF_LLC_DATA_RD:PF_LLC_RFO:PF_LLC_IFETCH:BUS_LOCKS:STRM_ST:OTHER:LLC_MISS_REMOTE_DRAM:SNP_ANY:k=1:u=1:e=0:i=0:c=0:t=0"
 	},
+	{ SRC_LINE,
+	  .name = "hsw::mem_trans_retired:latency_above_threshold:ldlat=3:u",
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5101cd,
+	  .codes[1] = 3,
+	  .fstr = "hsw::MEM_TRANS_RETIRED:LOAD_LATENCY:k=0:u=1:e=0:i=0:c=0:t=0:ldlat=3",
+	},
+	{ SRC_LINE,
+	  .name = "hsw::mem_trans_retired:latency_above_threshold:ldlat=1000000",
+	  .ret = PFM_ERR_ATTR_VAL,
+	},
+	{ SRC_LINE,
+	  .name = "hsw::mem_trans_retired:load_latency",
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5301cd,
+	  .codes[1] = 3,
+	  .fstr = "hsw::MEM_TRANS_RETIRED:LOAD_LATENCY:k=1:u=1:e=0:i=0:c=0:t=0:ldlat=3",
+	},
+	{ SRC_LINE,
+	  .name = "hsw::mem_trans_retired:load_latency:ldlat=1000000",
+	  .ret = PFM_ERR_ATTR_VAL,
+	},
+	{ SRC_LINE,
+	  .name = "hsw::mem_trans_retired:latency_above_threshold:ldlat=2",
+	  .ret = PFM_ERR_ATTR_VAL,
+	},
+	{ SRC_LINE,
+	  .name = "hsw::cycle_activity:cycles_l2_pending",
+	  .ret = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x15301a3,
+	  .fstr = "hsw::CYCLE_ACTIVITY:CYCLES_L2_PENDING:k=1:u=1:e=0:i=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "hsw::cycle_activity:cycles_l2_pending:c=8",
+	  .ret = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "hsw::hle_retired:aborted",
+	  .ret = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x5304c8,
+	  .fstr = "hsw::HLE_RETIRED:ABORTED:k=1:u=1:e=0:i=0:c=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "hsw::rtm_retired:aborted",
+	  .ret = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x5304c9,
+	  .fstr = "hsw::RTM_RETIRED:ABORTED:k=1:u=1:e=0:i=0:c=0:t=0",
+	},
 };
 #define NUM_TEST_EVENTS (int)(sizeof(x86_test_events)/sizeof(test_event_t))
 
-- 
2.1.0

From 91f0b20fda85bea91c8ef1f8368eb6d3acdcfe2d Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Wed, 3 Jul 2013 12:10:47 -0400
Subject: [PATCH 02/24] libpfm4: Update

Catch some Haswell/IVB updates and Power 8.
Lines up with:
commit b52f161160dc0ddb9dfcdd51e61b4a9171a293ce
Author: Stephane Eranian <eranian@gmail.com>
Date:   Mon Jul 1 09:34:12 2013 +0200

    add Haswell UOPS_EXECUTED:STALL_CYCLES

    Handy alias to UOPS_EXECUTED:CORE:c=1:i

    Signed-off-by: Stephane Eranian <eranian@gmail.com>

diff --git a/src/libpfm4/README b/src/libpfm4/README
index 8a7e994..905b768 100644
--- a/src/libpfm4/README
+++ b/src/libpfm4/README
@@ -47,6 +47,7 @@ The library supports many PMUs. The current version can handle:
 		Intel Nehalem, Westmere
 		Intel Sandy Bridge
 		Intel Ivy Bridge
+		Intel Haswell
 		Intel Knights Corner
 		Intel architectural perfmon v1, v2, v3
 
@@ -66,6 +67,7 @@ The library supports many PMUs. The current version can handle:
 		Power 5
 		Power 6
 		Power 7
+		Power 8
 		PPC970
 		Torrent
 		System z (s390x)
diff --git a/src/libpfm4/debian/changelog b/src/libpfm4/debian/changelog
index ff721b6..1177830 100644
--- a/src/libpfm4/debian/changelog
+++ b/src/libpfm4/debian/changelog
@@ -1,3 +1,14 @@
+libpfm4 (4.0) unstable; urgency=low
+  * Intel IVB-EP support
+  * Intel IVB updates support
+  * Intel SNB updates support
+  * Intel SNB-EP uncore support
+  * ldlat support (PEBS-LL)
+  * New Intel Atom support
+  * bug fixes
+
+ -- Stephane Eranian <eranian@gmail.com>  Fri, 08 JUn  2013 18:45:01 +0200
+
 libpfm4 (3.0) unstable; urgency=low
 
   * ARM Cortex A15 support
diff --git a/src/libpfm4/docs/Makefile b/src/libpfm4/docs/Makefile
index 2e29b05..59678f41 100644
--- a/src/libpfm4/docs/Makefile
+++ b/src/libpfm4/docs/Makefile
@@ -44,6 +44,7 @@ ARCH_MAN=libpfm_intel_core.3	\
 	 libpfm_intel_snb.3	\
 	 libpfm_intel_snb_unc.3 \
 	 libpfm_intel_ivb.3	\
+	 libpfm_intel_ivb_unc.3 \
 	 libpfm_intel_hsw.3	\
 	 libpfm_intel_snbep_unc_cbo.3 \
 	 libpfm_intel_snbep_unc_ha.3 \
diff --git a/src/libpfm4/docs/man3/libpfm_intel_ivb_unc.3 b/src/libpfm4/docs/man3/libpfm_intel_ivb_unc.3
new file mode 100644
index 0000000..1e9921f
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_intel_ivb_unc.3
@@ -0,0 +1,48 @@
+.TH LIBPFM 3  "June, 2013" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_intel_ivb_unc - support for Intel Ivy Bridge uncore PMU
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: ivb_unc_cbo0, ivb_unc_cbo1, ivb_unc_cbo2, ivb_unc_cbo3
+.B PMU desc: Intel Ivy Bridge C-box uncore
+.sp
+.SH DESCRIPTION
+The library supports the Intel Ivy Bridge client part (model 58) uncore PMU.
+The support is currently limited to the Coherency Box, so called C-Box for up
+to 4 physical cores.
+
+Each physical core has an associated C-Box which it uses to communictate with
+the L3 cache. The C-boxes all support the same set of events. However, Core 0
+C-box (snb_unc_cbo0) supports an additional uncore clock ticks event: \fBUNC_CLOCKTICKS\fR.
+
+
+.SH MODIFIERS
+The following modifiers are supported on Intel Ivy Bridge C-Box uncore PMU:
+.TP
+.B i
+Invert the meaning of the event. The counter will now count cycles in which the event is \fBnot\fR
+occurring. This is a boolean modifier
+.TP
+.B e
+Enable edge detection, i.e., count only when there is a state transition from no occurrence of the event
+to at least one occurrence. This modifier must be combined with a counter mask modifier (m) with a value greater or equal to one.
+This is a boolean modifier.
+.TP
+.B c
+Set the counter mask value. The mask acts as a threshold. The counter will count the number of cycles
+in which the number of occurrences of the event is greater or equal to the threshold. This is an integer
+modifier with values in the range [0:255].
+
+.P
+Both the \fBUNC_CBO_CACHE_LOOKUP\fR and \fBUNC_CBO_XSNP_RESPONSE\fR requires two umasks to be valid.
+For \fBUNC_CBO_CACHE_LOOKUP\fR the first umask must be one of the MESI state umasks, the second has to be one
+of the filters.  For \fBUNC_CBO_XSNP_RESPONSE\fR the first umask must be one of the snoop types, the second
+has to be one of the filters.
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.PP
diff --git a/src/libpfm4/include/perfmon/perf_event.h b/src/libpfm4/include/perfmon/perf_event.h
index 54b21f7..46295c8 100644
--- a/src/libpfm4/include/perfmon/perf_event.h
+++ b/src/libpfm4/include/perfmon/perf_event.h
@@ -24,10 +24,10 @@
 
 #include <sys/types.h>
 #include <unistd.h>		/* for syscall numbers */
+#include <inttypes.h>
 #include <sys/syscall.h>	/* for syscall stub macros */
 #include <sys/ioctl.h>		/* for _IO */
 #include <sys/prctl.h>		/* for prctl() comamnds */
-#include <perfmon/pfmlib.h>	/* for os_err_t */
 
 #ifdef __cplusplus
 extern "C" {
@@ -407,7 +407,7 @@ enum perf_callchain_context {
 /*
  * perf_event_open() syscall stub
  */
-static inline os_err_t
+static inline int
 perf_event_open(
 	struct perf_event_attr		*hw_event_uptr,
 	pid_t				pid,
diff --git a/src/libpfm4/include/perfmon/pfmlib.h b/src/libpfm4/include/perfmon/pfmlib.h
index de99684..89b9fd8 100644
--- a/src/libpfm4/include/perfmon/pfmlib.h
+++ b/src/libpfm4/include/perfmon/pfmlib.h
@@ -185,6 +185,13 @@ typedef enum {
 	PFM_PMU_INTEL_IVB_EP,		/* Intel IvyBridge EP */
 	PFM_PMU_INTEL_HSW,		/* Intel Haswell */
 
+	PFM_PMU_INTEL_IVB_UNC_CB0,	/* Intel IvyBridge C-box 0 uncore PMU */
+	PFM_PMU_INTEL_IVB_UNC_CB1,	/* Intel IvyBridge C-box 1 uncore PMU */
+	PFM_PMU_INTEL_IVB_UNC_CB2,	/* Intel IvyBridge C-box 2 uncore PMU */
+	PFM_PMU_INTEL_IVB_UNC_CB3,	/* Intel IvyBridge C-box 3 uncore PMU */
+
+	PFM_PMU_POWER8,			/* IBM POWER8 */
+
 	/* MUST ADD NEW PMU MODELS HERE */
 
 	PFM_PMU_MAX			/* end marker */
diff --git a/src/libpfm4/lib/Makefile b/src/libpfm4/lib/Makefile
index 84248dd..98411b8 100644
--- a/src/libpfm4/lib/Makefile
+++ b/src/libpfm4/lib/Makefile
@@ -58,7 +58,7 @@ SRCS   += pfmlib_amd64.c pfmlib_intel_core.c pfmlib_intel_x86.c \
 	  pfmlib_intel_nhm_unc.c pfmlib_intel_nhm.c \
 	  pfmlib_intel_wsm.c  \
 	  pfmlib_intel_snb.c pfmlib_intel_snb_unc.c \
-	  pfmlib_intel_ivb.c \
+	  pfmlib_intel_ivb.c pfmlib_intel_ivb_unc.c \
 	  pfmlib_intel_hsw.c \
 	  pfmlib_intel_snbep_unc.c \
 	  pfmlib_intel_snbep_unc_cbo.c \
@@ -95,7 +95,7 @@ SRCS += pfmlib_powerpc_perf_event.c
 endif
 
 INCARCH = $(INC_POWERPC)
-SRCS   += pfmlib_powerpc.c pfmlib_power4.c pfmlib_ppc970.c pfmlib_power5.c pfmlib_power6.c pfmlib_power7.c pfmlib_torrent.c
+SRCS   += pfmlib_powerpc.c pfmlib_power4.c pfmlib_ppc970.c pfmlib_power5.c pfmlib_power6.c pfmlib_power7.c pfmlib_torrent.c pfmlib_power8.c
 CFLAGS += -DCONFIG_PFMLIB_ARCH_POWERPC
 endif
 
@@ -227,6 +227,7 @@ INC_POWERPC=events/ppc970_events.h	\
 	events/power5+_events.h		\
 	events/power6_events.h		\
 	events/power7_events.h		\
+	events/power8_events.h		\
 	events/torrent_events.h
 
 INC_S390X=pfmlib_s390x_priv.h \
diff --git a/src/libpfm4/lib/events/amd64_events_fam15h.h b/src/libpfm4/lib/events/amd64_events_fam15h.h
index 7195f13..5738e4c 100644
--- a/src/libpfm4/lib/events/amd64_events_fam15h.h
+++ b/src/libpfm4/lib/events/amd64_events_fam15h.h
@@ -2277,7 +2277,7 @@ static const amd64_entry_t amd64_fam15h_pe[]={
   .ngrp    = 1,
   .umasks  = amd64_fam15h_thermal_status,
 },
-{ .name    = "CPU_0O_REQUESTS_TO_MEMORY_IO",
+{ .name    = "CPU_IO_REQUESTS_TO_MEMORY_IO",
   .desc    = "CPU/IO Requests to Memory/IO",
   .code    = 0xe9,
   .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_cpu_io_requests_to_memory_io),
diff --git a/src/libpfm4/lib/events/intel_hsw_events.h b/src/libpfm4/lib/events/intel_hsw_events.h
index bc0549e..d479862 100644
--- a/src/libpfm4/lib/events/intel_hsw_events.h
+++ b/src/libpfm4/lib/events/intel_hsw_events.h
@@ -63,11 +63,6 @@ static const intel_x86_umask_t hsw_br_inst_exec[]={
     .ucode  = 0x9000,
     .uflags = INTEL_X86_NCOMBO,
   },
-  { .uname = "TAKEN_INDIRECT_NEAR_CALL",
-    .udesc  = "All taken indirect calls, including both register and memory indirect",
-    .ucode  = 0xa000,
-    .uflags = INTEL_X86_NCOMBO,
-  },
   { .uname = "ALL_CONDITIONAL",
     .udesc  = "Speculative and retired macro-conditional branches",
     .ucode  = 0xc100,
@@ -93,9 +88,9 @@ static const intel_x86_umask_t hsw_br_inst_exec[]={
     .ucode  = 0xd000,
     .uflags = INTEL_X86_NCOMBO,
   },
-  { .uname = "ANY_INDIRECT_NEAR_CALL",
+  { .uname = "TAKEN_INDIRECT_NEAR_CALL",
     .udesc  = "All indirect calls, including both register and memory indirect",
-    .ucode  = 0xe000,
+    .ucode  = 0xa000,
     .uflags = INTEL_X86_NCOMBO,
   },
   { .uname = "ALL_BRANCHES",
@@ -174,16 +169,6 @@ static const intel_x86_umask_t hsw_br_misp_exec[]={
     .ucode  = 0xc400,
     .uflags = INTEL_X86_NCOMBO,
   },
-  { .uname = "ANY_RETURN_NEAR",
-    .udesc  = "Speculative and retired mispredicted indirect branches with return mnemonic",
-    .ucode  = 0xc800,
-    .uflags = INTEL_X86_NCOMBO,
-  },
-  { .uname = "ANY_INDIRECT_NEAR_CALL",
-    .udesc  = "All mispredicted indirect calls, including both register and memory indirect",
-    .ucode  = 0xe000,
-    .uflags = INTEL_X86_NCOMBO,
-  },
   { .uname = "ALL_BRANCHES",
     .udesc  = "Speculative and retired mispredicted macro conditional branches",
     .ucode  = 0xff00,
@@ -1116,6 +1101,13 @@ static const intel_x86_umask_t hsw_uops_executed[]={
     .ucode  = 0x200,
     .uflags = INTEL_X86_DFL,
   },
+  { .uname = "STALL_CYCLES",
+    .udesc  = "Number of cycles with no uops executed",
+    .ucode  = 0x200 | INTEL_X86_MOD_INV | (1 << INTEL_X86_CMASK_BIT), /* inv=1 cnt=1 */
+    .uequiv = "CORE:c=1:i=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_I | _INTEL_X86_ATTR_C,
+  },
 };
 
 static const intel_x86_umask_t hsw_uops_executed_port[]={
@@ -2228,7 +2220,7 @@ static const intel_x86_entry_t intel_hsw_pe[]={
   },
   { .name = "LSD",
     .desc   = "Loop stream detector",
-    .code = 0xa0,
+    .code = 0xa8,
     .cntmsk = 0xff,
     .ngrp = 1,
     .modmsk = INTEL_V4_ATTRS,
diff --git a/src/libpfm4/lib/events/power8_events.h b/src/libpfm4/lib/events/power8_events.h
new file mode 100644
index 0000000..25945f3
--- /dev/null
+++ b/src/libpfm4/lib/events/power8_events.h
@@ -0,0 +1,1009 @@
+/****************************/
+/* THIS IS OPEN SOURCE CODE */
+/****************************/
+
+#ifndef __POWER8_EVENTS_H__
+#define __POWER8_EVENTS_H__
+
+/*
+* File:    power8_events.h
+* CVS:
+Author:  Carl Love
+*          carll.ibm.com
+* Mods:    <your name here>
+*          <your email address>
+*
+* (C) Copyright IBM Corporation, 2013.  All Rights Reserved.
+* Contributed by
+*
+* Note: This code was automatically generated and should not be modified by
+* hand.
+*
+* Documentation on the PMU events will be published at:
+*  http://www.power.org/documentation
+*/
+
+#define POWER8_PME_PM_1PLUS_PPC_CMPL 0
+#define POWER8_PME_PM_1PLUS_PPC_DISP 1
+#define POWER8_PME_PM_ANY_THRD_RUN_CYC 2
+#define POWER8_PME_PM_BR_MPRED_CMPL 3
+#define POWER8_PME_PM_BR_TAKEN_CMPL 4
+#define POWER8_PME_PM_CYC 5
+#define POWER8_PME_PM_DATA_FROM_L2MISS 6
+#define POWER8_PME_PM_DATA_FROM_L3MISS 7
+#define POWER8_PME_PM_DATA_FROM_MEM 8
+#define POWER8_PME_PM_DTLB_MISS 9
+#define POWER8_PME_PM_EXT_INT 10
+#define POWER8_PME_PM_FLOP 11
+#define POWER8_PME_PM_FLUSH 12
+#define POWER8_PME_PM_GCT_NOSLOT_CYC 13
+#define POWER8_PME_PM_IERAT_MISS 14
+#define POWER8_PME_PM_INST_DISP 15
+#define POWER8_PME_PM_INST_FROM_L3MISS 16
+#define POWER8_PME_PM_ITLB_MISS 17
+#define POWER8_PME_PM_L1_DCACHE_RELOAD_VALID 18
+#define POWER8_PME_PM_L1_ICACHE_MISS 19
+#define POWER8_PME_PM_LD_MISS_L1 20
+#define POWER8_PME_PM_LSU_DERAT_MISS 21
+#define POWER8_PME_PM_MRK_BR_MPRED_CMPL 22
+#define POWER8_PME_PM_MRK_BR_TAKEN_CMPL 23
+#define POWER8_PME_PM_MRK_DATA_FROM_L2MISS 24
+#define POWER8_PME_PM_MRK_DATA_FROM_L3MISS 25
+#define POWER8_PME_PM_MRK_DATA_FROM_MEM 26
+#define POWER8_PME_PM_MRK_DERAT_MISS 27
+#define POWER8_PME_PM_MRK_DTLB_MISS 28
+#define POWER8_PME_PM_MRK_INST_CMPL 29
+#define POWER8_PME_PM_MRK_INST_DISP 30
+#define POWER8_PME_PM_MRK_INST_FROM_L3MISS 31
+#define POWER8_PME_PM_MRK_L1_ICACHE_MISS 32
+#define POWER8_PME_PM_MRK_L1_RELOAD_VALID 33
+#define POWER8_PME_PM_MRK_LD_MISS_L1 34
+#define POWER8_PME_PM_MRK_ST_CMPL 35
+#define POWER8_PME_PM_RUN_CYC 36
+#define POWER8_PME_PM_RUN_INST_CMPL 37
+#define POWER8_PME_PM_RUN_PURR 38
+#define POWER8_PME_PM_ST_FIN 39
+#define POWER8_PME_PM_ST_MISS_L1 40
+#define POWER8_PME_PM_TB_BIT_TRANS 41
+#define POWER8_PME_PM_THRD_CONC_RUN_INST 42
+#define POWER8_PME_PM_THRESH_EXC_1024 43
+#define POWER8_PME_PM_THRESH_EXC_128 44
+#define POWER8_PME_PM_THRESH_EXC_2048 45
+#define POWER8_PME_PM_THRESH_EXC_256 46
+#define POWER8_PME_PM_THRESH_EXC_32 47
+#define POWER8_PME_PM_THRESH_EXC_4096 48
+#define POWER8_PME_PM_THRESH_EXC_512 49
+#define POWER8_PME_PM_THRESH_EXC_64 50
+#define POWER8_PME_PM_THRESH_MET 51
+#define POWER8_PME_PM_BR_2PATH 52
+#define POWER8_PME_PM_BR_CMPL 53
+#define POWER8_PME_PM_BR_MRK_2PATH 54
+#define POWER8_PME_PM_CMPLU_STALL 55
+#define POWER8_PME_PM_CMPLU_STALL_BRU 56
+#define POWER8_PME_PM_CMPLU_STALL_BRU_CRU 57
+#define POWER8_PME_PM_CMPLU_STALL_COQ_FULL 58
+#define POWER8_PME_PM_CMPLU_STALL_DCACHE_MISS 59
+#define POWER8_PME_PM_CMPLU_STALL_DMISS_L21_L31 60
+#define POWER8_PME_PM_CMPLU_STALL_DMISS_L2L3 61
+#define POWER8_PME_PM_CMPLU_STALL_DMISS_L2L3_CONFLICT 62
+#define POWER8_PME_PM_CMPLU_STALL_DMISS_L3MISS 63
+#define POWER8_PME_PM_CMPLU_STALL_DMISS_LMEM 64
+#define POWER8_PME_PM_CMPLU_STALL_DMISS_REMOTE 65
+#define POWER8_PME_PM_CMPLU_STALL_ERAT_MISS 66
+#define POWER8_PME_PM_CMPLU_STALL_FLUSH 67
+#define POWER8_PME_PM_CMPLU_STALL_FXLONG 68
+#define POWER8_PME_PM_CMPLU_STALL_FXU 69
+#define POWER8_PME_PM_CMPLU_STALL_HWSYNC 70
+#define POWER8_PME_PM_CMPLU_STALL_LOAD_FINISH 71
+#define POWER8_PME_PM_CMPLU_STALL_LSU 72
+#define POWER8_PME_PM_CMPLU_STALL_LWSYNC 73
+#define POWER8_PME_PM_CMPLU_STALL_MEM_ECC_DELAY 74
+#define POWER8_PME_PM_CMPLU_STALL_NTCG_FLUSH 75
+#define POWER8_PME_PM_CMPLU_STALL_OTHER_CMPL 76
+#define POWER8_PME_PM_CMPLU_STALL_REJECT 77
+#define POWER8_PME_PM_CMPLU_STALL_REJECT_LHS 78
+#define POWER8_PME_PM_CMPLU_STALL_REJ_LMQ_FULL 79
+#define POWER8_PME_PM_CMPLU_STALL_SCALAR 80
+#define POWER8_PME_PM_CMPLU_STALL_SCALAR_LONG 81
+#define POWER8_PME_PM_CMPLU_STALL_STORE 82
+#define POWER8_PME_PM_CMPLU_STALL_ST_FWD 83
+#define POWER8_PME_PM_CMPLU_STALL_THRD 84
+#define POWER8_PME_PM_CMPLU_STALL_VECTOR 85
+#define POWER8_PME_PM_CMPLU_STALL_VECTOR_LONG 86
+#define POWER8_PME_PM_CMPLU_STALL_VSU 87
+#define POWER8_PME_PM_DATA_FROM_L2 88
+#define POWER8_PME_PM_DATA_FROM_L2_NO_CONFLICT 89
+#define POWER8_PME_PM_DATA_FROM_L3 90
+#define POWER8_PME_PM_DATA_FROM_L3MISS_MOD 91
+#define POWER8_PME_PM_DATA_FROM_L3_NO_CONFLICT 92
+#define POWER8_PME_PM_DATA_FROM_LMEM 93
+#define POWER8_PME_PM_DATA_FROM_MEMORY 94
+#define POWER8_PME_PM_DC_PREF_STREAM_STRIDED_CONF 95
+#define POWER8_PME_PM_GCT_NOSLOT_BR_MPRED 96
+#define POWER8_PME_PM_GCT_NOSLOT_BR_MPRED_ICMISS 97
+#define POWER8_PME_PM_GCT_NOSLOT_DISP_HELD_ISSQ 98
+#define POWER8_PME_PM_GCT_NOSLOT_DISP_HELD_OTHER 99
+#define POWER8_PME_PM_GCT_NOSLOT_DISP_HELD_SRQ 100
+#define POWER8_PME_PM_GCT_NOSLOT_IC_L3MISS 101
+#define POWER8_PME_PM_GCT_NOSLOT_IC_MISS 102
+#define POWER8_PME_PM_GRP_DISP 103
+#define POWER8_PME_PM_GRP_MRK 104
+#define POWER8_PME_PM_HV_CYC 105
+#define POWER8_PME_PM_INST_CMPL 106
+#define POWER8_PME_PM_IOPS_CMPL 107
+#define POWER8_PME_PM_LD_CMPL 108
+#define POWER8_PME_PM_LD_L3MISS_PEND_CYC 109
+#define POWER8_PME_PM_MRK_DATA_FROM_L2 110
+#define POWER8_PME_PM_MRK_DATA_FROM_L2MISS_CYC 111
+#define POWER8_PME_PM_MRK_DATA_FROM_L2_CYC 112
+#define POWER8_PME_PM_MRK_DATA_FROM_L2_NO_CONFLICT 113
+#define POWER8_PME_PM_MRK_DATA_FROM_L2_NO_CONFLICT_CYC 114
+#define POWER8_PME_PM_MRK_DATA_FROM_L3 115
+#define POWER8_PME_PM_MRK_DATA_FROM_L3MISS_CYC 116
+#define POWER8_PME_PM_MRK_DATA_FROM_L3_CYC 117
+#define POWER8_PME_PM_MRK_DATA_FROM_L3_NO_CONFLICT 118
+#define POWER8_PME_PM_MRK_DATA_FROM_L3_NO_CONFLICT_CYC 119
+#define POWER8_PME_PM_MRK_DATA_FROM_LL4 120
+#define POWER8_PME_PM_MRK_DATA_FROM_LL4_CYC 121
+#define POWER8_PME_PM_MRK_DATA_FROM_LMEM 122
+#define POWER8_PME_PM_MRK_DATA_FROM_LMEM_CYC 123
+#define POWER8_PME_PM_MRK_DATA_FROM_MEMORY 124
+#define POWER8_PME_PM_MRK_DATA_FROM_MEMORY_CYC 125
+#define POWER8_PME_PM_MRK_GRP_CMPL 126
+#define POWER8_PME_PM_MRK_INST_DECODED 127
+#define POWER8_PME_PM_MRK_L2_RC_DISP 128
+#define POWER8_PME_PM_MRK_LD_MISS_L1_CYC 129
+#define POWER8_PME_PM_MRK_STALL_CMPLU_CYC 130
+#define POWER8_PME_PM_NEST_REF_CLK 131
+#define POWER8_PME_PM_PMC1_OVERFLOW 132
+#define POWER8_PME_PM_PMC2_OVERFLOW 133
+#define POWER8_PME_PM_PMC3_OVERFLOW 134
+#define POWER8_PME_PM_PMC4_OVERFLOW 135
+#define POWER8_PME_PM_PMC6_OVERFLOW 136
+#define POWER8_PME_PM_PPC_CMPL 137
+#define POWER8_PME_PM_THRD_ALL_RUN_CYC 138
+#define POWER8_PME_PM_THRESH_NOT_MET 139
+
+static const pme_power_entry_t power8_pe[] = {
+[ POWER8_PME_PM_1PLUS_PPC_CMPL ] = {
+	.pme_name = "PM_1PLUS_PPC_CMPL",
+	.pme_code = 0x100f2,
+	.pme_short_desc = "one or more ppc instructions completed",
+	.pme_long_desc = "one or more ppc instructions finished",
+},
+[ POWER8_PME_PM_1PLUS_PPC_DISP ] = {
+	.pme_name = "PM_1PLUS_PPC_DISP",
+	.pme_code = 0x400f2,
+	.pme_short_desc = "Cycles at least one Instr Dispatched",
+	.pme_long_desc = "Cycles at least one Instr Dispatched",
+},
+[ POWER8_PME_PM_ANY_THRD_RUN_CYC ] = {
+	.pme_name = "PM_ANY_THRD_RUN_CYC",
+	.pme_code = 0x100fa,
+	.pme_short_desc = "Any thread in run_cycles (was one thread in run_cycles)",
+	.pme_long_desc = "One of threads in run_cycles",
+},
+[ POWER8_PME_PM_BR_MPRED_CMPL ] = {
+	.pme_name = "PM_BR_MPRED_CMPL",
+	.pme_code = 0x400f6,
+	.pme_short_desc = "Number of Branch Mispredicts",
+	.pme_long_desc = "Number of Branch Mispredicts",
+},
+[ POWER8_PME_PM_BR_TAKEN_CMPL ] = {
+	.pme_name = "PM_BR_TAKEN_CMPL",
+	.pme_code = 0x200fa,
+	.pme_short_desc = "Branch Taken",
+	.pme_long_desc = "New event for Branch Taken",
+},
+[ POWER8_PME_PM_CYC ] = {
+	.pme_name = "PM_CYC",
+	.pme_code = 0x100f0,
+	.pme_short_desc = "Cycles",
+	.pme_long_desc = "Cycles",
+},
+[ POWER8_PME_PM_DATA_FROM_L2MISS ] = {
+	.pme_name = "PM_DATA_FROM_L2MISS",
+	.pme_code = 0x200fe,
+	.pme_short_desc = "Demand LD - L2 Miss (not L2 hit)",
+	.pme_long_desc = "Demand LD - L2 Miss (not L2 hit)",
+},
+[ POWER8_PME_PM_DATA_FROM_L3MISS ] = {
+	.pme_name = "PM_DATA_FROM_L3MISS",
+	.pme_code = 0x300fe,
+	.pme_short_desc = "Demand LD - L3 Miss (not L2 hit and not L3 hit)",
+	.pme_long_desc = "Demand LD - L3 Miss (not L2 hit and not L3 hit)",
+},
+[ POWER8_PME_PM_DATA_FROM_MEM ] = {
+	.pme_name = "PM_DATA_FROM_MEM",
+	.pme_code = 0x400fe,
+	.pme_short_desc = "Data cache reload from memory (including L4)",
+	.pme_long_desc = "data from Memory",
+},
+[ POWER8_PME_PM_DTLB_MISS ] = {
+	.pme_name = "PM_DTLB_MISS",
+	.pme_code = 0x300fc,
+	.pme_short_desc = "Data PTEG Reloaded (DTLB Miss)",
+	.pme_long_desc = "Data PTEG reload",
+},
+[ POWER8_PME_PM_EXT_INT ] = {
+	.pme_name = "PM_EXT_INT",
+	.pme_code = 0x200f8,
+	.pme_short_desc = "external interrupt",
+	.pme_long_desc = "external interrupt",
+},
+[ POWER8_PME_PM_FLOP ] = {
+	.pme_name = "PM_FLOP",
+	.pme_code = 0x100f4,
+	.pme_short_desc = "Floating Point Operations Finished",
+	.pme_long_desc = "Floating Point Operations Finished",
+},
+[ POWER8_PME_PM_FLUSH ] = {
+	.pme_name = "PM_FLUSH",
+	.pme_code = 0x400f8,
+	.pme_short_desc = "Flush (any type)",
+	.pme_long_desc = "Flush (any type)",
+},
+[ POWER8_PME_PM_GCT_NOSLOT_CYC ] = {
+	.pme_name = "PM_GCT_NOSLOT_CYC",
+	.pme_code = 0x100f8,
+	.pme_short_desc = "Pipeline empty (No itags assigned , no GCT slots used)",
+	.pme_long_desc = "No itags assigned",
+},
+[ POWER8_PME_PM_IERAT_MISS ] = {
+	.pme_name = "PM_IERAT_MISS",
+	.pme_code = 0x100f6,
+	.pme_short_desc = "IERAT Reloaded (Miss)",
+	.pme_long_desc = "Cycles Instruction ERAT was reloaded",
+},
+[ POWER8_PME_PM_INST_DISP ] = {
+	.pme_name = "PM_INST_DISP",
+	.pme_code = 0x200f2,
+	.pme_short_desc = "Number of PPC Dispatched",
+	.pme_long_desc = "Number of PPC Dispatched",
+},
+[ POWER8_PME_PM_INST_FROM_L3MISS ] = {
+	.pme_name = "PM_INST_FROM_L3MISS",
+	.pme_code = 0x300fa,
+	.pme_short_desc = "Inst from L3 miss",
+	.pme_long_desc = "A Instruction cacheline request resolved from a location that was beyond the local L3 cache",
+},
+[ POWER8_PME_PM_ITLB_MISS ] = {
+	.pme_name = "PM_ITLB_MISS",
+	.pme_code = 0x400fc,
+	.pme_short_desc = "ITLB Reloaded",
+	.pme_long_desc = "ITLB Reloaded (always zero on POWER6)",
+},
+[ POWER8_PME_PM_L1_DCACHE_RELOAD_VALID ] = {
+	.pme_name = "PM_L1_DCACHE_RELOAD_VALID",
+	.pme_code = 0x300f6,
+	.pme_short_desc = "DL1 reloaded due to Demand Load",
+	.pme_long_desc = "DL1 reloaded due to Demand Load",
+},
+[ POWER8_PME_PM_L1_ICACHE_MISS ] = {
+	.pme_name = "PM_L1_ICACHE_MISS",
+	.pme_code = 0x200fc,
+	.pme_short_desc = "Demand iCache Miss",
+	.pme_long_desc = "Demand iCache Miss",
+},
+[ POWER8_PME_PM_LD_MISS_L1 ] = {
+	.pme_name = "PM_LD_MISS_L1",
+	.pme_code = 0x400f0,
+	.pme_short_desc = "Load Missed L1",
+	.pme_long_desc = "Load Missed L1",
+},
+[ POWER8_PME_PM_LSU_DERAT_MISS ] = {
+	.pme_name = "PM_LSU_DERAT_MISS",
+	.pme_code = 0x200f6,
+	.pme_short_desc = "DERAT Reloaded (Miss)",
+	.pme_long_desc = "DERAT Reloaded due to a DERAT miss",
+},
+[ POWER8_PME_PM_MRK_BR_MPRED_CMPL ] = {
+	.pme_name = "PM_MRK_BR_MPRED_CMPL",
+	.pme_code = 0x300e4,
+	.pme_short_desc = "Marked Branch Mispredicted",
+	.pme_long_desc = "Marked Branch Mispredicted",
+},
+[ POWER8_PME_PM_MRK_BR_TAKEN_CMPL ] = {
+	.pme_name = "PM_MRK_BR_TAKEN_CMPL",
+	.pme_code = 0x100e2,
+	.pme_short_desc = "Marked Branch Taken",
+	.pme_long_desc = "Marked Branch Taken completed",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L2MISS ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L2MISS",
+	.pme_code = 0x400e8,
+	.pme_short_desc = "Data cache reload L2 miss",
+	.pme_long_desc = "sampled load resolved beyond L2",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L3MISS ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L3MISS",
+	.pme_code = 0x200e4,
+	.pme_short_desc = "The processor's data cache was reloaded from a location other than the local core's L3 due to a marked load",
+	.pme_long_desc = "sampled load resolved beyond L3",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_MEM ] = {
+	.pme_name = "PM_MRK_DATA_FROM_MEM",
+	.pme_code = 0x200e0,
+	.pme_short_desc = "The processor's data cache was reloaded from a memory location including L4 from local remote or distant due to a marked load",
+	.pme_long_desc = "sampled load resolved from memory",
+},
+[ POWER8_PME_PM_MRK_DERAT_MISS ] = {
+	.pme_name = "PM_MRK_DERAT_MISS",
+	.pme_code = 0x300e6,
+	.pme_short_desc = "Erat Miss (TLB Access) All page sizes",
+	.pme_long_desc = "Erat Miss (TLB Access) All page sizes",
+},
+[ POWER8_PME_PM_MRK_DTLB_MISS ] = {
+	.pme_name = "PM_MRK_DTLB_MISS",
+	.pme_code = 0x400e4,
+	.pme_short_desc = "Marked dtlb miss",
+	.pme_long_desc = "sampled Instruction dtlb miss",
+},
+[ POWER8_PME_PM_MRK_INST_CMPL ] = {
+	.pme_name = "PM_MRK_INST_CMPL",
+	.pme_code = 0x400e0,
+	.pme_short_desc = "marked instruction completed",
+	.pme_long_desc = "Marked group complete",
+},
+[ POWER8_PME_PM_MRK_INST_DISP ] = {
+	.pme_name = "PM_MRK_INST_DISP",
+	.pme_code = 0x100e0,
+	.pme_short_desc = "Marked Instruction dispatched",
+	.pme_long_desc = "The thread has dispatched a randomly sampled marked instruction",
+},
+[ POWER8_PME_PM_MRK_INST_FROM_L3MISS ] = {
+	.pme_name = "PM_MRK_INST_FROM_L3MISS",
+	.pme_code = 0x400e6,
+	.pme_short_desc = "sampled instruction missed icache and came from beyond L3 A Instruction cacheline request for a marked/sampled instruction resolved from a location that was beyond the local L3 cache",
+	.pme_long_desc = "sampled instruction missed icache and came from beyond L3 A Instruction cacheline request for a marked/sampled instruction resolved from a location that was beyond the local L3 cache",
+},
+[ POWER8_PME_PM_MRK_L1_ICACHE_MISS ] = {
+	.pme_name = "PM_MRK_L1_ICACHE_MISS",
+	.pme_code = 0x100e4,
+	.pme_short_desc = "Marked L1 Icache Miss",
+	.pme_long_desc = "sampled Instruction suffered an icache Miss",
+},
+[ POWER8_PME_PM_MRK_L1_RELOAD_VALID ] = {
+	.pme_name = "PM_MRK_L1_RELOAD_VALID",
+	.pme_code = 0x100ea,
+	.pme_short_desc = "Marked demand reload",
+	.pme_long_desc = "Sampled Instruction had a data reload",
+},
+[ POWER8_PME_PM_MRK_LD_MISS_L1 ] = {
+	.pme_name = "PM_MRK_LD_MISS_L1",
+	.pme_code = 0x200e2,
+	.pme_short_desc = "Marked DL1 Demand Miss counted at exec time",
+	.pme_long_desc = "Marked DL1 Demand Miss",
+},
+[ POWER8_PME_PM_MRK_ST_CMPL ] = {
+	.pme_name = "PM_MRK_ST_CMPL",
+	.pme_code = 0x300e2,
+	.pme_short_desc = "Marked store completed",
+	.pme_long_desc = "marked store completed and sent to nest",
+},
+[ POWER8_PME_PM_RUN_CYC ] = {
+	.pme_name = "PM_RUN_CYC",
+	.pme_code = 0x600f4,
+	.pme_short_desc = "Run_cycles",
+	.pme_long_desc = "Run_cycles",
+},
+[ POWER8_PME_PM_RUN_INST_CMPL ] = {
+	.pme_name = "PM_RUN_INST_CMPL",
+	.pme_code = 0x500fa,
+	.pme_short_desc = "Run_Instructions",
+	.pme_long_desc = "Run_Instructions",
+},
+[ POWER8_PME_PM_RUN_PURR ] = {
+	.pme_name = "PM_RUN_PURR",
+	.pme_code = 0x400f4,
+	.pme_short_desc = "Run_PURR",
+	.pme_long_desc = "Run_PURR",
+},
+[ POWER8_PME_PM_ST_FIN ] = {
+	.pme_name = "PM_ST_FIN",
+	.pme_code = 0x200f0,
+	.pme_short_desc = "Store Instructions Finished (store sent to nest)",
+	.pme_long_desc = "Store Instructions Finished",
+},
+[ POWER8_PME_PM_ST_MISS_L1 ] = {
+	.pme_name = "PM_ST_MISS_L1",
+	.pme_code = 0x300f0,
+	.pme_short_desc = "Store Missed L1",
+	.pme_long_desc = "Store Missed L1",
+},
+[ POWER8_PME_PM_TB_BIT_TRANS ] = {
+	.pme_name = "PM_TB_BIT_TRANS",
+	.pme_code = 0x300f8,
+	.pme_short_desc = "timebase event",
+	.pme_long_desc = "timebase event",
+},
+[ POWER8_PME_PM_THRD_CONC_RUN_INST ] = {
+	.pme_name = "PM_THRD_CONC_RUN_INST",
+	.pme_code = 0x300f4,
+	.pme_short_desc = "Concurrent Run Instructions",
+	.pme_long_desc = "PPC Instructions Finished when both threads in run_cycles",
+},
+[ POWER8_PME_PM_THRESH_EXC_1024 ] = {
+	.pme_name = "PM_THRESH_EXC_1024",
+	.pme_code = 0x300ea,
+	.pme_short_desc = "Threshold counter exceeded a value of 1024 Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 1024",
+	.pme_long_desc = "Threshold counter exceeded a value of 1024 Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 1024",
+},
+[ POWER8_PME_PM_THRESH_EXC_128 ] = {
+	.pme_name = "PM_THRESH_EXC_128",
+	.pme_code = 0x400ea,
+	.pme_short_desc = "Threshold counter exceeded a value of 128",
+	.pme_long_desc = "Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 128",
+},
+[ POWER8_PME_PM_THRESH_EXC_2048 ] = {
+	.pme_name = "PM_THRESH_EXC_2048",
+	.pme_code = 0x400ec,
+	.pme_short_desc = "Threshold counter exceeded a value of 2048",
+	.pme_long_desc = "Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 2048",
+},
+[ POWER8_PME_PM_THRESH_EXC_256 ] = {
+	.pme_name = "PM_THRESH_EXC_256",
+	.pme_code = 0x100e8,
+	.pme_short_desc = "Threshold counter exceed a count of 256",
+	.pme_long_desc = "Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 256",
+},
+[ POWER8_PME_PM_THRESH_EXC_32 ] = {
+	.pme_name = "PM_THRESH_EXC_32",
+	.pme_code = 0x200e6,
+	.pme_short_desc = "Threshold counter exceeded a value of 32",
+	.pme_long_desc = "Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 32",
+},
+[ POWER8_PME_PM_THRESH_EXC_4096 ] = {
+	.pme_name = "PM_THRESH_EXC_4096",
+	.pme_code = 0x100e6,
+	.pme_short_desc = "Threshold counter exceed a count of 4096",
+	.pme_long_desc = "Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 4096",
+},
+[ POWER8_PME_PM_THRESH_EXC_512 ] = {
+	.pme_name = "PM_THRESH_EXC_512",
+	.pme_code = 0x200e8,
+	.pme_short_desc = "Threshold counter exceeded a value of 512 Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 512",
+	.pme_long_desc = "Threshold counter exceeded a value of 512 Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 512",
+},
+[ POWER8_PME_PM_THRESH_EXC_64 ] = {
+	.pme_name = "PM_THRESH_EXC_64",
+	.pme_code = 0x300e8,
+	.pme_short_desc = "Threshold counter exceeded a value of 64 Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 64",
+	.pme_long_desc = "Threshold counter exceeded a value of 64 Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 64",
+},
+[ POWER8_PME_PM_THRESH_MET ] = {
+	.pme_name = "PM_THRESH_MET",
+	.pme_code = 0x100ec,
+	.pme_short_desc = "threshold exceeded",
+	.pme_long_desc = "Threshold exceeded",
+},
+[ POWER8_PME_PM_BR_2PATH ] = {
+	.pme_name = "PM_BR_2PATH",
+	.pme_code = 0x40036,
+	.pme_short_desc = "two path branch",
+	.pme_long_desc = "two path branch.",
+},
+[ POWER8_PME_PM_BR_CMPL ] = {
+	.pme_name = "PM_BR_CMPL",
+	.pme_code = 0x40060,
+	.pme_short_desc = "Branch Instruction completed",
+	.pme_long_desc = "Branch Instruction completed.",
+},
+[ POWER8_PME_PM_BR_MRK_2PATH ] = {
+	.pme_name = "PM_BR_MRK_2PATH",
+	.pme_code = 0x40138,
+	.pme_short_desc = "marked two path branch",
+	.pme_long_desc = "marked two path branch.",
+},
+[ POWER8_PME_PM_CMPLU_STALL ] = {
+	.pme_name = "PM_CMPLU_STALL",
+	.pme_code = 0x1e054,
+	.pme_short_desc = "Completion stall",
+	.pme_long_desc = "Completion stall.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_BRU ] = {
+	.pme_name = "PM_CMPLU_STALL_BRU",
+	.pme_code = 0x4d018,
+	.pme_short_desc = "Completion stall due to a Branch Unit",
+	.pme_long_desc = "Completion stall due to a Branch Unit.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_BRU_CRU ] = {
+	.pme_name = "PM_CMPLU_STALL_BRU_CRU",
+	.pme_code = 0x2d018,
+	.pme_short_desc = "Completion stall due to IFU",
+	.pme_long_desc = "Completion stall due to IFU.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_COQ_FULL ] = {
+	.pme_name = "PM_CMPLU_STALL_COQ_FULL",
+	.pme_code = 0x30026,
+	.pme_short_desc = "Completion stall due to CO q full",
+	.pme_long_desc = "Completion stall due to CO q full.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_DCACHE_MISS ] = {
+	.pme_name = "PM_CMPLU_STALL_DCACHE_MISS",
+	.pme_code = 0x2c012,
+	.pme_short_desc = "Completion stall by Dcache miss",
+	.pme_long_desc = "Completion stall by Dcache miss.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_DMISS_L21_L31 ] = {
+	.pme_name = "PM_CMPLU_STALL_DMISS_L21_L31",
+	.pme_code = 0x2c018,
+	.pme_short_desc = "Completion stall by Dcache miss which resolved on chip ( excluding local L2/L3)",
+	.pme_long_desc = "Completion stall by Dcache miss which resolved on chip ( excluding local L2/L3).",
+},
+[ POWER8_PME_PM_CMPLU_STALL_DMISS_L2L3 ] = {
+	.pme_name = "PM_CMPLU_STALL_DMISS_L2L3",
+	.pme_code = 0x2c016,
+	.pme_short_desc = "Completion stall by Dcache miss which resolved in L2/L3",
+	.pme_long_desc = "Completion stall by Dcache miss which resolved in L2/L3.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_DMISS_L2L3_CONFLICT ] = {
+	.pme_name = "PM_CMPLU_STALL_DMISS_L2L3_CONFLICT",
+	.pme_code = 0x4c016,
+	.pme_short_desc = "Completion stall due to cache miss due to L2 l3 conflict",
+	.pme_long_desc = "Completion stall due to cache miss resolving in core's L2/L3 with a conflict.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_DMISS_L3MISS ] = {
+	.pme_name = "PM_CMPLU_STALL_DMISS_L3MISS",
+	.pme_code = 0x4c01a,
+	.pme_short_desc = "Completion stall due to cache miss resolving missed the L3",
+	.pme_long_desc = "Completion stall due to cache miss resolving missed the L3.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_DMISS_LMEM ] = {
+	.pme_name = "PM_CMPLU_STALL_DMISS_LMEM",
+	.pme_code = 0x4c018,
+	.pme_short_desc = "GCT empty by branch mispredict + IC miss",
+	.pme_long_desc = "Completion stall due to cache miss resolving in core's Local Memory.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_DMISS_REMOTE ] = {
+	.pme_name = "PM_CMPLU_STALL_DMISS_REMOTE",
+	.pme_code = 0x2c01c,
+	.pme_short_desc = "Completion stall by Dcache miss which resolved from remote chip (cache or memory)",
+	.pme_long_desc = "Completion stall by Dcache miss which resolved on chip ( excluding local L2/L3).",
+},
+[ POWER8_PME_PM_CMPLU_STALL_ERAT_MISS ] = {
+	.pme_name = "PM_CMPLU_STALL_ERAT_MISS",
+	.pme_code = 0x4c012,
+	.pme_short_desc = "Completion stall due to LSU reject ERAT miss",
+	.pme_long_desc = "Completion stall due to LSU reject ERAT miss.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_FLUSH ] = {
+	.pme_name = "PM_CMPLU_STALL_FLUSH",
+	.pme_code = 0x30038,
+	.pme_short_desc = "completion stall due to flush by own thread",
+	.pme_long_desc = "completion stall due to flush by own thread.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_FXLONG ] = {
+	.pme_name = "PM_CMPLU_STALL_FXLONG",
+	.pme_code = 0x4d016,
+	.pme_short_desc = "Completion stall due to a long latency fixed point instruction",
+	.pme_long_desc = "Completion stall due to a long latency fixed point instruction.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_FXU ] = {
+	.pme_name = "PM_CMPLU_STALL_FXU",
+	.pme_code = 0x2d016,
+	.pme_short_desc = "Completion stall due to FXU",
+	.pme_long_desc = "Completion stall due to FXU.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_HWSYNC ] = {
+	.pme_name = "PM_CMPLU_STALL_HWSYNC",
+	.pme_code = 0x30036,
+	.pme_short_desc = "completion stall due to hwsync",
+	.pme_long_desc = "completion stall due to hwsync.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_LOAD_FINISH ] = {
+	.pme_name = "PM_CMPLU_STALL_LOAD_FINISH",
+	.pme_code = 0x4d014,
+	.pme_short_desc = "Completion stall due to a Load finish",
+	.pme_long_desc = "Completion stall due to a Load finish.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_LSU ] = {
+	.pme_name = "PM_CMPLU_STALL_LSU",
+	.pme_code = 0x2c010,
+	.pme_short_desc = "Completion stall by LSU instruction",
+	.pme_long_desc = "Completion stall by LSU instruction.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_LWSYNC ] = {
+	.pme_name = "PM_CMPLU_STALL_LWSYNC",
+	.pme_code = 0x10036,
+	.pme_short_desc = "completion stall due to isync/lwsync",
+	.pme_long_desc = "completion stall due to isync/lwsync.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_MEM_ECC_DELAY ] = {
+	.pme_name = "PM_CMPLU_STALL_MEM_ECC_DELAY",
+	.pme_code = 0x30028,
+	.pme_short_desc = "Completion stall due to mem ECC delay",
+	.pme_long_desc = "Completion stall due to mem ECC delay.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_NTCG_FLUSH ] = {
+	.pme_name = "PM_CMPLU_STALL_NTCG_FLUSH",
+	.pme_code = 0x2e01e,
+	.pme_short_desc = "Completion stall due to ntcg flush",
+	.pme_long_desc = "Completion stall due to reject (load hit store).",
+},
+[ POWER8_PME_PM_CMPLU_STALL_OTHER_CMPL ] = {
+	.pme_name = "PM_CMPLU_STALL_OTHER_CMPL",
+	.pme_code = 0x30006,
+	.pme_short_desc = "Instructions core completed while this thread was stalled.",
+	.pme_long_desc = "Instructions core completed while this thread was stalled.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_REJECT ] = {
+	.pme_name = "PM_CMPLU_STALL_REJECT",
+	.pme_code = 0x4c010,
+	.pme_short_desc = "Completion stall due to LSU reject",
+	.pme_long_desc = "Completion stall due to LSU reject.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_REJECT_LHS ] = {
+	.pme_name = "PM_CMPLU_STALL_REJECT_LHS",
+	.pme_code = 0x2c01a,
+	.pme_short_desc = "Completion stall due to reject (load hit store)",
+	.pme_long_desc = "Completion stall due to reject (load hit store).",
+},
+[ POWER8_PME_PM_CMPLU_STALL_REJ_LMQ_FULL ] = {
+	.pme_name = "PM_CMPLU_STALL_REJ_LMQ_FULL",
+	.pme_code = 0x4c014,
+	.pme_short_desc = "Completion stall due to LSU reject LMQ full",
+	.pme_long_desc = "Completion stall due to LSU reject LMQ full.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_SCALAR ] = {
+	.pme_name = "PM_CMPLU_STALL_SCALAR",
+	.pme_code = 0x4d010,
+	.pme_short_desc = "Completion stall due to VSU scalar instruction",
+	.pme_long_desc = "Completion stall due to VSU scalar instruction.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_SCALAR_LONG ] = {
+	.pme_name = "PM_CMPLU_STALL_SCALAR_LONG",
+	.pme_code = 0x2d010,
+	.pme_short_desc = "Completion stall due to VSU scalar long latency instruction",
+	.pme_long_desc = "Completion stall due to VSU scalar long latency instruction.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_STORE ] = {
+	.pme_name = "PM_CMPLU_STALL_STORE",
+	.pme_code = 0x2c014,
+	.pme_short_desc = "Completion stall by stores this includes store agent finishes in pipe LS0/LS1 and store data finishes in LS2/LS3",
+	.pme_long_desc = "Completion stall by stores.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_ST_FWD ] = {
+	.pme_name = "PM_CMPLU_STALL_ST_FWD",
+	.pme_code = 0x4c01c,
+	.pme_short_desc = "Completion stall due to store forward",
+	.pme_long_desc = "Completion stall due to store forward.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_THRD ] = {
+	.pme_name = "PM_CMPLU_STALL_THRD",
+	.pme_code = 0x1001c,
+	.pme_short_desc = "Completion Stalled due to thread conflict. Group ready to complete but it was another thread's turn",
+	.pme_long_desc = "Completion stall due to thread conflict.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_VECTOR ] = {
+	.pme_name = "PM_CMPLU_STALL_VECTOR",
+	.pme_code = 0x2d014,
+	.pme_short_desc = "Completion stall due to VSU vector instruction",
+	.pme_long_desc = "Completion stall due to VSU vector instruction.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_VECTOR_LONG ] = {
+	.pme_name = "PM_CMPLU_STALL_VECTOR_LONG",
+	.pme_code = 0x4d012,
+	.pme_short_desc = "Completion stall due to VSU vector long instruction",
+	.pme_long_desc = "Completion stall due to VSU vector long instruction.",
+},
+[ POWER8_PME_PM_CMPLU_STALL_VSU ] = {
+	.pme_name = "PM_CMPLU_STALL_VSU",
+	.pme_code = 0x2d012,
+	.pme_short_desc = "Completion stall due to VSU instruction",
+	.pme_long_desc = "Completion stall due to VSU instruction.",
+},
+[ POWER8_PME_PM_DATA_FROM_L2 ] = {
+	.pme_name = "PM_DATA_FROM_L2",
+	.pme_code = 0x1c042,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 due to a demand load or demand load plus prefetch controlled by MMCR1[16]",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 due to a demand load or demand load plus prefetch controlled by MMCR1[20].",
+},
+[ POWER8_PME_PM_DATA_FROM_L2_NO_CONFLICT ] = {
+	.pme_name = "PM_DATA_FROM_L2_NO_CONFLICT",
+	.pme_code = 0x1c040,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 without conflict due to a demand load or demand load plus prefetch controlled by MMCR1[16]",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 without conflict due to a demand load or demand load plus prefetch controlled by MMCR1[20] .",
+},
+[ POWER8_PME_PM_DATA_FROM_L3 ] = {
+	.pme_name = "PM_DATA_FROM_L3",
+	.pme_code = 0x4c042,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L3 due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L3 due to a demand load.",
+},
+[ POWER8_PME_PM_DATA_FROM_L3MISS_MOD ] = {
+	.pme_name = "PM_DATA_FROM_L3MISS_MOD",
+	.pme_code = 0x4c04e,
+	.pme_short_desc = "The processor's data cache was reloaded from a location other than the local core's L3 due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded from a location other than the local core's L3 due to a demand load.",
+},
+[ POWER8_PME_PM_DATA_FROM_L3_NO_CONFLICT ] = {
+	.pme_name = "PM_DATA_FROM_L3_NO_CONFLICT",
+	.pme_code = 0x1c044,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L3 without conflict due to a demand load or demand load plus prefetch controlled by MMCR1[16]",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L3 without conflict due to a demand load or demand load plus prefetch controlled by MMCR1[20].",
+},
+[ POWER8_PME_PM_DATA_FROM_LMEM ] = {
+	.pme_name = "PM_DATA_FROM_LMEM",
+	.pme_code = 0x2c048,
+	.pme_short_desc = "The processor's data cache was reloaded from the local chip's Memory due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded from the local chip's Memory due to a demand load.",
+},
+[ POWER8_PME_PM_DATA_FROM_MEMORY ] = {
+	.pme_name = "PM_DATA_FROM_MEMORY",
+	.pme_code = 0x2c04c,
+	.pme_short_desc = "The processor's data cache was reloaded from a memory location including L4 from local remote or distant due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded from a memory location including L4 from local remote or distant due to a demand load.",
+},
+[ POWER8_PME_PM_DC_PREF_STREAM_STRIDED_CONF ] = {
+	.pme_name = "PM_DC_PREF_STREAM_STRIDED_CONF",
+	.pme_code = 0x3e050,
+	.pme_short_desc = "A demand load referenced a line in an active strided prefetch stream. The stream could have been allocated through the hardware prefetch mechanism or through software.",
+	.pme_long_desc = "A demand load referenced a line in an active strided prefetch stream. The stream could have been allocated through the hardware prefetch mechanism or through software..",
+},
+[ POWER8_PME_PM_GCT_NOSLOT_BR_MPRED ] = {
+	.pme_name = "PM_GCT_NOSLOT_BR_MPRED",
+	.pme_code = 0x4d01e,
+	.pme_short_desc = "Gct empty fo this thread due to branch misprediction",
+	.pme_long_desc = "Gct empty for this thread due to branch misprediction.",
+},
+[ POWER8_PME_PM_GCT_NOSLOT_BR_MPRED_ICMISS ] = {
+	.pme_name = "PM_GCT_NOSLOT_BR_MPRED_ICMISS",
+	.pme_code = 0x4d01a,
+	.pme_short_desc = "Gct empty for this thread due to Icache Miss and branch mispred",
+	.pme_long_desc = "Gct empty for this thread due to Icache Miss and branch mispred.",
+},
+[ POWER8_PME_PM_GCT_NOSLOT_DISP_HELD_ISSQ ] = {
+	.pme_name = "PM_GCT_NOSLOT_DISP_HELD_ISSQ",
+	.pme_code = 0x2d01e,
+	.pme_short_desc = "Gct empty for this thread due to dispatch hold on this thread due to Issue q full",
+	.pme_long_desc = "Gct empty for this thread due to dispatch hold on this thread due to Issue q full.",
+},
+[ POWER8_PME_PM_GCT_NOSLOT_DISP_HELD_OTHER ] = {
+	.pme_name = "PM_GCT_NOSLOT_DISP_HELD_OTHER",
+	.pme_code = 0x2e010,
+	.pme_short_desc = "Gct empty for this thread due to dispatch hold on this thread due to sync",
+	.pme_long_desc = "Gct empty for this thread due to dispatch hold on this thread due to sync.",
+},
+[ POWER8_PME_PM_GCT_NOSLOT_DISP_HELD_SRQ ] = {
+	.pme_name = "PM_GCT_NOSLOT_DISP_HELD_SRQ",
+	.pme_code = 0x2d01c,
+	.pme_short_desc = "Gct empty for this thread due to dispatch hold on this thread due to SRQ full",
+	.pme_long_desc = "Gct empty for this thread due to dispatch hold on this thread due to SRQ full.",
+},
+[ POWER8_PME_PM_GCT_NOSLOT_IC_L3MISS ] = {
+	.pme_name = "PM_GCT_NOSLOT_IC_L3MISS",
+	.pme_code = 0x4e010,
+	.pme_short_desc = "Gct empty for this thread due to icach l3 miss",
+	.pme_long_desc = "Gct empty for this thread due to icach l3 miss.",
+},
+[ POWER8_PME_PM_GCT_NOSLOT_IC_MISS ] = {
+	.pme_name = "PM_GCT_NOSLOT_IC_MISS",
+	.pme_code = 0x2d01a,
+	.pme_short_desc = "Gct empty for this thread due to Icache Miss",
+	.pme_long_desc = "Gct empty for this thread due to Icache Miss.",
+},
+[ POWER8_PME_PM_GRP_DISP ] = {
+	.pme_name = "PM_GRP_DISP",
+	.pme_code = 0x3000a,
+	.pme_short_desc = "group dispatch",
+	.pme_long_desc = "dispatch_success (Group Dispatched).",
+},
+[ POWER8_PME_PM_GRP_MRK ] = {
+	.pme_name = "PM_GRP_MRK",
+	.pme_code = 0x10130,
+	.pme_short_desc = "Instruction Marked",
+	.pme_long_desc = "Instruction marked in idu.",
+},
+[ POWER8_PME_PM_HV_CYC ] = {
+	.pme_name = "PM_HV_CYC",
+	.pme_code = 0x2000a,
+	.pme_short_desc = "cycles in hypervisor mode",
+	.pme_long_desc = "cycles in hypervisor mode .",
+},
+[ POWER8_PME_PM_INST_CMPL ] = {
+	.pme_name = "PM_INST_CMPL",
+	.pme_code = 0x10002,
+	.pme_short_desc = "Number of PowerPC Instructions that completed.",
+	.pme_long_desc = "PPC Instructions Finished (completed).",
+},
+[ POWER8_PME_PM_IOPS_CMPL ] = {
+	.pme_name = "PM_IOPS_CMPL",
+	.pme_code = 0x10014,
+	.pme_short_desc = "Internal Operations completed",
+	.pme_long_desc = "IOPS Completed.",
+},
+[ POWER8_PME_PM_LD_CMPL ] = {
+	.pme_name = "PM_LD_CMPL",
+	.pme_code = 0x1002e,
+	.pme_short_desc = "count of Loads completed",
+	.pme_long_desc = "count of Loads completed.",
+},
+[ POWER8_PME_PM_LD_L3MISS_PEND_CYC ] = {
+	.pme_name = "PM_LD_L3MISS_PEND_CYC",
+	.pme_code = 0x10062,
+	.pme_short_desc = "Cycles L3 miss was pending for this thread",
+	.pme_long_desc = "Cycles L3 miss was pending for this thread.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L2 ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L2",
+	.pme_code = 0x1d142,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L2MISS_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L2MISS_CYC",
+	.pme_code = 0x4c12e,
+	.pme_short_desc = "Duration in cycles to reload from a location other than the local core's L2 due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from a location other than the local core's L2 due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L2_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L2_CYC",
+	.pme_code = 0x4c122,
+	.pme_short_desc = "Duration in cycles to reload from local core's L2 due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from local core's L2 due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L2_NO_CONFLICT ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L2_NO_CONFLICT",
+	.pme_code = 0x1d140,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 without conflict due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 without conflict due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L2_NO_CONFLICT_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L2_NO_CONFLICT_CYC",
+	.pme_code = 0x4c120,
+	.pme_short_desc = "Duration in cycles to reload from local core's L2 without conflict due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from local core's L2 without conflict due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L3 ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L3",
+	.pme_code = 0x4d142,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L3 due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L3 due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L3MISS_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L3MISS_CYC",
+	.pme_code = 0x2d12e,
+	.pme_short_desc = "Duration in cycles to reload from a location other than the local core's L3 due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from a location other than the local core's L3 due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L3_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L3_CYC",
+	.pme_code = 0x2d122,
+	.pme_short_desc = "Duration in cycles to reload from local core's L3 due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from local core's L3 due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L3_NO_CONFLICT ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L3_NO_CONFLICT",
+	.pme_code = 0x1d144,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L3 without conflict due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L3 without conflict due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L3_NO_CONFLICT_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L3_NO_CONFLICT_CYC",
+	.pme_code = 0x4c124,
+	.pme_short_desc = "Duration in cycles to reload from local core's L3 without conflict due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from local core's L3 without conflict due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_LL4 ] = {
+	.pme_name = "PM_MRK_DATA_FROM_LL4",
+	.pme_code = 0x1d14c,
+	.pme_short_desc = "The processor's data cache was reloaded from the local chip's L4 cache due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded from the local chip's L4 cache due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_LL4_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_LL4_CYC",
+	.pme_code = 0x4c12c,
+	.pme_short_desc = "Duration in cycles to reload from the local chip's L4 cache due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from the local chip's L4 cache due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_LMEM ] = {
+	.pme_name = "PM_MRK_DATA_FROM_LMEM",
+	.pme_code = 0x2d148,
+	.pme_short_desc = "The processor's data cache was reloaded from the local chip's Memory due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded from the local chip's Memory due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_LMEM_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_LMEM_CYC",
+	.pme_code = 0x4d128,
+	.pme_short_desc = "Duration in cycles to reload from the local chip's Memory due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from the local chip's Memory due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_MEMORY ] = {
+	.pme_name = "PM_MRK_DATA_FROM_MEMORY",
+	.pme_code = 0x2d14c,
+	.pme_short_desc = "The processor's data cache was reloaded from a memory location including L4 from local remote or distant due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded from a memory location including L4 from local remote or distant due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_MEMORY_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_MEMORY_CYC",
+	.pme_code = 0x4d12c,
+	.pme_short_desc = "Duration in cycles to reload from a memory location including L4 from local remote or distant due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from a memory location including L4 from local remote or distant due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_GRP_CMPL ] = {
+	.pme_name = "PM_MRK_GRP_CMPL",
+	.pme_code = 0x40130,
+	.pme_short_desc = "marked instruction finished (completed)",
+	.pme_long_desc = "marked instruction finished (completed).",
+},
+[ POWER8_PME_PM_MRK_INST_DECODED ] = {
+	.pme_name = "PM_MRK_INST_DECODED",
+	.pme_code = 0x20130,
+	.pme_short_desc = "marked instruction decoded",
+	.pme_long_desc = "marked instruction decoded. Name from ISU?",
+},
+[ POWER8_PME_PM_MRK_L2_RC_DISP ] = {
+	.pme_name = "PM_MRK_L2_RC_DISP",
+	.pme_code = 0x20114,
+	.pme_short_desc = "Marked Instruction RC dispatched in L2",
+	.pme_long_desc = "Marked Instruction RC dispatched in L2.",
+},
+[ POWER8_PME_PM_MRK_LD_MISS_L1_CYC ] = {
+	.pme_name = "PM_MRK_LD_MISS_L1_CYC",
+	.pme_code = 0x4013e,
+	.pme_short_desc = "Marked ld latency",
+	.pme_long_desc = "Marked ld latency.",
+},
+[ POWER8_PME_PM_MRK_STALL_CMPLU_CYC ] = {
+	.pme_name = "PM_MRK_STALL_CMPLU_CYC",
+	.pme_code = 0x3013e,
+	.pme_short_desc = "Marked Group completion Stall",
+	.pme_long_desc = "Marked Group Completion Stall cycles (use edge detect to count).",
+},
+[ POWER8_PME_PM_NEST_REF_CLK ] = {
+	.pme_name = "PM_NEST_REF_CLK",
+	.pme_code = 0x3006e,
+	.pme_short_desc = "Nest reference clocks",
+	.pme_long_desc = "Nest reference clocks.",
+},
+[ POWER8_PME_PM_PMC1_OVERFLOW ] = {
+	.pme_name = "PM_PMC1_OVERFLOW",
+	.pme_code = 0x20010,
+	.pme_short_desc = "Overflow from counter 1",
+	.pme_long_desc = "Overflow from counter 1.",
+},
+[ POWER8_PME_PM_PMC2_OVERFLOW ] = {
+	.pme_name = "PM_PMC2_OVERFLOW",
+	.pme_code = 0x30010,
+	.pme_short_desc = "Overflow from counter 2",
+	.pme_long_desc = "Overflow from counter 2.",
+},
+[ POWER8_PME_PM_PMC3_OVERFLOW ] = {
+	.pme_name = "PM_PMC3_OVERFLOW",
+	.pme_code = 0x40010,
+	.pme_short_desc = "Overflow from counter 3",
+	.pme_long_desc = "Overflow from counter 3.",
+},
+[ POWER8_PME_PM_PMC4_OVERFLOW ] = {
+	.pme_name = "PM_PMC4_OVERFLOW",
+	.pme_code = 0x10010,
+	.pme_short_desc = "Overflow from counter 4",
+	.pme_long_desc = "Overflow from counter 4.",
+},
+[ POWER8_PME_PM_PMC6_OVERFLOW ] = {
+	.pme_name = "PM_PMC6_OVERFLOW",
+	.pme_code = 0x30024,
+	.pme_short_desc = "Overflow from counter 6",
+	.pme_long_desc = "Overflow from counter 6.",
+},
+[ POWER8_PME_PM_PPC_CMPL ] = {
+	.pme_name = "PM_PPC_CMPL",
+	.pme_code = 0x40002,
+	.pme_short_desc = "PPC Instructions Finished (completed)",
+	.pme_long_desc = "PPC Instructions Finished (completed).",
+},
+[ POWER8_PME_PM_THRD_ALL_RUN_CYC ] = {
+	.pme_name = "PM_THRD_ALL_RUN_CYC",
+	.pme_code = 0x2000c,
+	.pme_short_desc = "All Threads in Run_cycles (was both threads in run_cycles)",
+	.pme_long_desc = "All Threads in Run_cycles (was both threads in run_cycles).",
+},
+[ POWER8_PME_PM_THRESH_NOT_MET ] = {
+	.pme_name = "PM_THRESH_NOT_MET",
+	.pme_code = 0x4016e,
+	.pme_short_desc = "Threshold counter did not meet threshold",
+	.pme_long_desc = "Threshold counter did not meet threshold.",
+},
+};
+#endif
diff --git a/src/libpfm4/lib/pfmlib_common.c b/src/libpfm4/lib/pfmlib_common.c
index d4aa142..71bddd9 100644
--- a/src/libpfm4/lib/pfmlib_common.c
+++ b/src/libpfm4/lib/pfmlib_common.c
@@ -91,6 +91,10 @@ static pfmlib_pmu_t *pfmlib_pmus[]=
 	&intel_snb_unc_cbo3_support,
 	&intel_snb_ep_support,
 	&intel_ivb_support,
+	&intel_ivb_unc_cbo0_support,
+	&intel_ivb_unc_cbo1_support,
+	&intel_ivb_unc_cbo2_support,
+	&intel_ivb_unc_cbo3_support,
 	&intel_ivb_ep_support,
 	&intel_hsw_support,
 	&intel_snbep_unc_cb0_support,
@@ -133,6 +137,7 @@ static pfmlib_pmu_t *pfmlib_pmus[]=
 	&power5p_support,
 	&power6_support,
 	&power7_support,
+	&power8_support,
 	&torrent_support,
 #endif
 
diff --git a/src/libpfm4/lib/pfmlib_intel_ivb_unc.c b/src/libpfm4/lib/pfmlib_intel_ivb_unc.c
new file mode 100644
index 0000000..bc94807
--- /dev/null
+++ b/src/libpfm4/lib/pfmlib_intel_ivb_unc.c
@@ -0,0 +1,84 @@
+/*
+ * pfmlib_intel_ivb_unc.c : Intel IvyBridge C-Box uncore PMU
+ *
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+/* private headers */
+#include "pfmlib_priv.h"
+#include "pfmlib_intel_x86_priv.h"
+
+#define INTEL_SNB_UNC_ATTRS \
+	(_INTEL_X86_ATTR_I|_INTEL_X86_ATTR_E|_INTEL_X86_ATTR_C)
+
+/* same event table and SNB */
+#include "events/intel_snb_unc_events.h"
+
+static int
+pfm_ivb_unc_detect(void *this)
+{
+	int ret;
+
+	ret = pfm_intel_x86_detect();
+	if (ret != PFM_SUCCESS)
+		return ret;
+
+	if (pfm_intel_x86_cfg.family != 6)
+		return PFM_ERR_NOTSUPP;
+
+	switch (pfm_intel_x86_cfg.model) {
+		case 58: /* IvyBridge */
+			break;
+		default:
+			return PFM_ERR_NOTSUPP;
+	}
+	return PFM_SUCCESS;
+}
+
+#define IVB_UNC_CBOX(n, p) \
+pfmlib_pmu_t intel_ivb_unc_cbo##n##_support={ \
+	.desc			= "Intel Ivy Bridge C-box"#n" uncore", \
+	.name			= "ivb_unc_cbo"#n, \
+	.perf_name		= "uncore_cbox_"#n, \
+	.pmu			= PFM_PMU_INTEL_IVB_UNC_CB##n, \
+	.pme_count		= LIBPFM_ARRAY_SIZE(intel_snb_unc_##p##_pe), \
+	.type			= PFM_PMU_TYPE_UNCORE, \
+	.num_cntrs		= 2, \
+	.num_fixed_cntrs	= 1, \
+	.max_encoding		= 1,\
+	.pe			= intel_snb_unc_##p##_pe, \
+	.atdesc			= intel_x86_mods, \
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK, \
+	.pmu_detect		= pfm_ivb_unc_detect, \
+	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding, \
+	 PFMLIB_ENCODE_PERF(pfm_intel_nhm_unc_get_perf_encoding), \
+	.get_event_first	= pfm_intel_x86_get_event_first, \
+	.get_event_next		= pfm_intel_x86_get_event_next, \
+	.event_is_valid		= pfm_intel_x86_event_is_valid, \
+	.validate_table		= pfm_intel_x86_validate_table, \
+	.get_event_info		= pfm_intel_x86_get_event_info, \
+	.get_event_attr_info	= pfm_intel_x86_get_event_attr_info, \
+	 PFMLIB_VALID_PERF_PATTRS(pfm_intel_x86_perf_validate_pattrs),\
+	.get_event_nattrs	= pfm_intel_x86_get_event_nattrs,\
+}
+
+IVB_UNC_CBOX(0, cbo0);
+IVB_UNC_CBOX(1, cbo);
+IVB_UNC_CBOX(2, cbo);
+IVB_UNC_CBOX(3, cbo);
diff --git a/src/libpfm4/lib/pfmlib_power8.c b/src/libpfm4/lib/pfmlib_power8.c
new file mode 100644
index 0000000..d274b59
--- /dev/null
+++ b/src/libpfm4/lib/pfmlib_power8.c
@@ -0,0 +1,57 @@
+/*
+ * pfmlib_power8.c : IBM Power8 support
+ *
+ * Copyright (C) IBM Corporation, 2013.  All rights reserved.
+ * Contributed by Carl Love (carll@us.ibm.com)
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+/* private headers */
+#include "pfmlib_priv.h"
+#include "pfmlib_power_priv.h"
+#include "events/power8_events.h"
+
+static int
+pfm_power8_detect(void* this)
+{
+	if (__is_processor(PV_POWER8))
+		return PFM_SUCCESS;
+	return PFM_ERR_NOTSUPP;
+}
+
+pfmlib_pmu_t power8_support={
+	.desc			= "POWER8",
+	.name			= "power8",
+	.pmu			= PFM_PMU_POWER8,
+	.pme_count		= LIBPFM_ARRAY_SIZE(power8_pe),
+	.type			= PFM_PMU_TYPE_CORE,
+	.num_cntrs		= 4,
+	.num_fixed_cntrs	= 2,
+	.max_encoding		= 1,
+	.pe			= power8_pe,
+	.pmu_detect		= pfm_power8_detect,
+	.get_event_encoding[PFM_OS_NONE] = pfm_gen_powerpc_get_encoding,
+	 PFMLIB_ENCODE_PERF(pfm_gen_powerpc_get_perf_encoding),
+	 PFMLIB_VALID_PERF_PATTRS(pfm_gen_powerpc_perf_validate_pattrs),
+	.get_event_first	= pfm_gen_powerpc_get_event_first,
+	.get_event_next		= pfm_gen_powerpc_get_event_next,
+	.event_is_valid		= pfm_gen_powerpc_event_is_valid,
+	.validate_table		= pfm_gen_powerpc_validate_table,
+	.get_event_info		= pfm_gen_powerpc_get_event_info,
+	.get_event_attr_info	= pfm_gen_powerpc_get_event_attr_info,
+};
diff --git a/src/libpfm4/lib/pfmlib_power_priv.h b/src/libpfm4/lib/pfmlib_power_priv.h
index 2f66c22..2721771 100644
--- a/src/libpfm4/lib/pfmlib_power_priv.h
+++ b/src/libpfm4/lib/pfmlib_power_priv.h
@@ -93,6 +93,7 @@ typedef struct {
 #define PV_POWER7p	0x004a
 #define PV_970MP	0x0044
 #define PV_970GX	0x0045
+#define PV_POWER8	0x004b
 
 extern int pfm_gen_powerpc_get_event_info(void *this, int pidx, pfm_event_info_t *info);
 extern int pfm_gen_powerpc_get_event_attr_info(void *this, int pidx, int umask_idx, pfm_event_attr_info_t *info);
diff --git a/src/libpfm4/lib/pfmlib_priv.h b/src/libpfm4/lib/pfmlib_priv.h
index 209c445..8e203d4 100644
--- a/src/libpfm4/lib/pfmlib_priv.h
+++ b/src/libpfm4/lib/pfmlib_priv.h
@@ -230,6 +230,10 @@ extern pfmlib_pmu_t intel_snb_unc_cbo2_support;
 extern pfmlib_pmu_t intel_snb_unc_cbo3_support;
 extern pfmlib_pmu_t intel_snb_ep_support;
 extern pfmlib_pmu_t intel_ivb_support;
+extern pfmlib_pmu_t intel_ivb_unc_cbo0_support;
+extern pfmlib_pmu_t intel_ivb_unc_cbo1_support;
+extern pfmlib_pmu_t intel_ivb_unc_cbo2_support;
+extern pfmlib_pmu_t intel_ivb_unc_cbo3_support;
 extern pfmlib_pmu_t intel_ivb_ep_support;
 extern pfmlib_pmu_t intel_hsw_support;
 extern pfmlib_pmu_t intel_snbep_unc_cb0_support;
@@ -260,6 +264,7 @@ extern pfmlib_pmu_t power5_support;
 extern pfmlib_pmu_t power5p_support;
 extern pfmlib_pmu_t power6_support;
 extern pfmlib_pmu_t power7_support;
+extern pfmlib_pmu_t power8_support;
 extern pfmlib_pmu_t torrent_support;
 extern pfmlib_pmu_t sparc_support;
 extern pfmlib_pmu_t sparc_ultra12_support;
diff --git a/src/libpfm4/tests/validate_x86.c b/src/libpfm4/tests/validate_x86.c
index 9c2ab0e..e3e2866 100644
--- a/src/libpfm4/tests/validate_x86.c
+++ b/src/libpfm4/tests/validate_x86.c
@@ -838,7 +838,7 @@ static const test_event_t x86_test_events[]={
 	  .name = "snb::offcore_response_1:ANY_REQUEST:LLC_MISS_LOCAL_DRAM",
 	  .count = 2,
 	  .codes[0] = 0x5301bb,
-	  .codes[1] = 0x3f80408fff,
+	  .codes[1] = 0x3f80408fffull,
 	  .fstr = "snb::OFFCORE_RESPONSE_1:DMND_DATA_RD:DMND_RFO:DMND_IFETCH:WB:PF_DATA_RD:PF_RFO:PF_IFETCH:PF_LLC_DATA_RD:PF_LLC_RFO:PF_LLC_IFETCH:BUS_LOCKS:STRM_ST:OTHER:MISS_DRAM:SNP_ANY:k=1:u=1:e=0:i=0:c=0:t=0",
 	},
 	{ SRC_LINE,
@@ -1676,14 +1676,14 @@ static const test_event_t x86_test_events[]={
 	  .name = "snb_ep::offcore_response_1:ANY_REQUEST:LLC_MISS_LOCAL_DRAM",
 	  .count = 2,
 	  .codes[0] = 0x5301bb,
-	  .codes[1] = 0x3f80408fff,
+	  .codes[1] = 0x3f80408fffull,
 	  .fstr = "snb_ep::OFFCORE_RESPONSE_1:DMND_DATA_RD:DMND_RFO:DMND_IFETCH:WB:PF_DATA_RD:PF_RFO:PF_IFETCH:PF_LLC_DATA_RD:PF_LLC_RFO:PF_LLC_IFETCH:BUS_LOCKS:STRM_ST:OTHER:LLC_MISS_LOCAL_DRAM:SNP_ANY:k=1:u=1:e=0:i=0:c=0:t=0",
 	},
 	{ SRC_LINE,
 	  .name = "snb_ep::offcore_response_1:ANY_REQUEST:LLC_MISS_REMOTE_DRAM",
 	  .count = 2,
 	  .codes[0] = 0x5301bb,
-	  .codes[1] = 0x3fff808fff,
+	  .codes[1] = 0x3fff808fffull,
 	  .fstr = "snb_ep::OFFCORE_RESPONSE_1:DMND_DATA_RD:DMND_RFO:DMND_IFETCH:WB:PF_DATA_RD:PF_RFO:PF_IFETCH:PF_LLC_DATA_RD:PF_LLC_RFO:PF_LLC_IFETCH:BUS_LOCKS:STRM_ST:OTHER:LLC_MISS_REMOTE_DRAM:SNP_ANY:k=1:u=1:e=0:i=0:c=0:t=0",
 	},
 	{ SRC_LINE,
@@ -1938,6 +1938,17 @@ static const test_event_t x86_test_events[]={
 	  .codes[0] = 0x5304c9,
 	  .fstr = "hsw::RTM_RETIRED:ABORTED:k=1:u=1:e=0:i=0:c=0:t=0",
 	},
+	{ SRC_LINE,
+	  .name = "ivb_unc_cbo0::unc_clockticks",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x5000ff,
+	  .fstr = "ivb_unc_cbo0::UNC_CLOCKTICKS",
+	},
+	{ SRC_LINE,
+	  .name = "ivb_unc_cbo1::unc_clockticks",
+	  .ret  = PFM_ERR_NOTFOUND
+	},
 };
 #define NUM_TEST_EVENTS (int)(sizeof(x86_test_events)/sizeof(test_event_t))
 
-- 
2.1.0

From 0381505ebd97d42d11b85038d9f0ee0ec233cf46 Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Fri, 2 Aug 2013 11:10:39 -0400
Subject: [PATCH 03/24] Update libpfm4:

Matches up with
-------------------------------------------------------
commit f5cedb91ab060cc16f178e98a4432a17b010f2b6
Author: Stephane Eranian <eranian@gmail.com>
Date:   Thu Aug 1 11:14:26 2013 +0200

    add Intel Haswell intx, intxcp description

    Signed-off-by: Stephane Eranian <eranian@gmail.com>
-------------------------------------------------------

diff --git a/src/libpfm4/docs/man3/libpfm_intel_hsw.3 b/src/libpfm4/docs/man3/libpfm_intel_hsw.3
index 913577d..fb36acf 100644
--- a/src/libpfm4/docs/man3/libpfm_intel_hsw.3
+++ b/src/libpfm4/docs/man3/libpfm_intel_hsw.3
@@ -50,6 +50,14 @@ Measure on both threads at the same time assuming hyper-threading is enabled. Th
 Pass a latency threshold to the MEM_TRANS_RETIRED:LOAD_LATENCY event.
 This is an integer attribute that must be in the range [3:65535]. It is required
 for this event.  Note that the event must be used with precise sampling (PEBS).
+.TP
+.B intx
+Monitor the event only when executing inside a transactional memory region (in tx). Event
+does not count otherwise. This is a boolean modifiers. Default value is 0.
+.TP
+.B intxcp
+Do not count occurrences of the event when they are inside an aborted transactional memory
+region. This is a boolean modifier. Default value is 0.
 
 .SH OFFCORE_RESPONSE events
 Intel Haswell provides two offcore_response events. They are called OFFCORE_RESPONSE_0 and OFFCORE_RESPONSE_1.
diff --git a/src/libpfm4/include/perfmon/perf_event.h b/src/libpfm4/include/perfmon/perf_event.h
index 46295c8..244cf51 100644
--- a/src/libpfm4/include/perfmon/perf_event.h
+++ b/src/libpfm4/include/perfmon/perf_event.h
@@ -363,7 +363,6 @@ enum perf_callchain_context {
 	PERF_CONTEXT_MAX		= (uint64_t)-4095,
 };
 
-#endif /* _LINUX_PERF_EVENT_H */
 /*
  * flags for perf_event_open()
  */
@@ -371,6 +370,7 @@ enum perf_callchain_context {
 #define PERF_FLAG_FD_OUTPUT	(1U << 1)
 #define PERF_FLAG_PID_CGROUP	(1U << 2)
 
+#endif /* _LINUX_PERF_EVENT_H */
 
 #ifndef __NR_perf_event_open
 #ifdef __x86_64__
@@ -428,6 +428,9 @@ perf_event_open(
 #define PR_TASK_PERF_EVENTS_DISABLE	31
 #endif
 
+/* handle case of older system perf_event.h included before this file */
+#ifndef PERF_MEM_OP_NA
+
 union perf_mem_data_src {
 	uint64_t val;
 	struct {
@@ -491,6 +494,7 @@ union perf_mem_data_src {
 #define PERF_MEM_S(a, s) \
 	(((u64)PERF_MEM_##a##_##s) << PERF_MEM_##a##_SHIFT)
 
+#endif /* PERF_MEM_OP_NA */
 
 #ifdef __cplusplus /* extern C */
 }
diff --git a/src/libpfm4/lib/events/intel_hsw_events.h b/src/libpfm4/lib/events/intel_hsw_events.h
index d479862..ccd4a2b 100644
--- a/src/libpfm4/lib/events/intel_hsw_events.h
+++ b/src/libpfm4/lib/events/intel_hsw_events.h
@@ -1855,7 +1855,7 @@ static const intel_x86_entry_t intel_hsw_pe[]={
     .code = 0xa3,
     .cntmsk = 0xf,
     .ngrp = 1,
-    .modmsk = INTEL_V3_ATTRS & ~_INTEL_X86_ATTR_C,
+    .modmsk = INTEL_V4_ATTRS & ~_INTEL_X86_ATTR_C,
     .numasks = LIBPFM_ARRAY_SIZE(hsw_cycle_activity),
     .umasks  = hsw_cycle_activity
   },
diff --git a/src/libpfm4/lib/pfmlib_common.c b/src/libpfm4/lib/pfmlib_common.c
index 71bddd9..e810eca 100644
--- a/src/libpfm4/lib/pfmlib_common.c
+++ b/src/libpfm4/lib/pfmlib_common.c
@@ -171,6 +171,7 @@ static pfmlib_pmu_t *pfmlib_pmus[]=
 #define PFMLIB_NUM_PMUS	(int)(sizeof(pfmlib_pmus)/sizeof(pfmlib_pmu_t *))
 
 static pfmlib_os_t pfmlib_os_none;
+pfmlib_os_t *pfmlib_os = &pfmlib_os_none;
 
 static pfmlib_os_t *pfmlib_oses[]={
 	&pfmlib_os_none,
@@ -611,6 +612,17 @@ pfmlib_init_pmus(void)
 		if (ret != PFM_SUCCESS)
 			continue;
 
+		/*
+		 * check if exported by OS if needed
+		 */
+		if (p->os_detect[pfmlib_os->id]) {
+			ret = p->os_detect[pfmlib_os->id](p);
+			if (ret != PFM_SUCCESS) {
+				DPRINT("%s PMU not exported by OS\n", p->name);
+				continue;
+			}
+		}
+
 		ret = pfmlib_pmu_activate(p);
 		if (ret == PFM_SUCCESS)
 			nsuccess++;
@@ -642,9 +654,13 @@ pfmlib_init_os(void)
 		if (os->detect(os) != PFM_SUCCESS)
 			continue;
 
+		if (os != &pfmlib_os_none && pfmlib_os == &pfmlib_os_none)
+			pfmlib_os = os;
+
 		DPRINT("OS layer %s activated\n", os->name);
 		os->flags = PFMLIB_OS_FL_ACTIVATED;
 	}
+	DPRINT("default OS layer: %s\n", pfmlib_os->name);
 }
 
 int
@@ -667,11 +683,13 @@ pfm_initialize(void)
 
 	pfmlib_init_env();
 
+	/* must be done before pfmlib_init_pmus() */
+	pfmlib_init_os();
+
 	ret = pfmlib_init_pmus();
 	if (ret != PFM_SUCCESS)
 		return ret;
 
-	pfmlib_init_os();
 
 	pfm_cfg.initdone = 1;
 
diff --git a/src/libpfm4/lib/pfmlib_intel_ivb_unc.c b/src/libpfm4/lib/pfmlib_intel_ivb_unc.c
index bc94807..c2f2165 100644
--- a/src/libpfm4/lib/pfmlib_intel_ivb_unc.c
+++ b/src/libpfm4/lib/pfmlib_intel_ivb_unc.c
@@ -27,7 +27,7 @@
 #define INTEL_SNB_UNC_ATTRS \
 	(_INTEL_X86_ATTR_I|_INTEL_X86_ATTR_E|_INTEL_X86_ATTR_C)
 
-/* same event table and SNB */
+/* same event table as SNB */
 #include "events/intel_snb_unc_events.h"
 
 static int
@@ -68,6 +68,7 @@ pfmlib_pmu_t intel_ivb_unc_cbo##n##_support={ \
 	.pmu_detect		= pfm_ivb_unc_detect, \
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding, \
 	 PFMLIB_ENCODE_PERF(pfm_intel_nhm_unc_get_perf_encoding), \
+	 PFMLIB_OS_DETECT(pfm_intel_x86_perf_detect), \
 	.get_event_first	= pfm_intel_x86_get_event_first, \
 	.get_event_next		= pfm_intel_x86_get_event_next, \
 	.event_is_valid		= pfm_intel_x86_event_is_valid, \
diff --git a/src/libpfm4/lib/pfmlib_intel_snb_unc.c b/src/libpfm4/lib/pfmlib_intel_snb_unc.c
index f4bfaba..b0be6e7 100644
--- a/src/libpfm4/lib/pfmlib_intel_snb_unc.c
+++ b/src/libpfm4/lib/pfmlib_intel_snb_unc.c
@@ -68,6 +68,7 @@ pfmlib_pmu_t intel_snb_unc_cbo##n##_support={ \
 	.pmu_detect		= pfm_snb_unc_detect, \
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding, \
 	 PFMLIB_ENCODE_PERF(pfm_intel_nhm_unc_get_perf_encoding), \
+	 PFMLIB_OS_DETECT(pfm_intel_x86_perf_detect), \
 	.get_event_first	= pfm_intel_x86_get_event_first, \
 	.get_event_next		= pfm_intel_x86_get_event_next, \
 	.event_is_valid		= pfm_intel_x86_event_is_valid, \
diff --git a/src/libpfm4/lib/pfmlib_intel_x86.c b/src/libpfm4/lib/pfmlib_intel_x86.c
index f069317..435ce9e 100644
--- a/src/libpfm4/lib/pfmlib_intel_x86.c
+++ b/src/libpfm4/lib/pfmlib_intel_x86.c
@@ -40,6 +40,8 @@ const pfmlib_attr_desc_t intel_x86_mods[]={
 	PFM_ATTR_I("c", "counter-mask in range [0-255]"),	/* counter-mask */
 	PFM_ATTR_B("t", "measure any thread"),			/* monitor on both threads */
 	PFM_ATTR_I("ldlat", "load latency threshold (cycles, [3-65535])"),	/* load latency threshold */
+	PFM_ATTR_B("intx", "monitor only inside transactional memory region"),
+	PFM_ATTR_B("intxcp", "do not count occurrences inside aborted transactional memory region"),
 	PFM_ATTR_NULL /* end-marker to avoid exporting number of entries */
 };
 
@@ -490,7 +492,18 @@ pfm_intel_x86_encode_gen(void *this, pfmlib_event_desc_t *e)
 						return PFM_ERR_ATTR_VAL;
 					ldlat = ival;
 					break;
-
+				case INTEL_X86_ATTR_INTX: /* in_tx */
+					if (modhw & _INTEL_X86_ATTR_INTX)
+						return PFM_ERR_ATTR_SET;
+					reg.sel_intx = !!ival;
+					umodmsk |= _INTEL_X86_ATTR_INTX;
+					break;
+				case INTEL_X86_ATTR_INTXCP: /* in_tx_cp */
+					if (modhw & _INTEL_X86_ATTR_INTXCP)
+						return PFM_ERR_ATTR_SET;
+					reg.sel_intxcp = !!ival;
+					umodmsk |= _INTEL_X86_ATTR_INTXCP;
+					break;
 			}
 		}
 	}
@@ -627,6 +640,12 @@ pfm_intel_x86_encode_gen(void *this, pfmlib_event_desc_t *e)
 		case INTEL_X86_ATTR_LDLAT:
 			evt_strcat(e->fstr, ":%s=%d", intel_x86_mods[id].name, ldlat);
 			break;
+		case INTEL_X86_ATTR_INTX:
+			evt_strcat(e->fstr, ":%s=%lu", intel_x86_mods[id].name, reg.sel_intx);
+			break;
+		case INTEL_X86_ATTR_INTXCP:
+			evt_strcat(e->fstr, ":%s=%lu", intel_x86_mods[id].name, reg.sel_intxcp);
+			break;
 		}
 	}
 	return PFM_SUCCESS;
diff --git a/src/libpfm4/lib/pfmlib_intel_x86_perf_event.c b/src/libpfm4/lib/pfmlib_intel_x86_perf_event.c
index 443a959..f29af94 100644
--- a/src/libpfm4/lib/pfmlib_intel_x86_perf_event.c
+++ b/src/libpfm4/lib/pfmlib_intel_x86_perf_event.c
@@ -276,3 +276,13 @@ pfm_intel_x86_perf_validate_pattrs(void *this, pfmlib_event_desc_t *e)
 		}
 	}
 }
+
+int
+pfm_intel_x86_perf_detect(void *this)
+{
+	pfmlib_pmu_t *pmu = this;
+	char file[64];
+
+	snprintf(file,sizeof(file), "/sys/devices/%s", pmu->perf_name);
+	return access(file, R_OK|X_OK) ? PFM_ERR_NOTSUPP : PFM_SUCCESS;
+}
diff --git a/src/libpfm4/lib/pfmlib_intel_x86_priv.h b/src/libpfm4/lib/pfmlib_intel_x86_priv.h
index ce369bc..1671ca6 100644
--- a/src/libpfm4/lib/pfmlib_intel_x86_priv.h
+++ b/src/libpfm4/lib/pfmlib_intel_x86_priv.h
@@ -101,7 +101,9 @@ typedef union pfm_intel_x86_reg {
 		unsigned long sel_en:1;			/* enable */
 		unsigned long sel_inv:1;		/* invert counter mask */
 		unsigned long sel_cnt_mask:8;		/* counter mask */
-		unsigned long sel_res2:32;
+		unsigned long sel_intx:1;		/* only in tx region */
+		unsigned long sel_intxcp:1;		/* excl. aborted tx region */
+		unsigned long sel_res2:30;
 	} perfevtsel;
 
 	struct {
@@ -149,14 +151,18 @@ typedef union pfm_intel_x86_reg {
 #define INTEL_X86_ATTR_C	4 /* counter mask */
 #define INTEL_X86_ATTR_T	5 /* any thread */
 #define INTEL_X86_ATTR_LDLAT	6 /* load latency threshold */
-
-#define _INTEL_X86_ATTR_U  (1 << INTEL_X86_ATTR_U)
-#define _INTEL_X86_ATTR_K  (1 << INTEL_X86_ATTR_K)
-#define _INTEL_X86_ATTR_I  (1 << INTEL_X86_ATTR_I)
-#define _INTEL_X86_ATTR_E  (1 << INTEL_X86_ATTR_E)
-#define _INTEL_X86_ATTR_C  (1 << INTEL_X86_ATTR_C)
-#define _INTEL_X86_ATTR_T  (1 << INTEL_X86_ATTR_T)
-#define _INTEL_X86_ATTR_LDLAT  (1 << INTEL_X86_ATTR_LDLAT)
+#define INTEL_X86_ATTR_INTX	7 /* in transaction */
+#define INTEL_X86_ATTR_INTXCP	8 /* not aborted transaction */
+
+#define _INTEL_X86_ATTR_U	(1 << INTEL_X86_ATTR_U)
+#define _INTEL_X86_ATTR_K	(1 << INTEL_X86_ATTR_K)
+#define _INTEL_X86_ATTR_I	(1 << INTEL_X86_ATTR_I)
+#define _INTEL_X86_ATTR_E	(1 << INTEL_X86_ATTR_E)
+#define _INTEL_X86_ATTR_C  	(1 << INTEL_X86_ATTR_C)
+#define _INTEL_X86_ATTR_T  	(1 << INTEL_X86_ATTR_T)
+#define _INTEL_X86_ATTR_INTX	(1 << INTEL_X86_ATTR_INTX)
+#define _INTEL_X86_ATTR_INTXCP	(1 << INTEL_X86_ATTR_INTXCP)
+#define _INTEL_X86_ATTR_LDLAT	(1 << INTEL_X86_ATTR_LDLAT)
 
 #define INTEL_X86_ATTRS \
 	(_INTEL_X86_ATTR_I|_INTEL_X86_ATTR_E|_INTEL_X86_ATTR_C|_INTEL_X86_ATTR_U|_INTEL_X86_ATTR_K)
@@ -166,7 +172,7 @@ typedef union pfm_intel_x86_reg {
 #define INTEL_FIXED2_ATTRS	(_INTEL_X86_ATTR_U|_INTEL_X86_ATTR_K)
 #define INTEL_FIXED3_ATTRS	(INTEL_FIXED2_ATTRS|_INTEL_X86_ATTR_T)
 #define INTEL_V3_ATTRS 		(INTEL_V2_ATTRS|_INTEL_X86_ATTR_T)
-#define INTEL_V4_ATTRS 		(INTEL_V3_ATTRS)
+#define INTEL_V4_ATTRS 		(INTEL_V3_ATTRS | _INTEL_X86_ATTR_INTX | _INTEL_X86_ATTR_INTXCP)
 
 /* let's define some handy shortcuts! */
 #define sel_event_select perfevtsel.sel_event_select
@@ -180,6 +186,8 @@ typedef union pfm_intel_x86_reg {
 #define sel_inv		 perfevtsel.sel_inv
 #define sel_cnt_mask	 perfevtsel.sel_cnt_mask
 #define sel_anythr	 perfevtsel.sel_anythr
+#define sel_intx	 perfevtsel.sel_intx
+#define sel_intxcp	 perfevtsel.sel_intxcp
 
 /*
  * shift relative to start of register
@@ -322,6 +330,7 @@ extern int pfm_intel_x86_get_event_attr_info(void *this, int idx, int attr_idx,
 extern int pfm_intel_x86_get_event_info(void *this, int idx, pfm_event_info_t *info);
 extern int pfm_intel_x86_valid_pebs(pfmlib_event_desc_t *e);
 extern int pfm_intel_x86_perf_event_encoding(pfmlib_event_desc_t *e, void *data);
+extern int pfm_intel_x86_perf_detect(void *this);
 extern unsigned int pfm_intel_x86_get_event_nattrs(void *this, int pidx);
 extern int intel_x86_attr2mod(void *this, int pidx, int attr_idx);
 
diff --git a/src/libpfm4/lib/pfmlib_priv.h b/src/libpfm4/lib/pfmlib_priv.h
index 8e203d4..758b65d 100644
--- a/src/libpfm4/lib/pfmlib_priv.h
+++ b/src/libpfm4/lib/pfmlib_priv.h
@@ -128,6 +128,7 @@ typedef struct pfmlib_pmu {
 	int		 (*get_event_encoding[PFM_OS_MAX])(void *this, pfmlib_event_desc_t *e);
 
 	void		 (*validate_pattrs[PFM_OS_MAX])(void *this, pfmlib_event_desc_t *e);
+	int		 (*os_detect[PFM_OS_MAX])(void *this);
 	int		 (*validate_table)(void *this, FILE *fp);
 	int 		 (*get_num_events)(void *this);	/* optional */
 	void		 (*display_reg)(void *this, pfmlib_event_desc_t *e, void *val); /* optional */
@@ -286,6 +287,7 @@ extern pfmlib_pmu_t arm_1176_support;
 extern pfmlib_pmu_t mips_74k_support;
 extern pfmlib_pmu_t s390x_cpum_cf_support;
 
+extern pfmlib_os_t *pfmlib_os;
 extern pfmlib_os_t pfmlib_os_perf;
 extern pfmlib_os_t pfmlib_os_perf_ext;
 
@@ -352,6 +354,10 @@ pfmlib_pidx2idx(pfmlib_pmu_t *pmu, int pidx)
 #define PFMLIB_ENCODE_PERF(f)  \
 	.get_event_encoding[PFM_OS_PERF_EVENT] = f, \
 	.get_event_encoding[PFM_OS_PERF_EVENT_EXT] = f
+
+#define PFMLIB_OS_DETECT(f)  \
+	.os_detect[PFM_OS_PERF_EVENT] = f, \
+	.os_detect[PFM_OS_PERF_EVENT_EXT] = f
 #else
 #define PFMLIB_VALID_PERF_PATTRS(f) \
 	.validate_pattrs[PFM_OS_PERF_EVENT] = NULL, \
@@ -360,6 +366,10 @@ pfmlib_pidx2idx(pfmlib_pmu_t *pmu, int pidx)
 #define PFMLIB_ENCODE_PERF(f)  \
 	.get_event_encoding[PFM_OS_PERF_EVENT] = NULL, \
 	.get_event_encoding[PFM_OS_PERF_EVENT_EXT] = NULL
+
+#define PFMLIB_OS_DETECT(f)  \
+	.os_detect[PFM_OS_PERF_EVENT] = NULL, \
+	.os_detect[PFM_OS_PERF_EVENT_EXT] = NULL
 #endif
 
 #endif /* __PFMLIB_PRIV_H__ */
diff --git a/src/libpfm4/tests/validate_x86.c b/src/libpfm4/tests/validate_x86.c
index e3e2866..f351bc0 100644
--- a/src/libpfm4/tests/validate_x86.c
+++ b/src/libpfm4/tests/validate_x86.c
@@ -1891,7 +1891,7 @@ static const test_event_t x86_test_events[]={
 	  .count = 2,
 	  .codes[0] = 0x5101cd,
 	  .codes[1] = 3,
-	  .fstr = "hsw::MEM_TRANS_RETIRED:LOAD_LATENCY:k=0:u=1:e=0:i=0:c=0:t=0:ldlat=3",
+	  .fstr = "hsw::MEM_TRANS_RETIRED:LOAD_LATENCY:k=0:u=1:e=0:i=0:c=0:t=0:ldlat=3:intx=0:intxcp=0",
 	},
 	{ SRC_LINE,
 	  .name = "hsw::mem_trans_retired:latency_above_threshold:ldlat=1000000",
@@ -1903,22 +1903,40 @@ static const test_event_t x86_test_events[]={
 	  .count = 2,
 	  .codes[0] = 0x5301cd,
 	  .codes[1] = 3,
-	  .fstr = "hsw::MEM_TRANS_RETIRED:LOAD_LATENCY:k=1:u=1:e=0:i=0:c=0:t=0:ldlat=3",
+	  .fstr = "hsw::MEM_TRANS_RETIRED:LOAD_LATENCY:k=1:u=1:e=0:i=0:c=0:t=0:ldlat=3:intx=0:intxcp=0",
 	},
 	{ SRC_LINE,
 	  .name = "hsw::mem_trans_retired:load_latency:ldlat=1000000",
 	  .ret = PFM_ERR_ATTR_VAL,
 	},
 	{ SRC_LINE,
-	  .name = "hsw::mem_trans_retired:latency_above_threshold:ldlat=2",
+	  .name = "hsw::mem_trans_retired:latency_above_threshold:ldlat=2:intx=0:intxcp=0",
 	  .ret = PFM_ERR_ATTR_VAL,
 	},
 	{ SRC_LINE,
+	  .name = "hsw::inst_Retired:any_p:intx",
+	  .count = 1,
+	  .codes[0] = 0x1005300c0,
+	  .fstr = "hsw::INST_RETIRED:ANY_P:k=1:u=1:e=0:i=0:c=0:t=0:intx=1:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "hsw::inst_Retired:any_p:intx:intxcp",
+	  .count = 1,
+	  .codes[0] = 0x3005300c0,
+	  .fstr = "hsw::INST_RETIRED:ANY_P:k=1:u=1:e=0:i=0:c=0:t=0:intx=1:intxcp=1",
+	},
+	{ SRC_LINE,
+	  .name = "hsw::inst_Retired:any_p:intx=0:intxcp",
+	  .count = 1,
+	  .codes[0] = 0x2005300c0,
+	  .fstr = "hsw::INST_RETIRED:ANY_P:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=1",
+	},
+	{ SRC_LINE,
 	  .name = "hsw::cycle_activity:cycles_l2_pending",
 	  .ret = PFM_SUCCESS,
 	  .count = 1,
 	  .codes[0] = 0x15301a3,
-	  .fstr = "hsw::CYCLE_ACTIVITY:CYCLES_L2_PENDING:k=1:u=1:e=0:i=0:t=0",
+	  .fstr = "hsw::CYCLE_ACTIVITY:CYCLES_L2_PENDING:k=1:u=1:e=0:i=0:t=0:intx=0:intxcp=0",
 	},
 	{ SRC_LINE,
 	  .name = "hsw::cycle_activity:cycles_l2_pending:c=8",
@@ -1929,14 +1947,14 @@ static const test_event_t x86_test_events[]={
 	  .ret = PFM_SUCCESS,
 	  .count = 1,
 	  .codes[0] = 0x5304c8,
-	  .fstr = "hsw::HLE_RETIRED:ABORTED:k=1:u=1:e=0:i=0:c=0:t=0",
+	  .fstr = "hsw::HLE_RETIRED:ABORTED:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
 	},
 	{ SRC_LINE,
 	  .name = "hsw::rtm_retired:aborted",
 	  .ret = PFM_SUCCESS,
 	  .count = 1,
 	  .codes[0] = 0x5304c9,
-	  .fstr = "hsw::RTM_RETIRED:ABORTED:k=1:u=1:e=0:i=0:c=0:t=0",
+	  .fstr = "hsw::RTM_RETIRED:ABORTED:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
 	},
 	{ SRC_LINE,
 	  .name = "ivb_unc_cbo0::unc_clockticks",
-- 
2.1.0

From f0502279812324129ae11fae1340e1b029444af6 Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Mon, 4 Nov 2013 13:17:44 -0500
Subject: [PATCH 04/24] Libpfm4 update: catches ivy bridge updates

Brings libpfm4 current to
-------------------------
commit 7af6bc46302812d29cfbc23d24430d31f09049da
Author: Stephane Eranian <eranian@gmail.com>
Date:   Mon Nov 4 19:07:23 2013 +0100

    add missing events/umasks for Intel Ivy Bridge
-------------------------

diff --git a/src/libpfm4/lib/events/intel_ivb_events.h b/src/libpfm4/lib/events/intel_ivb_events.h
index e473756..3c5583e 100644
--- a/src/libpfm4/lib/events/intel_ivb_events.h
+++ b/src/libpfm4/lib/events/intel_ivb_events.h
@@ -406,7 +406,12 @@ static const intel_x86_umask_t ivb_icache[]={
    { .uname  = "MISSES",
      .udesc  = "Number of Instruction Cache, Streaming Buffer and Victim Cache Misses. Includes UC accesses",
      .ucode = 0x200,
-     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "IFETCH_STALL",
+     .udesc  = "Number of cycles wher a code-fetch stalled due to L1 instruction cache miss or iTLB miss",
+     .ucode = 0x400,
+     .uflags= INTEL_X86_NCOMBO,
    },
 };
 
@@ -853,7 +858,12 @@ static const intel_x86_umask_t ivb_ld_blocks[]={
    { .uname  = "STORE_FORWARD",
      .udesc  = "Loads blocked by overlapping with store buffer that cannot be forwarded",
      .ucode = 0x200,
-     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "NO_SR",
+     .udesc  = "Number of times that split load operations are temporarily blocked because all resources for handlding the split accesses are in use",
+     .ucode = 0x800,
+     .uflags= INTEL_X86_NCOMBO,
    },
 };
 
@@ -1167,6 +1177,11 @@ static const intel_x86_umask_t ivb_other_assists[]={
      .ucode = 0x0800,
      .uflags= INTEL_X86_NCOMBO,
    },
+   { .uname  = "WB",
+     .udesc  = "Number of times the microcode assist is invoked by hardware upon uop writeback",
+     .ucode = 0x8000,
+     .uflags= INTEL_X86_NCOMBO,
+   },
 };
 
 static const intel_x86_umask_t ivb_resource_stalls[]={
@@ -1206,11 +1221,17 @@ static const intel_x86_umask_t ivb_rs_events[]={
 };
 
 static const intel_x86_umask_t ivb_tlb_access[]={
-   { .uname  = "LOAD_STLB_HIT",
-     .udesc  = "Number of load operations that missed L1TLN but hit L2TLB",
+   { .uname  = "STLB_HIT",
+     .udesc  = "Number of load operations that missed L1TLB but hit L2TLB",
      .ucode = 0x400,
      .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
    },
+   { .uname  = "LOAD_STLB_HIT",
+     .udesc  = "Number of load operations that missed L1TLB but hit L2TLB",
+     .ucode = 0x400,
+     .uequiv= "STLB_HIT",
+     .uflags= INTEL_X86_NCOMBO,
+   },
 };
 
 static const intel_x86_umask_t ivb_tlb_flush[]={
@@ -1230,7 +1251,12 @@ static const intel_x86_umask_t ivb_uops_executed[]={
    { .uname  = "CORE",
      .udesc  = "Counts total number of uops executed from any thread per cycle",
      .ucode = 0x200,
-     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "THREAD",
+     .udesc  = "Counts total number of uops executed per thread each cycle",
+     .ucode = 0x100,
+     .uflags= INTEL_X86_NCOMBO,
    },
 };
 
@@ -1577,6 +1603,55 @@ static const intel_x86_umask_t ivb_cycle_activity[]={
    },
 };
 
+static const intel_x86_umask_t ivb_fp_comp_ops_exe[]={
+   { .uname  = "X87",
+     .udesc  = "Number of X87 uops executed",
+     .ucode = 0x100,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "SSE_FP_PACKED_DOUBLE",
+     .udesc  = "Number of SSE or AVX-128 double precision FP packed uops executed",
+     .ucode = 0x1000,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "SSE_FP_SCALAR_SINGLE",
+     .udesc  = "Number of SSE or AVX-128 single precision FP scalar uops executed",
+     .ucode = 0x2000,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "SSE_PACKED_SINGLE",
+     .udesc  = "Number of SSE or AVX-128 single precision FP packed uops executed",
+     .ucode = 0x4000,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "SSE_SCALAR_DOUBLE",
+     .udesc  = "Number of SSE or AVX-128 double precision FP scalar uops executed",
+     .ucode = 0x8000,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+};
+
+static const intel_x86_umask_t ivb_simd_fp_256[]={
+   { .uname  = "PACKED_SINGLE",
+     .udesc  = "Counts 256-bit packed single-precision",
+     .ucode = 0x100,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "PACKED_DOUBLE",
+     .udesc  = "Counts 256-bit packed double-precision",
+     .ucode = 0x200,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+};
+
+static const intel_x86_umask_t ivb_lsd[]={
+   { .uname  = "UOPS",
+     .udesc  = "Number of uops delivered by the Loop Stream Detector (LSD)",
+     .ucode = 0x100,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+   },
+};
+
 static const intel_x86_entry_t intel_ivb_pe[]={
 { .name   = "ARITH",
   .desc   = "Counts arithmetic multiply operations",
@@ -1942,6 +2017,16 @@ static const intel_x86_entry_t intel_ivb_pe[]={
   .ngrp = 1,
   .umasks = ivb_l3_lat_cache,
 },
+{ .name   = "LONGEST_LAT_CACHE",
+  .desc   = "Core-originated cacheable demand requests to L3",
+  .modmsk = INTEL_V3_ATTRS,
+  .cntmsk = 0xff,
+  .code = 0x2e,
+  .numasks = LIBPFM_ARRAY_SIZE(ivb_l3_lat_cache),
+  .ngrp = 1,
+  .equiv = "L3_LAT_CACHE",
+  .umasks = ivb_l3_lat_cache,
+},
 { .name   = "MACHINE_CLEARS",
   .desc   = "Machine clear asserted",
   .modmsk = INTEL_V3_ATTRS,
@@ -2107,6 +2192,15 @@ static const intel_x86_entry_t intel_ivb_pe[]={
   .ngrp = 1,
   .umasks = ivb_rs_events,
 },
+{ .name   = "DTLB_LOAD_ACCESS",
+  .desc   = "TLB access",
+  .modmsk = INTEL_V3_ATTRS,
+  .cntmsk = 0xff,
+  .code = 0x5f,
+  .numasks = LIBPFM_ARRAY_SIZE(ivb_tlb_access),
+  .ngrp = 1,
+  .umasks = ivb_tlb_access,
+},
 { .name   = "TLB_ACCESS",
   .desc   = "TLB access",
   .modmsk = INTEL_V3_ATTRS,
@@ -2114,6 +2208,7 @@ static const intel_x86_entry_t intel_ivb_pe[]={
   .code = 0x5f,
   .numasks = LIBPFM_ARRAY_SIZE(ivb_tlb_access),
   .ngrp = 1,
+  .equiv = "DTLB_LOAD_ACCESS",
   .umasks = ivb_tlb_access,
 },
 { .name   = "TLB_FLUSH",
@@ -2175,6 +2270,33 @@ static const intel_x86_entry_t intel_ivb_pe[]={
   .ngrp = 1,
   .umasks = ivb_uops_retired,
 },
+{ .name   = "FP_COMP_OPS_EXE",
+  .desc   = "Counts number of floating point events",
+  .modmsk = INTEL_V3_ATTRS,
+  .cntmsk = 0xff,
+  .code = 0x10,
+  .numasks = LIBPFM_ARRAY_SIZE(ivb_fp_comp_ops_exe),
+  .ngrp = 1,
+  .umasks = ivb_fp_comp_ops_exe,
+},
+{ .name   = "SIMD_FP_256",
+  .desc   = "Counts 256-bit packed floating point instructions",
+  .modmsk = INTEL_V3_ATTRS,
+  .cntmsk = 0xff,
+  .code = 0x11,
+  .numasks = LIBPFM_ARRAY_SIZE(ivb_simd_fp_256),
+  .ngrp = 1,
+  .umasks = ivb_simd_fp_256,
+},
+{ .name   = "LSD",
+  .desc   = "Loop stream detector",
+  .modmsk = INTEL_V3_ATTRS,
+  .cntmsk = 0xff,
+  .code = 0xa8,
+  .numasks = LIBPFM_ARRAY_SIZE(ivb_lsd),
+  .ngrp = 1,
+  .umasks = ivb_lsd,
+},
 { .name   = "OFFCORE_RESPONSE_0",
   .desc   = "Offcore response event (must provide at least one request type and either any_response or any combination of supplier + snoop)",
   .modmsk = INTEL_V3_ATTRS,
diff --git a/src/libpfm4/lib/events/intel_snbep_unc_pcu_events.h b/src/libpfm4/lib/events/intel_snbep_unc_pcu_events.h
index dd4aa3e..10dc6b3 100644
--- a/src/libpfm4/lib/events/intel_snbep_unc_pcu_events.h
+++ b/src/libpfm4/lib/events/intel_snbep_unc_pcu_events.h
@@ -72,73 +72,49 @@ static const intel_x86_entry_t intel_snbep_unc_p_pe[]={
     .desc = "Core C State Transition Cycles",
     .code = 0x3 | (1ULL << 21), /* sel_ext */
     .cntmsk = 0xf,
-    .ngrp = 1,
     .modmsk = SNBEP_UNC_PCU_ATTRS,
-    .numasks = LIBPFM_ARRAY_SIZE(snbep_unc_p_occupancy_counters),
-    .umasks  = snbep_unc_p_occupancy_counters
   },
   { .name = "UNC_P_CORE1_TRANSITION_CYCLES",
     .desc = "Core C State Transition Cycles",
     .code = 0x4 | (1ULL << 21), /* sel_ext */
     .cntmsk = 0xf,
-    .ngrp = 1,
     .modmsk = SNBEP_UNC_PCU_ATTRS,
-    .numasks = LIBPFM_ARRAY_SIZE(snbep_unc_p_occupancy_counters),
-    .umasks  = snbep_unc_p_occupancy_counters
   },
   { .name = "UNC_P_CORE2_TRANSITION_CYCLES",
     .desc = "Core C State Transition Cycles",
     .code = 0x5 | (1ULL << 21), /* sel_ext */
     .cntmsk = 0xf,
-    .ngrp = 1,
     .modmsk = SNBEP_UNC_PCU_ATTRS,
-    .numasks = LIBPFM_ARRAY_SIZE(snbep_unc_p_occupancy_counters),
-    .umasks  = snbep_unc_p_occupancy_counters
   },
   { .name = "UNC_P_CORE3_TRANSITION_CYCLES",
     .desc = "Core C State Transition Cycles",
     .code = 0x6 | (1ULL << 21), /* sel_ext */
     .cntmsk = 0xf,
-    .ngrp = 1,
     .modmsk = SNBEP_UNC_PCU_ATTRS,
-    .numasks = LIBPFM_ARRAY_SIZE(snbep_unc_p_occupancy_counters),
-    .umasks  = snbep_unc_p_occupancy_counters
   },
   { .name = "UNC_P_CORE4_TRANSITION_CYCLES",
     .desc = "Core C State Transition Cycles",
     .code = 0x7 | (1ULL << 21), /* sel_ext */
     .cntmsk = 0xf,
-    .ngrp = 1,
     .modmsk = SNBEP_UNC_PCU_ATTRS,
-    .numasks = LIBPFM_ARRAY_SIZE(snbep_unc_p_occupancy_counters),
-    .umasks  = snbep_unc_p_occupancy_counters
   },
   { .name = "UNC_P_CORE5_TRANSITION_CYCLES",
     .desc = "Core C State Transition Cycles",
     .code = 0x8 | (1ULL << 21), /* sel_ext */
     .cntmsk = 0xf,
-    .ngrp = 1,
     .modmsk = SNBEP_UNC_PCU_ATTRS,
-    .numasks = LIBPFM_ARRAY_SIZE(snbep_unc_p_occupancy_counters),
-    .umasks  = snbep_unc_p_occupancy_counters
   },
   { .name = "UNC_P_CORE6_TRANSITION_CYCLES",
     .desc = "Core C State Transition Cycles",
     .code = 0x9 | (1ULL << 21), /* sel_ext */
     .cntmsk = 0xf,
-    .ngrp = 1,
     .modmsk = SNBEP_UNC_PCU_ATTRS,
-    .numasks = LIBPFM_ARRAY_SIZE(snbep_unc_p_occupancy_counters),
-    .umasks  = snbep_unc_p_occupancy_counters
   },
   { .name = "UNC_P_CORE7_TRANSITION_CYCLES",
     .desc = "Core C State Transition Cycles",
     .code = 0xa | (1ULL << 21), /* sel_ext */
     .cntmsk = 0xf,
-    .ngrp = 1,
     .modmsk = SNBEP_UNC_PCU_ATTRS,
-    .numasks = LIBPFM_ARRAY_SIZE(snbep_unc_p_occupancy_counters),
-    .umasks  = snbep_unc_p_occupancy_counters
   },
   { .name = "UNC_P_DEMOTIONS_CORE0",
     .desc = "Core C State Demotions",
diff --git a/src/libpfm4/lib/pfmlib_intel_ivb_unc.c b/src/libpfm4/lib/pfmlib_intel_ivb_unc.c
index c2f2165..d3160d2 100644
--- a/src/libpfm4/lib/pfmlib_intel_ivb_unc.c
+++ b/src/libpfm4/lib/pfmlib_intel_ivb_unc.c
@@ -64,7 +64,8 @@ pfmlib_pmu_t intel_ivb_unc_cbo##n##_support={ \
 	.max_encoding		= 1,\
 	.pe			= intel_snb_unc_##p##_pe, \
 	.atdesc			= intel_x86_mods, \
-	.flags			= PFMLIB_PMU_FL_RAW_UMASK, \
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK\
+				| PFMLIB_PMU_FL_NO_SMPL,\
 	.pmu_detect		= pfm_ivb_unc_detect, \
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding, \
 	 PFMLIB_ENCODE_PERF(pfm_intel_nhm_unc_get_perf_encoding), \
diff --git a/src/libpfm4/lib/pfmlib_intel_snb_unc.c b/src/libpfm4/lib/pfmlib_intel_snb_unc.c
index b0be6e7..b76c5c0 100644
--- a/src/libpfm4/lib/pfmlib_intel_snb_unc.c
+++ b/src/libpfm4/lib/pfmlib_intel_snb_unc.c
@@ -64,7 +64,8 @@ pfmlib_pmu_t intel_snb_unc_cbo##n##_support={ \
 	.max_encoding		= 1,\
 	.pe			= intel_snb_unc_##p##_pe, \
 	.atdesc			= intel_x86_mods, \
-	.flags			= PFMLIB_PMU_FL_RAW_UMASK, \
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK\
+				| PFMLIB_PMU_FL_NO_SMPL,\
 	.pmu_detect		= pfm_snb_unc_detect, \
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding, \
 	 PFMLIB_ENCODE_PERF(pfm_intel_nhm_unc_get_perf_encoding), \
diff --git a/src/libpfm4/lib/pfmlib_intel_snbep_unc.c b/src/libpfm4/lib/pfmlib_intel_snbep_unc.c
index 94ec7de..9813e1c 100644
--- a/src/libpfm4/lib/pfmlib_intel_snbep_unc.c
+++ b/src/libpfm4/lib/pfmlib_intel_snbep_unc.c
@@ -426,7 +426,7 @@ pfm_intel_snbep_unc_get_encoding(void *this, pfmlib_event_desc_t *e)
 		return PFM_ERR_ATTR;
 	}
 
-	if (modmsk_r && (umodmsk ^ modmsk_r)) {
+	if (modmsk_r && !(umodmsk & modmsk_r)) {
 		DPRINT("required modifiers missing: 0x%x\n", modmsk_r);
 		return PFM_ERR_ATTR;
 	}
diff --git a/src/libpfm4/lib/pfmlib_intel_snbep_unc_cbo.c b/src/libpfm4/lib/pfmlib_intel_snbep_unc_cbo.c
index 8ebd13e..b1dd1d0 100644
--- a/src/libpfm4/lib/pfmlib_intel_snbep_unc_cbo.c
+++ b/src/libpfm4/lib/pfmlib_intel_snbep_unc_cbo.c
@@ -80,7 +80,8 @@ pfmlib_pmu_t intel_snbep_unc_cb##n##_support = {\
 	.max_encoding		= 2,\
 	.pe			= intel_snbep_unc_c_pe,\
 	.atdesc			= snbep_unc_mods,\
-	.flags			= PFMLIB_PMU_FL_RAW_UMASK,\
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK\
+				| PFMLIB_PMU_FL_NO_SMPL,\
 	.pmu_detect		= pfm_intel_snbep_unc_detect,\
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_snbep_unc_get_encoding,\
 	 PFMLIB_ENCODE_PERF(pfm_intel_snbep_unc_get_perf_encoding),\
diff --git a/src/libpfm4/lib/pfmlib_intel_snbep_unc_ha.c b/src/libpfm4/lib/pfmlib_intel_snbep_unc_ha.c
index e50ce0d..28e6b71 100644
--- a/src/libpfm4/lib/pfmlib_intel_snbep_unc_ha.c
+++ b/src/libpfm4/lib/pfmlib_intel_snbep_unc_ha.c
@@ -76,7 +76,8 @@ pfmlib_pmu_t intel_snbep_unc_ha_support = {
 	.max_encoding		= 3, /* address matchers */
 	.pe			= intel_snbep_unc_h_pe,
 	.atdesc			= snbep_unc_mods,
-	.flags			= PFMLIB_PMU_FL_RAW_UMASK,
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK
+				| PFMLIB_PMU_FL_NO_SMPL,
 	.pmu_detect		= pfm_intel_snbep_unc_detect,
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_snbep_unc_get_encoding,
 	 PFMLIB_ENCODE_PERF(pfm_intel_snbep_unc_get_perf_encoding),
diff --git a/src/libpfm4/lib/pfmlib_intel_snbep_unc_imc.c b/src/libpfm4/lib/pfmlib_intel_snbep_unc_imc.c
index 35bfa69..c0cc0e1 100644
--- a/src/libpfm4/lib/pfmlib_intel_snbep_unc_imc.c
+++ b/src/libpfm4/lib/pfmlib_intel_snbep_unc_imc.c
@@ -46,7 +46,8 @@ pfmlib_pmu_t intel_snbep_unc_imc##n##_support = { \
 	.max_encoding		= 1, \
 	.pe			= intel_snbep_unc_m_pe, \
 	.atdesc			= snbep_unc_mods, \
-	.flags			= PFMLIB_PMU_FL_RAW_UMASK, \
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK\
+				| PFMLIB_PMU_FL_NO_SMPL,\
 	.pmu_detect		= pfm_intel_snbep_unc_detect, \
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_snbep_unc_get_encoding, \
 	 PFMLIB_ENCODE_PERF(pfm_intel_snbep_unc_get_perf_encoding), \
diff --git a/src/libpfm4/lib/pfmlib_intel_snbep_unc_pcu.c b/src/libpfm4/lib/pfmlib_intel_snbep_unc_pcu.c
index fb4499f..5d4dd47 100644
--- a/src/libpfm4/lib/pfmlib_intel_snbep_unc_pcu.c
+++ b/src/libpfm4/lib/pfmlib_intel_snbep_unc_pcu.c
@@ -78,7 +78,8 @@ pfmlib_pmu_t intel_snbep_unc_pcu_support = {
 	.max_encoding		= 2,
 	.pe			= intel_snbep_unc_p_pe,
 	.atdesc			= snbep_unc_mods,
-	.flags			= PFMLIB_PMU_FL_RAW_UMASK | INTEL_PMU_FL_UNC_OCC,
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK | INTEL_PMU_FL_UNC_OCC
+				| PFMLIB_PMU_FL_NO_SMPL,
 	.pmu_detect		= pfm_intel_snbep_unc_detect,
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_snbep_unc_get_encoding,
 	 PFMLIB_ENCODE_PERF(pfm_intel_snbep_unc_get_perf_encoding),
diff --git a/src/libpfm4/lib/pfmlib_intel_snbep_unc_perf_event.c b/src/libpfm4/lib/pfmlib_intel_snbep_unc_perf_event.c
index 601806f..e6cc625 100644
--- a/src/libpfm4/lib/pfmlib_intel_snbep_unc_perf_event.c
+++ b/src/libpfm4/lib/pfmlib_intel_snbep_unc_perf_event.c
@@ -110,6 +110,8 @@ pfm_intel_snbep_unc_get_perf_encoding(void *this, pfmlib_event_desc_t *e)
 void
 pfm_intel_snbep_unc_perf_validate_pattrs(void *this, pfmlib_event_desc_t *e)
 {
+	pfmlib_pmu_t *pmu = this;
+	int no_smpl = pmu->flags & PFMLIB_PMU_FL_NO_SMPL;
 	int i, compact;
 
 	for (i = 0; i < e->npattrs; i++) {
@@ -130,11 +132,20 @@ pfm_intel_snbep_unc_perf_validate_pattrs(void *this, pfmlib_event_desc_t *e)
 			if (e->pattrs[i].idx == PERF_ATTR_H)
 				compact = 1;
 
+			if (no_smpl
+			    && (   e->pattrs[i].idx == PERF_ATTR_FR
+			        || e->pattrs[i].idx == PERF_ATTR_PR
+			        || e->pattrs[i].idx == PERF_ATTR_PE))
+				compact = 1;
+
 			/*
 			 * uncore has no priv level support
 			 */
-			if (   e->pattrs[i].idx == PERF_ATTR_U
-			    || e->pattrs[i].idx == PERF_ATTR_K)
+			if (pmu->supported_plm == 0
+			    && (   e->pattrs[i].idx == PERF_ATTR_U
+			        || e->pattrs[i].idx == PERF_ATTR_K
+			        || e->pattrs[i].idx == PERF_ATTR_MG
+			        || e->pattrs[i].idx == PERF_ATTR_MH))
 				compact = 1;
 		}
 
diff --git a/src/libpfm4/lib/pfmlib_intel_snbep_unc_qpi.c b/src/libpfm4/lib/pfmlib_intel_snbep_unc_qpi.c
index 985a494..9cc4bac 100644
--- a/src/libpfm4/lib/pfmlib_intel_snbep_unc_qpi.c
+++ b/src/libpfm4/lib/pfmlib_intel_snbep_unc_qpi.c
@@ -65,7 +65,8 @@ pfmlib_pmu_t intel_snbep_unc_qpi##n##_support = {\
 	.max_encoding		= 3,\
 	.pe			= intel_snbep_unc_q_pe,\
 	.atdesc			= snbep_unc_mods,\
-	.flags			= PFMLIB_PMU_FL_RAW_UMASK,\
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK\
+				| PFMLIB_PMU_FL_NO_SMPL,\
 	.pmu_detect		= pfm_intel_snbep_unc_detect,\
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_snbep_unc_get_encoding,\
 	 PFMLIB_ENCODE_PERF(pfm_intel_snbep_unc_get_perf_encoding),\
diff --git a/src/libpfm4/lib/pfmlib_intel_snbep_unc_r2pcie.c b/src/libpfm4/lib/pfmlib_intel_snbep_unc_r2pcie.c
index 1fd3ca8..c6a64b9 100644
--- a/src/libpfm4/lib/pfmlib_intel_snbep_unc_r2pcie.c
+++ b/src/libpfm4/lib/pfmlib_intel_snbep_unc_r2pcie.c
@@ -45,7 +45,8 @@ pfmlib_pmu_t intel_snbep_unc_r2pcie_support = {
 	.max_encoding		= 1,
 	.pe			= intel_snbep_unc_r2_pe,
 	.atdesc			= snbep_unc_mods,
-	.flags			= PFMLIB_PMU_FL_RAW_UMASK,
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK
+				| PFMLIB_PMU_FL_NO_SMPL,
 	.pmu_detect		= pfm_intel_snbep_unc_detect,
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_snbep_unc_get_encoding,
 	 PFMLIB_ENCODE_PERF(pfm_intel_snbep_unc_get_perf_encoding),
diff --git a/src/libpfm4/lib/pfmlib_intel_snbep_unc_r3qpi.c b/src/libpfm4/lib/pfmlib_intel_snbep_unc_r3qpi.c
index 288abb1..28bb83a 100644
--- a/src/libpfm4/lib/pfmlib_intel_snbep_unc_r3qpi.c
+++ b/src/libpfm4/lib/pfmlib_intel_snbep_unc_r3qpi.c
@@ -46,7 +46,8 @@ pfmlib_pmu_t intel_snbep_unc_r3qpi##n##_support = {\
 	.max_encoding		= 1,\
 	.pe			= intel_snbep_unc_r3_pe,\
 	.atdesc			= snbep_unc_mods,\
-	.flags			= PFMLIB_PMU_FL_RAW_UMASK,\
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK\
+				| PFMLIB_PMU_FL_NO_SMPL,\
 	.pmu_detect		= pfm_intel_snbep_unc_detect,\
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_snbep_unc_get_encoding,\
 	 PFMLIB_ENCODE_PERF(pfm_intel_snbep_unc_get_perf_encoding),\
diff --git a/src/libpfm4/lib/pfmlib_intel_snbep_unc_ubo.c b/src/libpfm4/lib/pfmlib_intel_snbep_unc_ubo.c
index b9b4585..3b8abff 100644
--- a/src/libpfm4/lib/pfmlib_intel_snbep_unc_ubo.c
+++ b/src/libpfm4/lib/pfmlib_intel_snbep_unc_ubo.c
@@ -45,7 +45,8 @@ pfmlib_pmu_t intel_snbep_unc_ubo_support = {
 	.max_encoding		= 1,
 	.pe			= intel_snbep_unc_u_pe,
 	.atdesc			= snbep_unc_mods,
-	.flags			= PFMLIB_PMU_FL_RAW_UMASK,
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK
+				| PFMLIB_PMU_FL_NO_SMPL,
 	.pmu_detect		= pfm_intel_snbep_unc_detect,
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_snbep_unc_get_encoding,
 	 PFMLIB_ENCODE_PERF(pfm_intel_snbep_unc_get_perf_encoding),
diff --git a/src/libpfm4/lib/pfmlib_intel_x86.c b/src/libpfm4/lib/pfmlib_intel_x86.c
index 435ce9e..34c843d 100644
--- a/src/libpfm4/lib/pfmlib_intel_x86.c
+++ b/src/libpfm4/lib/pfmlib_intel_x86.c
@@ -160,6 +160,7 @@ pfm_intel_x86_detect(void)
 
 	pfm_intel_x86_cfg.family = (a >> 8) & 0xf;  // bits 11 - 8
 	pfm_intel_x86_cfg.model  = (a >> 4) & 0xf;  // Bits  7 - 4
+	pfm_intel_x86_cfg.stepping = a & 0xf;	    // Bits 0 - 3
 
 	/* extended family */
 	if (pfm_intel_x86_cfg.family == 0xf)
diff --git a/src/libpfm4/lib/pfmlib_intel_x86_perf_event.c b/src/libpfm4/lib/pfmlib_intel_x86_perf_event.c
index f29af94..460a2c8 100644
--- a/src/libpfm4/lib/pfmlib_intel_x86_perf_event.c
+++ b/src/libpfm4/lib/pfmlib_intel_x86_perf_event.c
@@ -99,8 +99,24 @@ pfm_intel_x86_get_perf_encoding(void *this, pfmlib_event_desc_t *e)
 		DPRINT("%s: unsupported count=%d\n", e->count);
 		return PFM_ERR_NOTSUPP;
 	}
-
+	/* default PMU type */
 	attr->type = PERF_TYPE_RAW;
+
+	/*
+	 * if PMU specifies a perf PMU name, then grab the type
+	 * from sysfs as it is most likely dynamically assigned.
+	 * This allows this function to use used by some uncore PMUs
+	 */
+	if (pmu->perf_name) {
+		int type = find_pmu_type_by_name(pmu->perf_name);
+		if (type == PFM_ERR_NOTSUPP) {
+			DPRINT("perf PMU %s, not supported by OS\n", pmu->perf_name);
+		} else {
+			DPRINT("PMU %s perf type=%d\n", pmu->name, type);
+			attr->type = type;
+		}
+	}
+
 	attr->config = e->codes[0];
 
 	if (e->count > 1) {
@@ -233,6 +249,7 @@ pfm_intel_x86_perf_validate_pattrs(void *this, pfmlib_event_desc_t *e)
 	pfmlib_pmu_t *pmu = this;
 	int i, compact;
 	int has_pebs = intel_x86_event_has_pebs(this, e);
+	int no_smpl = pmu->flags & PFMLIB_PMU_FL_NO_SMPL;
 
 	for (i = 0; i < e->npattrs; i++) {
 		compact = 0;
@@ -261,17 +278,26 @@ pfm_intel_x86_perf_validate_pattrs(void *this, pfmlib_event_desc_t *e)
 			if (e->pattrs[i].idx == PERF_ATTR_H)
 				compact = 1;
 
+			if (no_smpl
+			    && (   e->pattrs[i].idx == PERF_ATTR_FR
+			        || e->pattrs[i].idx == PERF_ATTR_PR
+			        || e->pattrs[i].idx == PERF_ATTR_PE))
+				compact = 1;
 			/*
-			 * uncore has no priv level support
+			 * no priv level support
 			 */
-			if (pmu->type == PFM_PMU_TYPE_UNCORE
-			    && (e->pattrs[i].idx == PERF_ATTR_U
-			        || e->pattrs[i].idx == PERF_ATTR_K))
+			if (pmu->supported_plm == 0
+			    && (   e->pattrs[i].idx == PERF_ATTR_U
+			        || e->pattrs[i].idx == PERF_ATTR_K
+			        || e->pattrs[i].idx == PERF_ATTR_MG
+			        || e->pattrs[i].idx == PERF_ATTR_MH))
 				compact = 1;
 		}
 
 		if (compact) {
+			/* e->npattrs modified by call */
 			pfmlib_compact_pattrs(e, i);
+			/* compensate for i++ */
 			i--;
 		}
 	}
diff --git a/src/libpfm4/lib/pfmlib_intel_x86_priv.h b/src/libpfm4/lib/pfmlib_intel_x86_priv.h
index 1671ca6..0f0c1f5 100644
--- a/src/libpfm4/lib/pfmlib_intel_x86_priv.h
+++ b/src/libpfm4/lib/pfmlib_intel_x86_priv.h
@@ -242,6 +242,7 @@ typedef struct {
 	int model;
 	int family; /* 0 means nothing detected yet */
 	int arch_version;
+	int stepping;
 } pfm_intel_x86_config_t;
 
 extern pfm_intel_x86_config_t pfm_intel_x86_cfg;
diff --git a/src/libpfm4/lib/pfmlib_perf_event.c b/src/libpfm4/lib/pfmlib_perf_event.c
index 91465d4..4458d98 100644
--- a/src/libpfm4/lib/pfmlib_perf_event.c
+++ b/src/libpfm4/lib/pfmlib_perf_event.c
@@ -44,6 +44,10 @@ static const pfmlib_attr_desc_t perf_event_mods[]={
 	PFM_ATTR_B("u", "monitor at user level"),	/* monitor user level */
 	PFM_ATTR_B("k", "monitor at kernel level"),	/* monitor kernel level */
 	PFM_ATTR_B("h", "monitor at hypervisor level"),	/* monitor hypervisor level */
+	PFM_ATTR_SKIP,
+	PFM_ATTR_SKIP,
+	PFM_ATTR_SKIP,
+	PFM_ATTR_SKIP,
 	PFM_ATTR_B("mg", "monitor guest execution"),	/* monitor guest level */
 	PFM_ATTR_B("mh", "monitor host execution"),	/* monitor host level */
 	PFM_ATTR_NULL /* end-marker to avoid exporting number of entries */
@@ -177,7 +181,7 @@ pfmlib_perf_event_encode(void *this, const char *str, int dfl_plm, void *data)
 			attr->sample_period = ival;
 			break;
 		case PERF_ATTR_FR:
-			if (!ival)
+			if (!ival || attr->sample_period)
 				return PFM_ERR_ATTR_VAL;
 			attr->sample_freq = ival;
 			attr->freq = 1;
@@ -216,7 +220,8 @@ pfmlib_perf_event_encode(void *this, const char *str, int dfl_plm, void *data)
 	 * goal here is to set to zero any exclude_* not supported
 	 * by underlying PMU
 	 */
-	plm |= (~pmu->supported_plm) & PFM_PLM_ALL;
+	plm     |= (~pmu->supported_plm) & PFM_PLM_ALL;
+	vmx_plm |= (~pmu->supported_plm) & PFM_PLM_ALL;
 
 	attr->exclude_user   = !(plm & PFM_PLM3);
 	attr->exclude_kernel = !(plm & PFM_PLM0);
@@ -294,6 +299,9 @@ pfmlib_perf_event_encode(void *this, const char *str, int dfl_plm, void *data)
 		case PERF_ATTR_MH:
 			evt_strcat(e.fstr, ":%s=%lu", perf_event_ext_mods[idx].name, !attr->exclude_host);
 			break;
+		case PERF_ATTR_EX:
+			evt_strcat(e.fstr, ":%s=%lu", perf_event_ext_mods[idx].name, attr->exclusive);
+			break;
 		}
 	}
 
@@ -312,11 +320,12 @@ static int
 perf_get_os_nattrs(void *this, pfmlib_event_desc_t *e)
 {
 	pfmlib_os_t *os = this;
-	int i = 0;
-
-	for (; os->atdesc[i].name; i++);
+	int i, n = 0;
 
-	return i;
+	for (i = 0; os->atdesc[i].name; i++)
+		if (!is_empty_attr(os->atdesc+i))
+			n++;
+	return n;
 }
 
 static int
@@ -324,10 +333,14 @@ perf_get_os_attr_info(void *this, pfmlib_event_desc_t *e)
 {
 	pfmlib_os_t *os = this;
 	pfm_event_attr_info_t *info;
-	int i, j = e->npattrs;
+	int i, k, j = e->npattrs;
+
+	for (i = k = 0; os->atdesc[i].name; i++) {
+		/* skip padding entries */
+		if (is_empty_attr(os->atdesc+i))
+			continue;
 
-	for (i = 0; os->atdesc[i].name; i++, j++) {
-		info = e->pattrs+j;
+		info = e->pattrs + j + k;
 
 		info->name = os->atdesc[i].name;
 		info->desc = os->atdesc[i].desc;
@@ -337,8 +350,9 @@ perf_get_os_attr_info(void *this, pfmlib_event_desc_t *e)
 		info->type = os->atdesc[i].type;
 		info->is_dfl = 0;
 		info->ctrl = PFM_ATTR_CTRL_PERF_EVENT;
+		k++;
 	}
-	e->npattrs += i;
+	e->npattrs += k;
 
 	return PFM_SUCCESS;
 }
diff --git a/src/libpfm4/lib/pfmlib_priv.h b/src/libpfm4/lib/pfmlib_priv.h
index 758b65d..d3ed361 100644
--- a/src/libpfm4/lib/pfmlib_priv.h
+++ b/src/libpfm4/lib/pfmlib_priv.h
@@ -25,6 +25,7 @@
 #ifndef __PFMLIB_PRIV_H__
 #define __PFMLIB_PRIV_H__
 #include <perfmon/pfmlib.h>
+#include <string.h>
 
 #define PFM_PLM_ALL (PFM_PLM0|PFM_PLM1|PFM_PLM2|PFM_PLM3|PFM_PLMH)
 
@@ -34,6 +35,7 @@
 
 #define PFM_ATTR_I(y, d) { .name = (y), .type = PFM_ATTR_MOD_INTEGER, .desc = (d) }
 #define PFM_ATTR_B(y, d) { .name = (y), .type = PFM_ATTR_MOD_BOOL, .desc = (d) }
+#define PFM_ATTR_SKIP	 { .name = "" } /* entry not populated (skipped) */
 #define PFM_ATTR_NULL	{ .name = NULL }
 
 #define PFMLIB_EVT_MAX_NAME_LEN	256
@@ -154,6 +156,7 @@ typedef struct {
 #define PFMLIB_PMU_FL_ACTIVE	0x2	/* PMU is initialized + detected on host */
 #define PFMLIB_PMU_FL_RAW_UMASK	0x4	/* PMU supports PFM_ATTR_RAW_UMASKS */
 #define PFMLIB_PMU_FL_ARCH_DFL	0x8	/* PMU is arch default */
+#define PFMLIB_PMU_FL_NO_SMPL	0x10	/* PMU does not support sampling */
 
 typedef struct {
 	int	initdone;
@@ -372,4 +375,10 @@ pfmlib_pidx2idx(pfmlib_pmu_t *pmu, int pidx)
 	.os_detect[PFM_OS_PERF_EVENT_EXT] = NULL
 #endif
 
+static inline int
+is_empty_attr(const pfmlib_attr_desc_t *a)
+{
+	return !a || !a->name || strlen(a->name) == 0 ? 1 : 0;
+}
+
 #endif /* __PFMLIB_PRIV_H__ */
diff --git a/src/libpfm4/perf_examples/perf_util.h b/src/libpfm4/perf_examples/perf_util.h
index 6252225..04704bd 100644
--- a/src/libpfm4/perf_examples/perf_util.h
+++ b/src/libpfm4/perf_examples/perf_util.h
@@ -89,6 +89,7 @@ perf_scale(uint64_t *values)
 static inline uint64_t
 perf_scale_delta(uint64_t *values, uint64_t *prev_values)
 {
+	double pval[3], val[3];
 	uint64_t res = 0;
 
 	if (!values[2] && !values[1] && values[0])
@@ -97,8 +98,16 @@ perf_scale_delta(uint64_t *values, uint64_t *prev_values)
 	if (values[2] > values[1])
 		warnx("WARNING: time_running > time_enabled\n");
 
-	if (values[2] - prev_values[2])
-		res = (uint64_t)((double)((values[0] - prev_values[0]) * (values[1] - prev_values[1])/ (values[2] - prev_values[2])));
+	if (values[2] - prev_values[2]) {
+		/* covnert everything to double to avoid overflows! */
+		pval[0] = prev_values[0];
+		pval[1] = prev_values[1];
+		pval[2] = prev_values[2];
+		val[0] = values[0];
+		val[1] = values[1];
+		val[2] = values[2];
+		res = (uint64_t)(((val[0] - pval[0]) * (val[1] - pval[1])/ (val[2] - pval[2])));
+	}
 	return res;
 }
 
diff --git a/src/libpfm4/tests/validate_x86.c b/src/libpfm4/tests/validate_x86.c
index f351bc0..955df41 100644
--- a/src/libpfm4/tests/validate_x86.c
+++ b/src/libpfm4/tests/validate_x86.c
@@ -1062,7 +1062,21 @@ static const test_event_t x86_test_events[]={
 	  .ret  = PFM_SUCCESS,
 	  .count = 1,
 	  .codes[0] = 0x53045f,
-	  .fstr = "ivb::TLB_ACCESS:LOAD_STLB_HIT:k=1:u=1:e=0:i=0:c=0:t=0",
+	  .fstr = "ivb::DTLB_LOAD_ACCESS:STLB_HIT:k=1:u=1:e=0:i=0:c=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivb::TLB_ACCESS:STLB_HIT",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x53045f,
+	  .fstr = "ivb::DTLB_LOAD_ACCESS:STLB_HIT:k=1:u=1:e=0:i=0:c=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivb::DTLB_LOAD_ACCESS:STLB_HIT",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x53045f,
+	  .fstr = "ivb::DTLB_LOAD_ACCESS:STLB_HIT:k=1:u=1:e=0:i=0:c=0:t=0",
 	},
 	{ SRC_LINE,
 	  .name = "ivb::MOVE_ELIMINATION:INT_NOT_ELIMINATED",
@@ -1086,6 +1100,31 @@ static const test_event_t x86_test_events[]={
 	  .fstr = "ivb::RESOURCE_STALLS:RS:ROB:k=1:u=1:e=0:i=0:c=0:t=0",
 	},
 	{ SRC_LINE,
+	  .name = "ivb::UOPS_EXECUTED:THREAD",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x5301b1,
+	  .fstr = "ivb::UOPS_EXECUTED:THREAD:k=1:u=1:e=0:i=0:c=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivb::UOPS_EXECUTED:THREAD:e:c=1",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x15701b1,
+	  .fstr = "ivb::UOPS_EXECUTED:THREAD:k=1:u=1:e=1:i=0:c=1:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivb::UOPS_EXECUTED:THREAD:e",
+	  .ret  = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "ivb::UOPS_EXECUTED:THREAD:c=1:i",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x1d301b1,
+	  .fstr = "ivb::UOPS_EXECUTED:THREAD:k=1:u=1:e=0:i=1:c=1:t=0",
+	},
+	{ SRC_LINE,
 	  .name = "ivb::CPU_CLK_UNHALTED:REF_P",
 	  .ret  = PFM_SUCCESS,
 	  .count = 1,
@@ -1346,11 +1385,11 @@ static const test_event_t x86_test_events[]={
 	  .fstr = "snbep_unc_pcu::UNC_P_CLOCKTICKS:e=0:i=0:t=1",
 	},
 	{ SRC_LINE,
-	  .name = "snbep_unc_pcu::UNC_P_CORE0_TRANSITION_CYCLES:C6",
+	  .name = "snbep_unc_pcu::UNC_P_CORE0_TRANSITION_CYCLES",
 	  .ret  = PFM_SUCCESS,
 	  .count = 1,
-	  .codes[0] = 0x200303,
-	  .fstr = "snbep_unc_pcu::UNC_P_CORE0_TRANSITION_CYCLES:C6:e=0:i=0:t=0",
+	  .codes[0] = 0x200003,
+	  .fstr = "snbep_unc_pcu::UNC_P_CORE0_TRANSITION_CYCLES:e=0:i=0:t=0",
 	},
 	{ SRC_LINE,
 	  .name = "snbep_unc_pcu::UNC_P_FREQ_BAND0_CYCLES",
@@ -1401,6 +1440,38 @@ static const test_event_t x86_test_events[]={
 	  .fstr = "snbep_unc_pcu::UNC_P_FREQ_BAND3_CYCLES:e=0:i=0:t=0:ff=40",
 	},
 	{ SRC_LINE,
+	  .name = "snbep_unc_pcu::UNC_P_FREQ_BAND0_CYCLES:ff=32:e",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x4000b,
+	  .codes[1] = 0x20,
+	  .fstr = "snbep_unc_pcu::UNC_P_FREQ_BAND0_CYCLES:e=1:i=0:t=0:ff=32",
+	},
+	{ SRC_LINE,
+	  .name = "snbep_unc_pcu::UNC_P_FREQ_BAND0_CYCLES:ff=32:i",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x80000b,
+	  .codes[1] = 0x20,
+	  .fstr = "snbep_unc_pcu::UNC_P_FREQ_BAND0_CYCLES:e=0:i=1:t=0:ff=32",
+	},
+	{ SRC_LINE,
+	  .name = "snbep_unc_pcu::UNC_P_FREQ_BAND0_CYCLES:ff=32:e:i",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x84000b,
+	  .codes[1] = 0x20,
+	  .fstr = "snbep_unc_pcu::UNC_P_FREQ_BAND0_CYCLES:e=1:i=1:t=0:ff=32",
+	},
+	{ SRC_LINE,
+	  .name = "snbep_unc_pcu::UNC_P_FREQ_BAND0_CYCLES:ff=32:e:i:t=4",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x484000b,
+	  .codes[1] = 0x20,
+	  .fstr = "snbep_unc_pcu::UNC_P_FREQ_BAND0_CYCLES:e=1:i=1:t=4:ff=32",
+	},
+	{ SRC_LINE,
 	  .name = "SNBEP_UNC_PCU::UNC_P_POWER_STATE_OCCUPANCY:CORES_C0",
 	  .ret  = PFM_SUCCESS,
 	  .count = 1,
@@ -1970,6 +2041,34 @@ static const test_event_t x86_test_events[]={
 };
 #define NUM_TEST_EVENTS (int)(sizeof(x86_test_events)/sizeof(test_event_t))
 
+static int
+check_pmu_supported(const char *evt)
+{
+	pfm_pmu_info_t info;
+	char *p;
+	int i, ret;
+
+	memset(&info, 0, sizeof(info));
+	info.size = sizeof(info);
+
+	/* look for pmu_name::.... */
+	p = strchr(evt, ':');
+	if (!p)
+		return 1;
+	if (*(p+1) != ':')
+		return 1;
+
+	pfm_for_all_pmus(i) {
+		ret = pfm_get_pmu_info(i, &info);
+		if (ret != PFM_SUCCESS)
+			continue;
+		if (!strncmp(info.name, evt, p - evt))
+			return 1;
+	}
+	/* PMU not there */
+	return 0;
+}
+
 static int check_test_events(FILE *fp)
 {
 	const test_event_t *e;
@@ -1984,6 +2083,10 @@ static int check_test_events(FILE *fp)
 		fstr = NULL;
 		ret = pfm_get_event_encoding(e->name, PFM_PLM0 | PFM_PLM3, &fstr, NULL, &codes, &count);
 		if (ret != e->ret) {
+			if (ret == PFM_ERR_NOTFOUND && !check_pmu_supported(e->name)) {
+				fprintf(fp,"Line %d, Event%d %s, skipped because no PMU support\n", e->line, i, e->name);
+				continue;
+			}
 			fprintf(fp,"Line %d, Event%d %s, ret=%s(%d) expected %s(%d)\n", e->line, i, e->name, pfm_strerror(ret), ret, pfm_strerror(e->ret), e->ret);
 			errors++;
 		} else {
-- 
2.1.0

From ade8ff4fb2e2e8273cbcad140eafb64052b552e4 Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Mon, 11 Nov 2013 12:04:32 -0500
Subject: [PATCH 05/24] Libpfm4 update

commit fe3e6e865e98cd7f1743a26896e777873ae8b682
Author: Stephane Eranian <eranian@gmail.com>
Date:   Mon Nov 11 17:58:19 2013 +0100

    add missing Core select umasks to AMD Fam15h event table

    As documented in BKDG Fam15 rev 3.08.

    As per encoding, the core_select umasks cannot be combined.
    User has to select either ANY_CORE or one specific core, e.g.,
    CORE_1. Default is ANY_CORE for all relevant events.

    Patch adds corresponding tests to validation test suite.

diff --git a/src/libpfm4/lib/events/amd64_events_fam15h.h b/src/libpfm4/lib/events/amd64_events_fam15h.h
index 5738e4c..ac2b111 100644
--- a/src/libpfm4/lib/events/amd64_events_fam15h.h
+++ b/src/libpfm4/lib/events/amd64_events_fam15h.h
@@ -40,6 +40,62 @@
  * Processors, Rev 0.90, May 18, 2010
  */
 
+#define CORE_SELECT(b) \
+   { .uname  = "CORE_0",\
+     .udesc  = "Measure on Core0",\
+     .ucode = 0 << 4,\
+     .grpid = b,\
+     .uflags= AMD64_FL_NCOMBO,\
+   },\
+   { .uname  = "CORE_1",\
+     .udesc  = "Measure on Core1",\
+     .ucode = 1 << 4,\
+     .grpid = b,\
+     .uflags= AMD64_FL_NCOMBO,\
+   },\
+   { .uname  = "CORE_2",\
+     .udesc  = "Measure on Core2",\
+     .ucode = 2 << 4,\
+     .grpid = b,\
+     .uflags= AMD64_FL_NCOMBO,\
+   },\
+   { .uname  = "CORE_3",\
+     .udesc  = "Measure on Core3",\
+     .ucode = 3 << 4,\
+     .grpid = b,\
+     .uflags= AMD64_FL_NCOMBO,\
+   },\
+   { .uname  = "CORE_4",\
+     .udesc  = "Measure on Core4",\
+     .ucode = 4 << 4,\
+     .grpid = b,\
+     .uflags= AMD64_FL_NCOMBO,\
+   },\
+   { .uname  = "CORE_5",\
+     .udesc  = "Measure on Core5",\
+     .ucode = 5 << 4,\
+     .grpid = b,\
+     .uflags= AMD64_FL_NCOMBO,\
+   },\
+   { .uname  = "CORE_6",\
+     .udesc  = "Measure on Core6",\
+     .ucode = 6 << 4,\
+     .grpid = b,\
+     .uflags= AMD64_FL_NCOMBO,\
+   },\
+   { .uname  = "CORE_7",\
+     .udesc  = "Measure on Core7",\
+     .ucode = 7 << 4,\
+     .grpid = b,\
+     .uflags= AMD64_FL_NCOMBO,\
+   },\
+   { .uname  = "ANY_CORE",\
+     .udesc  = "Measure on any core",\
+     .ucode = 0xf << 4,\
+     .grpid = b,\
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,\
+   }
+
 static const amd64_umask_t amd64_fam15h_dispatched_fpu_ops[]={
    { .uname  = "OPS_PIPE0",
      .udesc  = "Total number uops assigned to Pipe 0",
@@ -1639,20 +1695,30 @@ static const amd64_umask_t amd64_fam15h_read_request_to_l3_cache[]={
    { .uname = "READ_BLOCK_EXCLUSIVE",
      .udesc = "Read Block Exclusive (Data cache read)",
      .ucode = 0x1,
+     .grpid = 0,
    },
    { .uname = "READ_BLOCK_SHARED",
      .udesc = "Read Block Shared (Instruction cache read)",
      .ucode = 0x2,
+     .grpid = 0,
    },
    { .uname = "READ_BLOCK_MODIFY",
      .udesc = "Read Block Modify",
      .ucode = 0x4,
+     .grpid = 0,
    },
-   { .uname  = "ALL",
-     .udesc  = "All sub-events selected",
+   { .uname = "PREFETCH",
+     .udesc = "Count prefetches honly",
+     .ucode = 0x8,
+     .grpid = 0,
+   },
+   { .uname  = "READ_BLOCK_ANY",
+     .udesc  = "Count any read request",
      .ucode = 0x7,
-     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+     .grpid = 0,
+     .uflags= AMD64_FL_DFL | AMD64_FL_NCOMBO,
    },
+  CORE_SELECT(1),
 };
 
 static const amd64_umask_t amd64_fam15h_l3_fills_caused_by_l2_evictions[]={
@@ -1682,13 +1748,7 @@ static const amd64_umask_t amd64_fam15h_l3_fills_caused_by_l2_evictions[]={
      .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
      .grpid = 0,
    },
-   { .uname = "ALL_CORES",
-     .udesc = "All core",
-     .ucode = 0xf0,
-     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
-     .grpid = 1,
-   },
-
+   CORE_SELECT(1),
  };
 
 static const amd64_umask_t amd64_fam15h_l3_evictions[]={
@@ -2421,7 +2481,7 @@ static const amd64_entry_t amd64_fam15h_pe[]={
   .desc    = "Read Request to L3 Cache",
   .code    = 0x4e0,
   .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_read_request_to_l3_cache),
-  .ngrp    = 1,
+  .ngrp    = 2,
   .umasks  = amd64_fam15h_read_request_to_l3_cache,
 },
 { .name    = "L3_CACHE_MISSES",
@@ -2449,7 +2509,7 @@ static const amd64_entry_t amd64_fam15h_pe[]={
   .desc    = "Non-canceled L3 Read Requests",
   .code    = 0x4ed,
   .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_read_request_to_l3_cache),
-  .ngrp    = 1,
+  .ngrp    = 2,
   .umasks  = amd64_fam15h_read_request_to_l3_cache,
 },
 { .name    = "L3_LATENCY",
diff --git a/src/libpfm4/tests/validate_x86.c b/src/libpfm4/tests/validate_x86.c
index 955df41..0fc36c7 100644
--- a/src/libpfm4/tests/validate_x86.c
+++ b/src/libpfm4/tests/validate_x86.c
@@ -1917,6 +1917,42 @@ static const test_event_t x86_test_events[]={
 	  .fstr = "amd64_fam15h_interlagos::DISPATCHED_FPU_OPS:0xff:k=0:u=1:e=0:i=0:c=0:h=0:g=0"
 	},
 	{ SRC_LINE,
+	  .name = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE:read_block_modify:core_3",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x4005334e0ull,
+	  .fstr = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE:READ_BLOCK_MODIFY:CORE_3",
+	},
+	{ SRC_LINE,
+	  .name = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x40053f7e0ull,
+	  .fstr = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE:READ_BLOCK_ANY:ANY_CORE",
+	},
+	{ SRC_LINE,
+	  .name = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE:READ_BLOCK_EXCLUSIVE:PREFETCH:READ_BLOCK_MODIFY:core_4",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x400534de0ull,
+	  .fstr = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE:READ_BLOCK_EXCLUSIVE:READ_BLOCK_MODIFY:PREFETCH:CORE_4",
+	},
+	{ SRC_LINE,
+	  .name = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE:read_block_any:prefetch:core_1",
+	  .ret  = PFM_ERR_FEATCOMB, /* must use individual umasks to combine with prefetch */
+	},
+	{ SRC_LINE,
+	  .name = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE:read_block_any:prefetch:core_1:core_3",
+	  .ret  = PFM_ERR_FEATCOMB, /* core umasks cannot be combined */
+	},
+	{ SRC_LINE,
+	  .name = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE:prefetch:core_0",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x4005308e0ull,
+	  .fstr = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE:PREFETCH:CORE_0",
+	},
+	{ SRC_LINE,
 	  .name = "ivb_ep::mem_load_uops_llc_miss_retired:local_dram",
 	  .ret = PFM_SUCCESS,
 	  .count = 1,
-- 
2.1.0

From ff3e15da3f96cba7ee47776016418628e8fd5ea4 Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Thu, 21 Nov 2013 16:39:43 -0500
Subject: [PATCH 06/24] libpfm4: Pull in the latest updates

Brings us upto
commit 0b87987b121a9eb2a67652e1d164e9b7e404412b
Author: Stephane Eranian <eranian@gmail.com>
Date:   Tue Nov 19 00:36:45 2013 +0100

    increase number of groups for examples

    to allow bigger event sets for testing

    Signed-off-by: Stephane Eranian <eranian@gmail.com>

diff --git a/src/libpfm4/libpfm.spec b/src/libpfm4/libpfm.spec
index 84ff2ce..31756dd 100644
--- a/src/libpfm4/libpfm.spec
+++ b/src/libpfm4/libpfm.spec
@@ -3,7 +3,7 @@
 %define python_prefix %(python -c "import sys; print sys.prefix")
 
 Name:		libpfm
-Version:	4.3.0
+Version:	4.4.0
 Release:	1%{?dist}
 
 Summary:	Library to encode performance events for use by perf tool
@@ -97,6 +97,15 @@ rm -fr $RPM_BUILD_ROOT
 %endif
 
 %changelog
+* Wed Nov 13 2013 Lukas Berk <lberk@redhat.com> 4.4.0-1
+- Intel IVB-EP support
+- Intel IVB updates support
+- Intel SNB updates support
+- Intel SNB-EP uncore support
+- ldlat support (PEBS-LL)
+- New Intel Atom support
+- bug fixes
+
 * Tue Aug 28 2012 Stephane Eranian  <eranian@gmail.com> 4.3.0-1
 - ARM Cortex A15 support
 - updated Intel Sandy Bridge core PMU events
diff --git a/src/libpfm4/perf_examples/syst_count.c b/src/libpfm4/perf_examples/syst_count.c
index 7771277..df2ed0a 100644
--- a/src/libpfm4/perf_examples/syst_count.c
+++ b/src/libpfm4/perf_examples/syst_count.c
@@ -37,7 +37,7 @@
 
 #include "perf_util.h"
 
-#define MAX_GROUPS	16
+#define MAX_GROUPS	256
 #define MAX_PATH	1024
 
 #ifndef STR
diff --git a/src/libpfm4/perf_examples/task.c b/src/libpfm4/perf_examples/task.c
index 392602f..c72d90c 100644
--- a/src/libpfm4/perf_examples/task.c
+++ b/src/libpfm4/perf_examples/task.c
@@ -35,7 +35,7 @@
 
 #include "perf_util.h"
 
-#define MAX_GROUPS 16
+#define MAX_GROUPS 256
 
 typedef struct {
 	const char *events[MAX_GROUPS];
diff --git a/src/libpfm4/perf_examples/task_cpu.c b/src/libpfm4/perf_examples/task_cpu.c
index 52d6938..1541a49 100644
--- a/src/libpfm4/perf_examples/task_cpu.c
+++ b/src/libpfm4/perf_examples/task_cpu.c
@@ -36,7 +36,7 @@
 
 #include "perf_util.h"
 
-#define MAX_GROUPS	16
+#define MAX_GROUPS	256
 #define MAX_CPUS	64
 
 typedef struct {
-- 
2.1.0

From 41fa460ea2cb6f092dda0517b886396b79b073b7 Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Mon, 2 Dec 2013 12:57:29 -0500
Subject: [PATCH 07/24] Libpfm4 Update

---------------------------------------------------------
commit b81ff2dc94f7e9acee2c4ba306d13e343cce4a18
Author: Stephane Eranian <eranian@gmail.com>
Date:   Sun Dec 1 17:12:49 2013 +0100

    fix compiler warning on pfm_intel_rapl_get_encoding()

    Avoid clang warning

    Signed-off-by: Stephane Eranian <eranian@gmail.com>
---------------------------------------------------------

diff --git a/src/libpfm4/README b/src/libpfm4/README
index 905b768..a765cb4 100644
--- a/src/libpfm4/README
+++ b/src/libpfm4/README
@@ -37,7 +37,7 @@ The library supports many PMUs. The current version can handle:
 		AMD64 Fam11h (Turion)
 		AMD64 Fam12h (Llano)
 		AMD64 Fam14h (Bobcat)
-		AMD64 Fam15h (Bulldozer)
+		AMD64 Fam15h (Bulldozer) (core and uncore)
 
 	- For Intel X86: 
 		Intel P6 (Pentium II, Pentium Pro, Pentium III, Pentium M)
@@ -48,6 +48,8 @@ The library supports many PMUs. The current version can handle:
 		Intel Sandy Bridge
 		Intel Ivy Bridge
 		Intel Haswell
+		Intel Silvermont
+		Intel RAPL (energy consumption)
 		Intel Knights Corner
 		Intel architectural perfmon v1, v2, v3
 
diff --git a/src/libpfm4/docs/Makefile b/src/libpfm4/docs/Makefile
index 59678f41..f24999f 100644
--- a/src/libpfm4/docs/Makefile
+++ b/src/libpfm4/docs/Makefile
@@ -36,6 +36,7 @@ ARCH_MAN=libpfm_intel_core.3	\
 	 libpfm_amd64_k7.3	\
 	 libpfm_amd64_k8.3	\
 	 libpfm_amd64_fam10h.3	\
+	 libpfm_amd64_fam15h.3	\
 	 libpfm_intel_atom.3	\
 	 libpfm_intel_nhm.3	\
 	 libpfm_intel_nhm_unc.3 \
@@ -46,6 +47,8 @@ ARCH_MAN=libpfm_intel_core.3	\
 	 libpfm_intel_ivb.3	\
 	 libpfm_intel_ivb_unc.3 \
 	 libpfm_intel_hsw.3	\
+	 libpfm_intel_rapl.3	\
+	 libpfm_intel_slm.3	\
 	 libpfm_intel_snbep_unc_cbo.3 \
 	 libpfm_intel_snbep_unc_ha.3 \
 	 libpfm_intel_snbep_unc_imc.3 \
diff --git a/src/libpfm4/docs/man3/libpfm_amd64_fam15h.3 b/src/libpfm4/docs/man3/libpfm_amd64_fam15h.3
new file mode 100644
index 0000000..84ae455
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_amd64_fam15h.3
@@ -0,0 +1,55 @@
+.TH LIBPFM 3  "Nov, 2013" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_amd64_fam15h - support for AMD64 Family 15h processors
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: amd64_fam15h_interlagos
+.B PMU desc: AMD64 Fam15h Interlagos
+.B PMU name: amd64_fam15h_nb
+.B PMU desc: AMD64 Fam15h Northbridge
+.sp
+.SH DESCRIPTION
+The library supports AMD Family 15h processors core PMU in both 32 and 64-bit modes. The
+uncore PMU (Northbridge) is also supported as a separate PMU model.
+
+.SH MODIFIERS
+The following modifiers are supported on AMD64 Family 15h core PMU:
+.TP
+.B u
+Measure at user level which includes privilege levels 1, 2, 3. This corresponds to \fBPFM_PLM3\fR.
+This is a boolean modifier.
+.TP
+.B k
+Measure at kernel level which includes privilege level 0. This corresponds to \fBPFM_PLM0\fR.
+This is a boolean modifier.
+.TP
+.B h
+Measure at while executing in host mode (when using virtualization). This corresponds to \fBPFM_PLMH\fR.
+This modifier is available starting with Fam10h. This is a boolean modifier.
+.TP
+.B g
+Measure at while executing in guest mode (when using virtualization). This modifier is available
+starting with Fam10h. This is a boolean modifier.
+.TP
+.B i
+Invert the meaning of the event. The counter will now count cycles in which the event is \fBnot\fR
+occurring. This is a boolean modifier
+.TP
+.B e
+Enable edge detection, i.e., count only when there is a state transition. This is a boolean modifier.
+.TP
+.B c
+Set the counter mask value. The mask acts as a threshold. The counter will count the number of cycles
+in which the number of occurrences of the event is greater or equal to the threshold. This is an integer
+modifier with values in the range [0:255].
+.TP
+The uncore (NorthBridge) PMU \fBdoes not support\fR any modifiers.
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+Robert Richter <robert.richter@amd.com>
+.if
+.PP
diff --git a/src/libpfm4/docs/man3/libpfm_intel_rapl.3 b/src/libpfm4/docs/man3/libpfm_intel_rapl.3
new file mode 100644
index 0000000..cf7835c
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_intel_rapl.3
@@ -0,0 +1,39 @@
+.TH LIBPFM 3  "November, 2013" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_intel_rapl - support for Intel RAPL PMU
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: rapl
+.B PMU desc: Intel RAPL (Intel SandyBridge, IvyBridge, Haswell)
+.sp
+.SH DESCRIPTION
+The library supports the Intel Running Average Power Limit (RAPL)
+energy consomption counters. This is a socket-level set of counters
+which reports energy consumption in Joules. There are up to 3 counters
+each measuring only one event. The following events are defined:
+.TP
+.B  RAPL_ENERGY_CORES
+On all processors, the event reports the number of Joules consumed by all cores.
+ On all processors,
+.TP
+.B RAPL_ENERGYC_PKG
+On all processors, th event reports the number of Joules consumed by all
+the cores and Last Level cache (L3).
+.TP
+.B RAPL_ENERGY_DRAM
+On server processors, the event reports the number of Joules consumed
+n by the DRAM controller.
+
+By construction, the events are socket-level and can only be measured in
+system-wide mode. It is necessary and sufficient to measure only one CPU
+per socket to get meaningful results.
+
+.SH MODIFIERS
+The PMU does not support any modifiers.
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.PP
diff --git a/src/libpfm4/docs/man3/pfm_get_event_encoding.3 b/src/libpfm4/docs/man3/pfm_get_event_encoding.3
index dce196b..10187c7 100644
--- a/src/libpfm4/docs/man3/pfm_get_event_encoding.3
+++ b/src/libpfm4/docs/man3/pfm_get_event_encoding.3
@@ -59,7 +59,7 @@ specific man page.
 The raw encoding means the encoding as mandated by the underlying PMU model. It may not be directly suitable
 to pass to a kernel API. You may want to use API-specific library calls to ensure the correct encoding is passed.
 
-If \fBfstr\fR is not NULL, it will point to the fully qualified event string upon succesful return. The string
+If \fBfstr\fR is not NULL, it will point to the fully qualified event string upon successful return. The string
 contains the event name, any umask set, and the value of all the modifiers. It reflects what the encoding will
 actually measure. The function allocates the memory to store the string. The caller must eventually free the
 string.
diff --git a/src/libpfm4/docs/man3/pfm_get_event_next.3 b/src/libpfm4/docs/man3/pfm_get_event_next.3
index da0be17..3a14af6 100644
--- a/src/libpfm4/docs/man3/pfm_get_event_next.3
+++ b/src/libpfm4/docs/man3/pfm_get_event_next.3
@@ -12,7 +12,7 @@ Events are uniquely identified with opaque integer identifiers.
 There is no guaranteed order within identifiers. Thus, to list 
 all the events, it is necessary to use iterators.
 
-Events are grouped in tables within the libary. A table usually
+Events are grouped in tables within the library. A table usually
 corresponds to a PMU model or family. The library contains support
 for multiple PMU models, thus it has multiple tables. Based on the
 host hardware and software environments, tables get activated when
@@ -30,7 +30,7 @@ is usually obainted via \fBpfm_get_pmu_info()\fR.
 The \fBpfm_get_event_next()\fR function returns the identifier of
 next supported event after the one passed in \fBidx\fR. This iterator
 stops when the last event for the PMU is passed as argument, in which
-case the function returns -1.
+case the function returns \-1.
 .sp
 .nf
 void list_pmu_events(pfm_pmu_t pmu)
@@ -49,7 +49,7 @@ void list_pmu_events(pfm_pmu_t pmu)
    if (ret != PFM_SUCCESS)
       errx(1, "cannot get pmu info");
 
-   for (i = pinfo.first_event; i != -1; i = pfm_get_event_next(i)) {
+   for (i = pinfo.first_event; i != \-1; i = pfm_get_event_next(i)) {
       ret = pfm_get_event_info(i, &info);
       if (ret != PFM_SUCCESS)
         errx(1, "cannot get event info");
@@ -63,11 +63,11 @@ void list_pmu_events(pfm_pmu_t pmu)
 
 .SH RETURN
 The function returns the identifier of the next
-supported event. It returns -1 when the argument is already the last
+supported event. It returns \-1 when the argument is already the last
 event for the PMU.
 
 .SH ERRORS
-No error code, besides -1, is returned by this function.
+No error code, besides \-1, is returned by this function.
 .SH SEE ALSO
 pfm_find_event(3)
 .SH AUTHOR
diff --git a/src/libpfm4/docs/man3/pfm_strerror.3 b/src/libpfm4/docs/man3/pfm_strerror.3
index 5853d68..85ef404 100644
--- a/src/libpfm4/docs/man3/pfm_strerror.3
+++ b/src/libpfm4/docs/man3/pfm_strerror.3
@@ -12,7 +12,7 @@ This function returns a string which describes the libpfm error
 value in \fBcode\fR. The string returned by the call is \fBread-only\fR.
 
 The function must \fBonly\fR be used with libpfm calls documented to return
-specific error codes. The value -1 is not considered a specific error code.
+specific error codes. The value \-1 is not considered a specific error code.
 Strings and \fBpfm_pmu_t\fR return values cannot be used with this function.
 Typically \fBNULL\fR is returned in case of error for string values, and
 \fBPFM_PMU_NONE\fR is returned for \fBpfm_pmu_t\fR values.
diff --git a/src/libpfm4/include/perfmon/pfmlib.h b/src/libpfm4/include/perfmon/pfmlib.h
index 89b9fd8..ac9ed03 100644
--- a/src/libpfm4/include/perfmon/pfmlib.h
+++ b/src/libpfm4/include/perfmon/pfmlib.h
@@ -191,6 +191,10 @@ typedef enum {
 	PFM_PMU_INTEL_IVB_UNC_CB3,	/* Intel IvyBridge C-box 3 uncore PMU */
 
 	PFM_PMU_POWER8,			/* IBM POWER8 */
+	PFM_PMU_INTEL_RAPL,		/* Intel RAPL */
+
+	PFM_PMU_INTEL_SLM,		/* Intel Silvermont */
+	PFM_PMU_AMD64_FAM15H_NB,	/* AMD AMD64 Fam15h NorthBridge */
 
 	/* MUST ADD NEW PMU MODELS HERE */
 
diff --git a/src/libpfm4/lib/Makefile b/src/libpfm4/lib/Makefile
index 98411b8..02dcfbb 100644
--- a/src/libpfm4/lib/Makefile
+++ b/src/libpfm4/lib/Makefile
@@ -60,6 +60,7 @@ SRCS   += pfmlib_amd64.c pfmlib_intel_core.c pfmlib_intel_x86.c \
 	  pfmlib_intel_snb.c pfmlib_intel_snb_unc.c \
 	  pfmlib_intel_ivb.c pfmlib_intel_ivb_unc.c \
 	  pfmlib_intel_hsw.c \
+	  pfmlib_intel_rapl.c \
 	  pfmlib_intel_snbep_unc.c \
 	  pfmlib_intel_snbep_unc_cbo.c \
 	  pfmlib_intel_snbep_unc_ha.c \
@@ -70,6 +71,7 @@ SRCS   += pfmlib_amd64.c pfmlib_intel_core.c pfmlib_intel_x86.c \
 	  pfmlib_intel_snbep_unc_r2pcie.c \
 	  pfmlib_intel_snbep_unc_r3qpi.c \
 	  pfmlib_intel_knc.c \
+	  pfmlib_intel_slm.c \
 	  pfmlib_intel_netburst.c \
 	  pfmlib_amd64_k7.c pfmlib_amd64_k8.c pfmlib_amd64_fam10h.c \
 	  pfmlib_amd64_fam11h.c pfmlib_amd64_fam12h.c \
@@ -216,7 +218,8 @@ INC_X86= pfmlib_intel_x86_priv.h	\
 	events/intel_snbep_unc_ubo_events.h \
 	events/intel_snbep_unc_r2pcie_events.h \
 	events/intel_snbep_unc_r3qpi_events.h \
-	events/intel_knc_events.h
+	events/intel_knc_events.h \
+	events/intel_slm_events.h
 
 INC_MIPS=events/mips_74k_events.h events/mips_74k_events.h
 
diff --git a/src/libpfm4/lib/events/amd64_events_fam15h.h b/src/libpfm4/lib/events/amd64_events_fam15h.h
index ac2b111..7872468 100644
--- a/src/libpfm4/lib/events/amd64_events_fam15h.h
+++ b/src/libpfm4/lib/events/amd64_events_fam15h.h
@@ -2295,228 +2295,4 @@ static const amd64_entry_t amd64_fam15h_pe[]={
   .modmsk  = AMD64_FAM15H_ATTRS,
   .code    = 0x1d8,
 },
-{ .name    = "DRAM_ACCESSES",
-  .desc    = "DRAM Accesses",
-  .code    = 0xe0,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_dram_accesses),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_dram_accesses,
-},
-{ .name    = "DRAM_CONTROLLER_PAGE_TABLE_OVERFLOWS",
-  .desc    = "DRAM Controller Page Table Overflows",
-  .code    = 0xe1,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_dram_controller_page_table_overflows),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_dram_controller_page_table_overflows,
-},
-{ .name    = "MEMORY_CONTROLLER_DRAM_COMMAND_SLOTS_MISSED",
-  .desc    = "Memory Controller DRAM Command Slots Missed",
-  .code    = 0xe2,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_memory_controller_dram_command_slots_missed),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_memory_controller_dram_command_slots_missed,
-},
-{ .name    = "MEMORY_CONTROLLER_TURNAROUNDS",
-  .desc    = "Memory Controller Turnarounds",
-  .code    = 0xe3,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_memory_controller_turnarounds),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_memory_controller_turnarounds,
-},
-{ .name    = "MEMORY_CONTROLLER_BYPASS_COUNTER_SATURATION",
-  .desc    = "Memory Controller Bypass Counter Saturation",
-  .code    = 0xe4,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_memory_controller_bypass_counter_saturation),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_memory_controller_bypass_counter_saturation,
-},
-{ .name    = "THERMAL_STATUS",
-  .desc    = "Thermal Status",
-  .code    = 0xe8,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_thermal_status),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_thermal_status,
-},
-{ .name    = "CPU_IO_REQUESTS_TO_MEMORY_IO",
-  .desc    = "CPU/IO Requests to Memory/IO",
-  .code    = 0xe9,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_cpu_io_requests_to_memory_io),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_cpu_io_requests_to_memory_io,
-},
-{ .name    = "CACHE_BLOCK_COMMANDS",
-  .desc    = "Cache Block Commands",
-  .code    = 0xea,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_cache_block_commands),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_cache_block_commands,
-},
-{ .name    = "SIZED_COMMANDS",
-  .desc    = "Sized Commands",
-  .code    = 0xeb,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_sized_commands),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_sized_commands,
-},
-{ .name    = "PROBE_RESPONSES_AND_UPSTREAM_REQUESTS",
-  .desc    = "Probe Responses and Upstream Requests",
-  .code    = 0xec,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_probe_responses_and_upstream_requests),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_probe_responses_and_upstream_requests,
-},
-{ .name    = "GART_EVENTS",
-  .desc    = "GART Events",
-  .code    = 0xee,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_gart_events),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_gart_events,
-},
-{ .name    = "LINK_TRANSMIT_BANDWIDTH_LINK_0",
-  .desc    = "Link Transmit Bandwidth Link 0",
-  .code    = 0xf6,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_link_transmit_bandwidth),
-  .ngrp    = 2,
-  .umasks  = amd64_fam15h_link_transmit_bandwidth,
-},
-{ .name    = "LINK_TRANSMIT_BANDWIDTH_LINK_1",
-  .desc    = "Link Transmit Bandwidth Link 1",
-  .code    = 0xf7,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_link_transmit_bandwidth),
-  .ngrp    = 2,
-  .umasks  = amd64_fam15h_link_transmit_bandwidth,
-},
-{ .name    = "LINK_TRANSMIT_BANDWIDTH_LINK_2",
-  .desc    = "Link Transmit Bandwidth Link 2",
-  .code    = 0xf8,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_link_transmit_bandwidth),
-  .ngrp    = 2,
-  .umasks  = amd64_fam15h_link_transmit_bandwidth,
-},
-{ .name    = "LINK_TRANSMIT_BANDWIDTH_LINK_3",
-  .desc    = "Link Transmit Bandwidth Link 3",
-  .code    = 0x1f9,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_link_transmit_bandwidth),
-  .ngrp    = 2,
-  .umasks  = amd64_fam15h_link_transmit_bandwidth,
-},
-{ .name    = "CPU_TO_DRAM_REQUESTS_TO_TARGET_NODE",
-  .desc    = "CPU to DRAM Requests to Target Node",
-  .code    = 0x1e0,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_cpu_to_dram_requests_to_target_node),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_cpu_to_dram_requests_to_target_node,
-},
-{ .name    = "IO_TO_DRAM_REQUESTS_TO_TARGET_NODE",
-  .desc    = "IO to DRAM Requests to Target Node",
-  .code    = 0x1e1,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_io_to_dram_requests_to_target_node),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_io_to_dram_requests_to_target_node,
-},
-{ .name    = "CPU_READ_COMMAND_LATENCY_TO_TARGET_NODE_0_3",
-  .desc    = "CPU Read Command Latency to Target Node 0-3",
-  .code    = 0x1e2,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_cpu_read_command_requests_to_target_node_0_3),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_cpu_read_command_requests_to_target_node_0_3,
-},
-{ .name    = "CPU_READ_COMMAND_REQUESTS_TO_TARGET_NODE_0_3",
-  .desc    = "CPU Read Command Requests to Target Node 0-3",
-  .code    = 0x1e3,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_cpu_read_command_requests_to_target_node_0_3),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_cpu_read_command_requests_to_target_node_0_3,
-},
-{ .name    = "CPU_READ_COMMAND_LATENCY_TO_TARGET_NODE_4_7",
-  .desc    = "CPU Read Command Latency to Target Node 4-7",
-  .code    = 0x1e4,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_cpu_read_command_requests_to_target_node_4_7),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_cpu_read_command_requests_to_target_node_4_7,
-},
-{ .name    = "CPU_READ_COMMAND_REQUESTS_TO_TARGET_NODE_4_7",
-  .desc    = "CPU Read Command Requests to Target Node 4-7",
-  .code    = 0x1e5,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_cpu_read_command_requests_to_target_node_4_7),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_cpu_read_command_requests_to_target_node_4_7,
-},
-{ .name    = "CPU_COMMAND_LATENCY_TO_TARGET_NODE",
-  .desc    = "CPU Command Latency to Target Node",
-  .code    = 0x1e6,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_cpu_command_requests_to_target_node),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_cpu_command_requests_to_target_node,
-},
-{ .name    = "CPU_REQUESTS_TO_TARGET_NODE",
-  .desc    = "CPU Requests to Target Node",
-  .code    = 0x1e7,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_cpu_command_requests_to_target_node),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_cpu_command_requests_to_target_node,
-},
-{ .name    = "REQUEST_CACHE_STATUS_0",
-  .desc    = "Request Cache Status 0",
-  .code    = 0x1ea,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_request_cache_status_0),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_request_cache_status_0,
-},
-{ .name    = "REQUEST_CACHE_STATUS_1",
-  .desc    = "Request Cache Status 1",
-  .code    = 0x1eb,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_request_cache_status_1),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_request_cache_status_1,
-},
-{ .name    = "MEMORY_CONTROLLER_REQUESTS",
-  .desc    = "Memory Controller Requests",
-  .code    = 0x1f0,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_memory_controller_requests),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_memory_controller_requests,
-},
-{ .name    = "READ_REQUEST_TO_L3_CACHE",
-  .desc    = "Read Request to L3 Cache",
-  .code    = 0x4e0,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_read_request_to_l3_cache),
-  .ngrp    = 2,
-  .umasks  = amd64_fam15h_read_request_to_l3_cache,
-},
-{ .name    = "L3_CACHE_MISSES",
-  .desc    = "L3 Cache Misses",
-  .code    = 0x4e1,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_read_request_to_l3_cache),
-  .ngrp    = 2,
-  .umasks  = amd64_fam15h_read_request_to_l3_cache,
-},
-{ .name    = "L3_FILLS_CAUSED_BY_L2_EVICTIONS",
-  .desc    = "L3 Fills caused by L2 Evictions",
-  .code    = 0x4e2,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_l3_fills_caused_by_l2_evictions),
-  .ngrp    = 2,
-  .umasks  = amd64_fam15h_l3_fills_caused_by_l2_evictions,
-},
-{ .name    = "L3_EVICTIONS",
-  .desc    = "L3 Evictions",
-  .code    = 0x4e3,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_l3_evictions),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_l3_evictions,
-},
-{ .name    = "NON_CANCELED_L3_READ_REQUESTS",
-  .desc    = "Non-canceled L3 Read Requests",
-  .code    = 0x4ed,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_read_request_to_l3_cache),
-  .ngrp    = 2,
-  .umasks  = amd64_fam15h_read_request_to_l3_cache,
-},
-{ .name    = "L3_LATENCY",
-  .desc    = "L3 Latency",
-  .code    = 0x4ef,
-  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_l3_latency),
-  .ngrp    = 1,
-  .umasks  = amd64_fam15h_l3_latency,
-},
 };
diff --git a/src/libpfm4/lib/events/amd64_events_fam15h_nb.h b/src/libpfm4/lib/events/amd64_events_fam15h_nb.h
new file mode 100644
index 0000000..5969eb6
--- /dev/null
+++ b/src/libpfm4/lib/events/amd64_events_fam15h_nb.h
@@ -0,0 +1,2022 @@
+/*
+ * Copyright (c) 2013 Google, Inc
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * This file is part of libpfm, a performance monitoring support library for
+ * applications on Linux.
+ *
+ * This file has been automatically generated.
+ *
+ * PMU: amd64_fam15h_nb_nb (AMD64 Fam15h Interlagos NorthBridge)
+ *
+ * Based on libpfm patch by Robert Richter <robert.richter@amd.com>:
+ * Family 15h Microarchitecture performance monitor events
+ *
+ * History:
+ *
+ * Nov 30 2013 -- Stephane Eranian , eranian@gmail.com:
+ * Split core and Northbridge events as PMU is distinct
+ *
+ * Apr 29 2011 -- Robert Richter, robert.richter@amd.com:
+ * Source: BKDG for AMD Family 15h Models 00h-0Fh Processors,
+ * 42301, Rev 1.15, April 18, 2011
+ *
+ * Dec 09 2010 -- Robert Richter, robert.richter@amd.com:
+ * Source: BIOS and Kernel Developer's Guide for the AMD Family 15h
+ * Processors, Rev 0.90, May 18, 2010
+ */
+
+#define CORE_SELECT(b) \
+   { .uname  = "CORE_0",\
+     .udesc  = "Measure on Core0",\
+     .ucode = 0 << 4,\
+     .grpid = b,\
+     .uflags= AMD64_FL_NCOMBO,\
+   },\
+   { .uname  = "CORE_1",\
+     .udesc  = "Measure on Core1",\
+     .ucode = 1 << 4,\
+     .grpid = b,\
+     .uflags= AMD64_FL_NCOMBO,\
+   },\
+   { .uname  = "CORE_2",\
+     .udesc  = "Measure on Core2",\
+     .ucode = 2 << 4,\
+     .grpid = b,\
+     .uflags= AMD64_FL_NCOMBO,\
+   },\
+   { .uname  = "CORE_3",\
+     .udesc  = "Measure on Core3",\
+     .ucode = 3 << 4,\
+     .grpid = b,\
+     .uflags= AMD64_FL_NCOMBO,\
+   },\
+   { .uname  = "CORE_4",\
+     .udesc  = "Measure on Core4",\
+     .ucode = 4 << 4,\
+     .grpid = b,\
+     .uflags= AMD64_FL_NCOMBO,\
+   },\
+   { .uname  = "CORE_5",\
+     .udesc  = "Measure on Core5",\
+     .ucode = 5 << 4,\
+     .grpid = b,\
+     .uflags= AMD64_FL_NCOMBO,\
+   },\
+   { .uname  = "CORE_6",\
+     .udesc  = "Measure on Core6",\
+     .ucode = 6 << 4,\
+     .grpid = b,\
+     .uflags= AMD64_FL_NCOMBO,\
+   },\
+   { .uname  = "CORE_7",\
+     .udesc  = "Measure on Core7",\
+     .ucode = 7 << 4,\
+     .grpid = b,\
+     .uflags= AMD64_FL_NCOMBO,\
+   },\
+   { .uname  = "ANY_CORE",\
+     .udesc  = "Measure on any core",\
+     .ucode = 0xf << 4,\
+     .grpid = b,\
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,\
+   }
+
+static const amd64_umask_t amd64_fam15h_nb_dispatched_fpu_ops[]={
+   { .uname  = "OPS_PIPE0",
+     .udesc  = "Total number uops assigned to Pipe 0",
+     .ucode = 0x1,
+   },
+   { .uname  = "OPS_PIPE1",
+     .udesc  = "Total number uops assigned to Pipe 1",
+     .ucode = 0x2,
+   },
+   { .uname  = "OPS_PIPE2",
+     .udesc  = "Total number uops assigned to Pipe 2",
+     .ucode = 0x4,
+   },
+   { .uname  = "OPS_PIPE3",
+     .udesc  = "Total number uops assigned to Pipe 3",
+     .ucode = 0x8,
+   },
+   { .uname  = "OPS_DUAL_PIPE0",
+     .udesc  = "Total number dual-pipe uops assigned to Pipe 0",
+     .ucode = 0x10,
+   },
+   { .uname  = "OPS_DUAL_PIPE1",
+     .udesc  = "Total number dual-pipe uops assigned to Pipe 1",
+     .ucode = 0x20,
+   },
+   { .uname  = "OPS_DUAL_PIPE2",
+     .udesc  = "Total number dual-pipe uops assigned to Pipe 2",
+     .ucode = 0x40,
+   },
+   { .uname  = "OPS_DUAL_PIPE3",
+     .udesc  = "Total number dual-pipe uops assigned to Pipe 3",
+     .ucode = 0x80,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0xff,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_retired_sse_ops[]={
+   { .uname  = "SINGLE_ADD_SUB_OPS",
+     .udesc  = "Single-precision add/subtract FLOPS",
+     .ucode = 0x1,
+   },
+   { .uname  = "SINGLE_MUL_OPS",
+     .udesc  = "Single-precision multiply FLOPS",
+     .ucode = 0x2,
+   },
+   { .uname  = "SINGLE_DIV_OPS",
+     .udesc  = "Single-precision divide/square root FLOPS",
+     .ucode = 0x4,
+   },
+   { .uname  = "SINGLE_MUL_ADD_OPS",
+     .udesc  = "Single precision multiply-add FLOPS. Multiply-add counts as 2 FLOPS",
+     .ucode = 0x8,
+   },
+   { .uname  = "DOUBLE_ADD_SUB_OPS",
+     .udesc  = "Double precision add/subtract FLOPS",
+     .ucode = 0x10,
+   },
+   { .uname  = "DOUBLE_MUL_OPS",
+     .udesc  = "Double precision multiply FLOPS",
+     .ucode = 0x20,
+   },
+   { .uname  = "DOUBLE_DIV_OPS",
+     .udesc  = "Double precision divide/square root FLOPS",
+     .ucode = 0x40,
+   },
+   { .uname  = "DOUBLE_MUL_ADD_OPS",
+     .udesc  = "Double precision multiply-add FLOPS. Multiply-add counts as 2 FLOPS",
+     .ucode = 0x80,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0xff,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_move_scalar_optimization[]={
+   { .uname  = "SSE_MOVE_OPS",
+     .udesc  = "Number of SSE Move Ops",
+     .ucode = 0x1,
+   },
+   { .uname  = "SSE_MOVE_OPS_ELIM",
+     .udesc  = "Number of SSE Move Ops eliminated",
+     .ucode = 0x2,
+   },
+   { .uname  = "OPT_CAND",
+     .udesc  = "Number of Ops that are candidates for optimization (Z-bit set or pass)",
+     .ucode = 0x4,
+   },
+   { .uname  = "SCALAR_OPS_OPTIMIZED",
+     .udesc  = "Number of Scalar ops optimized",
+     .ucode = 0x8,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0xf,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_retired_serializing_ops[]={
+   { .uname  = "SSE_RETIRED",
+     .udesc  = "SSE bottom-executing uops retired",
+     .ucode = 0x1,
+   },
+   { .uname  = "SSE_MISPREDICTED",
+     .udesc  = "SSE control word mispredict traps due to mispredictions",
+     .ucode = 0x2,
+   },
+   { .uname  = "X87_RETIRED",
+     .udesc  = "X87 bottom-executing uops retired",
+     .ucode = 0x4,
+   },
+   { .uname  = "X87_MISPREDICTED",
+     .udesc  = "X87 control word mispredict traps due to mispredictions",
+     .ucode = 0x8,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0xf,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_segment_register_loads[]={
+   { .uname  = "ES",
+     .udesc  = "ES",
+     .ucode = 0x1,
+   },
+   { .uname  = "CS",
+     .udesc  = "CS",
+     .ucode = 0x2,
+   },
+   { .uname  = "SS",
+     .udesc  = "SS",
+     .ucode = 0x4,
+   },
+   { .uname  = "DS",
+     .udesc  = "DS",
+     .ucode = 0x8,
+   },
+   { .uname  = "FS",
+     .udesc  = "FS",
+     .ucode = 0x10,
+   },
+   { .uname  = "GS",
+     .udesc  = "GS",
+     .ucode = 0x20,
+   },
+   { .uname  = "HS",
+     .udesc  = "HS",
+     .ucode = 0x40,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x7f,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_load_q_store_q_full[]={
+   { .uname  = "LOAD_QUEUE",
+     .udesc  = "The number of cycles that the load buffer is full",
+     .ucode = 0x1,
+   },
+   { .uname  = "STORE_QUEUE",
+     .udesc  = "The number of cycles that the store buffer is full",
+     .ucode = 0x2,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x3,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_locked_ops[]={
+   { .uname  = "EXECUTED",
+     .udesc  = "Number of locked instructions executed",
+     .ucode = 0x1,
+   },
+   { .uname  = "CYCLES_NON_SPECULATIVE_PHASE",
+     .udesc  = "Number of cycles spent in non-speculative phase, excluding cache miss penalty",
+     .ucode = 0x4,
+   },
+   { .uname  = "CYCLES_WAITING",
+     .udesc  = "Number of cycles spent in non-speculative phase, including the cache miss penalty",
+     .ucode = 0x8,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0xd,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_cancelled_store_to_load[]={
+   { .uname  = "SIZE_ADDRESS_MISMATCHES",
+     .udesc  = "Store is smaller than load or different starting byte but partial overlap",
+     .ucode = 0x1,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x1,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_data_cache_misses[]={
+   { .uname  = "DC_MISS_STREAMING_STORE",
+     .udesc  = "First data cache miss or streaming store to a 64B cache line",
+     .ucode = 0x1,
+   },
+   { .uname  = "STREAMING_STORE",
+     .udesc  = "First streaming store to a 64B cache line",
+     .ucode = 0x2,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x3,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_data_cache_refills_from_l2_or_northbridge[]={
+   { .uname  = "GOOD",
+     .udesc  = "Fill with good data. (Final valid status is valid)",
+     .ucode = 0x1,
+   },
+   { .uname  = "INVALID",
+     .udesc  = "Early valid status turned out to be invalid",
+     .ucode = 0x2,
+   },
+   { .uname  = "POISON",
+     .udesc  = "Fill with poison data",
+     .ucode = 0x4,
+   },
+   { .uname  = "READ_ERROR",
+     .udesc  = "Fill with read data error",
+     .ucode = 0x8,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0xf,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_unified_tlb_hit[]={
+   { .uname  = "4K_DATA",
+     .udesc  = "4 KB unified TLB hit for data",
+     .ucode = 0x1,
+   },
+   { .uname  = "2M_DATA",
+     .udesc  = "2 MB unified TLB hit for data",
+     .ucode = 0x2,
+   },
+   { .uname  = "1G_DATA",
+     .udesc  = "1 GB unified TLB hit for data",
+     .ucode = 0x4,
+   },
+   { .uname  = "4K_INST",
+     .udesc  = "4 KB unified TLB hit for instruction",
+     .ucode = 0x10,
+   },
+   { .uname  = "2M_INST",
+     .udesc  = "2 MB unified TLB hit for instruction",
+     .ucode = 0x20,
+   },
+   { .uname  = "1G_INST",
+     .udesc  = "1 GB unified TLB hit for instruction",
+     .ucode = 0x40,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x77,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_unified_tlb_miss[]={
+   { .uname  = "4K_DATA",
+     .udesc  = "4 KB unified TLB miss for data",
+     .ucode = 0x1,
+   },
+   { .uname  = "2M_DATA",
+     .udesc  = "2 MB unified TLB miss for data",
+     .ucode = 0x2,
+   },
+   { .uname  = "1GB_DATA",
+     .udesc  = "1 GB unified TLB miss for data",
+     .ucode = 0x4,
+   },
+   { .uname  = "4K_INST",
+     .udesc  = "4 KB unified TLB miss for instruction",
+     .ucode = 0x10,
+   },
+   { .uname  = "2M_INST",
+     .udesc  = "2 MB unified TLB miss for instruction",
+     .ucode = 0x20,
+   },
+   { .uname  = "1G_INST",
+     .udesc  = "1 GB unified TLB miss for instruction",
+     .ucode = 0x40,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x77,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_prefetch_instructions_dispatched[]={
+   { .uname  = "LOAD",
+     .udesc  = "Load (Prefetch, PrefetchT0/T1/T2)",
+     .ucode = 0x1,
+   },
+   { .uname  = "STORE",
+     .udesc  = "Store (PrefetchW)",
+     .ucode = 0x2,
+   },
+   { .uname  = "NTA",
+     .udesc  = "NTA (PrefetchNTA)",
+     .ucode = 0x4,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x7,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_ineffective_sw_prefetches[]={
+   { .uname  = "SW_PREFETCH_HIT_IN_L1",
+     .udesc  = "Software prefetch hit in the L1",
+     .ucode = 0x1,
+   },
+   { .uname  = "SW_PREFETCH_HIT_IN_L2",
+     .udesc  = "Software prefetch hit in the L2",
+     .ucode = 0x8,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x9,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_memory_requests[]={
+   { .uname  = "NON_CACHEABLE",
+     .udesc  = "Requests to non-cacheable (UC) memory",
+     .ucode = 0x1,
+   },
+   { .uname  = "WRITE_COMBINING",
+     .udesc  = "Requests to non-cacheable (WC, but not WC+/SS) memory",
+     .ucode = 0x2,
+   },
+   { .uname  = "STREAMING_STORE",
+     .udesc  = "Requests to non-cacheable (WC+/SS, but not WC) memory",
+     .ucode = 0x80,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x83,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_data_prefetcher[]={
+   { .uname  = "ATTEMPTED",
+     .udesc  = "Prefetch attempts",
+     .ucode = 0x2,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x2,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_mab_reqs[]={
+   { .uname  = "BUFFER_BIT_0",
+     .udesc  = "Buffer entry index bit 0",
+     .ucode = 0x1,
+   },
+   { .uname  = "BUFFER_BIT_1",
+     .udesc  = "Buffer entry index bit 1",
+     .ucode = 0x2,
+   },
+   { .uname  = "BUFFER_BIT_2",
+     .udesc  = "Buffer entry index bit 2",
+     .ucode = 0x4,
+   },
+   { .uname  = "BUFFER_BIT_3",
+     .udesc  = "Buffer entry index bit 3",
+     .ucode = 0x8,
+   },
+   { .uname  = "BUFFER_BIT_4",
+     .udesc  = "Buffer entry index bit 4",
+     .ucode = 0x10,
+   },
+   { .uname  = "BUFFER_BIT_5",
+     .udesc  = "Buffer entry index bit 5",
+     .ucode = 0x20,
+   },
+   { .uname  = "BUFFER_BIT_6",
+     .udesc  = "Buffer entry index bit 6",
+     .ucode = 0x40,
+   },
+   { .uname  = "BUFFER_BIT_7",
+     .udesc  = "Buffer entry index bit 7",
+     .ucode = 0x80,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0xff,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_system_read_responses[]={
+   { .uname  = "EXCLUSIVE",
+     .udesc  = "Exclusive",
+     .ucode = 0x1,
+   },
+   { .uname  = "MODIFIED",
+     .udesc  = "Modified (D18F0x68[ATMModeEn]==0), Modified written (D18F0x68[ATMModeEn]==1)",
+     .ucode = 0x2,
+   },
+   { .uname  = "SHARED",
+     .udesc  = "Shared",
+     .ucode = 0x4,
+   },
+   { .uname  = "OWNED",
+     .udesc  = "Owned",
+     .ucode = 0x8,
+   },
+   { .uname  = "DATA_ERROR",
+     .udesc  = "Data Error",
+     .ucode = 0x10,
+   },
+   { .uname  = "MODIFIED_UNWRITTEN",
+     .udesc  = "Modified unwritten",
+     .ucode = 0x20,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x3f,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_octword_write_transfers[]={
+   { .uname  = "OCTWORD_WRITE_TRANSFER",
+     .udesc  = "OW write transfer",
+     .ucode = 0x1,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x1,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_requests_to_l2[]={
+   { .uname  = "INSTRUCTIONS",
+     .udesc  = "IC fill",
+     .ucode = 0x1,
+   },
+   { .uname  = "DATA",
+     .udesc  = "DC fill",
+     .ucode = 0x2,
+   },
+   { .uname  = "TLB_WALK",
+     .udesc  = "TLB fill (page table walks)",
+     .ucode = 0x4,
+   },
+   { .uname  = "SNOOP",
+     .udesc  = "NB probe request",
+     .ucode = 0x8,
+   },
+   { .uname  = "CANCELLED",
+     .udesc  = "Canceled request",
+     .ucode = 0x10,
+   },
+   { .uname  = "PREFETCHER",
+     .udesc  = "L2 cache prefetcher request",
+     .ucode = 0x40,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x5f,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_l2_cache_miss[]={
+   { .uname  = "INSTRUCTIONS",
+     .udesc  = "IC fill",
+     .ucode = 0x1,
+   },
+   { .uname  = "DATA",
+     .udesc  = "DC fill (includes possible replays, whereas PMCx041 does not)",
+     .ucode = 0x2,
+   },
+   { .uname  = "TLB_WALK",
+     .udesc  = "TLB page table walk",
+     .ucode = 0x4,
+   },
+   { .uname  = "PREFETCHER",
+     .udesc  = "L2 Cache Prefetcher request",
+     .ucode = 0x10,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x17,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_l2_cache_fill_writeback[]={
+   { .uname  = "L2_FILLS",
+     .udesc  = "L2 fills from system",
+     .ucode = 0x1,
+   },
+   { .uname  = "L2_WRITEBACKS",
+     .udesc  = "L2 Writebacks to system (Clean and Dirty)",
+     .ucode = 0x2,
+   },
+   { .uname  = "L2_WRITEBACKS_CLEAN",
+     .udesc  = "L2 Clean Writebacks to system",
+     .ucode = 0x4,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x7,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_page_splintering[]={
+   { .uname  = "GUEST_LARGER",
+     .udesc  = "Guest page size is larger than host page size when nested paging is enabled",
+     .ucode = 0x1,
+   },
+   { .uname  = "MTRR_MISMATCH",
+     .udesc  = "Splintering due to MTRRs, IORRs, APIC, TOMs or other special address region",
+     .ucode = 0x2,
+   },
+   { .uname  = "HOST_LARGER",
+     .udesc  = "Host page size is larger than the guest page size",
+     .ucode = 0x4,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x7,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_l1_itlb_miss_and_l2_itlb_miss[]={
+   { .uname  = "4K_PAGE_FETCHES",
+     .udesc  = "Instruction fetches to a 4 KB page",
+     .ucode = 0x1,
+   },
+   { .uname  = "2M_PAGE_FETCHES",
+     .udesc  = "Instruction fetches to a 2 MB page",
+     .ucode = 0x2,
+   },
+   { .uname  = "1G_PAGE_FETCHES",
+     .udesc  = "Instruction fetches to a 1 GB page",
+     .ucode = 0x4,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x7,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_instruction_cache_invalidated[]={
+   { .uname  = "NON_SMC_PROBE_MISS",
+     .udesc  = "Non-SMC invalidating probe that missed on in-flight instructions",
+     .ucode = 0x1,
+   },
+   { .uname  = "NON_SMC_PROBE_HIT",
+     .udesc  = "Non-SMC invalidating probe that hit on in-flight instructions",
+     .ucode = 0x2,
+   },
+   { .uname  = "SMC_PROBE_MISS",
+     .udesc  = "SMC invalidating probe that missed on in-flight instructions",
+     .ucode = 0x4,
+   },
+   { .uname  = "SMC_PROBE_HIT",
+     .udesc  = "SMC invalidating probe that hit on in-flight instructions",
+     .ucode = 0x8,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0xf,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_retired_mmx_fp_instructions[]={
+   { .uname  = "X87",
+     .udesc  = "X87 instructions",
+     .ucode = 0x1,
+   },
+   { .uname  = "MMX",
+     .udesc  = "MMX(tm) instructions",
+     .ucode = 0x2,
+   },
+   { .uname  = "SSE",
+     .udesc  = "SSE instructions (SSE,SSE2,SSE3,SSSE3,SSE4A,SSE4.1,SSE4.2,AVX,XOP,FMA4)",
+     .ucode = 0x4,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x7,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_fpu_exceptions[]={
+   { .uname  = "TOTAL_FAULTS",
+     .udesc  = "Total microfaults",
+     .ucode = 0x1,
+   },
+   { .uname  = "TOTAL_TRAPS",
+     .udesc  = "Total microtraps",
+     .ucode = 0x2,
+   },
+   { .uname  = "INT2EXT_FAULTS",
+     .udesc  = "Int2Ext faults",
+     .ucode = 0x4,
+   },
+   { .uname  = "EXT2INT_FAULTS",
+     .udesc  = "Ext2Int faults",
+     .ucode = 0x8,
+   },
+   { .uname  = "BYPASS_FAULTS",
+     .udesc  = "Bypass faults",
+     .ucode = 0x10,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x1f,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_ibs_ops_tagged[]={
+   { .uname  = "TAGGED",
+     .udesc  = "Number of ops tagged by IBS",
+     .ucode = 0x1,
+   },
+   { .uname  = "RETIRED",
+     .udesc  = "Number of ops tagged by IBS that retired",
+     .ucode = 0x2,
+   },
+   { .uname  = "IGNORED",
+     .udesc  = "Number of times an op could not be tagged by IBS because of a previous tagged op that has not retired",
+     .ucode = 0x4,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x7,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_ls_dispatch[]={
+   { .uname  = "LOADS",
+     .udesc  = "Loads",
+     .ucode = 0x1,
+   },
+   { .uname  = "STORES",
+     .udesc  = "Stores",
+     .ucode = 0x2,
+   },
+   { .uname  = "LOAD_OP_STORES",
+     .udesc  = "Load-op-Stores",
+     .ucode = 0x4,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x7,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_l2_prefetcher_trigger_events[]={
+   { .uname  = "LOAD_L1_MISS_SEEN_BY_PREFETCHER",
+     .udesc  = "Load L1 miss seen by prefetcher",
+     .ucode = 0x1,
+   },
+   { .uname  = "STORE_L1_MISS_SEEN_BY_PREFETCHER",
+     .udesc  = "Store L1 miss seen by prefetcher",
+     .ucode = 0x2,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x3,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_dram_accesses[]={
+   { .uname = "DCT0_PAGE_HIT",
+     .udesc = "DCT0 Page hit",
+     .ucode = 0x1,
+   },
+   { .uname = "DCT0_PAGE_MISS",
+     .udesc = "DCT0 Page Miss",
+     .ucode = 0x2,
+   },
+   { .uname = "DCT0_PAGE_CONFLICT",
+     .udesc = "DCT0 Page Conflict",
+     .ucode = 0x4,
+   },
+   { .uname = "DCT1_PAGE_HIT",
+     .udesc = "DCT1 Page hit",
+     .ucode = 0x8,
+   },
+   { .uname = "DCT1_PAGE_MISS",
+     .udesc = "DCT1 Page Miss",
+     .ucode = 0x10,
+   },
+   { .uname = "DCT1_PAGE_CONFLICT",
+     .udesc = "DCT1 Page Conflict",
+     .ucode = 0x20,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x3f,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_dram_controller_page_table_overflows[]={
+   { .uname = "DCT0_PAGE_TABLE_OVERFLOW",
+     .udesc = "DCT0 Page Table Overflow",
+     .ucode = 0x1,
+   },
+   { .uname = "DCT1_PAGE_TABLE_OVERFLOW",
+     .udesc = "DCT1 Page Table Overflow",
+     .ucode = 0x2,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode  = 0x3,
+     .uflags = AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_memory_controller_dram_command_slots_missed[]={
+   { .uname = "DCT0_COMMAND_SLOTS_MISSED",
+     .udesc = "DCT0 Command Slots Missed (in MemClks)",
+     .ucode = 0x1,
+   },
+   { .uname = "DCT1_COMMAND_SLOTS_MISSED",
+     .udesc = "DCT1 Command Slots Missed (in MemClks)",
+     .ucode = 0x2,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode  = 0x3,
+     .uflags = AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_memory_controller_turnarounds[]={
+   { .uname = "DCT0_DIMM_TURNAROUND",
+     .udesc = "DCT0 DIMM (chip select) turnaround",
+     .ucode = 0x1,
+   },
+   { .uname = "DCT0_READ_WRITE_TURNAROUND",
+     .udesc = "DCT0 Read to write turnaround",
+     .ucode = 0x2,
+   },
+   { .uname = "DCT0_WRITE_READ_TURNAROUND",
+     .udesc = "DCT0 Write to read turnaround",
+     .ucode = 0x4,
+   },
+   { .uname = "DCT1_DIMM_TURNAROUND",
+     .udesc = "DCT1 DIMM (chip select) turnaround",
+     .ucode = 0x8,
+   },
+   { .uname = "DCT1_READ_WRITE_TURNAROUND",
+     .udesc = "DCT1 Read to write turnaround",
+     .ucode = 0x10,
+   },
+   { .uname = "DCT1_WRITE_READ_TURNAROUND",
+     .udesc = "DCT1 Write to read turnaround",
+     .ucode = 0x20,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode  = 0x3f,
+     .uflags = AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_memory_controller_bypass_counter_saturation[]={
+   { .uname = "MEMORY_CONTROLLER_HIGH_PRIORITY_BYPASS",
+     .udesc = "Memory controller high priority bypass",
+     .ucode = 0x1,
+   },
+   { .uname = "MEMORY_CONTROLLER_MEDIUM_PRIORITY_BYPASS",
+     .udesc = "Memory controller medium priority bypass",
+     .ucode = 0x2,
+   },
+   { .uname = "DCT0_DCQ_BYPASS",
+     .udesc = "DCT0 DCQ bypass",
+     .ucode = 0x4,
+   },
+   { .uname = "DCT1_DCQ_BYPASS",
+     .udesc = "DCT1 DCQ bypass",
+     .ucode = 0x8,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode  = 0xf,
+     .uflags = AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_thermal_status[]={
+   { .uname = "NUM_HTC_TRIP_POINT_CROSSED",
+     .udesc = "Number of times the HTC trip point is crossed",
+     .ucode = 0x4,
+   },
+   { .uname = "NUM_CLOCKS_HTC_PSTATE_INACTIVE",
+     .udesc = "Number of clocks HTC P-state is inactive",
+     .ucode = 0x20,
+   },
+   { .uname = "NUM_CLOCKS_HTC_PSTATE_ACTIVE",
+     .udesc = "Number of clocks HTC P-state is active",
+     .ucode = 0x40,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x64,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_cpu_io_requests_to_memory_io[]={
+   { .uname = "REMOTE_IO_TO_LOCAL_IO",
+     .udesc = "Remote IO to Local IO",
+     .ucode = 0x61,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "REMOTE_CPU_TO_LOCAL_IO",
+     .udesc = "Remote CPU to Local IO",
+     .ucode = 0x64,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "LOCAL_IO_TO_REMOTE_IO",
+     .udesc = "Local IO to Remote IO",
+     .ucode = 0x91,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "LOCAL_IO_TO_REMOTE_MEM",
+     .udesc = "Local IO to Remote Mem",
+     .ucode = 0x92,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "LOCAL_CPU_TO_REMOTE_IO",
+     .udesc = "Local CPU to Remote IO",
+     .ucode = 0x94,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "LOCAL_CPU_TO_REMOTE_MEM",
+     .udesc = "Local CPU to Remote Mem",
+     .ucode = 0x98,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "LOCAL_IO_TO_LOCAL_IO",
+     .udesc = "Local IO to Local IO",
+     .ucode = 0xa1,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "LOCAL_IO_TO_LOCAL_MEM",
+     .udesc = "Local IO to Local Mem",
+     .ucode = 0xa2,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "LOCAL_CPU_TO_LOCAL_IO",
+     .udesc = "Local CPU to Local IO",
+     .ucode = 0xa4,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "LOCAL_CPU_TO_LOCAL_MEM",
+     .udesc = "Local CPU to Local Mem",
+     .ucode = 0xa8,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_cache_block_commands[]={
+   { .uname = "VICTIM_BLOCK",
+     .udesc = "Victim Block (Writeback)",
+     .ucode = 0x1,
+   },
+   { .uname = "READ_BLOCK",
+     .udesc = "Read Block (Dcache load miss refill)",
+     .ucode = 0x4,
+   },
+   { .uname = "READ_BLOCK_SHARED",
+     .udesc = "Read Block Shared (Icache refill)",
+     .ucode = 0x8,
+   },
+   { .uname = "READ_BLOCK_MODIFIED",
+     .udesc = "Read Block Modified (Dcache store miss refill)",
+     .ucode = 0x10,
+   },
+   { .uname = "CHANGE_TO_DIRTY",
+     .udesc = "Change-to-Dirty (first store to clean block already in cache)",
+     .ucode = 0x20,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode  = 0x3d,
+     .uflags = AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_sized_commands[]={
+   { .uname = "NON-POSTED_SZWR_BYTE",
+     .udesc = "Non-Posted SzWr Byte (1-32 bytes). Typical Usage: Legacy or mapped IO, typically 1-4 bytes.",
+     .ucode = 0x1,
+   },
+   { .uname = "NON-POSTED_SZWR_DW",
+     .udesc = "Non-Posted SzWr DW (1-16 dwords). Typical Usage: Legacy or mapped IO, typically 1",
+     .ucode = 0x2,
+   },
+   { .uname = "POSTED_SZWR_BYTE",
+     .udesc = "Posted SzWr Byte (1-32 bytes). Typical Usage: Subcache-line DMA writes, size varies; also",
+     .ucode = 0x4,
+   },
+   { .uname = "POSTED_SZWR_DW",
+     .udesc = "Posted SzWr DW (1-16 dwords). Typical Usage: Block-oriented DMA writes, often cache-line",
+     .ucode = 0x8,
+   },
+   { .uname = "SZRD_BYTE",
+     .udesc = "SzRd Byte (4 bytes). Typical Usage: Legacy or mapped IO.",
+     .ucode = 0x10,
+   },
+   { .uname = "SZRD_DW",
+     .udesc = "SzRd DW (1-16 dwords). Typical Usage: Block-oriented DMA reads, typically cache-line size.",
+     .ucode = 0x20,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x3f,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_probe_responses_and_upstream_requests[]={
+   { .uname = "PROBE_MISS",
+     .udesc = "Probe miss",
+     .ucode = 0x1,
+   },
+   { .uname = "PROBE_HIT_CLEAN",
+     .udesc = "Probe hit clean",
+     .ucode = 0x2,
+   },
+   { .uname = "PROBE_HIT_DIRTY_WITHOUT_MEMORY_CANCEL",
+     .udesc = "Probe hit dirty without memory cancel (probed by Sized Write or Change2Dirty)",
+     .ucode = 0x4,
+   },
+   { .uname = "PROBE_HIT_DIRTY_WITH_MEMORY_CANCEL",
+     .udesc = "Probe hit dirty with memory cancel (probed by DMA read or cache refill request)",
+     .ucode = 0x8,
+   },
+   { .uname = "UPSTREAM_DISPLAY_REFRESH_ISOC_READS",
+     .udesc = "Upstream display refresh/ISOC reads",
+     .ucode = 0x10,
+   },
+   { .uname = "UPSTREAM_NON-DISPLAY_REFRESH_READS",
+     .udesc = "Upstream non-display refresh reads",
+     .ucode = 0x20,
+   },
+   { .uname = "UPSTREAM_ISOC_WRITES",
+     .udesc = "Upstream ISOC writes",
+     .ucode = 0x40,
+   },
+   { .uname = "UPSTREAM_NON-ISOC_WRITES",
+     .udesc = "Upstream non-ISOC writes",
+     .ucode = 0x80,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0xff,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_gart_events[]={
+   { .uname = "GART_APERTURE_HIT_ON_ACCESS_FROM_CPU",
+     .udesc = "GART aperture hit on access from CPU",
+     .ucode = 0x1,
+   },
+   { .uname = "GART_APERTURE_HIT_ON_ACCESS_FROM_IO",
+     .udesc = "GART aperture hit on access from IO",
+     .ucode = 0x2,
+   },
+   { .uname = "GART_MISS",
+     .udesc = "GART miss",
+     .ucode = 0x4,
+   },
+   { .uname = "GART_REQUEST_HIT_TABLE_WALK_IN_PROGRESS",
+     .udesc = "GART Request hit table walk in progress",
+     .ucode = 0x8,
+   },
+   { .uname = "GART_MULTIPLE_TABLE_WALK_IN_PROGRESS",
+     .udesc = "GART multiple table walk in progress",
+     .ucode = 0x80,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x8f,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_link_transmit_bandwidth[]={
+   { .uname = "COMMAND_DW_SENT",
+     .udesc = "Command DW sent",
+     .ucode = 0x1,
+     .grpid = 0,
+   },
+   { .uname = "DATA_DW_SENT",
+     .udesc = "Data DW sent",
+     .ucode = 0x2,
+     .grpid = 0,
+   },
+   { .uname = "BUFFER_RELEASE_DW_SENT",
+     .udesc = "Buffer release DW sent",
+     .ucode = 0x4,
+     .grpid = 0,
+   },
+   { .uname = "NOP_DW_SENT",
+     .udesc = "NOP DW sent (idle)",
+     .ucode = 0x8,
+     .grpid = 0,
+   },
+   { .uname = "ADDRESS_DW_SENT",
+     .udesc = "Address (including extensions) DW sent",
+     .ucode = 0x10,
+     .grpid = 0,
+   },
+   { .uname = "PER_PACKET_CRC_SENT",
+     .udesc = "Per packet CRC sent",
+     .ucode = 0x20,
+     .grpid = 0,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x3f,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+     .grpid = 0,
+   },
+   { .uname = "SUBLINK_1",
+     .udesc = "When links are unganged, enable this umask to select sublink 1",
+     .ucode = 0x80,
+     .grpid = 1,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "SUBLINK_0",
+     .udesc = "When links are unganged, enable this umask to select sublink 0 (default when links ganged)",
+     .ucode = 0x00,
+     .grpid = 1,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+
+
+};
+
+static const amd64_umask_t amd64_fam15h_nb_cpu_to_dram_requests_to_target_node[]={
+   { .uname = "LOCAL_TO_NODE_0",
+     .udesc = "From Local node to Node 0",
+     .ucode = 0x1,
+   },
+   { .uname = "LOCAL_TO_NODE_1",
+     .udesc = "From Local node to Node 1",
+     .ucode = 0x2,
+   },
+   { .uname = "LOCAL_TO_NODE_2",
+     .udesc = "From Local node to Node 2",
+     .ucode = 0x4,
+   },
+   { .uname = "LOCAL_TO_NODE_3",
+     .udesc = "From Local node to Node 3",
+     .ucode = 0x8,
+   },
+   { .uname = "LOCAL_TO_NODE_4",
+     .udesc = "From Local node to Node 4",
+     .ucode = 0x10,
+   },
+   { .uname = "LOCAL_TO_NODE_5",
+     .udesc = "From Local node to Node 5",
+     .ucode = 0x20,
+   },
+   { .uname = "LOCAL_TO_NODE_6",
+     .udesc = "From Local node to Node 6",
+     .ucode = 0x40,
+   },
+   { .uname = "LOCAL_TO_NODE_7",
+     .udesc = "From Local node to Node 7",
+     .ucode = 0x80,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0xff,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_io_to_dram_requests_to_target_node[]={
+   { .uname = "LOCAL_TO_NODE_0",
+     .udesc = "From Local node to Node 0",
+     .ucode = 0x1,
+   },
+   { .uname = "LOCAL_TO_NODE_1",
+     .udesc = "From Local node to Node 1",
+     .ucode = 0x2,
+   },
+   { .uname = "LOCAL_TO_NODE_2",
+     .udesc = "From Local node to Node 2",
+     .ucode = 0x4,
+   },
+   { .uname = "LOCAL_TO_NODE_3",
+     .udesc = "From Local node to Node 3",
+     .ucode = 0x8,
+   },
+   { .uname = "LOCAL_TO_NODE_4",
+     .udesc = "From Local node to Node 4",
+     .ucode = 0x10,
+   },
+   { .uname = "LOCAL_TO_NODE_5",
+     .udesc = "From Local node to Node 5",
+     .ucode = 0x20,
+   },
+   { .uname = "LOCAL_TO_NODE_6",
+     .udesc = "From Local node to Node 6",
+     .ucode = 0x40,
+   },
+   { .uname = "LOCAL_TO_NODE_7",
+     .udesc = "From Local node to Node 7",
+     .ucode = 0x80,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0xff,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_cpu_read_command_requests_to_target_node_0_3[]={
+   { .uname = "READ_BLOCK_LOCAL_TO_NODE_0",
+     .udesc = "Read block From Local node to Node 0",
+     .ucode = 0x11,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_SHARED_LOCAL_TO_NODE_0",
+     .udesc = "Read block shared From Local node to Node 0",
+     .ucode = 0x12,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_MODIFIED_LOCAL_TO_NODE_0",
+     .udesc = "Read block modified From Local node to Node 0",
+     .ucode = 0x14,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "CHANGE_TO_DIRTY_LOCAL_TO_NODE_0",
+     .udesc = "Change-to-Dirty From Local node to Node 0",
+     .ucode = 0x18,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_LOCAL_TO_NODE_1",
+     .udesc = "Read block From Local node to Node 1",
+     .ucode = 0x21,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_SHARED_LOCAL_TO_NODE_1",
+     .udesc = "Read block shared From Local node to Node 1",
+     .ucode = 0x22,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_MODIFIED_LOCAL_TO_NODE_1",
+     .udesc = "Read block modified From Local node to Node 1",
+     .ucode = 0x24,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "CHANGE_TO_DIRTY_LOCAL_TO_NODE_1",
+     .udesc = "Change-to-Dirty From Local node to Node 1",
+     .ucode = 0x28,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_LOCAL_TO_NODE_2",
+     .udesc = "Read block From Local node to Node 2",
+     .ucode = 0x41,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_SHARED_LOCAL_TO_NODE_2",
+     .udesc = "Read block shared From Local node to Node 2",
+     .ucode = 0x42,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_MODIFIED_LOCAL_TO_NODE_2",
+     .udesc = "Read block modified From Local node to Node 2",
+     .ucode = 0x44,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "CHANGE_TO_DIRTY_LOCAL_TO_NODE_2",
+     .udesc = "Change-to-Dirty From Local node to Node 2",
+     .ucode = 0x48,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_LOCAL_TO_NODE_3",
+     .udesc = "Read block From Local node to Node 3",
+     .ucode = 0x81,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_SHARED_LOCAL_TO_NODE_3",
+     .udesc = "Read block shared From Local node to Node 3",
+     .ucode = 0x82,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_MODIFIED_LOCAL_TO_NODE_3",
+     .udesc = "Read block modified From Local node to Node 3",
+     .ucode = 0x84,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "CHANGE_TO_DIRTY_LOCAL_TO_NODE_3",
+     .udesc = "Change-to-Dirty From Local node to Node 3",
+     .ucode = 0x88,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0xff,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_cpu_read_command_requests_to_target_node_4_7[]={
+   { .uname = "READ_BLOCK_LOCAL_TO_NODE_4",
+     .udesc = "Read block From Local node to Node 4",
+     .ucode = 0x11,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_SHARED_LOCAL_TO_NODE_4",
+     .udesc = "Read block shared From Local node to Node 4",
+     .ucode = 0x12,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_MODIFIED_LOCAL_TO_NODE_4",
+     .udesc = "Read block modified From Local node to Node 4",
+     .ucode = 0x14,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "CHANGE_TO_DIRTY_LOCAL_TO_NODE_4",
+     .udesc = "Change-to-Dirty From Local node to Node 4",
+     .ucode = 0x18,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_LOCAL_TO_NODE_5",
+     .udesc = "Read block From Local node to Node 5",
+     .ucode = 0x21,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_SHARED_LOCAL_TO_NODE_5",
+     .udesc = "Read block shared From Local node to Node 5",
+     .ucode = 0x22,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_MODIFIED_LOCAL_TO_NODE_5",
+     .udesc = "Read block modified From Local node to Node 5",
+     .ucode = 0x24,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "CHANGE_TO_DIRTY_LOCAL_TO_NODE_5",
+     .udesc = "Change-to-Dirty From Local node to Node 5",
+     .ucode = 0x28,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_LOCAL_TO_NODE_6",
+     .udesc = "Read block From Local node to Node 6",
+     .ucode = 0x41,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_SHARED_LOCAL_TO_NODE_6",
+     .udesc = "Read block shared From Local node to Node 6",
+     .ucode = 0x42,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_MODIFIED_LOCAL_TO_NODE_6",
+     .udesc = "Read block modified From Local node to Node 6",
+     .ucode = 0x44,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "CHANGE_TO_DIRTY_LOCAL_TO_NODE_6",
+     .udesc = "Change-to-Dirty From Local node to Node 6",
+     .ucode = 0x48,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_LOCAL_TO_NODE_7",
+     .udesc = "Read block From Local node to Node 7",
+     .ucode = 0x81,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_SHARED_LOCAL_TO_NODE_7",
+     .udesc = "Read block shared From Local node to Node 7",
+     .ucode = 0x82,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_BLOCK_MODIFIED_LOCAL_TO_NODE_7",
+     .udesc = "Read block modified From Local node to Node 7",
+     .ucode = 0x84,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "CHANGE_TO_DIRTY_LOCAL_TO_NODE_7",
+     .udesc = "Change-to-Dirty From Local node to Node 7",
+     .ucode = 0x88,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0xff,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_cpu_command_requests_to_target_node[]={
+   { .uname = "READ_SIZED_LOCAL_TO_NODE_0",
+     .udesc = "Read Sized From Local node to Node 0",
+     .ucode = 0x11,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "WRITE_SIZED_LOCAL_TO_NODE_0",
+     .udesc = "Write Sized From Local node to Node 0",
+     .ucode = 0x12,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "VICTIM_BLOCK_LOCAL_TO_NODE_0",
+     .udesc = "Victim Block From Local node to Node 0",
+     .ucode = 0x14,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_SIZED_LOCAL_TO_NODE_1",
+     .udesc = "Read Sized From Local node to Node 1",
+     .ucode = 0x21,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "WRITE_SIZED_LOCAL_TO_NODE_1",
+     .udesc = "Write Sized From Local node to Node 1",
+     .ucode = 0x22,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "VICTIM_BLOCK_LOCAL_TO_NODE_1",
+     .udesc = "Victim Block From Local node to Node 1",
+     .ucode = 0x24,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_SIZED_LOCAL_TO_NODE_2",
+     .udesc = "Read Sized From Local node to Node 2",
+     .ucode = 0x41,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "WRITE_SIZED_LOCAL_TO_NODE_2",
+     .udesc = "Write Sized From Local node to Node 2",
+     .ucode = 0x42,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "VICTIM_BLOCK_LOCAL_TO_NODE_2",
+     .udesc = "Victim Block From Local node to Node 2",
+     .ucode = 0x44,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_SIZED_LOCAL_TO_NODE_3",
+     .udesc = "Read Sized From Local node to Node 3",
+     .ucode = 0x81,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "WRITE_SIZED_LOCAL_TO_NODE_3",
+     .udesc = "Write Sized From Local node to Node 3",
+     .ucode = 0x82,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "VICTIM_BLOCK_LOCAL_TO_NODE_3",
+     .udesc = "Victim Block From Local node to Node 3",
+     .ucode = 0x84,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_SIZED_LOCAL_TO_NODE_4",
+     .udesc = "Read Sized From Local node to Node 4",
+     .ucode = 0x19,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "WRITE_SIZED_LOCAL_TO_NODE_4",
+     .udesc = "Write Sized From Local node to Node 4",
+     .ucode = 0x1a,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "VICTIM_BLOCK_LOCAL_TO_NODE_4",
+     .udesc = "Victim Block From Local node to Node 4",
+     .ucode = 0x1c,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_SIZED_LOCAL_TO_NODE_5",
+     .udesc = "Read Sized From Local node to Node 5",
+     .ucode = 0x29,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "WRITE_SIZED_LOCAL_TO_NODE_5",
+     .udesc = "Write Sized From Local node to Node 5",
+     .ucode = 0x2a,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "VICTIM_BLOCK_LOCAL_TO_NODE_5",
+     .udesc = "Victim Block From Local node to Node 5",
+     .ucode = 0x2c,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_SIZED_LOCAL_TO_NODE_6",
+     .udesc = "Read Sized From Local node to Node 6",
+     .ucode = 0x49,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "WRITE_SIZED_LOCAL_TO_NODE_6",
+     .udesc = "Write Sized From Local node to Node 6",
+     .ucode = 0x4a,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "VICTIM_BLOCK_LOCAL_TO_NODE_6",
+     .udesc = "Victim Block From Local node to Node 6",
+     .ucode = 0x4c,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "READ_SIZED_LOCAL_TO_NODE_7",
+     .udesc = "Read Sized From Local node to Node 7",
+     .ucode = 0x89,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "WRITE_SIZED_LOCAL_TO_NODE_7",
+     .udesc = "Write Sized From Local node to Node 7",
+     .ucode = 0x8a,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname = "VICTIM_BLOCK_LOCAL_TO_NODE_7",
+     .udesc = "Victim Block From Local node to Node 7",
+     .ucode = 0x8c,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname  = "ALL_LOCAL_TO_NODE_0_3",
+     .udesc  = "All From Local node to Node 0-3",
+     .ucode = 0xf7,
+     .uflags= AMD64_FL_NCOMBO,
+   },
+   { .uname  = "ALL_LOCAL_TO_NODE_4_7",
+     .udesc  = "All From Local node to Node 4-7",
+     .ucode = 0xff,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_request_cache_status_0[]={
+   { .uname = "PROBE_HIT_S",
+     .udesc = "Probe Hit S",
+     .ucode = 0x1,
+   },
+   { .uname = "PROBE_HIT_E",
+     .udesc = "Probe Hit E",
+     .ucode = 0x2,
+   },
+   { .uname = "PROBE_HIT_MUW_OR_O",
+     .udesc = "Probe Hit MuW or O",
+     .ucode = 0x4,
+   },
+   { .uname = "PROBE_HIT_M",
+     .udesc = "Probe Hit M",
+     .ucode = 0x8,
+   },
+   { .uname = "PROBE_MISS",
+     .udesc = "Probe Miss",
+     .ucode = 0x10,
+   },
+   { .uname = "DIRECTED_PROBE",
+     .udesc = "Directed Probe",
+     .ucode = 0x20,
+   },
+   { .uname = "TRACK_CACHE_STAT_FOR_RDBLK",
+     .udesc = "Track Cache Stat for RdBlk",
+     .ucode = 0x40,
+   },
+   { .uname = "TRACK_CACHE_STAT_FOR_RDBLKS",
+     .udesc = "Track Cache Stat for RdBlkS",
+     .ucode = 0x80,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0xff,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_request_cache_status_1[]={
+   { .uname = "PROBE_HIT_S",
+     .udesc = "Probe Hit S",
+     .ucode = 0x1,
+   },
+   { .uname = "PROBE_HIT_E",
+     .udesc = "Probe Hit E",
+     .ucode = 0x2,
+   },
+   { .uname = "PROBE_HIT_MUW_OR_O",
+     .udesc = "Probe Hit MuW or O",
+     .ucode = 0x4,
+   },
+   { .uname = "PROBE_HIT_M",
+     .udesc = "Probe Hit M",
+     .ucode = 0x8,
+   },
+   { .uname = "PROBE_MISS",
+     .udesc = "Probe Miss",
+     .ucode = 0x10,
+   },
+   { .uname = "DIRECTED_PROBE",
+     .udesc = "Directed Probe",
+     .ucode = 0x20,
+   },
+   { .uname = "TRACK_CACHE_STAT_FOR_CHGTODIRTY",
+     .udesc = "Track Cache Stat for ChgToDirty",
+     .ucode = 0x40,
+   },
+   { .uname = "TRACK_CACHE_STAT_FOR_RDBLKM",
+     .udesc = "Track Cache Stat for RdBlkM",
+     .ucode = 0x80,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0xff,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_memory_controller_requests[]={
+   { .uname = "WRITE_REQUESTS_TO_DCT",
+     .udesc = "Write requests sent to the DCT",
+     .ucode = 0x1,
+   },
+   { .uname = "READ_REQUESTS_TO_DCT",
+     .udesc = "Read requests (including prefetch requests) sent to the DCT",
+     .ucode = 0x2,
+   },
+   { .uname = "PREFETCH_REQUESTS_TO_DCT",
+     .udesc = "Prefetch requests sent to the DCT",
+     .ucode = 0x4,
+   },
+   { .uname = "32_BYTES_SIZED_WRITES",
+     .udesc = "32 Bytes Sized Writes",
+     .ucode = 0x8,
+   },
+   { .uname = "64_BYTES_SIZED_WRITES",
+     .udesc = "64 Bytes Sized Writes",
+     .ucode = 0x10,
+   },
+   { .uname = "32_BYTES_SIZED_READS",
+     .udesc = "32 Bytes Sized Reads",
+     .ucode = 0x20,
+   },
+   { .uname = "64_BYTE_SIZED_READS",
+     .udesc = "64 Byte Sized Reads",
+     .ucode = 0x40,
+   },
+   { .uname = "READ_REQUESTS_TO_DCT_WHILE_WRITES_PENDING",
+     .udesc = "Read requests sent to the DCT while writes requests are pending in the DCT",
+     .ucode = 0x80,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0xff,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_read_request_to_l3_cache[]={
+   { .uname = "READ_BLOCK_EXCLUSIVE",
+     .udesc = "Read Block Exclusive (Data cache read)",
+     .ucode = 0x1,
+     .grpid = 0,
+   },
+   { .uname = "READ_BLOCK_SHARED",
+     .udesc = "Read Block Shared (Instruction cache read)",
+     .ucode = 0x2,
+     .grpid = 0,
+   },
+   { .uname = "READ_BLOCK_MODIFY",
+     .udesc = "Read Block Modify",
+     .ucode = 0x4,
+     .grpid = 0,
+   },
+   { .uname = "PREFETCH",
+     .udesc = "Count prefetches honly",
+     .ucode = 0x8,
+     .grpid = 0,
+   },
+   { .uname  = "READ_BLOCK_ANY",
+     .udesc  = "Count any read request",
+     .ucode = 0x7,
+     .grpid = 0,
+     .uflags= AMD64_FL_DFL | AMD64_FL_NCOMBO,
+   },
+  CORE_SELECT(1),
+};
+
+static const amd64_umask_t amd64_fam15h_nb_l3_fills_caused_by_l2_evictions[]={
+   { .uname = "SHARED",
+     .udesc = "Shared",
+     .ucode = 0x1,
+     .grpid = 0,
+   },
+   { .uname = "EXCLUSIVE",
+     .udesc = "Exclusive",
+     .ucode = 0x2,
+     .grpid = 0,
+   },
+   { .uname = "OWNED",
+     .udesc = "Owned",
+     .ucode = 0x4,
+     .grpid = 0,
+   },
+   { .uname = "MODIFIED",
+     .udesc = "Modified",
+     .ucode = 0x8,
+     .grpid = 0,
+   },
+  { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0xff,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+     .grpid = 0,
+   },
+   CORE_SELECT(1),
+ };
+
+static const amd64_umask_t amd64_fam15h_nb_l3_evictions[]={
+   { .uname = "SHARED",
+     .udesc = "Shared",
+     .ucode = 0x1,
+   },
+   { .uname = "EXCLUSIVE",
+     .udesc = "Exclusive",
+     .ucode = 0x2,
+   },
+   { .uname = "OWNED",
+     .udesc = "Owned",
+     .ucode = 0x4,
+   },
+   { .uname = "MODIFIED",
+     .udesc = "Modified",
+     .ucode = 0x8,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0xf,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_umask_t amd64_fam15h_nb_l3_latency[]={
+   { .uname = "L3_REQUEST_CYCLE",
+     .udesc = "L3 Request cycle count.",
+     .ucode = 0x1,
+   },
+   { .uname = "L3_REQUEST",
+     .udesc = "L3 request count.",
+     .ucode = 0x2,
+   },
+   { .uname  = "ALL",
+     .udesc  = "All sub-events selected",
+     .ucode = 0x3,
+     .uflags= AMD64_FL_NCOMBO | AMD64_FL_DFL,
+   },
+};
+
+static const amd64_entry_t amd64_fam15h_nb_pe[]={
+{ .name    = "DRAM_ACCESSES",
+  .desc    = "DRAM Accesses",
+  .code    = 0xe0,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_dram_accesses),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_dram_accesses,
+},
+{ .name    = "DRAM_CONTROLLER_PAGE_TABLE_OVERFLOWS",
+  .desc    = "DRAM Controller Page Table Overflows",
+  .code    = 0xe1,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_dram_controller_page_table_overflows),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_dram_controller_page_table_overflows,
+},
+{ .name    = "MEMORY_CONTROLLER_DRAM_COMMAND_SLOTS_MISSED",
+  .desc    = "Memory Controller DRAM Command Slots Missed",
+  .code    = 0xe2,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_memory_controller_dram_command_slots_missed),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_memory_controller_dram_command_slots_missed,
+},
+{ .name    = "MEMORY_CONTROLLER_TURNAROUNDS",
+  .desc    = "Memory Controller Turnarounds",
+  .code    = 0xe3,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_memory_controller_turnarounds),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_memory_controller_turnarounds,
+},
+{ .name    = "MEMORY_CONTROLLER_BYPASS_COUNTER_SATURATION",
+  .desc    = "Memory Controller Bypass Counter Saturation",
+  .code    = 0xe4,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_memory_controller_bypass_counter_saturation),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_memory_controller_bypass_counter_saturation,
+},
+{ .name    = "THERMAL_STATUS",
+  .desc    = "Thermal Status",
+  .code    = 0xe8,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_thermal_status),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_thermal_status,
+},
+{ .name    = "CPU_IO_REQUESTS_TO_MEMORY_IO",
+  .desc    = "CPU/IO Requests to Memory/IO",
+  .code    = 0xe9,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_cpu_io_requests_to_memory_io),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_cpu_io_requests_to_memory_io,
+},
+{ .name    = "CACHE_BLOCK_COMMANDS",
+  .desc    = "Cache Block Commands",
+  .code    = 0xea,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_cache_block_commands),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_cache_block_commands,
+},
+{ .name    = "SIZED_COMMANDS",
+  .desc    = "Sized Commands",
+  .code    = 0xeb,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_sized_commands),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_sized_commands,
+},
+{ .name    = "PROBE_RESPONSES_AND_UPSTREAM_REQUESTS",
+  .desc    = "Probe Responses and Upstream Requests",
+  .code    = 0xec,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_probe_responses_and_upstream_requests),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_probe_responses_and_upstream_requests,
+},
+{ .name    = "GART_EVENTS",
+  .desc    = "GART Events",
+  .code    = 0xee,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_gart_events),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_gart_events,
+},
+{ .name    = "LINK_TRANSMIT_BANDWIDTH_LINK_0",
+  .desc    = "Link Transmit Bandwidth Link 0",
+  .code    = 0xf6,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_link_transmit_bandwidth),
+  .ngrp    = 2,
+  .umasks  = amd64_fam15h_nb_link_transmit_bandwidth,
+},
+{ .name    = "LINK_TRANSMIT_BANDWIDTH_LINK_1",
+  .desc    = "Link Transmit Bandwidth Link 1",
+  .code    = 0xf7,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_link_transmit_bandwidth),
+  .ngrp    = 2,
+  .umasks  = amd64_fam15h_nb_link_transmit_bandwidth,
+},
+{ .name    = "LINK_TRANSMIT_BANDWIDTH_LINK_2",
+  .desc    = "Link Transmit Bandwidth Link 2",
+  .code    = 0xf8,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_link_transmit_bandwidth),
+  .ngrp    = 2,
+  .umasks  = amd64_fam15h_nb_link_transmit_bandwidth,
+},
+{ .name    = "LINK_TRANSMIT_BANDWIDTH_LINK_3",
+  .desc    = "Link Transmit Bandwidth Link 3",
+  .code    = 0x1f9,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_link_transmit_bandwidth),
+  .ngrp    = 2,
+  .umasks  = amd64_fam15h_nb_link_transmit_bandwidth,
+},
+{ .name    = "CPU_TO_DRAM_REQUESTS_TO_TARGET_NODE",
+  .desc    = "CPU to DRAM Requests to Target Node",
+  .code    = 0x1e0,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_cpu_to_dram_requests_to_target_node),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_cpu_to_dram_requests_to_target_node,
+},
+{ .name    = "IO_TO_DRAM_REQUESTS_TO_TARGET_NODE",
+  .desc    = "IO to DRAM Requests to Target Node",
+  .code    = 0x1e1,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_io_to_dram_requests_to_target_node),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_io_to_dram_requests_to_target_node,
+},
+{ .name    = "CPU_READ_COMMAND_LATENCY_TO_TARGET_NODE_0_3",
+  .desc    = "CPU Read Command Latency to Target Node 0-3",
+  .code    = 0x1e2,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_cpu_read_command_requests_to_target_node_0_3),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_cpu_read_command_requests_to_target_node_0_3,
+},
+{ .name    = "CPU_READ_COMMAND_REQUESTS_TO_TARGET_NODE_0_3",
+  .desc    = "CPU Read Command Requests to Target Node 0-3",
+  .code    = 0x1e3,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_cpu_read_command_requests_to_target_node_0_3),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_cpu_read_command_requests_to_target_node_0_3,
+},
+{ .name    = "CPU_READ_COMMAND_LATENCY_TO_TARGET_NODE_4_7",
+  .desc    = "CPU Read Command Latency to Target Node 4-7",
+  .code    = 0x1e4,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_cpu_read_command_requests_to_target_node_4_7),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_cpu_read_command_requests_to_target_node_4_7,
+},
+{ .name    = "CPU_READ_COMMAND_REQUESTS_TO_TARGET_NODE_4_7",
+  .desc    = "CPU Read Command Requests to Target Node 4-7",
+  .code    = 0x1e5,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_cpu_read_command_requests_to_target_node_4_7),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_cpu_read_command_requests_to_target_node_4_7,
+},
+{ .name    = "CPU_COMMAND_LATENCY_TO_TARGET_NODE",
+  .desc    = "CPU Command Latency to Target Node",
+  .code    = 0x1e6,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_cpu_command_requests_to_target_node),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_cpu_command_requests_to_target_node,
+},
+{ .name    = "CPU_REQUESTS_TO_TARGET_NODE",
+  .desc    = "CPU Requests to Target Node",
+  .code    = 0x1e7,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_cpu_command_requests_to_target_node),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_cpu_command_requests_to_target_node,
+},
+{ .name    = "REQUEST_CACHE_STATUS_0",
+  .desc    = "Request Cache Status 0",
+  .code    = 0x1ea,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_request_cache_status_0),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_request_cache_status_0,
+},
+{ .name    = "REQUEST_CACHE_STATUS_1",
+  .desc    = "Request Cache Status 1",
+  .code    = 0x1eb,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_request_cache_status_1),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_request_cache_status_1,
+},
+{ .name    = "MEMORY_CONTROLLER_REQUESTS",
+  .desc    = "Memory Controller Requests",
+  .code    = 0x1f0,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_memory_controller_requests),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_memory_controller_requests,
+},
+{ .name    = "READ_REQUEST_TO_L3_CACHE",
+  .desc    = "Read Request to L3 Cache",
+  .code    = 0x4e0,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_read_request_to_l3_cache),
+  .ngrp    = 2,
+  .umasks  = amd64_fam15h_nb_read_request_to_l3_cache,
+},
+{ .name    = "L3_CACHE_MISSES",
+  .desc    = "L3 Cache Misses",
+  .code    = 0x4e1,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_read_request_to_l3_cache),
+  .ngrp    = 2,
+  .umasks  = amd64_fam15h_nb_read_request_to_l3_cache,
+},
+{ .name    = "L3_FILLS_CAUSED_BY_L2_EVICTIONS",
+  .desc    = "L3 Fills caused by L2 Evictions",
+  .code    = 0x4e2,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_l3_fills_caused_by_l2_evictions),
+  .ngrp    = 2,
+  .umasks  = amd64_fam15h_nb_l3_fills_caused_by_l2_evictions,
+},
+{ .name    = "L3_EVICTIONS",
+  .desc    = "L3 Evictions",
+  .code    = 0x4e3,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_l3_evictions),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_l3_evictions,
+},
+{ .name    = "NON_CANCELED_L3_READ_REQUESTS",
+  .desc    = "Non-canceled L3 Read Requests",
+  .code    = 0x4ed,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_read_request_to_l3_cache),
+  .ngrp    = 2,
+  .umasks  = amd64_fam15h_nb_read_request_to_l3_cache,
+},
+{ .name    = "L3_LATENCY",
+  .desc    = "L3 Latency",
+  .code    = 0x4ef,
+  .numasks = LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_l3_latency),
+  .ngrp    = 1,
+  .umasks  = amd64_fam15h_nb_l3_latency,
+},
+};
diff --git a/src/libpfm4/lib/events/arm_cortex_a8_events.h b/src/libpfm4/lib/events/arm_cortex_a8_events.h
index 467813e..2b61dda 100644
--- a/src/libpfm4/lib/events/arm_cortex_a8_events.h
+++ b/src/libpfm4/lib/events/arm_cortex_a8_events.h
@@ -82,7 +82,7 @@ static const arm_entry_t arm_cortex_a8_pe []={
 	},
 	{.name = "PC_WRITE",
 	 .code = 0x0c,
-	 .desc = "Software change of PC.  Equivelant to branches"
+	 .desc = "Software change of PC.  Equivalent to branches"
 	},
 	{.name = "PC_IMM_BRANCH",
 	 .code = 0x0d,
diff --git a/src/libpfm4/lib/events/arm_cortex_a9_events.h b/src/libpfm4/lib/events/arm_cortex_a9_events.h
index 4f56fac..c034bd3 100644
--- a/src/libpfm4/lib/events/arm_cortex_a9_events.h
+++ b/src/libpfm4/lib/events/arm_cortex_a9_events.h
@@ -82,7 +82,7 @@ static const arm_entry_t arm_cortex_a9_pe []={
 	},
 	{.name = "PC_WRITE",
 	 .code = 0x0c,
-	 .desc = "Software change of PC.  Equivelant to branches"
+	 .desc = "Software change of PC.  Equivalent to branches"
 	},
 	{.name = "PC_IMM_BRANCH",
 	 .code = 0x0d,
diff --git a/src/libpfm4/lib/events/intel_netburst_events.h b/src/libpfm4/lib/events/intel_netburst_events.h
index 73f58da..e24f22f 100644
--- a/src/libpfm4/lib/events/intel_netburst_events.h
+++ b/src/libpfm4/lib/events/intel_netburst_events.h
@@ -396,7 +396,7 @@ static const netburst_entry_t netburst_events[] = {
 	 .desc = "Number of entries (clipped at 15) in the IOQ that are "
 		 "active. An allocated entry can be a sector (64 bytes) "
 		 "or a chunk of 8 bytes. This event must be programmed in "
-		 "conjuction with IOQ_allocation. All 'TYPE_BIT*' event-masks "
+		 "conjunction with IOQ_allocation. All 'TYPE_BIT*' event-masks "
 		 "together are treated as a single 5-bit value",
 	 .event_select = 0x1A,
 	 .escr_select = 0x6,
diff --git a/src/libpfm4/lib/events/intel_slm_events.h b/src/libpfm4/lib/events/intel_slm_events.h
new file mode 100644
index 0000000..c540e64
--- /dev/null
+++ b/src/libpfm4/lib/events/intel_slm_events.h
@@ -0,0 +1,896 @@
+/*
+ * Copyright (c) 2013 Google, Inc
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * This file is part of libpfm, a performance monitoring support library for
+ * applications on Linux.
+ *
+ * PMU: slm (Intel Silvermont)
+ */
+
+static const intel_x86_umask_t slm_icache[]={
+   { .uname  = "ACCESSES",
+     .udesc  = "Instruction fetches, including uncacheacble fetches",
+     .ucode = 0x300,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+   },
+   { .uname  = "MISSES",
+     .udesc  = "Count all instructions fetches that miss tha icache or produce memory requests. This includes uncacheache fetches. Any instruction fetch miss is counted only once and not once for every cycle it is outstanding",
+     .ucode = 0x200,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "HIT",
+     .udesc  = "Count all instructions fetches from the instruction cache",
+     .ucode = 0x100,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+};
+
+static const intel_x86_umask_t slm_uops_retired[]={
+   { .uname  = "ANY",
+     .udesc  = "Micro-ops retired",
+     .ucode = 0x1000,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+   },
+   { .uname  = "MS",
+     .udesc  = "Micro-ops retired that were supplied fro MSROM",
+     .ucode = 0x0100,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "X87",
+     .udesc  = "Micro-ops retired that used X87 hardware",
+     .ucode = 0x0200,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "MUL",
+     .udesc  = "Micro-ops retired that used MUL hardware",
+     .ucode = 0x0400,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "DIV",
+     .udesc  = "Micro-ops retired that used DIV hardware",
+     .ucode = 0x0800,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "STALLED_CYCLES",
+     .udesc  = "Cycles no micro-ops retired",
+     .ucode = 0x1000 | INTEL_X86_MOD_INV | (0x1 << INTEL_X86_CMASK_BIT),
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "STALLS",
+     .udesc  = "Periods no micro-ops retired",
+     .ucode = 0x1000 | INTEL_X86_MOD_EDGE | INTEL_X86_MOD_INV | (0x1 << INTEL_X86_CMASK_BIT),
+     .uflags= INTEL_X86_NCOMBO,
+   },
+};
+
+static const intel_x86_umask_t slm_inst_retired[]={
+   { .uname  = "ANY_P",
+     .udesc  = "Instructions retired using generic counter (precise event)",
+     .ucode = 0x0,
+     .uflags= INTEL_X86_PEBS | INTEL_X86_DFL,
+   },
+   { .uname  = "ANY",
+     .udesc  = "Instructions retired using generic counter (precise event)",
+     .uequiv = "ANY_P",
+     .ucode = 0x0,
+     .uflags= INTEL_X86_PEBS,
+   },
+};
+
+static const intel_x86_umask_t slm_l2_reject_xq[]={
+   { .uname  = "ALL",
+     .udesc  = "Number of demand and prefetch transactions that the L2 XQ rejects due to a full or near full condition which likely indictes back pressure from the IDI link. The XQ may reject transactions fro mthe L2Q (non-cacheable requests), BBS (L2 misses) and WOB (L2 write-back victims)",
+     .ucode = 0x000,
+     .uflags= INTEL_X86_DFL,
+   },
+};
+
+static const intel_x86_umask_t slm_machine_clears[]={
+   { .uname  = "SMC",
+     .udesc  = "Self-Modifying Code detected",
+     .ucode = 0x100,
+     .uflags= INTEL_X86_DFL,
+   },
+   { .uname  = "MEMORY_ORDERING",
+     .udesc  = "Number of stalled cycles due to memory ordering",
+     .ucode = 0x200,
+   },
+   { .uname  = "FP_ASSIST",
+     .udesc  = "Number of stalled cycle due to FPU assist",
+     .ucode = 0x400,
+   },
+   { .uname  = "ALL",
+     .udesc  = "Count any the machine clears",
+     .ucode = 0x800,
+   },
+   { .uname  = "ANY",
+     .udesc  = "Count any the machine clears",
+     .uequiv = "ALL",
+     .ucode = 0x800,
+   },
+};
+
+static const intel_x86_umask_t slm_br_inst_retired[]={
+   { .uname  = "ANY",
+     .udesc  = "Any retired branch instruction (Precise Event)",
+     .ucode = 0x0,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL | INTEL_X86_PEBS,
+   },
+   { .uname  = "ALL_BRANCHES",
+     .udesc  = "Any Retired branch instruction (Precise Event)",
+     .uequiv = "ANY",
+     .ucode = 0x0,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "JCC",
+     .udesc  = "JCC instructions retired (Precise Event)",
+     .ucode = 0x7e00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "TAKEN_JCC",
+     .udesc  = "Taken JCC instructions retired (Precise Event)",
+     .ucode = 0xfe00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "CALL",
+     .udesc  = "Near call instructions retired (Precise Event)",
+     .ucode = 0xf900,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "REL_CALL",
+     .udesc  = "Near relative call instructions retired (Precise Event)",
+     .ucode = 0xfd00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "IND_CALL",
+     .udesc  = "Near indirect call instructions retired (Precise Event)",
+     .ucode = 0xfb00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "RETURN",
+     .udesc  = "Near ret instructions retired (Precise Event)",
+     .ucode = 0xc00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "NON_RETURN_IND",
+     .udesc  = "Number of near indirect jmp and near indirect call instructions retired (Precise Event)",
+     .ucode = 0xeb00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "FAR_BRANCH",
+     .udesc  = "Far branch instructions retired (Precise Event)",
+     .uequiv = "FAR",
+     .ucode = 0xbf00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "FAR",
+     .udesc  = "Far branch instructions retired (Precise Event)",
+     .ucode = 0xbf00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+};
+
+static const intel_x86_umask_t slm_baclears[]={
+   { .uname  = "ANY",
+     .udesc  = "BACLEARS asserted",
+     .uequiv = "ALL",
+     .ucode = 0x100,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "ALL",
+     .udesc  = "BACLEARS asserted",
+     .ucode = 0x100,
+     .uflags= INTEL_X86_DFL | INTEL_X86_NCOMBO,
+   },
+   { .uname  = "INDIRECT",
+     .udesc  = "Number of baclears for indirect branches",
+     .ucode = 0x200,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "UNCOND",
+     .udesc  = "Number of baclears for unconditional branches",
+     .ucode = 0x400,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "RETURN",
+     .udesc  = "Number of baclears for return branches",
+     .ucode = 0x800,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "COND",
+     .udesc  = "Number of baclears for conditional branches",
+     .ucode = 0x1000,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+};
+
+static const intel_x86_umask_t slm_cpu_clk_unhalted[]={
+   { .uname  = "CORE_P",
+     .udesc  = "Core cycles when core is not halted",
+     .ucode = 0x0,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+   },
+   { .uname  = "BUS",
+     .udesc  = "Bus cycles when core is not halted. This event can give a measurement of the elapsed time. This events has a constant ratio with CPU_CLK_UNHALTED:REF event, which is the maximum bus to processor frequency ratio",
+     .uequiv = "REF_P",
+     .ucode = 0x100,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "REF_P",
+     .udesc  = "Number of reference cycles that the core is not in a halted state. The core enters the halted state when it is running the HLT instruction. In mobile systems, the core frequency may change from time to time. This event is not affected by core frequency changes but counts as if the core is running a the same maximum frequency all the time",
+     .ucode = 0x200,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+};
+
+static const intel_x86_umask_t slm_mem_uop_retired[]={
+   { .uname  = "LD_DCU_MISS",
+     .udesc  = "Number of load uops retired that miss in L1 data cache. Note that prefetch misses will not be counted",
+     .ucode = 0x100,
+   },
+   { .uname  = "LD_L2_HIT",
+     .udesc  = "Number of load uops retired that hit L2 (Precise Event)",
+     .ucode = 0x200,
+     .uflags= INTEL_X86_PEBS,
+   },
+   { .uname  = "LD_L2_MISS",
+     .udesc  = "Number of load uops retired that missed L2 (Precise Event)",
+     .ucode = 0x400,
+     .uflags= INTEL_X86_PEBS,
+   },
+   { .uname  = "LD_DTLB_MISS",
+     .udesc  = "Number of load uops retired that had a DTLB miss (Precise Event)",
+     .ucode = 0x800,
+     .uflags= INTEL_X86_PEBS,
+   },
+   { .uname  = "LD_UTLB_MISS",
+     .udesc  = "Number of load uops retired that had a UTLB miss",
+     .ucode = 0x1000,
+   },
+   { .uname  = "HITM",
+     .udesc  = "Number of load uops retired that got data from the other core or from the other module and the line was modified (Precise Event)",
+     .ucode = 0x2000,
+     .uflags= INTEL_X86_PEBS,
+   },
+   { .uname  = "ANY_LD",
+     .udesc  = "Number of load uops retired",
+     .ucode = 0x4000,
+   },
+   { .uname  = "ANY_ST",
+     .udesc  = "Number of store uops retired",
+     .ucode = 0x8000,
+   },
+};
+
+static const intel_x86_umask_t slm_page_walks[]={
+   { .uname  = "D_SIDE_CYCLES",
+     .udesc  = "Number of cycles when a D-side page walk is in progress. Page walk duration divided by number of page walks is the average duration of page-walks",
+     .ucode = 0x100,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "D_SIDE_WALKS",
+     .udesc  = "Number of D-side page walks",
+     .ucode = 0x100 | INTEL_X86_MOD_EDGE | (1ULL << INTEL_X86_CMASK_BIT),
+     .modhw = _INTEL_X86_ATTR_E |  _INTEL_X86_ATTR_C,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "I_SIDE_CYCLES",
+     .udesc  = "Number of cycles when a I-side page walk is in progress. Page walk duration divided by number of page walks is the average duration of page-walks",
+     .ucode = 0x200,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "I_SIDE_WALKS",
+     .udesc  = "Number of I-side page walks",
+     .ucode = 0x200 | INTEL_X86_MOD_EDGE | (1ULL << INTEL_X86_CMASK_BIT),
+     .modhw = _INTEL_X86_ATTR_E |  _INTEL_X86_ATTR_C,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+};
+
+static const intel_x86_umask_t slm_llc_rqsts[]={
+   { .uname  = "MISS",
+     .udesc  = "Number of L2 cache misses",
+     .ucode = 0x4100,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "ANY",
+     .udesc  = "Number of L2 cache references",
+     .ucode = 0x4f00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+   },
+};
+
+static const intel_x86_umask_t slm_rehabq[]={
+   { .uname  = "LD_BLOCK_ST_FORWARD",
+     .udesc  = "Number of retired loads that were prohibited from receiving forwarded data from the store because of address mismatch (Precise Event)",
+     .ucode = 0x0100,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "LD_BLOCK_STD_NOTREADY",
+     .udesc  = "Number of times forward was technically possible but did not occur because the store data was not available at the right time",
+     .ucode = 0x0200,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "ST_SPLITS",
+     .udesc  = "Number of retired stores that experienced cache line boundary splits",
+     .ucode = 0x0400,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "LD_SPLITS",
+     .udesc  = "Number of retired loads that experienced cache line boundary splits (Precise Event)",
+     .ucode = 0x0800,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "LOCK",
+     .udesc  = "Number of retired memory operations with lock semantics. These are either implicit locked instructions such as XCHG or instructions with an explicit LOCK prefix",
+     .ucode = 0x1000,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "STA_FULL",
+     .udesc  = "Number of retired stores that are delayed becuase there is not a store address buffer available",
+     .ucode = 0x2000,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "ANY_LD",
+     .udesc  = "Number of load uops reissued from RehabQ",
+     .ucode = 0x4000,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "ANY_ST",
+     .udesc  = "Number of store uops reissued from RehabQ",
+     .ucode = 0x8000,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+};
+
+static const intel_x86_umask_t slm_offcore_response[]={
+   { .uname  = "DMND_DATA_RD",
+     .udesc  = "Request: number of demand and DCU prefetch data reads of full and partial cachelines as well as demand data page table entry cacheline reads. Does not count L2 data read prefetches or instruction fetches",
+     .ucode = 1ULL << (0 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "DMND_RFO",
+     .udesc  = "Request: number of demand and DCU prefetch reads for ownership (RFO) requests generated by a write to data cacheline. Does not count L2 RFO prefetches",
+     .ucode = 1ULL << (1 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "DMND_IFETCH",
+     .udesc  = "Request: number of demand and DCU prefetch instruction cacheline reads. Does not count L2 code read prefetches",
+     .ucode = 1ULL << (2 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "WB",
+     .udesc  = "Request: number of writebacks (modified to exclusive) transactions",
+     .ucode = 1ULL << (3 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PF_L2_DATA_RD",
+     .udesc  = "Request: number of data cacheline reads generated by L2 prefetchers",
+     .ucode = 1ULL << (4 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PF_RFO",
+     .udesc  = "Request: number of RFO requests generated by L2 prefetchers",
+     .ucode = 1ULL << (5 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PF_IFETCH",
+     .udesc  = "Request: number of code reads generated by L2 prefetchers",
+     .ucode = 1ULL << (6 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PARTIAL_READ",
+     .udesc  = "Request: number of demand reads of partial cachelines (including UC, WC)",
+     .ucode = 1ULL << (7 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PARTIAL_WRITE",
+     .udesc  = "Request: number of demand RFO requests to write to partial cache lines (includes UC, WT, WP)",
+     .ucode = 1ULL << (8 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "UC_IFETCH",
+     .udesc  = "Request: number of UC instruction fetches",
+     .ucode = 1ULL << (9 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "BUS_LOCKS",
+     .udesc  = "Request: number bus lock and split lock requests",
+     .ucode = 1ULL << (10 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "STRM_ST",
+     .udesc  = "Request: number of streaming store requests",
+     .ucode = 1ULL << (11 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "SW_PREFETCH",
+     .udesc  = "Request: number of software prefetch requests",
+     .ucode = 1ULL << (12 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PF_L1_DATA_RD",
+     .udesc  = "Request: number of data cacheline reads generated by L1 prefetchers",
+     .ucode = 1ULL << (13 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PARTIAL_STRM_ST",
+     .udesc  = "Request: number of partial streaming store requests",
+     .ucode = 1ULL << (14 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "OTHER",
+     .udesc  = "Request: counts one any other request that crosses IDI, including I/O",
+     .ucode = 1ULL << (15+8),
+     .grpid = 0,
+   },
+   { .uname  = "ANY_IFETCH",
+     .udesc  = "Request: combination of PF_IFETCH | DMND_IFETCH | UC_IFETCH",
+     .uequiv = "PF_IFETCH:DMND_IFETCH:UC_IFETCH",
+     .ucode =  (1ULL << 6 | 1ULL << 2 | 1ULL << 9)  << 8,
+     .grpid = 0,
+   },
+   { .uname  = "ANY_REQUEST",
+     .udesc  = "Request: combination of all request umasks",
+     .uequiv = "DMND_DATA_RD:DMND_RFO:DMND_IFETCH:WB:PF_L2_DATA_RD:PF_RFO:PF_IFETCH:PARTIAL_READ:PARTIAL_WRITE:UC_IFETCH:BUS_LOCKS:STRM_ST:SW_PREFETCH:PF_L1_DATA_RD:PARTIAL_STRM_ST:OTHER",
+     .ucode = 0xffff00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+     .grpid = 0,
+   },
+   { .uname  = "ANY_DATA",
+     .udesc  = "Request: combination of DMND_DATA | PF_L1_DATA_RD | PF_L2_DATA_RD",
+     .uequiv = "DMND_DATA_RD:PF_L1_DATA_RD:PF_L2_DATA_RD",
+     .ucode =  (1ULL << 0 | 1ULL << 4 | 1ULL << 13) << 8,
+     .grpid = 0,
+   },
+   { .uname  = "ANY_RFO",
+     .udesc  = "Request: combination of DMND_RFO | PF_RFO",
+     .uequiv = "DMND_RFO:PF_RFO",
+     .ucode =  (1ULL << 1 | 1ULL << 5) << 8,
+     .grpid = 0,
+   },
+   { .uname  = "ANY_RESPONSE",
+     .udesc  = "Response: count any response type",
+     .ucode = 1ULL << (16+8),
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL | INTEL_X86_EXCL_GRP_GT,
+     .grpid = 1,
+   },
+   { .uname  = "L2_HIT",
+     .udesc  = "Supplier: counts L2 hits in M/E/S states",
+     .ucode = 1ULL << (18+8),
+     .grpid = 1,
+   },
+   { .uname  = "SNP_NONE",
+     .udesc  = "Snoop: counts number of times no snoop-related information is available",
+     .ucode = 1ULL << (31+8),
+     .grpid = 2,
+   },
+   { .uname  = "SNP_MISS",
+     .udesc  = "Snoop: counts number of times a snoop was needed and it missed all snooped caches",
+     .ucode = 1ULL << (33+8),
+     .grpid = 2,
+   },
+   { .uname  = "SNP_HIT",
+     .udesc  = "Snoop: counts number of times a snoop hits in the other module where no modified copies were found in the L1 cache of the other core",
+     .ucode = 1ULL << (34+8),
+     .grpid = 2,
+   },
+   { .uname  = "SNP_HITM",
+     .udesc  = "Snoop: counts number of times a snoop hits in the other module where modified copies were found in the L1 cache of the other core",
+     .ucode = 1ULL << (36+8),
+     .grpid = 2,
+   },
+   { .uname  = "NON_DRAM",
+     .udesc  = "Snoop:  counts number of times target was a non-DRAM system address. This includes MMIO transactions",
+     .ucode = 1ULL << (37+8),
+     .grpid = 2,
+   },
+   { .uname  = "SNP_ANY",
+     .udesc  = "Snoop: any snoop reason",
+     .ucode = 0x7dULL << (31+8),
+     .uequiv = "SNP_NONE:SNP_MISS:SNP_HIT:SNP_HITM:NON_DRAM",
+     .uflags= INTEL_X86_DFL,
+     .grpid = 2,
+   },
+};
+
+static const intel_x86_umask_t slm_br_misp_inst_retired[]={
+   { .uname  = "ALL_BRANCHES",
+     .udesc  = "All mispredicted branches (Precise Event)",
+     .uequiv = "ANY",
+     .ucode = 0x0000, /* architectural encoding */
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "ANY",
+     .udesc  = "All mispredicted branches (Precise Event)",
+     .ucode = 0x0000, /* architectural encoding */
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_DFL,
+   },
+   { .uname  = "JCC",
+     .udesc  = "Number of mispredicted conditional branch instructions retired (Precise Event)",
+     .ucode = 0x7e00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "NON_RETURN_IND",
+     .udesc  = "Number of mispredicted non-return branch instructions retired (Precise Event)",
+     .ucode = 0xeb00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "FAR",
+     .udesc  = "Number of mispredicted far branch instructions retired (Precise Event)",
+     .ucode  = 0xbf00,
+     .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "RETURN",
+     .udesc  = "Number of mispredicted return branch instructions retired (Precise Event)",
+     .ucode = 0xf700,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "CALL",
+     .udesc  = "Number of mispredicted call branch instructions retired (Precise Event)",
+     .ucode = 0xf900,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "IND_CALL",
+     .udesc  = "Number of mispredicted indirect call branch instructions retired (Precise Event)",
+     .ucode = 0xfb00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "REL_CALL",
+     .udesc  = "Number of mispredicted relative call branch instructions retired (Precise Event)",
+     .ucode = 0xfd00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "TAKEN_JCC",
+     .udesc  = "Number of mispredicted taken conditional branch instructions retired (Precise Event)",
+     .ucode = 0xfe00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+};
+
+static const intel_x86_umask_t slm_no_alloc_cycles[]={
+   { .uname  = "ANY",
+     .udesc  = "Number of cycles when the front-end does not provide any instructions to be allocated for any reason",
+     .ucode = 0x3f00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+   },
+   { .uname  = "NOT_DELIVERED",
+     .udesc  = "Number of cycles when the front-end does not provide any instructions to be allocated but the back-end is not stalled",
+     .ucode = 0x5000,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+};
+
+static const intel_x86_umask_t slm_rs_full_stall[]={
+   { .uname  = "MEC",
+     .udesc  = "Number of cycles when the allocation pipeline is stalled due to the RS for the MEC cluster is full",
+     .ucode = 0x0100,
+   },
+   { .uname  = "IEC_PORT0",
+     .udesc  = "Number of cycles when the allocation pipeline is stalled due to the RS for port 0 integer cluster is full",
+     .ucode = 0x0200,
+   },
+   { .uname  = "IEC_PORT1",
+     .udesc  = "Number of cycles when the allocation pipeline is stalled due to the RS for port 1 integer cluster is full",
+     .ucode = 0x0400,
+   },
+   { .uname  = "FPC_PORT0",
+     .udesc  = "Number of cycles when the allocation pipeline is stalled due to the RS for port 0 floating-pointer cluster is full",
+     .ucode = 0x0800,
+   },
+   { .uname  = "FPC_PORT1",
+     .udesc  = "Number of cycles when the allocation pipeline is stalled due to the RS for port 1 floating-pointer cluster is full",
+     .ucode = 0x1000,
+   },
+   { .uname  = "ANY",
+     .udesc  = "Number of cycles when the allocation pipeline is stalled due any one of the RS being full",
+     .ucode = 0x1f00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+   },
+};
+
+static const intel_x86_umask_t slm_cycles_div_busy[]={
+   { .uname  = "ANY",
+     .udesc  = "Number of cycles the divider is busy",
+     .ucode = 0x0100,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+   },
+};
+
+static const intel_x86_umask_t slm_ms_decoded[]={
+   { .uname  = "ENTRY",
+     .udesc  = "Number of times the MSROM starts a flow of uops",
+     .ucode = 0x0100,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+   },
+};
+
+static const intel_x86_umask_t slm_decode_restriction[]={
+   { .uname  = "PREDECODE_WRONG",
+     .udesc  = "Number of times the prediction (from the predecode cache) for intruction length is incorrect",
+     .ucode = 0x0100,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+   },
+};
+
+static const intel_x86_entry_t intel_slm_pe[]={
+{ .name   = "UNHALTED_CORE_CYCLES",
+  .desc   = "Unhalted core cycles",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x200000003ull,
+  .code = 0x3c,
+},
+{ .name   = "UNHALTED_REFERENCE_CYCLES",
+  .desc   = "Unhalted reference cycle",
+  .modmsk = INTEL_FIXED3_ATTRS,
+  .cntmsk = 0x400000000ull,
+  .code = 0x0300, /* pseudo encoding */
+  .flags = INTEL_X86_FIXED,
+},
+{ .name   = "INSTRUCTION_RETIRED",
+  .desc   = "Instructions retired",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x100000003ull,
+  .code = 0xc0,
+},
+{ .name   = "INSTRUCTIONS_RETIRED",
+  .desc   = "This is an alias for INSTRUCTION_RETIRED",
+  .modmsk = INTEL_V2_ATTRS,
+  .equiv = "INSTRUCTION_RETIRED",
+  .cntmsk = 0x10003,
+  .code = 0xc0,
+},
+{ .name   = "LLC_REFERENCES",
+  .desc   = "Last level of cache references",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0x4f2e,
+},
+{ .name   = "LAST_LEVEL_CACHE_REFERENCES",
+  .desc   = "This is an alias for LLC_REFERENCES",
+  .modmsk = INTEL_V2_ATTRS,
+  .equiv = "LLC_REFERENCES",
+  .cntmsk = 0x3,
+  .code = 0x4f2e,
+},
+{ .name   = "LLC_MISSES",
+  .desc   = "Last level of cache misses",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0x412e,
+},
+{ .name   = "LAST_LEVEL_CACHE_MISSES",
+  .desc   = "This is an alias for LLC_MISSES",
+  .modmsk = INTEL_V2_ATTRS,
+  .equiv = "LLC_MISSES",
+  .cntmsk = 0x3,
+  .code = 0x412e,
+},
+{ .name   = "BRANCH_INSTRUCTIONS_RETIRED",
+  .desc   = "Branch instructions retired",
+  .modmsk = INTEL_V2_ATTRS,
+  .equiv = "BR_INST_RETIRED:ANY",
+  .cntmsk = 0x3,
+  .code = 0xc4,
+},
+{ .name   = "MISPREDICTED_BRANCH_RETIRED",
+  .desc   = "Mispredicted branch instruction retired",
+  .equiv  = "BR_MISP_INST_RETIRED",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0xc5,
+  .flags= INTEL_X86_PEBS,
+},
+/* begin model specific events */
+{ .name   = "DECODE_RESTRICTION",
+  .desc   = "Instruction length prediction delay",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0xe9,
+  .ngrp = 1,
+  .numasks = LIBPFM_ARRAY_SIZE(slm_decode_restriction),
+  .umasks = slm_decode_restriction,
+},
+{ .name   = "L2_REJECT_XQ",
+  .desc   = "Rejected L2 requests to XQ",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0x30,
+  .numasks = LIBPFM_ARRAY_SIZE(slm_l2_reject_xq),
+  .ngrp = 1,
+  .umasks = slm_l2_reject_xq,
+},
+{ .name   = "ICACHE",
+  .desc   = "Instruction fetches",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0x80,
+  .numasks = LIBPFM_ARRAY_SIZE(slm_icache),
+  .ngrp = 1,
+  .umasks = slm_icache,
+},
+{ .name   = "UOPS_RETIRED",
+  .desc   = "Micro-ops retired",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0xc2,
+  .numasks = LIBPFM_ARRAY_SIZE(slm_uops_retired),
+  .ngrp = 1,
+  .umasks = slm_uops_retired,
+},
+{ .name   = "INST_RETIRED",
+  .desc   = "Instructions retired",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0xc0,
+  .flags= INTEL_X86_PEBS,
+  .numasks = LIBPFM_ARRAY_SIZE(slm_inst_retired),
+  .ngrp = 1,
+  .umasks = slm_inst_retired,
+},
+{ .name   = "CYCLES_DIV_BUSY",
+  .desc   = "Cycles the divider is busy",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0xcd,
+  .numasks = LIBPFM_ARRAY_SIZE(slm_cycles_div_busy),
+  .ngrp = 1,
+  .umasks = slm_cycles_div_busy,
+},
+{ .name   = "RS_FULL_STALL",
+  .desc   = "RS full",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0xcb,
+  .numasks = LIBPFM_ARRAY_SIZE(slm_rs_full_stall),
+  .ngrp = 1,
+  .umasks = slm_rs_full_stall,
+},
+{ .name   = "LLC_RQSTS",
+  .desc   = "L2 cache requests",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0x2e,
+  .numasks = LIBPFM_ARRAY_SIZE(slm_llc_rqsts),
+  .ngrp = 1,
+  .umasks = slm_llc_rqsts,
+},
+{ .name   = "MACHINE_CLEARS",
+  .desc   = "Self-Modifying Code detected",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0xc3,
+  .numasks = LIBPFM_ARRAY_SIZE(slm_machine_clears),
+  .ngrp = 1,
+  .umasks = slm_machine_clears,
+},
+{ .name   = "BR_INST_RETIRED",
+  .desc   = "Retired branch instructions",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0xc4,
+  .numasks = LIBPFM_ARRAY_SIZE(slm_br_inst_retired),
+  .flags= INTEL_X86_PEBS,
+  .ngrp = 1,
+  .umasks = slm_br_inst_retired,
+},
+{ .name   = "BR_MISP_INST_RETIRED",
+  .desc   = "Mispredicted retired branch instructions",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0xc5,
+  .flags= INTEL_X86_PEBS,
+  .numasks = LIBPFM_ARRAY_SIZE(slm_br_misp_inst_retired),
+  .ngrp = 1,
+  .umasks = slm_br_misp_inst_retired,
+},
+{ .name   = "MS_DECODED",
+  .desc   = "MS decoder",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0xe7,
+  .numasks = LIBPFM_ARRAY_SIZE(slm_ms_decoded),
+  .ngrp = 1,
+  .umasks = slm_ms_decoded,
+},
+{ .name   = "BACLEARS",
+  .desc   = "Branch address calculator",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0xe6,
+  .numasks = LIBPFM_ARRAY_SIZE(slm_baclears),
+  .ngrp = 1,
+  .umasks = slm_baclears,
+},
+{ .name   = "NO_ALLOC_CYCLES",
+  .desc   = "Front-end allocation",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0xca,
+  .numasks = LIBPFM_ARRAY_SIZE(slm_no_alloc_cycles),
+  .ngrp = 1,
+  .umasks = slm_no_alloc_cycles,
+},
+{ .name   = "CPU_CLK_UNHALTED",
+  .desc   = "Core cycles when core is not halted",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0x3c,
+  .numasks = LIBPFM_ARRAY_SIZE(slm_cpu_clk_unhalted),
+  .ngrp = 1,
+  .umasks = slm_cpu_clk_unhalted,
+},
+{ .name   = "MEM_UOP_RETIRED",
+  .desc   = "Retired loads micro-ops",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0x4,
+  .flags= INTEL_X86_PEBS,
+  .numasks = LIBPFM_ARRAY_SIZE(slm_mem_uop_retired),
+  .ngrp = 1,
+  .umasks = slm_mem_uop_retired,
+},
+{ .name   = "PAGE_WALKS",
+  .desc   = "Number of page-walks executed",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0x5,
+  .numasks = LIBPFM_ARRAY_SIZE(slm_page_walks),
+  .ngrp = 1,
+  .umasks = slm_page_walks,
+},
+{ .name   = "CORE_REJECT",
+  .desc   = "Demand and L1 prefetcher requests rejected by L2",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0x31,
+},
+{ .name   = "REHABQ",
+  .desc   = "Memory reference queue",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0x3,
+  .code = 0x03,
+  .flags= INTEL_X86_PEBS,
+  .numasks = LIBPFM_ARRAY_SIZE(slm_rehabq),
+  .ngrp = 1,
+  .umasks = slm_rehabq,
+},
+{ .name   = "OFFCORE_RESPONSE_0",
+  .desc   = "Offcore response event (must provide at least one request type and either any_response or any combination of supplier + snoop)",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0xf,
+  .code = 0x01b7,
+  .flags= INTEL_X86_NHM_OFFCORE,
+  .numasks = LIBPFM_ARRAY_SIZE(slm_offcore_response),
+  .ngrp = 3,
+  .umasks = slm_offcore_response,
+},
+{ .name   = "OFFCORE_RESPONSE_1",
+  .desc   = "Offcore response event (must provide at least one request type and either any_response or any combination of supplier + snoop)",
+  .modmsk = INTEL_V2_ATTRS,
+  .cntmsk = 0xf,
+  .code = 0x02b7,
+  .flags= INTEL_X86_NHM_OFFCORE,
+  .numasks =  LIBPFM_ARRAY_SIZE(slm_offcore_response),
+  .ngrp = 3,
+  .umasks = slm_offcore_response, /* identical to actual umasks list for this event */
+},
+};
diff --git a/src/libpfm4/lib/pfmlib_amd64_fam15h.c b/src/libpfm4/lib/pfmlib_amd64_fam15h.c
index 9170868..b752d87 100644
--- a/src/libpfm4/lib/pfmlib_amd64_fam15h.c
+++ b/src/libpfm4/lib/pfmlib_amd64_fam15h.c
@@ -27,43 +27,72 @@
 #include "pfmlib_priv.h"
 #include "pfmlib_amd64_priv.h"
 #include "events/amd64_events_fam15h.h"
+#include "events/amd64_events_fam15h_nb.h"
 
-#define DEFINE_FAM15H_REV(d, n, r, pmuid) \
-static int							\
-pfm_amd64_fam15h_##n##_detect(void *this)			\
-{								\
-	int ret;						\
-	ret = pfm_amd64_detect(this);				\
-	if (ret != PFM_SUCCESS)					\
-		return ret;					\
-	ret = pfm_amd64_cfg.revision;				\
-	return ret == pmuid ? PFM_SUCCESS : PFM_ERR_NOTSUPP;	\
-}								\
-pfmlib_pmu_t amd64_fam15h_##n##_support={			\
-	.desc			= "AMD64 Fam15h "#d,		\
-	.name			= "amd64_fam15h_"#n,		\
-	.pmu			= pmuid,			\
-	.pmu_rev		= r,				\
-	.pme_count		= LIBPFM_ARRAY_SIZE(amd64_fam15h_pe),\
-	.type			= PFM_PMU_TYPE_CORE,		\
-	.supported_plm		= AMD64_FAM10H_PLM,		\
-	.num_cntrs		= 6,				\
-	.max_encoding		= 1,				\
-	.pe			= amd64_fam15h_pe,		\
-	.atdesc			= amd64_mods,			\
-	.flags			= PFMLIB_PMU_FL_RAW_UMASK,	\
-								\
-	.pmu_detect		= pfm_amd64_fam15h_##n##_detect,\
-	.get_event_encoding[PFM_OS_NONE] = pfm_amd64_get_encoding,\
-	 PFMLIB_ENCODE_PERF(pfm_amd64_get_perf_encoding),	\
-	.get_event_first	= pfm_amd64_get_event_first,	\
-	.get_event_next		= pfm_amd64_get_event_next,	\
-	.event_is_valid		= pfm_amd64_event_is_valid,	\
-	.validate_table		= pfm_amd64_validate_table,	\
-	.get_event_info		= pfm_amd64_get_event_info,	\
-	.get_event_attr_info	= pfm_amd64_get_event_attr_info,\
-	 PFMLIB_VALID_PERF_PATTRS(pfm_amd64_perf_validate_pattrs),\
-	.get_event_nattrs	= pfm_amd64_get_event_nattrs,	\
+static int
+pfm_amd64_fam15h_detect(void *this)
+{
+	int ret;
+
+	ret = pfm_amd64_detect(this);
+	if (ret != PFM_SUCCESS)
+		return ret;
+
+	if (pfm_amd64_cfg.revision == PFM_PMU_AMD64_FAM15H_INTERLAGOS)
+		return PFM_SUCCESS;
+
+	return PFM_ERR_NOTSUPP;
 }
 
-DEFINE_FAM15H_REV(Interlagos, interlagos, 0, PFM_PMU_AMD64_FAM15H_INTERLAGOS);
+pfmlib_pmu_t amd64_fam15h_interlagos_support={
+	.desc			= "AMD64 Fam15h Interlagos",
+	.name			= "amd64_fam15h_interlagos",
+	.pmu			= PFM_PMU_AMD64_FAM15H_INTERLAGOS,
+	.pmu_rev		= 0,
+	.pme_count		= LIBPFM_ARRAY_SIZE(amd64_fam15h_pe),
+	.type			= PFM_PMU_TYPE_CORE,
+	.supported_plm		= AMD64_FAM10H_PLM,
+	.num_cntrs		= 6,
+	.max_encoding		= 1,
+	.pe			= amd64_fam15h_pe,
+	.atdesc			= amd64_mods,
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK,
+	.pmu_detect		= pfm_amd64_fam15h_detect,
+	.get_event_encoding[PFM_OS_NONE] = pfm_amd64_get_encoding,
+	 PFMLIB_ENCODE_PERF(pfm_amd64_get_perf_encoding),
+	.get_event_first	= pfm_amd64_get_event_first,
+	.get_event_next		= pfm_amd64_get_event_next,
+	.event_is_valid		= pfm_amd64_event_is_valid,
+	.validate_table		= pfm_amd64_validate_table,
+	.get_event_info		= pfm_amd64_get_event_info,
+	.get_event_attr_info	= pfm_amd64_get_event_attr_info,
+	 PFMLIB_VALID_PERF_PATTRS(pfm_amd64_perf_validate_pattrs),
+	.get_event_nattrs	= pfm_amd64_get_event_nattrs,
+};
+
+pfmlib_pmu_t amd64_fam15h_nb_support={
+	.desc			= "AMD64 Fam15h NorthBridge",
+	.name			= "amd64_fam15h_nb",
+	.pmu			= PFM_PMU_AMD64_FAM15H_NB,
+	.perf_name		= "amd_nb",
+	.pmu_rev		= 0,
+	.pme_count		= LIBPFM_ARRAY_SIZE(amd64_fam15h_nb_pe),
+	.type			= PFM_PMU_TYPE_UNCORE,
+	.supported_plm		= 0, /* no plm support */
+	.num_cntrs		= 4,
+	.max_encoding		= 1,
+	.pe			= amd64_fam15h_nb_pe,
+	.atdesc			= amd64_mods,
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK,
+	.pmu_detect		= pfm_amd64_fam15h_detect,
+	.get_event_encoding[PFM_OS_NONE] = pfm_amd64_get_encoding,
+	 PFMLIB_ENCODE_PERF(pfm_amd64_get_perf_encoding),
+	.get_event_first	= pfm_amd64_get_event_first,
+	.get_event_next		= pfm_amd64_get_event_next,
+	.event_is_valid		= pfm_amd64_event_is_valid,
+	.validate_table		= pfm_amd64_validate_table,
+	.get_event_info		= pfm_amd64_get_event_info,
+	.get_event_attr_info	= pfm_amd64_get_event_attr_info,
+	 PFMLIB_VALID_PERF_PATTRS(pfm_amd64_nb_perf_validate_pattrs),
+	.get_event_nattrs	= pfm_amd64_get_event_nattrs,
+};
diff --git a/src/libpfm4/lib/pfmlib_amd64_perf_event.c b/src/libpfm4/lib/pfmlib_amd64_perf_event.c
index 68cf2b9..e210328 100644
--- a/src/libpfm4/lib/pfmlib_amd64_perf_event.c
+++ b/src/libpfm4/lib/pfmlib_amd64_perf_event.c
@@ -24,12 +24,38 @@
 #include <sys/types.h>
 #include <string.h>
 #include <stdlib.h>
+#include <limits.h>
 
 /* private headers */
 #include "pfmlib_priv.h"		/* library private */
 #include "pfmlib_amd64_priv.h"		/* architecture private */
 #include "pfmlib_perf_event_priv.h"
 
+static int
+find_pmu_type_by_name(const char *name)
+{
+	char filename[PATH_MAX];
+	FILE *fp;
+	int ret, type;
+
+	if (!name)
+		return PFM_ERR_NOTSUPP;
+
+	sprintf(filename, "/sys/bus/event_source/devices/%s/type", name);
+
+	fp = fopen(filename, "r");
+	if (!fp)
+		return PFM_ERR_NOTSUPP;
+
+	ret = fscanf(fp, "%d", &type);
+	if (ret != 1)
+		type = PFM_ERR_NOTSUPP;
+
+	fclose(fp);
+
+	return type;
+}
+
 int
 pfm_amd64_get_perf_encoding(void *this, pfmlib_event_desc_t *e)
 {
@@ -52,8 +78,20 @@ pfm_amd64_get_perf_encoding(void *this, pfmlib_event_desc_t *e)
 		return PFM_ERR_NOTSUPP;
 	}
 
-	/* all events treated as raw for now */
-	attr->type = PERF_TYPE_RAW;
+	ret = PERF_TYPE_RAW;
+
+	/*
+	 * if specific perf PMU is provided then try to locate it
+	 * otherwise assume core PMU and thus type RAW
+	 */
+	if (pmu->perf_name) {
+		/* greab PMU type from sysfs */
+		ret = find_pmu_type_by_name(pmu->perf_name);
+		if (ret < 0)
+			return ret;
+	}
+	DPRINT("amd64_get_perf_encoding: PMU type=%d\n", ret);
+	attr->type = ret;
 	attr->config = e->codes[0];
 
 	return PFM_SUCCESS;
@@ -80,8 +118,8 @@ pfm_amd64_perf_validate_pattrs(void *this, pfmlib_event_desc_t *e)
 		if (e->pattrs[i].ctrl == PFM_ATTR_CTRL_PMU) {
 
 			if (e->pattrs[i].idx == AMD64_ATTR_U
-					|| e->pattrs[i].idx == AMD64_ATTR_K
-					|| e->pattrs[i].idx == AMD64_ATTR_H)
+			    || e->pattrs[i].idx == AMD64_ATTR_K
+			    || e->pattrs[i].idx == AMD64_ATTR_H)
 				compact = 1;
 		}
 
@@ -102,3 +140,30 @@ pfm_amd64_perf_validate_pattrs(void *this, pfmlib_event_desc_t *e)
 		}
 	}
 }
+
+void
+pfm_amd64_nb_perf_validate_pattrs(void *this, pfmlib_event_desc_t *e)
+{
+	int i, compact;
+
+	for (i=0; i < e->npattrs; i++) {
+		compact = 0;
+
+		/* umasks never conflict */
+		if (e->pattrs[i].type == PFM_ATTR_UMASK)
+			continue;
+
+		/*
+		 * no perf_events attr is supported by AMD64 Northbridge PMU
+		 * sampling is not supported
+		 */
+		if (e->pattrs[i].ctrl == PFM_ATTR_CTRL_PERF_EVENT) {
+			compact = 1;
+		}
+
+		if (compact) {
+			pfmlib_compact_pattrs(e, i);
+			i--;
+		}
+	}
+}
diff --git a/src/libpfm4/lib/pfmlib_amd64_priv.h b/src/libpfm4/lib/pfmlib_amd64_priv.h
index e940758..14c9526 100644
--- a/src/libpfm4/lib/pfmlib_amd64_priv.h
+++ b/src/libpfm4/lib/pfmlib_amd64_priv.h
@@ -212,4 +212,5 @@ extern int pfm_amd64_get_num_events(void *this);
 
 extern int pfm_amd64_get_perf_encoding(void *this, pfmlib_event_desc_t *e);
 extern void pfm_amd64_perf_validate_pattrs(void *this, pfmlib_event_desc_t *e);
+extern void pfm_amd64_nb_perf_validate_pattrs(void *this, pfmlib_event_desc_t *e);
 #endif /* __PFMLIB_AMD64_PRIV_H__ */
diff --git a/src/libpfm4/lib/pfmlib_common.c b/src/libpfm4/lib/pfmlib_common.c
index e810eca..4f4092f 100644
--- a/src/libpfm4/lib/pfmlib_common.c
+++ b/src/libpfm4/lib/pfmlib_common.c
@@ -76,6 +76,7 @@ static pfmlib_pmu_t *pfmlib_pmus[]=
 	&amd64_fam12h_llano_support,
 	&amd64_fam14h_bobcat_support,
 	&amd64_fam15h_interlagos_support,
+	&amd64_fam15h_nb_support,
 	&intel_core_support,
 	&intel_atom_support,
 	&intel_nhm_support,
@@ -97,6 +98,7 @@ static pfmlib_pmu_t *pfmlib_pmus[]=
 	&intel_ivb_unc_cbo3_support,
 	&intel_ivb_ep_support,
 	&intel_hsw_support,
+	&intel_rapl_support,
 	&intel_snbep_unc_cb0_support,
 	&intel_snbep_unc_cb1_support,
 	&intel_snbep_unc_cb2_support,
@@ -118,6 +120,7 @@ static pfmlib_pmu_t *pfmlib_pmus[]=
 	&intel_snbep_unc_r3qpi0_support,
 	&intel_snbep_unc_r3qpi1_support,
 	&intel_knc_support,
+	&intel_slm_support,
 	&intel_x86_arch_support, /* must always be last for x86 */
 #endif
 
@@ -825,6 +828,7 @@ pfmlib_parse_event_attr(char *str, pfmlib_event_desc_t *d)
 				goto found_attr;
 			}
 		}
+		DPRINT("cannot find attribute %s\n", s);
 		return PFM_ERR_ATTR;
 found_attr:
 		type = ainfo->type;
diff --git a/src/libpfm4/lib/pfmlib_intel_rapl.c b/src/libpfm4/lib/pfmlib_intel_rapl.c
new file mode 100644
index 0000000..4570d65
--- /dev/null
+++ b/src/libpfm4/lib/pfmlib_intel_rapl.c
@@ -0,0 +1,150 @@
+/*
+ * pfmlib_intel_rapl.c : Intel RAPL PMU
+ *
+ * Copyright (c) 2013 Google, Inc
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Based on:
+ * Copyright (c) 2006 Hewlett-Packard Development Company, L.P.
+ * Contributed by Stephane Eranian <eranian@hpl.hp.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * RAPL PMU (SNB, IVB, HSW)
+ */
+
+/* private headers */
+#include "pfmlib_priv.h"
+/*
+ * for now, we reuse the x86 table entry format and callback to avoid duplicating
+ * code. We may revisit this later on
+ */
+#include "pfmlib_intel_x86_priv.h"
+
+extern pfmlib_pmu_t intel_rapl_support;
+
+#define RAPL_COMMON_EVENTS \
+  { .name   = "RAPL_ENERGY_CORES",\
+    .desc   = "Number of Joules consumed by all cores on the package. Unit is 2^-32 Joules",\
+    .cntmsk = 0x1,\
+    .code   = 0x1,\
+  },\
+  { .name   = "RAPL_ENERGY_PKG",\
+    .desc   = "Number of Joules consumed by all cores and Last level cache on the package. Unit is 2^-32 Joules",\
+    .cntmsk = 0x2,\
+    .code   = 0x2,\
+  }
+
+static const intel_x86_entry_t intel_rapl_cln_pe[]={
+	RAPL_COMMON_EVENTS
+};
+
+static const intel_x86_entry_t intel_rapl_srv_pe[]={
+  RAPL_COMMON_EVENTS,
+  { .name   = "RAPL_ENERGY_DRAM",
+    .desc   = "Number of Joules consumed by the DRAM. Unit is 2^-32 Joules",
+    .cntmsk = 0x4,
+    .code   = 0x3,
+  },
+};
+
+static int
+pfm_rapl_detect(void *this)
+{
+	int ret;
+
+	ret = pfm_intel_x86_detect();
+	if (ret != PFM_SUCCESS)
+		return ret;
+
+	if (pfm_intel_x86_cfg.family != 6)
+		return PFM_ERR_NOTSUPP;
+
+	switch(pfm_intel_x86_cfg.model) {
+		case 42: /* Sandy Bridge */
+		case 58: /* Ivy Bridge */
+		case 70: /* Haswell */
+			 /* already setup by default */
+			  break;
+		case 45: /* Sandy Bridg-EP  */
+		case 62: /* Ivy Bridge-EP  */
+			intel_rapl_support.pe 	     = intel_rapl_srv_pe;
+			intel_rapl_support.pme_count = LIBPFM_ARRAY_SIZE(intel_rapl_srv_pe);
+			break;
+		default:
+			return PFM_ERR_NOTSUPP;
+	}
+	return PFM_SUCCESS;
+}
+
+static int
+pfm_intel_rapl_get_encoding(void *this, pfmlib_event_desc_t *e)
+
+{
+	const intel_x86_entry_t *pe;
+
+	pe = this_pe(this);
+
+	e->fstr[0] = '\0';
+
+	e->codes[0] = pe[e->event].code;
+	e->count = 1;
+	evt_strcat(e->fstr, "%s", pe[e->event].name);
+
+	__pfm_vbprintf("[0x%"PRIx64" event=0x%x] %s\n",
+		       e->codes[0],
+		       e->codes[0], e->fstr);
+
+	return PFM_SUCCESS;
+}
+
+/*
+ * number modifiers for RAPL
+ * define an empty modifier to avoid firing the
+ * sanity pfm_intel_x86_validate_table(). We are
+ * using this function to avoid duplicating code.
+ */
+static const pfmlib_attr_desc_t rapl_mods[]=
+{};
+
+pfmlib_pmu_t intel_rapl_support={
+	.desc			= "Intel RAPL",
+	.name			= "rapl",
+	.perf_name		= "power",
+	.pmu			= PFM_PMU_INTEL_RAPL,
+	.pme_count		= LIBPFM_ARRAY_SIZE(intel_rapl_cln_pe),
+	.type			= PFM_PMU_TYPE_UNCORE,
+	.num_cntrs		= 0,
+	.num_fixed_cntrs	= 3,
+	.max_encoding		= 1,
+	.pe			= intel_rapl_cln_pe, /* default, maybe updated */
+	.pmu_detect		= pfm_rapl_detect,
+	.atdesc			= rapl_mods,
+
+	.get_event_encoding[PFM_OS_NONE] = pfm_intel_rapl_get_encoding,
+	 PFMLIB_ENCODE_PERF(pfm_intel_x86_get_perf_encoding),
+	 PFMLIB_OS_DETECT(pfm_intel_x86_perf_detect), \
+	.get_event_first	= pfm_intel_x86_get_event_first,
+	.get_event_next		= pfm_intel_x86_get_event_next,
+	.event_is_valid		= pfm_intel_x86_event_is_valid,
+	.validate_table		= pfm_intel_x86_validate_table,
+	.get_event_info		= pfm_intel_x86_get_event_info,
+	.get_event_attr_info	= pfm_intel_x86_get_event_attr_info,
+	 PFMLIB_VALID_PERF_PATTRS(pfm_intel_x86_perf_validate_pattrs),
+	.get_event_nattrs	= pfm_intel_x86_get_event_nattrs,
+};
diff --git a/src/libpfm4/lib/pfmlib_intel_slm.c b/src/libpfm4/lib/pfmlib_intel_slm.c
new file mode 100644
index 0000000..ba61450
--- /dev/null
+++ b/src/libpfm4/lib/pfmlib_intel_slm.c
@@ -0,0 +1,89 @@
+/*
+ * pfmlib_intel_slm.c : Intel Silvermont core PMU
+ *
+ * Copyright (c) 2013 Google, Inc
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Based on Intel Software Optimization Guide June 2013
+ */
+
+/* private headers */
+#include "pfmlib_priv.h"
+#include "pfmlib_intel_x86_priv.h"
+#include "events/intel_slm_events.h"
+
+static int
+pfm_intel_slm_detect(void *this)
+{
+	int ret;
+
+	ret = pfm_intel_x86_detect();
+	if (ret != PFM_SUCCESS)
+		return ret;
+	if (pfm_intel_x86_cfg.family != 6)
+		return PFM_ERR_NOTSUPP;
+
+	switch(pfm_intel_x86_cfg.model) {
+	case 55: /* Silvermont */
+	case 77: /* Silvermont Avoton */
+		break;
+	default:
+		return PFM_ERR_NOTSUPP;
+	}
+	return PFM_SUCCESS;
+}
+
+static int
+pfm_intel_slm_init(void *this)
+{
+	pfm_intel_x86_cfg.arch_version = 2;
+	return PFM_SUCCESS;
+}
+
+pfmlib_pmu_t intel_slm_support={
+	.desc			= "Intel Silvermont",
+	.name			= "slm",
+	.pmu			= PFM_PMU_INTEL_SLM,
+	.pme_count		= LIBPFM_ARRAY_SIZE(intel_slm_pe),
+	.type			= PFM_PMU_TYPE_CORE,
+	.num_cntrs		= 4,
+	.num_fixed_cntrs	= 3,
+	.max_encoding		= 2,
+	.pe			= intel_slm_pe,
+	.atdesc			= intel_x86_mods,
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK
+				| INTEL_X86_PMU_FL_ECMASK,
+	.supported_plm		= INTEL_X86_PLM,
+
+	.pmu_detect		= pfm_intel_slm_detect,
+	.pmu_init		= pfm_intel_slm_init,
+
+	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding,
+	 PFMLIB_ENCODE_PERF(pfm_intel_x86_get_perf_encoding),
+
+	.get_event_first	= pfm_intel_x86_get_event_first,
+	.get_event_next		= pfm_intel_x86_get_event_next,
+	.event_is_valid		= pfm_intel_x86_event_is_valid,
+	.validate_table		= pfm_intel_x86_validate_table,
+	.get_event_info		= pfm_intel_x86_get_event_info,
+	.get_event_attr_info	= pfm_intel_x86_get_event_attr_info,
+	PFMLIB_VALID_PERF_PATTRS(pfm_intel_x86_perf_validate_pattrs),
+	.get_event_nattrs	= pfm_intel_x86_get_event_nattrs,
+};
diff --git a/src/libpfm4/lib/pfmlib_intel_x86.c b/src/libpfm4/lib/pfmlib_intel_x86.c
index 34c843d..baa9f63 100644
--- a/src/libpfm4/lib/pfmlib_intel_x86.c
+++ b/src/libpfm4/lib/pfmlib_intel_x86.c
@@ -599,6 +599,7 @@ pfm_intel_x86_encode_gen(void *this, pfmlib_event_desc_t *e)
 
 	e->codes[0] = reg.val;
 
+DPRINT("sel_edge=%d cnt=%d\n", reg.sel_edge, reg.sel_cnt_mask);
 	/*
 	 * on recent processors (except Atom), edge requires cmask >=1
 	 */
diff --git a/src/libpfm4/lib/pfmlib_priv.h b/src/libpfm4/lib/pfmlib_priv.h
index d3ed361..0b46a86 100644
--- a/src/libpfm4/lib/pfmlib_priv.h
+++ b/src/libpfm4/lib/pfmlib_priv.h
@@ -213,6 +213,7 @@ extern pfmlib_pmu_t amd64_fam11h_turion_support;
 extern pfmlib_pmu_t amd64_fam12h_llano_support;
 extern pfmlib_pmu_t amd64_fam14h_bobcat_support;
 extern pfmlib_pmu_t amd64_fam15h_interlagos_support;
+extern pfmlib_pmu_t amd64_fam15h_nb_support;
 extern pfmlib_pmu_t intel_p6_support;
 extern pfmlib_pmu_t intel_ppro_support;
 extern pfmlib_pmu_t intel_pii_support;
@@ -240,6 +241,7 @@ extern pfmlib_pmu_t intel_ivb_unc_cbo2_support;
 extern pfmlib_pmu_t intel_ivb_unc_cbo3_support;
 extern pfmlib_pmu_t intel_ivb_ep_support;
 extern pfmlib_pmu_t intel_hsw_support;
+extern pfmlib_pmu_t intel_rapl_support;
 extern pfmlib_pmu_t intel_snbep_unc_cb0_support;
 extern pfmlib_pmu_t intel_snbep_unc_cb1_support;
 extern pfmlib_pmu_t intel_snbep_unc_cb2_support;
@@ -261,6 +263,7 @@ extern pfmlib_pmu_t intel_snbep_unc_r2pcie_support;
 extern pfmlib_pmu_t intel_snbep_unc_r3qpi0_support;
 extern pfmlib_pmu_t intel_snbep_unc_r3qpi1_support;
 extern pfmlib_pmu_t intel_knc_support;
+extern pfmlib_pmu_t intel_slm_support;
 extern pfmlib_pmu_t power4_support;
 extern pfmlib_pmu_t ppc970_support;
 extern pfmlib_pmu_t ppc970mp_support;
diff --git a/src/libpfm4/perf_examples/perf_util.c b/src/libpfm4/perf_examples/perf_util.c
index cc8b002..a5635d5 100644
--- a/src/libpfm4/perf_examples/perf_util.c
+++ b/src/libpfm4/perf_examples/perf_util.c
@@ -350,7 +350,7 @@ perf_display_stack_user(perf_event_desc_t *hw, FILE *fp)
 	size_t sz;
 	int ret;
 
-	ret = perf_read_buffer(hw, &nr, sizeof(hw));
+	ret = perf_read_buffer(hw, &nr, sizeof(nr));
 	if (ret)
 		errx(1, "cannot user stack size");
 
diff --git a/src/libpfm4/tests/validate_x86.c b/src/libpfm4/tests/validate_x86.c
index 0fc36c7..8dc222b 100644
--- a/src/libpfm4/tests/validate_x86.c
+++ b/src/libpfm4/tests/validate_x86.c
@@ -1879,31 +1879,35 @@ static const test_event_t x86_test_events[]={
 	},
 	{ SRC_LINE,
 	  .name = "amd64_fam15h_interlagos::LINK_TRANSMIT_BANDWIDTH_LINK_0:NOP_DW_SENT",
+	  .ret = PFM_ERR_NOTFOUND, /* event in Northbridge PMU */
+	},
+	{ SRC_LINE,
+	  .name = "amd64_fam15h_nb::LINK_TRANSMIT_BANDWIDTH_LINK_0:NOP_DW_SENT",
 	  .ret = PFM_SUCCESS,
 	  .count = 1,
 	  .codes[0] = 0x5308f6,
-	  .fstr = "amd64_fam15h_interlagos::LINK_TRANSMIT_BANDWIDTH_LINK_0:NOP_DW_SENT:SUBLINK_0",
+	  .fstr = "amd64_fam15h_nb::LINK_TRANSMIT_BANDWIDTH_LINK_0:NOP_DW_SENT:SUBLINK_0",
 	},
 	{ SRC_LINE,
-	  .name = "amd64_fam15h_interlagos::LINK_TRANSMIT_BANDWIDTH_LINK_0:ALL",
+	  .name = "amd64_fam15h_nb::LINK_TRANSMIT_BANDWIDTH_LINK_0:ALL",
 	  .ret = PFM_SUCCESS,
 	  .count = 1,
 	  .codes[0] = 0x533ff6,
-	  .fstr = "amd64_fam15h_interlagos::LINK_TRANSMIT_BANDWIDTH_LINK_0:ALL:SUBLINK_0",
+	  .fstr = "amd64_fam15h_nb::LINK_TRANSMIT_BANDWIDTH_LINK_0:ALL:SUBLINK_0",
 	},
 	{ SRC_LINE,
-	  .name = "amd64_fam15h_interlagos::LINK_TRANSMIT_BANDWIDTH_LINK_0:ALL:SUBLINK_1",
+	  .name = "amd64_fam15h_nb::LINK_TRANSMIT_BANDWIDTH_LINK_0:ALL:SUBLINK_1",
 	  .ret = PFM_SUCCESS,
 	  .count = 1,
 	  .codes[0] = 0x53bff6,
-	  .fstr = "amd64_fam15h_interlagos::LINK_TRANSMIT_BANDWIDTH_LINK_0:ALL:SUBLINK_1",
+	  .fstr = "amd64_fam15h_nb::LINK_TRANSMIT_BANDWIDTH_LINK_0:ALL:SUBLINK_1",
 	},
 	{ SRC_LINE,
-	  .name = "amd64_fam15h_interlagos::LINK_TRANSMIT_BANDWIDTH_LINK_0:COMMAND_DW_SENT:DATA_DW_SENT",
+	  .name = "amd64_fam15h_nb::LINK_TRANSMIT_BANDWIDTH_LINK_0:COMMAND_DW_SENT:DATA_DW_SENT",
 	  .ret = PFM_SUCCESS,
 	  .count = 1,
 	  .codes[0] = 0x5303f6,
-	  .fstr = "amd64_fam15h_interlagos::LINK_TRANSMIT_BANDWIDTH_LINK_0:COMMAND_DW_SENT:DATA_DW_SENT:SUBLINK_0",
+	  .fstr = "amd64_fam15h_nb::LINK_TRANSMIT_BANDWIDTH_LINK_0:COMMAND_DW_SENT:DATA_DW_SENT:SUBLINK_0",
 	},
 	{ SRC_LINE,
 	  .name = "amd64_fam15h_interlagos::DISPATCHED_FPU_OPS:0x4ff:u",
@@ -1917,40 +1921,40 @@ static const test_event_t x86_test_events[]={
 	  .fstr = "amd64_fam15h_interlagos::DISPATCHED_FPU_OPS:0xff:k=0:u=1:e=0:i=0:c=0:h=0:g=0"
 	},
 	{ SRC_LINE,
-	  .name = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE:read_block_modify:core_3",
+	  .name = "amd64_fam15h_nb::READ_REQUEST_TO_L3_CACHE:read_block_modify:core_3",
 	  .ret  = PFM_SUCCESS,
 	  .count = 1,
 	  .codes[0] = 0x4005334e0ull,
-	  .fstr = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE:READ_BLOCK_MODIFY:CORE_3",
+	  .fstr = "amd64_fam15h_nb::READ_REQUEST_TO_L3_CACHE:READ_BLOCK_MODIFY:CORE_3",
 	},
 	{ SRC_LINE,
-	  .name = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE",
+	  .name = "amd64_fam15h_nb::READ_REQUEST_TO_L3_CACHE",
 	  .ret  = PFM_SUCCESS,
 	  .count = 1,
 	  .codes[0] = 0x40053f7e0ull,
-	  .fstr = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE:READ_BLOCK_ANY:ANY_CORE",
+	  .fstr = "amd64_fam15h_nb::READ_REQUEST_TO_L3_CACHE:READ_BLOCK_ANY:ANY_CORE",
 	},
 	{ SRC_LINE,
-	  .name = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE:READ_BLOCK_EXCLUSIVE:PREFETCH:READ_BLOCK_MODIFY:core_4",
+	  .name = "amd64_fam15h_nb::READ_REQUEST_TO_L3_CACHE:READ_BLOCK_EXCLUSIVE:PREFETCH:READ_BLOCK_MODIFY:core_4",
 	  .ret  = PFM_SUCCESS,
 	  .count = 1,
 	  .codes[0] = 0x400534de0ull,
-	  .fstr = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE:READ_BLOCK_EXCLUSIVE:READ_BLOCK_MODIFY:PREFETCH:CORE_4",
+	  .fstr = "amd64_fam15h_nb::READ_REQUEST_TO_L3_CACHE:READ_BLOCK_EXCLUSIVE:READ_BLOCK_MODIFY:PREFETCH:CORE_4",
 	},
 	{ SRC_LINE,
-	  .name = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE:read_block_any:prefetch:core_1",
+	  .name = "amd64_fam15h_nb::READ_REQUEST_TO_L3_CACHE:read_block_any:prefetch:core_1",
 	  .ret  = PFM_ERR_FEATCOMB, /* must use individual umasks to combine with prefetch */
 	},
 	{ SRC_LINE,
-	  .name = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE:read_block_any:prefetch:core_1:core_3",
+	  .name = "amd64_fam15h_nb::READ_REQUEST_TO_L3_CACHE:read_block_any:prefetch:core_1:core_3",
 	  .ret  = PFM_ERR_FEATCOMB, /* core umasks cannot be combined */
 	},
 	{ SRC_LINE,
-	  .name = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE:prefetch:core_0",
+	  .name = "amd64_fam15h_nb::READ_REQUEST_TO_L3_CACHE:prefetch:core_0",
 	  .ret  = PFM_SUCCESS,
 	  .count = 1,
 	  .codes[0] = 0x4005308e0ull,
-	  .fstr = "amd64_fam15h_interlagos::READ_REQUEST_TO_L3_CACHE:PREFETCH:CORE_0",
+	  .fstr = "amd64_fam15h_nb::READ_REQUEST_TO_L3_CACHE:PREFETCH:CORE_0",
 	},
 	{ SRC_LINE,
 	  .name = "ivb_ep::mem_load_uops_llc_miss_retired:local_dram",
@@ -2074,6 +2078,113 @@ static const test_event_t x86_test_events[]={
 	  .name = "ivb_unc_cbo1::unc_clockticks",
 	  .ret  = PFM_ERR_NOTFOUND
 	},
+	{ SRC_LINE,
+	  .name = "rapl::rapl_energy_cores",
+	  .ret = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x1,
+	  .fstr = "rapl::RAPL_ENERGY_CORES",
+	},
+	{ SRC_LINE,
+	  .name = "rapl::rapl_energy_pkg",
+	  .ret = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x2,
+	  .fstr = "rapl::RAPL_ENERGY_PKG",
+	},
+	{ SRC_LINE,
+	  .name = "rapl::rapl_energy_cores:u",
+	  .ret = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "slm::offcore_response_0:snp_hitm",
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5301b7,
+	  .codes[1]=0x100001ffffull,
+	  .fstr = "slm::OFFCORE_RESPONSE_0:ANY_REQUEST:ANY_RESPONSE:SNP_HITM:k=1:u=1:e=0:i=0:c=0",
+	},
+	{ SRC_LINE,
+	  .name = "slm::offcore_response_0:any_data",
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5301b7,
+	  .codes[1]=0x12011,
+	  .fstr = "slm::OFFCORE_RESPONSE_0:DMND_DATA_RD:PF_L2_DATA_RD:PF_L1_DATA_RD:ANY_RESPONSE:k=1:u=1:e=0:i=0:c=0",
+	},
+	{ SRC_LINE,
+	  .name = "slm::offcore_response_0:uc_ifetch",
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5301b7,
+	  .codes[1]=0x10200,
+	  .fstr = "slm::OFFCORE_RESPONSE_0:UC_IFETCH:ANY_RESPONSE:k=1:u=1:e=0:i=0:c=0",
+	},
+	{ SRC_LINE,
+	  .name = "slm::offcore_response_0:any_ifetch",
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5301b7,
+	  .codes[1]=0x10244,
+	  .fstr = "slm::OFFCORE_RESPONSE_0:DMND_IFETCH:PF_IFETCH:UC_IFETCH:ANY_RESPONSE:k=1:u=1:e=0:i=0:c=0",
+	},
+	{ SRC_LINE,
+	  .name = "slm::offcore_response_1:snp_hitm",
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5302b7,
+	  .codes[1]=0x100001ffffull,
+	  .fstr = "slm::OFFCORE_RESPONSE_1:ANY_REQUEST:ANY_RESPONSE:SNP_HITM:k=1:u=1:e=0:i=0:c=0",
+	},
+	{ SRC_LINE,
+	  .name = "slm::offcore_response_1:any_data",
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5302b7,
+	  .codes[1]=0x12011,
+	  .fstr = "slm::OFFCORE_RESPONSE_1:DMND_DATA_RD:PF_L2_DATA_RD:PF_L1_DATA_RD:ANY_RESPONSE:k=1:u=1:e=0:i=0:c=0",
+	},
+	{ SRC_LINE,
+	  .name = "slm::offcore_response_1:uc_ifetch",
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5302b7,
+	  .codes[1]=0x10200,
+	  .fstr = "slm::OFFCORE_RESPONSE_1:UC_IFETCH:ANY_RESPONSE:k=1:u=1:e=0:i=0:c=0",
+	},
+	{ SRC_LINE,
+	  .name = "slm::offcore_response_1:any_ifetch",
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5302b7,
+	  .codes[1]=0x10244,
+	  .fstr = "slm::OFFCORE_RESPONSE_1:DMND_IFETCH:PF_IFETCH:UC_IFETCH:ANY_RESPONSE:k=1:u=1:e=0:i=0:c=0",
+	},
+	{ SRC_LINE,
+	  .name = "slm::decode_restriction:predecode_wrong",
+	  .ret = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x5301e9,
+	  .fstr = "slm::DECODE_RESTRICTION:PREDECODE_WRONG:k=1:u=1:e=0:i=0:c=0",
+	},
+	{ SRC_LINE,
+	  .name = "slm::rs_full_stall:fpc_port0",
+	  .ret = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x5308cb,
+	  .fstr = "slm::RS_FULL_STALL:FPC_PORT0:k=1:u=1:e=0:i=0:c=0",
+	},
+	{ SRC_LINE,
+	  .name = "slm::no_alloc_cycles:any",
+	  .ret = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x533fca,
+	  .fstr = "slm::NO_ALLOC_CYCLES:ANY:k=1:u=1:e=0:i=0:c=0",
+	},
+	{ SRC_LINE,
+	  .name = "slm::no_alloc_cycles:any:t=1",
+	  .ret = PFM_ERR_ATTR
+	},
 };
 #define NUM_TEST_EVENTS (int)(sizeof(x86_test_events)/sizeof(test_event_t))
 
-- 
2.1.0

From 84dad7f246173738e979c050d98d43a6f97957dd Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Tue, 3 Dec 2013 10:09:25 -0500
Subject: [PATCH 08/24] Libpfm4 update: Catches  the Intel Silvermont manpage

-----------------------------------------------------
commit b35f8115e173f4c1cf5d58b6e6b62f0ad91cb2dd
Author: Stephane Eranian <eranian@gmail.com>
Date:   Tue Dec 3 06:48:24 2013 +0100

    Add missing Intel Silvermont libpfm4 man page.

    Adds the man pag for Intel Silvermont core PMU.

    Reported-by: Steve Kaufman <sbk@cray.com>
    Signed-off-by: Stephane Eranian <eranian@gmail.com>
-----------------------------------------------------

diff --git a/src/libpfm4/docs/man3/libpfm_intel_slm.3 b/src/libpfm4/docs/man3/libpfm_intel_slm.3
new file mode 100644
index 0000000..1e1153f
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_intel_slm.3
@@ -0,0 +1,84 @@
+.TH LIBPFM 3  "November, 2013" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_intel_slm - support for Intel Silvermont core PMU
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: slm
+.B PMU desc: Intel Silvermont
+.sp
+.SH DESCRIPTION
+The library supports the Intel Silvermont core PMU.
+
+.SH MODIFIERS
+The following modifiers are supported on Intel Silvermont processors:
+.TP
+.B u
+Measure at user level which includes privilege levels 1, 2, 3. This corresponds to \fBPFM_PLM3\fR.
+This is a boolean modifier.
+.TP
+.B k
+Measure at kernel level which includes privilege level 0. This corresponds to \fBPFM_PLM0\fR.
+This is a boolean modifier.
+.TP
+.B i
+Invert the meaning of the event. The counter will now count cycles in which the event is \fBnot\fR
+occurring. This is a boolean modifier
+.TP
+.B e
+Enable edge detection, i.e., count only when there is a state transition from no occurrence of the event
+to at least one occurrence. This modifier must be combined with a counter mask modifier (m) with a value greater or equal to one.
+This is a boolean modifier.
+.TP
+.B c
+Set the counter mask value. The mask acts as a threshold. The counter will count the number of cycles
+in which the number of occurrences of the event is greater or equal to the threshold. This is an integer
+modifier with values in the range [0:255].
+
+.SH OFFCORE_RESPONSE events
+Intel Silvermont provides two offcore_response events:
+\fBOFFCORE_RESPONSE_0\fR and \fBOFFCORE_RESPONSE_1\fR.
+
+Those events need special treatment in the performance monitoring infrastructure
+because each event uses an extra register to store some settings. Thus, in
+case multiple offcore_response events are monitored simultaneously, the kernel needs
+to manage the sharing of that extra register.
+
+The offcore_response events are exposed as a normal event by the library. The extra
+settings are exposed as regular umasks. The library takes care of encoding the
+events according to the underlying kernel interface.
+
+On Intel Silvermont, the umasks are divided into three categories: request, supplier
+and snoop. The user must provide at least one umask for each category. The categories
+are shown in the umask descriptions. The library provides a default umask per category
+if not provided by the user.
+
+There is also the special response umask called \fBANY_RESPONSE\fR. When this umask
+is used then it overrides any supplier and snoop umasks. In other words, users can
+specify either \fBANY_RESPONSE\fR \fBOR\fR any combinations of supplier + snoops.
+
+In case no supplier or snoop is specified, the library defaults to using
+\fBANY_RESPONSE\fR.
+
+For instance, the following are valid event selections:
+.TP
+.B OFFCORE_RESPONSE_0:DMND_DATA_RD:ANY_RESPONSE
+.TP
+.B OFFCORE_RESPONSE_0:ANY_REQUEST
+.TP
+.B OFFCORE_RESPONSE_0:ANY_RFO:LLC_HITM:SNOOP_ANY
+
+.P
+But the following are illegal:
+
+.TP
+.B OFFCORE_RESPONSE_0:ANY_RFO:NON_DRAM:ANY_RESPONSE
+.TP
+.B OFFCORE_RESPONSE_0:ANY_RFO:L2_HIT:SNOOP_ANY:ANY_RESPONSE
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.PP
-- 
2.1.0

From 438bebfecfe1f41132915f5045593ab6f7f430a2 Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Fri, 6 Dec 2013 11:19:55 -0500
Subject: [PATCH 09/24] Update libpfm4: catch several haswell model numbers

Bumps us to
-----------------------------------------------
commit 4b0a11762f62f7763be31ade2d70ff0ae5f80fd4
Author: Vince Weaver <vincent.weaver@maine.edu>
Date:   Fri Dec 6 10:17:18 2013 -0500

    add missing Intel Haswell model numbers

    This patch adds support for a few more Haswell
    models: 63, 69, 70, 71.

    Signed-off-by: Vince Weaver <vincent.weaver@maine.edu>
-----------------------------------------------

diff --git a/src/libpfm4/docs/man3/libpfm.3 b/src/libpfm4/docs/man3/libpfm.3
index 54a7d48..08a0f49 100644
--- a/src/libpfm4/docs/man3/libpfm.3
+++ b/src/libpfm4/docs/man3/libpfm.3
@@ -113,6 +113,12 @@ LIBPFM_FORCE_PMU=amd64,16,2,1.
 .B LIBPFM_ENCODE_INACTIVE
 Set this variable to 1 to enable encoding of events for non detected, but supported,
 PMUs models.
+.TP
+.B LIBPFM_DISABLED_PMUS
+Provides a list of PMU models to disable. This is a comma separated list of PMU
+models. The PMU model is the string in \fBname\fR field of the \fBpfm_pmu_info_t\fR
+structure. For instance: LIBPFM_DISABLE_PMUS=core,snb, will disable both the Intel
+Core and SandyBridge core PMU support.
 
 .SH AUTHORS
 .nf
diff --git a/src/libpfm4/lib/pfmlib_common.c b/src/libpfm4/lib/pfmlib_common.c
index 4f4092f..1ff74e8 100644
--- a/src/libpfm4/lib/pfmlib_common.c
+++ b/src/libpfm4/lib/pfmlib_common.c
@@ -503,6 +503,10 @@ pfmlib_init_env(void)
 	str = getenv("LIBPFM_ENCODE_INACTIVE");
 	if (str)
 		pfm_cfg.inactive = 1;
+
+	str = getenv("LIBPFM_DISABLED_PMUS");
+	if (str)
+		pfm_cfg.blacklist_pmus = str;
 }
 
 static int
@@ -574,6 +578,30 @@ pfmlib_match_forced_pmu(const char *name)
 }
 
 static int
+pfmlib_is_blacklisted_pmu(pfmlib_pmu_t *p)
+{
+	const char *a, *b;
+
+	if (!pfm_cfg.blacklist_pmus)
+		return 0;
+
+	/*
+	 * scan list for matching PMU names, we accept substrings.
+	 * for instance: snbep does match snbep*
+	 */
+	for (a = pfm_cfg.blacklist_pmus, b = p->name; *a && *b; a++) {
+		if (*a != *b++) {
+			char *n = strchr(a, ',');
+			if (!n)
+				break;
+			a = n;
+			b = p->name;
+		}
+	}
+	return *a == ',' || !*a;
+}
+
+static int
 pfmlib_init_pmus(void)
 {
 	pfmlib_pmu_t *p;
@@ -605,6 +633,10 @@ pfmlib_init_pmus(void)
 		if (pfmlib_pmu_sanity_checks(p) != PFM_SUCCESS)
 			continue;
 
+		if (pfmlib_is_blacklisted_pmu(p)) {
+			DPRINT("%d PMU blacklisted, skipping initialization\n");
+			continue;
+		}
 		p->flags |= PFMLIB_PMU_FL_INIT;
 
 		/*
diff --git a/src/libpfm4/lib/pfmlib_intel_hsw.c b/src/libpfm4/lib/pfmlib_intel_hsw.c
index 7d01ff1..f4975f6 100644
--- a/src/libpfm4/lib/pfmlib_intel_hsw.c
+++ b/src/libpfm4/lib/pfmlib_intel_hsw.c
@@ -40,6 +40,10 @@ pfm_hsw_detect(void *this)
 
 	switch (pfm_intel_x86_cfg.model) {
 		case 60: /* Haswell */
+		case 63: /* Haswell */
+		case 69: /* Haswell */
+		case 70: /* Haswell */
+		case 71: /* Haswell */
 			break;
 		default:
 			return PFM_ERR_NOTSUPP;
diff --git a/src/libpfm4/lib/pfmlib_priv.h b/src/libpfm4/lib/pfmlib_priv.h
index 0b46a86..f44ffe5 100644
--- a/src/libpfm4/lib/pfmlib_priv.h
+++ b/src/libpfm4/lib/pfmlib_priv.h
@@ -164,6 +164,7 @@ typedef struct {
 	int	debug;
 	int	inactive;
 	char	*forced_pmu;
+	char	*blacklist_pmus;
 	FILE 	*fp;	/* verbose and debug file descriptor, default stderr or PFMLIB_DEBUG_STDOUT */
 } pfmlib_config_t;	
 
-- 
2.1.0

From a7f61597ecc2c2758bd8d3302b9f7e38433fe621 Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Thu, 16 Jan 2014 09:36:57 -0500
Subject: [PATCH 10/24] Libpfm4: Update for RAPL GPU counters

Brings us in line with
----------------------
commit bca43a50f9249df79db82e149de2a8d846eb6d45
Author: Stephane Eranian <eranian@gmail.com>
Date:   Mon Jan 13 16:21:44 2014 +0100

    add support for RAPL GPU energy counter

    This patch adds a new RAPL event to measure
    builtin GPU energy consumption on Intel SNB/IVB/HSW
    client processors.

    Requires a kernel with RAPL support in perf_events
    such as Linux v3.13 or later.

    New event: rapl::rapl_energy_gpu

    Signed-off-by: Stephane Eranian <eranian@gmail.com>
-----------------------

diff --git a/src/libpfm4/lib/events/amd64_events_fam14h.h b/src/libpfm4/lib/events/amd64_events_fam14h.h
index e975521..0cf11a9 100644
--- a/src/libpfm4/lib/events/amd64_events_fam14h.h
+++ b/src/libpfm4/lib/events/amd64_events_fam14h.h
@@ -121,7 +121,7 @@ static const amd64_umask_t amd64_fam14h_retired_serializing_ops[]={
 
 static const amd64_umask_t amd64_fam14h_retired_x87_fpu_ops[]={
    { .uname  = "ADD_SUB_OPS",
-     .udesc  = "Add/substract ops",
+     .udesc  = "Add/subtract ops",
      .ucode = 0x1,
    },
    { .uname  = "MULT_OPS",
@@ -1180,7 +1180,7 @@ static const amd64_entry_t amd64_fam14h_pe[]={
   .umasks  = amd64_fam14h_l1_dtlb_hit,
 },
 { .name    = "DCACHE_SW_PREFETCHES",
-  .desc    = "Number of software prefetches that do not cuase an actual data cache refill",
+  .desc    = "Number of software prefetches that do not cause an actual data cache refill",
   .modmsk  = AMD64_FAM10H_ATTRS,
   .code    = 0x52,
   .numasks = LIBPFM_ARRAY_SIZE(amd64_fam14h_dcache_sw_prefetches),
diff --git a/src/libpfm4/lib/events/amd64_events_fam15h.h b/src/libpfm4/lib/events/amd64_events_fam15h.h
index 7872468..0b8c17b 100644
--- a/src/libpfm4/lib/events/amd64_events_fam15h.h
+++ b/src/libpfm4/lib/events/amd64_events_fam15h.h
@@ -1708,7 +1708,7 @@ static const amd64_umask_t amd64_fam15h_read_request_to_l3_cache[]={
      .grpid = 0,
    },
    { .uname = "PREFETCH",
-     .udesc = "Count prefetches honly",
+     .udesc = "Count prefetches only",
      .ucode = 0x8,
      .grpid = 0,
    },
diff --git a/src/libpfm4/lib/events/amd64_events_fam15h_nb.h b/src/libpfm4/lib/events/amd64_events_fam15h_nb.h
index 5969eb6..82799f0 100644
--- a/src/libpfm4/lib/events/amd64_events_fam15h_nb.h
+++ b/src/libpfm4/lib/events/amd64_events_fam15h_nb.h
@@ -1711,7 +1711,7 @@ static const amd64_umask_t amd64_fam15h_nb_read_request_to_l3_cache[]={
      .grpid = 0,
    },
    { .uname = "PREFETCH",
-     .udesc = "Count prefetches honly",
+     .udesc = "Count prefetches only",
      .ucode = 0x8,
      .grpid = 0,
    },
diff --git a/src/libpfm4/lib/events/arm_1176_events.h b/src/libpfm4/lib/events/arm_1176_events.h
index 35a43fa..d31d810 100644
--- a/src/libpfm4/lib/events/arm_1176_events.h
+++ b/src/libpfm4/lib/events/arm_1176_events.h
@@ -121,7 +121,7 @@ static const arm_entry_t arm_1176_pe []={
 	},
 	{.name = "PROC_RET_EXEC_PRED",
 	 .code = 0x25,
-	 .desc = "Proceudre return instruction executed and address predicted"
+	 .desc = "Procedure return instruction executed and address predicted"
 	},
 	{.name = "PROC_RET_EXEC_PRED_INCORRECT",
 	 .code = 0x26,
diff --git a/src/libpfm4/lib/events/arm_cortex_a8_events.h b/src/libpfm4/lib/events/arm_cortex_a8_events.h
index 2b61dda..f5c99e5 100644
--- a/src/libpfm4/lib/events/arm_cortex_a8_events.h
+++ b/src/libpfm4/lib/events/arm_cortex_a8_events.h
@@ -86,7 +86,7 @@ static const arm_entry_t arm_cortex_a8_pe []={
 	},
 	{.name = "PC_IMM_BRANCH",
 	 .code = 0x0d,
-	 .desc = "Immedidate branches architecturally executed"
+	 .desc = "Immediate branches architecturally executed"
 	},
 	{.name = "PC_PROC_RETURN",
 	 .code = 0x0e,
@@ -194,7 +194,7 @@ static const arm_entry_t arm_cortex_a8_pe []={
 	},  
 	{.name = "OP_EXECUTED",
 	 .code = 0x55,
-	 .desc = "Operations excuted (includes sub-ops in multi-cycle instructions)"
+	 .desc = "Operations executed (includes sub-ops in multi-cycle instructions)"
 	},
 	{.name = "CYCLES_INST_STALL",
 	 .code = 0x56,
diff --git a/src/libpfm4/lib/events/arm_cortex_a9_events.h b/src/libpfm4/lib/events/arm_cortex_a9_events.h
index c034bd3..ef5b337 100644
--- a/src/libpfm4/lib/events/arm_cortex_a9_events.h
+++ b/src/libpfm4/lib/events/arm_cortex_a9_events.h
@@ -86,7 +86,7 @@ static const arm_entry_t arm_cortex_a9_pe []={
 	},
 	{.name = "PC_IMM_BRANCH",
 	 .code = 0x0d,
-	 .desc = "Immedidate branches architecturally executed"
+	 .desc = "Immediate branches architecturally executed"
 	},
 	{.name = "UNALIGNED_ACCESS",
 	 .code = 0x0f,
diff --git a/src/libpfm4/lib/events/intel_atom_events.h b/src/libpfm4/lib/events/intel_atom_events.h
index 0b72ad3..3b564be 100644
--- a/src/libpfm4/lib/events/intel_atom_events.h
+++ b/src/libpfm4/lib/events/intel_atom_events.h
@@ -85,7 +85,7 @@ static const intel_x86_umask_t atom_icache[]={
      .uflags= INTEL_X86_NCOMBO,
    },
    { .uname  = "MISSES",
-     .udesc  = "Count all instructions fetches that miss tha icache or produce memory requests. This includes uncacheache fetches. Any instruction fetch miss is counted only once and not once for every cycle it is outstanding",
+     .udesc  = "Count all instructions fetches that miss the icache or produce memory requests. This includes uncacheache fetches. Any instruction fetch miss is counted only once and not once for every cycle it is outstanding",
      .ucode = 0x200,
    },
 };
diff --git a/src/libpfm4/lib/events/intel_coreduo_events.h b/src/libpfm4/lib/events/intel_coreduo_events.h
index 16336f9..9e0cb5e 100644
--- a/src/libpfm4/lib/events/intel_coreduo_events.h
+++ b/src/libpfm4/lib/events/intel_coreduo_events.h
@@ -315,12 +315,12 @@ static const intel_x86_umask_t coreduo_sse_instructions_retired[]={
      .uflags= INTEL_X86_NCOMBO,
    },
    { .uname  = "PACKED_DOUBLE",
-     .udesc  = "Number of SSE/SSE2 packed double percision instructions retired",
+     .udesc  = "Number of SSE/SSE2 packed double precision instructions retired",
      .ucode = 0x200,
      .uflags= INTEL_X86_NCOMBO,
    },
    { .uname  = "DOUBLE",
-     .udesc  = "Number of SSE/SSE2 scalar double percision instructions retired",
+     .udesc  = "Number of SSE/SSE2 scalar double precision instructions retired",
      .ucode = 0x300,
      .uflags= INTEL_X86_NCOMBO,
    },
@@ -579,7 +579,7 @@ static const intel_x86_entry_t intel_coreduo_pe[]={
   .umasks = coreduo_l2_lines_in, /* identical to actual umasks list for this event */
 },
 { .name   = "L2_IFETCH",
-  .desc   = "L2 instruction fetches from nstruction fetch unit (includes speculative fetches) ",
+  .desc   = "L2 instruction fetches from instruction fetch unit (includes speculative fetches) ",
   .modmsk = INTEL_X86_ATTRS,
   .cntmsk = 0x3,
   .code = 0x28,
diff --git a/src/libpfm4/lib/events/intel_hsw_events.h b/src/libpfm4/lib/events/intel_hsw_events.h
index ccd4a2b..0491fdd 100644
--- a/src/libpfm4/lib/events/intel_hsw_events.h
+++ b/src/libpfm4/lib/events/intel_hsw_events.h
@@ -26,7 +26,7 @@
 
 static const intel_x86_umask_t hsw_baclears[]={
   { .uname = "ANY",
-    .udesc  = "NUmber of front-end re-steers due to BPU misprediction",
+    .udesc  = "Number of front-end re-steers due to BPU misprediction",
     .ucode  = 0x1f00,
     .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
   },
@@ -1511,7 +1511,7 @@ static const intel_x86_umask_t hsw_hle_retired[]={
     .uflags = INTEL_X86_NCOMBO,
   },
   { .uname = "ABORTED_MISC4",
-    .udesc  = "Number of times an HLE execution aborted due to incomptaible memory type",
+    .udesc  = "Number of times an HLE execution aborted due to incompatible memory type",
     .ucode  = 0x4000,
     .uflags = INTEL_X86_NCOMBO,
   },
@@ -1554,7 +1554,7 @@ static const intel_x86_umask_t hsw_rtm_retired[]={
     .uflags = INTEL_X86_NCOMBO,
   },
   { .uname = "ABORTED_MISC4",
-    .udesc  = "Number of times an RTM execution aborted due to incomptaible memory type",
+    .udesc  = "Number of times an RTM execution aborted due to incompatible memory type",
     .ucode  = 0x4000,
     .uflags = INTEL_X86_NCOMBO,
   },
@@ -1779,7 +1779,7 @@ static const intel_x86_entry_t intel_hsw_pe[]={
     .code = 0xc5,
   },
   { .name = "BACLEARS",
-    .desc   = "Branch resteered",
+    .desc   = "Branch re-steered",
     .code = 0xe6,
     .cntmsk = 0xff,
     .ngrp = 1,
@@ -1934,7 +1934,7 @@ static const intel_x86_entry_t intel_hsw_pe[]={
     .umasks  = hsw_inst_retired
   },
   { .name = "INT_MISC",
-    .desc = "Miscelleanous interruptions",
+    .desc = "Miscellaneous interruptions",
     .code = 0xd,
     .cntmsk = 0xff,
     .ngrp = 1,
diff --git a/src/libpfm4/lib/events/intel_ivb_events.h b/src/libpfm4/lib/events/intel_ivb_events.h
index 3c5583e..28e0216 100644
--- a/src/libpfm4/lib/events/intel_ivb_events.h
+++ b/src/libpfm4/lib/events/intel_ivb_events.h
@@ -510,7 +510,7 @@ static const intel_x86_umask_t ivb_idq[]={
      .uflags= INTEL_X86_NCOMBO,
    },
    { .uname  = "MS_DSB_UOPS_OCCUR",
-     .udesc  = "Occurences of DSB MS going active",
+     .udesc  = "Occurrences of DSB MS going active",
      .uequiv = "MS_DSB_UOPS:c=1:e=1",
      .ucode = 0x1000 | INTEL_X86_MOD_EDGE | (0x1 << INTEL_X86_CMASK_BIT),
      .uflags= INTEL_X86_NCOMBO,
@@ -861,7 +861,7 @@ static const intel_x86_umask_t ivb_ld_blocks[]={
      .uflags= INTEL_X86_NCOMBO,
    },
    { .uname  = "NO_SR",
-     .udesc  = "Number of times that split load operations are temporarily blocked because all resources for handlding the split accesses are in use",
+     .udesc  = "Number of times that split load operations are temporarily blocked because all resources for handling the split accesses are in use",
      .ucode = 0x800,
      .uflags= INTEL_X86_NCOMBO,
    },
@@ -1173,7 +1173,7 @@ static const intel_x86_umask_t ivb_other_assists[]={
      .uflags= INTEL_X86_NCOMBO,
    },
    { .uname  = "AVX_STORE",
-     .udesc  = "Number of assists associated with 25-bit AVX stores",
+     .udesc  = "Number of assists associated with 256-bit AVX stores",
      .ucode = 0x0800,
      .uflags= INTEL_X86_NCOMBO,
    },
@@ -1277,7 +1277,7 @@ static const intel_x86_umask_t ivb_uops_dispatched_port[]={
      .uflags= INTEL_X86_NCOMBO,
    },
    { .uname  = "PORT_3",
-     .udesc  = "Cycles in which a uop is disptached on port 3",
+     .udesc  = "Cycles in which a uop is dispatched on port 3",
      .ucode = 0x3000,
      .uflags= INTEL_X86_NCOMBO,
    },
@@ -1553,7 +1553,7 @@ static const intel_x86_umask_t ivb_offcore_response[]={
 
 static const intel_x86_umask_t ivb_baclears[]={
    { .uname  = "ANY",
-     .udesc  = "Counts the number of times the front end is resteered, mainly when the BPU cannot provide a correct prediction and this is corrected by other branch handling mechanisms at the front end",
+     .udesc  = "Counts the number of times the front end is re-steered, mainly when the BPU cannot provide a correct prediction and this is corrected by other branch handling mechanisms at the front end",
      .ucode = 0x1f00,
      .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
    },
@@ -1663,7 +1663,7 @@ static const intel_x86_entry_t intel_ivb_pe[]={
   .umasks = ivb_arith,
 },
 { .name   = "BACLEARS",
-  .desc   = "Branch resteered",
+  .desc   = "Branch re-steered",
   .modmsk = INTEL_V3_ATTRS,
   .cntmsk = 0xff,
   .code = 0xe6,
@@ -1909,7 +1909,7 @@ static const intel_x86_entry_t intel_ivb_pe[]={
   .umasks = ivb_l2_l1d_wb_rqsts,
 },
 { .name   = "L2_LINES_IN",
-  .desc   = "L2 lines alloacated",
+  .desc   = "L2 lines allocated",
   .modmsk = INTEL_V3_ATTRS,
   .cntmsk = 0xff,
   .code = 0xf1,
diff --git a/src/libpfm4/lib/events/intel_netburst_events.h b/src/libpfm4/lib/events/intel_netburst_events.h
index e24f22f..bf08b02 100644
--- a/src/libpfm4/lib/events/intel_netburst_events.h
+++ b/src/libpfm4/lib/events/intel_netburst_events.h
@@ -1495,7 +1495,7 @@ static const netburst_entry_t netburst_events[] = {
 
 	/* 44 */
 	{.name = "machine_clear",
-	 .desc = "Number of occurances when the entire "
+	 .desc = "Number of occurrences when the entire "
 		 "pipeline of the machine is cleared",
 	 .event_select = 0x2,
 	 .escr_select = 0x5,
@@ -1506,7 +1506,7 @@ static const netburst_entry_t netburst_events[] = {
 		 .desc = "Counts for a portion of the many cycles while the "
 			 "machine is cleared for any cause. Use edge-"
 			 "triggering for this bit only to get a count of "
-			 "occurances versus a duration",
+			 "occurrences versus a duration",
 		 .bit = 0,
 		},
 		{.name = "MOCLEAR",
diff --git a/src/libpfm4/lib/events/intel_nhm_events.h b/src/libpfm4/lib/events/intel_nhm_events.h
index e47068f..265002d 100644
--- a/src/libpfm4/lib/events/intel_nhm_events.h
+++ b/src/libpfm4/lib/events/intel_nhm_events.h
@@ -61,7 +61,7 @@ static const intel_x86_umask_t nhm_baclear[]={
 
 static const intel_x86_umask_t nhm_bpu_clears[]={
    { .uname  = "EARLY",
-     .udesc  = "Early Branch Prediciton Unit clears",
+     .udesc  = "Early Branch Prediction Unit clears",
      .ucode = 0x100,
      .uflags= INTEL_X86_NCOMBO,
    },
@@ -332,7 +332,7 @@ static const intel_x86_umask_t nhm_fp_assist[]={
      .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_DFL,
    },
    { .uname  = "INPUT",
-     .udesc  = "Floating poiint assists for invalid input value (Precise Event)",
+     .udesc  = "Floating point assists for invalid input value (Precise Event)",
      .ucode = 0x400,
      .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
    },
@@ -740,7 +740,7 @@ static const intel_x86_umask_t nhm_l2_hw_prefetch[]={
 
 static const intel_x86_umask_t nhm_l2_lines_in[]={
    { .uname  = "ANY",
-     .udesc  = "L2 lines alloacated",
+     .udesc  = "L2 lines allocated",
      .ucode = 0x700,
      .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
    },
@@ -1976,7 +1976,7 @@ static const intel_x86_entry_t intel_nhm_pe[]={
   .umasks = nhm_fp_assist,
 },
 { .name   = "FP_COMP_OPS_EXE",
-  .desc   = "Floating poing computational micro-ops",
+  .desc   = "Floating point computational micro-ops",
   .modmsk = INTEL_V3_ATTRS,
   .cntmsk = 0xf,
   .code = 0x10,
@@ -2179,7 +2179,7 @@ static const intel_x86_entry_t intel_nhm_pe[]={
   .umasks = nhm_l2_hw_prefetch,
 },
 { .name   = "L2_LINES_IN",
-  .desc   = "L2 lines alloacated",
+  .desc   = "L2 lines allocated",
   .modmsk = INTEL_V3_ATTRS,
   .cntmsk = 0xf,
   .code = 0xf1,
@@ -2348,7 +2348,7 @@ static const intel_x86_entry_t intel_nhm_pe[]={
   .code = 0x1b2,
 },
 { .name   = "PARTIAL_ADDRESS_ALIAS",
-  .desc   = "False dependencies due to partial address froming",
+  .desc   = "False dependencies due to partial address forming",
   .modmsk = INTEL_V3_ATTRS,
   .cntmsk = 0xf,
   .code = 0x107,
diff --git a/src/libpfm4/lib/events/intel_nhm_unc_events.h b/src/libpfm4/lib/events/intel_nhm_unc_events.h
index 513a730..6421a6b 100644
--- a/src/libpfm4/lib/events/intel_nhm_unc_events.h
+++ b/src/libpfm4/lib/events/intel_nhm_unc_events.h
@@ -29,15 +29,15 @@
 
 static const intel_x86_umask_t nhm_unc_unc_dram_open[]={
    { .uname  = "CH0",
-     .udesc  = "DRAM Channel 0 open comamnds issued for read or write",
+     .udesc  = "DRAM Channel 0 open commands issued for read or write",
      .ucode = 0x100,
    },
    { .uname  = "CH1",
-     .udesc  = "DRAM Channel 1 open comamnds issued for read or write",
+     .udesc  = "DRAM Channel 1 open commands issued for read or write",
      .ucode = 0x200,
    },
    { .uname  = "CH2",
-     .udesc  = "DRAM Channel 2 open comamnds issued for read or write",
+     .udesc  = "DRAM Channel 2 open commands issued for read or write",
      .ucode = 0x400,
    },
 };
@@ -878,7 +878,7 @@ static const intel_x86_entry_t intel_nhm_unc_pe[]={
   .flags = INTEL_X86_FIXED,
 },
 { .name   = "UNC_DRAM_OPEN",
-  .desc   = "DRAM open comamnds issued for read or write",
+  .desc   = "DRAM open commands issued for read or write",
   .modmsk = NHM_UNC_ATTRS,
   .cntmsk = 0x1fe00000,
   .code = 0x60,
diff --git a/src/libpfm4/lib/events/intel_p6_events.h b/src/libpfm4/lib/events/intel_p6_events.h
index ba9512d..f8a83a8 100644
--- a/src/libpfm4/lib/events/intel_p6_events.h
+++ b/src/libpfm4/lib/events/intel_p6_events.h
@@ -168,7 +168,7 @@ static const intel_x86_entry_t intel_p6_pe[]={
   .code = 0xc0,
 },
 { .name   = "DATA_MEM_REFS",
-  .desc   = "All loads from any memory type. All stores to any memory typeEach part of a split is counted separately. The internal logic counts not only memory loads and stores but also internal retries. 80-bit floating point accesses are double counted, since they are decomposed into a 16-bit exponent load and a 64-bit mantissa load. Memory accesses are only counted when they are  actually performed (such as a load that gets squashed because a previous cache miss is outstanding to the same address, and which finally gets performe, is only counted once). Does ot include I/O accesses or other non-memory accesses",
+  .desc   = "All loads from any memory type. All stores to any memory typeEach part of a split is counted separately. The internal logic counts not only memory loads and stores but also internal retries. 80-bit floating point accesses are double counted, since they are decomposed into a 16-bit exponent load and a 64-bit mantissa load. Memory accesses are only counted when they are  actually performed (such as a load that gets squashed because a previous cache miss is outstanding to the same address, and which finally gets performed, is only counted once). Does not include I/O accesses or other non-memory accesses",
   .modmsk = INTEL_X86_ATTRS,
   .cntmsk = 0x3,
   .code = 0x43,
@@ -237,7 +237,7 @@ static const intel_x86_entry_t intel_p6_pe[]={
   .umasks = p6_l2_ifetch,
 },
 { .name   = "L2_ST",
-  .desc   = "Number of L2 data stores. This event indicates that a normal, unlocked, store memory access was received by the L2. Specifically, it indictes that the DCU sent a read-for ownership request to the L2. It also includes Invalid to Modified reqyests sent by the DCU to the L2. It includes only L2 cacheable memory accesses;  it does not include I/O accesses, other non-memory accesses, or memory accesses such as UC/WT memory accesses. It does include L2 cacheable TLB miss memory accesses",
+  .desc   = "Number of L2 data stores. This event indicates that a normal, unlocked, store memory access was received by the L2. Specifically, it indicates that the DCU sent a read-for ownership request to the L2. It also includes Invalid to Modified requests sent by the DCU to the L2. It includes only L2 cacheable memory accesses;  it does not include I/O accesses, other non-memory accesses, or memory accesses such as UC/WT memory accesses. It does include L2 cacheable TLB miss memory accesses",
   .modmsk = INTEL_X86_ATTRS,
   .cntmsk = 0x3,
   .code = 0x2a,
diff --git a/src/libpfm4/lib/events/intel_pii_events.h b/src/libpfm4/lib/events/intel_pii_events.h
index 4bff1ec..5846c64 100644
--- a/src/libpfm4/lib/events/intel_pii_events.h
+++ b/src/libpfm4/lib/events/intel_pii_events.h
@@ -132,7 +132,7 @@ static const intel_x86_entry_t intel_pii_pe[]={
   .code = 0xc0,
 },
 { .name   = "DATA_MEM_REFS",
-  .desc   = "All loads from any memory type. All stores to any memory typeEach part of a split is counted separately. The internal logic counts not only memory loads and stores but also internal retries. 80-bit floating point accesses are double counted, since they are decomposed into a 16-bit exponent load and a 64-bit mantissa load. Memory accesses are only counted when they are  actually performed (such as a load that gets squashed because a previous cache miss is outstanding to the same address, and which finally gets performe, is only counted once). Does ot include I/O accesses or other non-memory accesses",
+  .desc   = "All loads from any memory type. All stores to any memory typeEach part of a split is counted separately. The internal logic counts not only memory loads and stores but also internal retries. 80-bit floating point accesses are double counted, since they are decomposed into a 16-bit exponent load and a 64-bit mantissa load. Memory accesses are only counted when they are  actually performed (such as a load that gets squashed because a previous cache miss is outstanding to the same address, and which finally gets performed, is only counted once). Does not include I/O accesses or other non-memory accesses",
   .modmsk = INTEL_X86_ATTRS,
   .cntmsk = 0x3,
   .code = 0x43,
@@ -201,7 +201,7 @@ static const intel_x86_entry_t intel_pii_pe[]={
   .umasks = pii_l2_ifetch,
 },
 { .name   = "L2_ST",
-  .desc   = "Number of L2 data stores. This event indicates that a normal, unlocked, store memory access was received by the L2. Specifically, it indictes that the DCU sent a read-for ownership request to the L2. It also includes Invalid to Modified reqyests sent by the DCU to the L2. It includes only L2 cacheable memory accesses;  it does not include I/O accesses, other non-memory accesses, or memory accesses such as UC/WT memory accesses. It does include L2 cacheable TLB miss memory accesses",
+  .desc   = "Number of L2 data stores. This event indicates that a normal, unlocked, store memory access was received by the L2. Specifically, it indicates that the DCU sent a read-for ownership request to the L2. It also includes Invalid to Modified requests sent by the DCU to the L2. It includes only L2 cacheable memory accesses;  it does not include I/O accesses, other non-memory accesses, or memory accesses such as UC/WT memory accesses. It does include L2 cacheable TLB miss memory accesses",
   .modmsk = INTEL_X86_ATTRS,
   .cntmsk = 0x3,
   .code = 0x2a,
diff --git a/src/libpfm4/lib/events/intel_pm_events.h b/src/libpfm4/lib/events/intel_pm_events.h
index 4fa8795..e32a883 100644
--- a/src/libpfm4/lib/events/intel_pm_events.h
+++ b/src/libpfm4/lib/events/intel_pm_events.h
@@ -235,7 +235,7 @@ static const intel_x86_entry_t intel_pm_pe[]={
   .code = 0xc0,
 },
 { .name   = "DATA_MEM_REFS",
-  .desc   = "All loads from any memory type. All stores to any memory typeEach part of a split is counted separately. The internal logic counts not only memory loads and stores but also internal retries. 80-bit floating point accesses are double counted, since they are decomposed into a 16-bit exponent load and a 64-bit mantissa load. Memory accesses are only counted when they are  actually performed (such as a load that gets squashed because a previous cache miss is outstanding to the same address, and which finally gets performe, is only counted once). Does ot include I/O accesses or other non-memory accesses",
+  .desc   = "All loads from any memory type. All stores to any memory typeEach part of a split is counted separately. The internal logic counts not only memory loads and stores but also internal retries. 80-bit floating point accesses are double counted, since they are decomposed into a 16-bit exponent load and a 64-bit mantissa load. Memory accesses are only counted when they are  actually performed (such as a load that gets squashed because a previous cache miss is outstanding to the same address, and which finally gets performed, is only counted once). Does not include I/O accesses or other non-memory accesses",
   .modmsk = INTEL_X86_ATTRS,
   .cntmsk = 0x3,
   .code = 0x43,
@@ -304,7 +304,7 @@ static const intel_x86_entry_t intel_pm_pe[]={
   .umasks = pm_l2_ifetch,
 },
 { .name   = "L2_ST",
-  .desc   = "Number of L2 data stores. This event indicates that a normal, unlocked, store memory access was received by the L2. Specifically, it indictes that the DCU sent a read-for ownership request to the L2. It also includes Invalid to Modified reqyests sent by the DCU to the L2. It includes only L2 cacheable memory accesses;  it does not include I/O accesses, other non-memory accesses, or memory accesses such as UC/WT memory accesses. It does include L2 cacheable TLB miss memory accesses",
+  .desc   = "Number of L2 data stores. This event indicates that a normal, unlocked, store memory access was received by the L2. Specifically, it indicates that the DCU sent a read-for ownership request to the L2. It also includes Invalid to Modified requests sent by the DCU to the L2. It includes only L2 cacheable memory accesses;  it does not include I/O accesses, other non-memory accesses, or memory accesses such as UC/WT memory accesses. It does include L2 cacheable TLB miss memory accesses",
   .modmsk = INTEL_X86_ATTRS,
   .cntmsk = 0x3,
   .code = 0x2a,
diff --git a/src/libpfm4/lib/events/intel_ppro_events.h b/src/libpfm4/lib/events/intel_ppro_events.h
index 63ad7b7..0555652 100644
--- a/src/libpfm4/lib/events/intel_ppro_events.h
+++ b/src/libpfm4/lib/events/intel_ppro_events.h
@@ -73,7 +73,7 @@ static const intel_x86_entry_t intel_ppro_pe[]={
   .code = 0xc0,
 },
 { .name   = "DATA_MEM_REFS",
-  .desc   = "All loads from any memory type. All stores to any memory typeEach part of a split is counted separately. The internal logic counts not only memory loads and stores but also internal retries. 80-bit floating point accesses are double counted, since they are decomposed into a 16-bit exponent load and a 64-bit mantissa load. Memory accesses are only counted when they are  actually performed (such as a load that gets squashed because a previous cache miss is outstanding to the same address, and which finally gets performe, is only counted once). Does ot include I/O accesses or other non-memory accesses",
+  .desc   = "All loads from any memory type. All stores to any memory typeEach part of a split is counted separately. The internal logic counts not only memory loads and stores but also internal retries. 80-bit floating point accesses are double counted, since they are decomposed into a 16-bit exponent load and a 64-bit mantissa load. Memory accesses are only counted when they are  actually performed (such as a load that gets squashed because a previous cache miss is outstanding to the same address, and which finally gets performed, is only counted once). Does not include I/O accesses or other non-memory accesses",
   .modmsk = INTEL_X86_ATTRS,
   .cntmsk = 0x3,
   .code = 0x43,
@@ -142,7 +142,7 @@ static const intel_x86_entry_t intel_ppro_pe[]={
   .umasks = ppro_l2_ifetch,
 },
 { .name   = "L2_ST",
-  .desc   = "Number of L2 data stores. This event indicates that a normal, unlocked, store memory access was received by the L2. Specifically, it indictes that the DCU sent a read-for ownership request to the L2. It also includes Invalid to Modified reqyests sent by the DCU to the L2. It includes only L2 cacheable memory accesses;  it does not include I/O accesses, other non-memory accesses, or memory accesses such as UC/WT memory accesses. It does include L2 cacheable TLB miss memory accesses",
+  .desc   = "Number of L2 data stores. This event indicates that a normal, unlocked, store memory access was received by the L2. Specifically, it indicates that the DCU sent a read-for ownership request to the L2. It also includes Invalid to Modified requests sent by the DCU to the L2. It includes only L2 cacheable memory accesses;  it does not include I/O accesses, other non-memory accesses, or memory accesses such as UC/WT memory accesses. It does include L2 cacheable TLB miss memory accesses",
   .modmsk = INTEL_X86_ATTRS,
   .cntmsk = 0x3,
   .code = 0x2a,
diff --git a/src/libpfm4/lib/events/intel_slm_events.h b/src/libpfm4/lib/events/intel_slm_events.h
index c540e64..558dbf8 100644
--- a/src/libpfm4/lib/events/intel_slm_events.h
+++ b/src/libpfm4/lib/events/intel_slm_events.h
@@ -32,7 +32,7 @@ static const intel_x86_umask_t slm_icache[]={
      .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
    },
    { .uname  = "MISSES",
-     .udesc  = "Count all instructions fetches that miss tha icache or produce memory requests. This includes uncacheache fetches. Any instruction fetch miss is counted only once and not once for every cycle it is outstanding",
+     .udesc  = "Count all instructions fetches that miss the icache or produce memory requests. This includes uncacheache fetches. Any instruction fetch miss is counted only once and not once for every cycle it is outstanding",
      .ucode = 0x200,
      .uflags= INTEL_X86_NCOMBO,
    },
@@ -97,7 +97,7 @@ static const intel_x86_umask_t slm_inst_retired[]={
 
 static const intel_x86_umask_t slm_l2_reject_xq[]={
    { .uname  = "ALL",
-     .udesc  = "Number of demand and prefetch transactions that the L2 XQ rejects due to a full or near full condition which likely indictes back pressure from the IDI link. The XQ may reject transactions fro mthe L2Q (non-cacheable requests), BBS (L2 misses) and WOB (L2 write-back victims)",
+     .udesc  = "Number of demand and prefetch transactions that the L2 XQ rejects due to a full or near full condition which likely indicates back pressure from the IDI link. The XQ may reject transactions fro mthe L2Q (non-cacheable requests), BBS (L2 misses) and WOB (L2 write-back victims)",
      .ucode = 0x000,
      .uflags= INTEL_X86_DFL,
    },
@@ -345,7 +345,7 @@ static const intel_x86_umask_t slm_rehabq[]={
      .uflags= INTEL_X86_NCOMBO,
    },
    { .uname  = "STA_FULL",
-     .udesc  = "Number of retired stores that are delayed becuase there is not a store address buffer available",
+     .udesc  = "Number of retired stores that are delayed because there is not a store address buffer available",
      .ucode = 0x2000,
      .uflags= INTEL_X86_NCOMBO,
    },
@@ -625,7 +625,7 @@ static const intel_x86_umask_t slm_ms_decoded[]={
 
 static const intel_x86_umask_t slm_decode_restriction[]={
    { .uname  = "PREDECODE_WRONG",
-     .udesc  = "Number of times the prediction (from the predecode cache) for intruction length is incorrect",
+     .udesc  = "Number of times the prediction (from the predecode cache) for instruction length is incorrect",
      .ucode = 0x0100,
      .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
    },
diff --git a/src/libpfm4/lib/events/intel_snb_events.h b/src/libpfm4/lib/events/intel_snb_events.h
index 68e8d2d..11937ea 100644
--- a/src/libpfm4/lib/events/intel_snb_events.h
+++ b/src/libpfm4/lib/events/intel_snb_events.h
@@ -571,7 +571,7 @@ static const intel_x86_umask_t snb_idq[]={
      .uflags= INTEL_X86_NCOMBO,
    },
    { .uname  = "MS_DSB_UOPS_OCCUR",
-     .udesc  = "Occurences of DSB MS going active",
+     .udesc  = "Occurrences of DSB MS going active",
      .uequiv = "MS_DSB_UOPS:c=1:e=1",
      .ucode = 0x1000 | INTEL_X86_MOD_EDGE | (0x1 << INTEL_X86_CMASK_BIT),
      .uflags= INTEL_X86_NCOMBO,
@@ -1408,17 +1408,17 @@ static const intel_x86_umask_t snb_uops_dispatched_port[]={
      .uflags= INTEL_X86_NCOMBO,
    },
    { .uname  = "PORT_3_LD",
-     .udesc  = "Cycles in which a load uop is disptached on port 3",
+     .udesc  = "Cycles in which a load uop is dispatched on port 3",
      .ucode = 0x1000,
      .uflags= INTEL_X86_NCOMBO,
    },
    { .uname  = "PORT_3_STA",
-     .udesc  = "Cycles in which a store uop is disptached on port 3",
+     .udesc  = "Cycles in which a store uop is dispatched on port 3",
      .ucode = 0x2000,
      .uflags= INTEL_X86_NCOMBO,
    },
    { .uname  = "PORT_3",
-     .udesc  = "Cycles in which a uop is disptached on port 3",
+     .udesc  = "Cycles in which a uop is dispatched on port 3",
      .ucode = 0x3000,
      .uflags= INTEL_X86_NCOMBO,
    },
@@ -1683,7 +1683,7 @@ static const intel_x86_umask_t snb_offcore_response[]={
 
 static const intel_x86_umask_t snb_baclears[]={
    { .uname  = "ANY",
-     .udesc  = "Counts the number of times the front end is resteered, mainly when the BPU cannot provide a correct prediction and this is corrected by other branch handling mechanisms at the front end",
+     .udesc  = "Counts the number of times the front end is re-steered, mainly when the BPU cannot provide a correct prediction and this is corrected by other branch handling mechanisms at the front end",
      .ucode = 0x1f00,
      .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
    },
@@ -1742,7 +1742,7 @@ static const intel_x86_entry_t intel_snb_pe[]={
   .umasks = snb_arith,
 },
 { .name   = "BACLEARS",
-  .desc   = "Branch resteered",
+  .desc   = "Branch re-steered",
   .modmsk = INTEL_V3_ATTRS,
   .cntmsk = 0xff,
   .code = 0xe6,
@@ -2033,7 +2033,7 @@ static const intel_x86_entry_t intel_snb_pe[]={
   .umasks = snb_l2_l1d_wb_rqsts,
 },
 { .name   = "L2_LINES_IN",
-  .desc   = "L2 lines alloacated",
+  .desc   = "L2 lines allocated",
   .modmsk = INTEL_V3_ATTRS,
   .cntmsk = 0xff,
   .code = 0xf1,
diff --git a/src/libpfm4/lib/events/intel_snbep_events.h b/src/libpfm4/lib/events/intel_snbep_events.h
index 0df2b5c..a9d88f5 100644
--- a/src/libpfm4/lib/events/intel_snbep_events.h
+++ b/src/libpfm4/lib/events/intel_snbep_events.h
@@ -24,7 +24,7 @@
  *
  * This file has been automatically generated.
  *
- * PMU: snb (Intel Sandy Bridge EP)
+ * PMU: snb_ep (Intel Sandy Bridge EP)
  */
 
 static const intel_x86_umask_t snbep_agu_bypass_cancel[]={
@@ -571,7 +571,7 @@ static const intel_x86_umask_t snbep_idq[]={
      .uflags= INTEL_X86_NCOMBO,
    },
    { .uname  = "MS_DSB_UOPS_OCCUR",
-     .udesc  = "Occurences of DSB MS going active",
+     .udesc  = "Occurrences of DSB MS going active",
      .uequiv = "MS_DSB_UOPS:c=1:e=1",
      .ucode = 0x1000 | INTEL_X86_MOD_EDGE | (0x1 << INTEL_X86_CMASK_BIT),
      .uflags= INTEL_X86_NCOMBO,
@@ -1421,17 +1421,17 @@ static const intel_x86_umask_t snbep_uops_dispatched_port[]={
      .uflags= INTEL_X86_NCOMBO,
    },
    { .uname  = "PORT_3_LD",
-     .udesc  = "Cycles in which a load uop is disptached on port 3",
+     .udesc  = "Cycles in which a load uop is dispatched on port 3",
      .ucode = 0x1000,
      .uflags= INTEL_X86_NCOMBO,
    },
    { .uname  = "PORT_3_STA",
-     .udesc  = "Cycles in which a store uop is disptached on port 3",
+     .udesc  = "Cycles in which a store uop is dispatched on port 3",
      .ucode = 0x2000,
      .uflags= INTEL_X86_NCOMBO,
    },
    { .uname  = "PORT_3",
-     .udesc  = "Cycles in which a uop is disptached on port 3",
+     .udesc  = "Cycles in which a uop is dispatched on port 3",
      .ucode = 0x3000,
      .uflags= INTEL_X86_NCOMBO,
    },
@@ -1695,7 +1695,7 @@ static const intel_x86_umask_t snbep_offcore_response[]={
 
 static const intel_x86_umask_t snbep_baclears[]={
    { .uname  = "ANY",
-     .udesc  = "Counts the number of times the front end is resteered, mainly when the BPU cannot provide a correct prediction and this is corrected by other branch handling mechanisms at the front end",
+     .udesc  = "Counts the number of times the front end is re-steered, mainly when the BPU cannot provide a correct prediction and this is corrected by other branch handling mechanisms at the front end",
      .ucode = 0x1f00,
      .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
    },
@@ -1754,7 +1754,7 @@ static const intel_x86_entry_t intel_snbep_pe[]={
   .umasks = snbep_arith,
 },
 { .name   = "BACLEARS",
-  .desc   = "Branch resteered",
+  .desc   = "Branch re-steered",
   .modmsk = INTEL_V3_ATTRS,
   .cntmsk = 0xff,
   .code = 0xe6,
@@ -2045,7 +2045,7 @@ static const intel_x86_entry_t intel_snbep_pe[]={
   .umasks = snbep_l2_l1d_wb_rqsts,
 },
 { .name   = "L2_LINES_IN",
-  .desc   = "L2 lines alloacated",
+  .desc   = "L2 lines allocated",
   .modmsk = INTEL_V3_ATTRS,
   .cntmsk = 0xff,
   .code = 0xf1,
diff --git a/src/libpfm4/lib/events/intel_snbep_unc_cbo_events.h b/src/libpfm4/lib/events/intel_snbep_unc_cbo_events.h
index 125c5ad..b2f0878 100644
--- a/src/libpfm4/lib/events/intel_snbep_unc_cbo_events.h
+++ b/src/libpfm4/lib/events/intel_snbep_unc_cbo_events.h
@@ -641,7 +641,7 @@ static const intel_x86_entry_t intel_snbep_unc_c_pe[]={
     .umasks = snbep_unc_c_llc_victims,
   },
   { .name   = "UNC_C_MISC",
-    .desc   = "Miscelleanous C-Box events",
+    .desc   = "Miscellaneous C-Box events",
     .modmsk = SNBEP_UNC_CBO_ATTRS,
     .cntmsk = 0x3,
     .code = 0x39,
@@ -659,7 +659,7 @@ static const intel_x86_entry_t intel_snbep_unc_c_pe[]={
     .umasks = snbep_unc_c_ring_ad_used,
   },
   { .name   = "UNC_C_RING_AK_USED",
-    .desc   = "Acknowledgement ring in use. Counts number of cycles ring is being used at this ring stop",
+    .desc   = "Acknowledgment ring in use. Counts number of cycles ring is being used at this ring stop",
     .modmsk = SNBEP_UNC_CBO_ATTRS,
     .cntmsk = 0xc,
     .code = 0x1c,
diff --git a/src/libpfm4/lib/events/intel_wsm_events.h b/src/libpfm4/lib/events/intel_wsm_events.h
index 07dffb0..d6f59cb 100644
--- a/src/libpfm4/lib/events/intel_wsm_events.h
+++ b/src/libpfm4/lib/events/intel_wsm_events.h
@@ -299,7 +299,7 @@ static const intel_x86_umask_t wsm_dtlb_load_misses[]={
 
 static const intel_x86_umask_t wsm_l2_lines_in[]={
    { .uname  = "ANY",
-     .udesc  = "L2 lines alloacated",
+     .udesc  = "L2 lines allocated",
      .ucode = 0x700,
      .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
    },
@@ -1993,7 +1993,7 @@ static const intel_x86_entry_t intel_wsm_pe[]={
   .umasks = wsm_dtlb_load_misses,
 },
 { .name   = "L2_LINES_IN",
-  .desc   = "L2 lines alloacated",
+  .desc   = "L2 lines allocated",
   .modmsk = INTEL_V3_ATTRS,
   .cntmsk = 0xf,
   .code = 0xf1,
diff --git a/src/libpfm4/lib/events/intel_wsm_unc_events.h b/src/libpfm4/lib/events/intel_wsm_unc_events.h
index fa76e26..66fd961 100644
--- a/src/libpfm4/lib/events/intel_wsm_unc_events.h
+++ b/src/libpfm4/lib/events/intel_wsm_unc_events.h
@@ -29,15 +29,15 @@
 
 static const intel_x86_umask_t wsm_unc_unc_dram_open[]={
    { .uname  = "CH0",
-     .udesc  = "DRAM Channel 0 open comamnds issued for read or write",
+     .udesc  = "DRAM Channel 0 open commands issued for read or write",
      .ucode = 0x100,
    },
    { .uname  = "CH1",
-     .udesc  = "DRAM Channel 1 open comamnds issued for read or write",
+     .udesc  = "DRAM Channel 1 open commands issued for read or write",
      .ucode = 0x200,
    },
    { .uname  = "CH2",
-     .udesc  = "DRAM Channel 2 open comamnds issued for read or write",
+     .udesc  = "DRAM Channel 2 open commands issued for read or write",
      .ucode = 0x400,
    },
 };
@@ -925,7 +925,7 @@ static const intel_x86_entry_t intel_wsm_unc_pe[]={
   .flags = INTEL_X86_FIXED,
 },
 { .name   = "UNC_DRAM_OPEN",
-  .desc   = "DRAM open comamnds issued for read or write",
+  .desc   = "DRAM open commands issued for read or write",
   .modmsk = NHM_UNC_ATTRS,
   .cntmsk = 0x1fe00000,
   .code = 0x60,
@@ -1334,7 +1334,7 @@ static const intel_x86_entry_t intel_wsm_unc_pe[]={
   .umasks = wsm_unc_unc_thermal_throttling_temp, /* identical to actual umasks list for this event */
 },
 { .name   = "UNC_PROCHOT_ASSERTION",
-  .desc   = "Number of system ssertions of PROCHOT indicating the entire processor has exceeded the thermal limit",
+  .desc   = "Number of system assertions of PROCHOT indicating the entire processor has exceeded the thermal limit",
   .modmsk = NHM_UNC_ATTRS,
   .cntmsk = 0x1fe00000,
   .code = 0x82,
diff --git a/src/libpfm4/lib/events/intel_x86_arch_events.h b/src/libpfm4/lib/events/intel_x86_arch_events.h
index 0b9ff6a..c8c862b 100644
--- a/src/libpfm4/lib/events/intel_x86_arch_events.h
+++ b/src/libpfm4/lib/events/intel_x86_arch_events.h
@@ -42,7 +42,7 @@ static intel_x86_entry_t intel_x86_arch_pe[]={
 	{.name = "UNHALTED_REFERENCE_CYCLES",
 	 .code = 0x013c,
 	 .cntmsk = 0x400000000ull, /* temporary */
-	 .desc =  "count reference clock cycles while the clock signal on the specific core is running. The reference clock operates at a fixed frequency, irrespective of core freqeuncy changes due to performance state transitions",
+	 .desc =  "count reference clock cycles while the clock signal on the specific core is running. The reference clock operates at a fixed frequency, irrespective of core frequency changes due to performance state transitions",
 	},
 	{.name = "LLC_REFERENCES",
 	 .code = 0x4f2e,
diff --git a/src/libpfm4/lib/events/mips_74k_events.h b/src/libpfm4/lib/events/mips_74k_events.h
index 399da6e..523627b 100644
--- a/src/libpfm4/lib/events/mips_74k_events.h
+++ b/src/libpfm4/lib/events/mips_74k_events.h
@@ -224,7 +224,7 @@ static const mips_entry_t mips_74k_pe []={
   {
     .name = "DCACHE_MISSES",
     .code = 0x98,
-    .desc = "D-cache misses. This count is per instruction at grad- uation and includes load, store, prefetch, synci and address based cacheops",
+    .desc = "D-cache misses. This count is per instruction at graduation and includes load, store, prefetch, synci and address based cacheops",
   },
   {
     .name = "JTLB_DATA_ACCESSES",
@@ -244,7 +244,7 @@ static const mips_entry_t mips_74k_pe []={
   {
     .name = "DCACHE_VTAG_MISMATCH",
     .code = 0x9a,
-    .desc = "The 74K core's D-cache has an auxiliary virtual tag, used to pick the right line early. When (occasionally) the physical tag match and virtual tag match do not line up, it is treated as a cache miss - in processing the miss the virtual tag is correcyed for future accesses. This event counts those bogus misses",
+    .desc = "The 74K core's D-cache has an auxiliary virtual tag, used to pick the right line early. When (occasionally) the physical tag match and virtual tag match do not line up, it is treated as a cache miss - in processing the miss the virtual tag is corrected for future accesses. This event counts those bogus misses",
   },
   {
     .name = "L2_CACHE_WRITEBACKS",
@@ -349,7 +349,7 @@ static const mips_entry_t mips_74k_pe []={
   {
     .name = "INTEGER_INSNS",
     .code = 0x28,
-    .desc = "Integer instructions graduated (includes nop, ssnop, ehb as well as all arithmetic, locial, shift and extract type operations)",
+    .desc = "Integer instructions graduated (includes nop, ssnop, ehb as well as all arithmetic, logical, shift and extract type operations)",
   },
   {
     .name = "FPU_INSNS",
diff --git a/src/libpfm4/lib/events/sparc_ultra3_events.h b/src/libpfm4/lib/events/sparc_ultra3_events.h
index a074e3a..c19097d 100644
--- a/src/libpfm4/lib/events/sparc_ultra3_events.h
+++ b/src/libpfm4/lib/events/sparc_ultra3_events.h
@@ -20,7 +20,7 @@ static const sparc_entry_t ultra3_pe[] = {
 	},
 	{
 		.name = "IC_ref",
-		.desc = "I-cache refrences",
+		.desc = "I-cache references",
 		.ctrl = PME_CTRL_S0,
 		.code = 0x8,
 	},
@@ -84,13 +84,13 @@ static const sparc_entry_t ultra3_pe[] = {
 	},
 	{
 		.name = "Rstall_storeQ",
-		.desc = "R-stage stall for a store instruction which is the next instruction to be executed, but it stailled due to the store queue being full",
+		.desc = "R-stage stall for a store instruction which is the next instruction to be executed, but it stalled due to the store queue being full",
 		.ctrl = PME_CTRL_S0,
 		.code = 0x5,
 	},
 	{
 		.name = "Rstall_IU_use",
-		.desc = "R-stage stall for an event that the next instruction to be executed depends on the result of a preceeding integer instruction in the pipeline that is not yet available",
+		.desc = "R-stage stall for an event that the next instruction to be executed depends on the result of a preceding integer instruction in the pipeline that is not yet available",
 		.ctrl = PME_CTRL_S0,
 		.code = 0x6,
 	},
@@ -204,7 +204,7 @@ static const sparc_entry_t ultra3_pe[] = {
 	},
 	{
 		.name = "Rstall_FP_use",
-		.desc = "R-stage stall for an event that the next instruction to be executed depends on the result of a preceeding floating-point instruction in the pipeline that is not yet available",
+		.desc = "R-stage stall for an event that the next instruction to be executed depends on the result of a preceding floating-point instruction in the pipeline that is not yet available",
 		.ctrl = PME_CTRL_S1,
 		.code = 0xb,
 	},
diff --git a/src/libpfm4/lib/events/sparc_ultra3i_events.h b/src/libpfm4/lib/events/sparc_ultra3i_events.h
index a8ce584..f81213e 100644
--- a/src/libpfm4/lib/events/sparc_ultra3i_events.h
+++ b/src/libpfm4/lib/events/sparc_ultra3i_events.h
@@ -20,7 +20,7 @@ static const sparc_entry_t ultra3i_pe[] = {
 	},
 	{
 		.name = "IC_ref",
-		.desc = "I-cache refrences",
+		.desc = "I-cache references",
 		.ctrl = PME_CTRL_S0,
 		.code = 0x8,
 	},
@@ -84,13 +84,13 @@ static const sparc_entry_t ultra3i_pe[] = {
 	},
 	{
 		.name = "Rstall_storeQ",
-		.desc = "R-stage stall for a store instruction which is the next instruction to be executed, but it stailled due to the store queue being full",
+		.desc = "R-stage stall for a store instruction which is the next instruction to be executed, but it stalled due to the store queue being full",
 		.ctrl = PME_CTRL_S0,
 		.code = 0x5,
 	},
 	{
 		.name = "Rstall_IU_use",
-		.desc = "R-stage stall for an event that the next instruction to be executed depends on the result of a preceeding integer instruction in the pipeline that is not yet available",
+		.desc = "R-stage stall for an event that the next instruction to be executed depends on the result of a preceding integer instruction in the pipeline that is not yet available",
 		.ctrl = PME_CTRL_S0,
 		.code = 0x6,
 	},
@@ -204,7 +204,7 @@ static const sparc_entry_t ultra3i_pe[] = {
 	},
 	{
 		.name = "Rstall_FP_use",
-		.desc = "R-stage stall for an event that the next instruction to be executed depends on the result of a preceeding floating-point instruction in the pipeline that is not yet available",
+		.desc = "R-stage stall for an event that the next instruction to be executed depends on the result of a preceding floating-point instruction in the pipeline that is not yet available",
 		.ctrl = PME_CTRL_S1,
 		.code = 0xb,
 	},
@@ -383,7 +383,7 @@ static const sparc_entry_t ultra3i_pe[] = {
 	/* PIC1 events specific to UltraSPARC-III+/IIIi */
 	{
 		.name = "Re_DC_missovhd",
-		.desc = "Used to measure D-cache stall counts seperatedly for L2-cache hits and misses.  This counter is used with the recirculation and cache access events to seperately calculate the D-cache loads that hit and miss the L2-cache",
+		.desc = "Used to measure D-cache stall counts separately for L2-cache hits and misses.  This counter is used with the recirculation and cache access events to separately calculate the D-cache loads that hit and miss the L2-cache",
 		.ctrl = PME_CTRL_S1,
 		.code = 0x4,
 	},
diff --git a/src/libpfm4/lib/events/sparc_ultra3plus_events.h b/src/libpfm4/lib/events/sparc_ultra3plus_events.h
index 04de4a6..b1dc8ca 100644
--- a/src/libpfm4/lib/events/sparc_ultra3plus_events.h
+++ b/src/libpfm4/lib/events/sparc_ultra3plus_events.h
@@ -20,7 +20,7 @@ static const sparc_entry_t ultra3plus_pe[] = {
 	},
 	{
 		.name = "IC_ref",
-		.desc = "I-cache refrences",
+		.desc = "I-cache references",
 		.ctrl = PME_CTRL_S0,
 		.code = 0x8,
 	},
@@ -84,13 +84,13 @@ static const sparc_entry_t ultra3plus_pe[] = {
 	},
 	{
 		.name = "Rstall_storeQ",
-		.desc = "R-stage stall for a store instruction which is the next instruction to be executed, but it stailled due to the store queue being full",
+		.desc = "R-stage stall for a store instruction which is the next instruction to be executed, but it stalled due to the store queue being full",
 		.ctrl = PME_CTRL_S0,
 		.code = 0x5,
 	},
 	{
 		.name = "Rstall_IU_use",
-		.desc = "R-stage stall for an event that the next instruction to be executed depends on the result of a preceeding integer instruction in the pipeline that is not yet available",
+		.desc = "R-stage stall for an event that the next instruction to be executed depends on the result of a preceding integer instruction in the pipeline that is not yet available",
 		.ctrl = PME_CTRL_S0,
 		.code = 0x6,
 	},
@@ -204,7 +204,7 @@ static const sparc_entry_t ultra3plus_pe[] = {
 	},
 	{
 		.name = "Rstall_FP_use",
-		.desc = "R-stage stall for an event that the next instruction to be executed depends on the result of a preceeding floating-point instruction in the pipeline that is not yet available",
+		.desc = "R-stage stall for an event that the next instruction to be executed depends on the result of a preceding floating-point instruction in the pipeline that is not yet available",
 		.ctrl = PME_CTRL_S1,
 		.code = 0xb,
 	},
@@ -421,7 +421,7 @@ static const sparc_entry_t ultra3plus_pe[] = {
 	/* PIC1 events specific to UltraSPARC-III+/IIIi processors */
 	{
 		.name = "Re_DC_missovhd",
-		.desc = "Used to measure D-cache stall counts seperatedly for L2-cache hits and misses.  This counter is used with the recirculation and cache access events to seperately calculate the D-cache loads that hit and miss the L2-cache",
+		.desc = "Used to measure D-cache stall counts separately for L2-cache hits and misses.  This counter is used with the recirculation and cache access events to separately calculate the D-cache loads that hit and miss the L2-cache",
 		.ctrl = PME_CTRL_S1,
 		.code = 0x4,
 	},
diff --git a/src/libpfm4/lib/events/sparc_ultra4plus_events.h b/src/libpfm4/lib/events/sparc_ultra4plus_events.h
index 47512da..ca473a4 100644
--- a/src/libpfm4/lib/events/sparc_ultra4plus_events.h
+++ b/src/libpfm4/lib/events/sparc_ultra4plus_events.h
@@ -32,13 +32,13 @@ static const sparc_entry_t ultra4plus_pe[] = {
 	},
 	{
 		.name = "Rstall_storeQ",
-		.desc = "R-stage stall for a store instruction which is the next instruction to be executed, but it stailled due to the store queue being full",
+		.desc = "R-stage stall for a store instruction which is the next instruction to be executed, but it stalled due to the store queue being full",
 		.ctrl = PME_CTRL_S0,
 		.code = 0x5,
 	},
 	{
 		.name = "Rstall_IU_use",
-		.desc = "R-stage stall for an event that the next instruction to be executed depends on the result of a preceeding integer instruction in the pipeline that is not yet available",
+		.desc = "R-stage stall for an event that the next instruction to be executed depends on the result of a preceding integer instruction in the pipeline that is not yet available",
 		.ctrl = PME_CTRL_S0,
 		.code = 0x6,
 	},
@@ -50,7 +50,7 @@ static const sparc_entry_t ultra4plus_pe[] = {
 	},
 	{
 		.name = "IC_ref",
-		.desc = "I-cache refrences",
+		.desc = "I-cache references",
 		.ctrl = PME_CTRL_S0,
 		.code = 0x8,
 	},
@@ -62,7 +62,7 @@ static const sparc_entry_t ultra4plus_pe[] = {
 	},
 	{
 		.name = "Rstall_FP_use",
-		.desc = "R-stage stall for an event that the next instruction to be executed depends on the result of a preceeding floating-point instruction in the pipeline that is not yet available",
+		.desc = "R-stage stall for an event that the next instruction to be executed depends on the result of a preceding floating-point instruction in the pipeline that is not yet available",
 		.ctrl = PME_CTRL_S0,
 		.code = 0xa,
 	},
@@ -179,7 +179,7 @@ static const sparc_entry_t ultra4plus_pe[] = {
 	},
 	{
 		.name = "IPB_to_IC_fill",
-		.desc = "I-cache filles from the instruction prefetch buffer",
+		.desc = "I-cache fills from the instruction prefetch buffer",
 		.ctrl = PME_CTRL_S0,
 		.code = 0x1e,
 	},
@@ -577,7 +577,7 @@ static const sparc_entry_t ultra4plus_pe[] = {
 	},
 	{
 		.name = "L3_miss",
-		.desc = "Number of L3 cache misses sent out to SIU from this core by cacheable I-cache, D-cache, P-cache, and W-cache (exclusing block stores) requests",
+		.desc = "Number of L3 cache misses sent out to SIU from this core by cacheable I-cache, D-cache, P-cache, and W-cache (excluding block stores) requests",
 		.ctrl = PME_CTRL_S1,
 		.code = 0x31,
 	},
diff --git a/src/libpfm4/lib/pfmlib_common.c b/src/libpfm4/lib/pfmlib_common.c
index 1ff74e8..ea05e37 100644
--- a/src/libpfm4/lib/pfmlib_common.c
+++ b/src/libpfm4/lib/pfmlib_common.c
@@ -580,8 +580,6 @@ pfmlib_match_forced_pmu(const char *name)
 static int
 pfmlib_is_blacklisted_pmu(pfmlib_pmu_t *p)
 {
-	const char *a, *b;
-
 	if (!pfm_cfg.blacklist_pmus)
 		return 0;
 
@@ -589,16 +587,15 @@ pfmlib_is_blacklisted_pmu(pfmlib_pmu_t *p)
 	 * scan list for matching PMU names, we accept substrings.
 	 * for instance: snbep does match snbep*
 	 */
-	for (a = pfm_cfg.blacklist_pmus, b = p->name; *a && *b; a++) {
-		if (*a != *b++) {
-			char *n = strchr(a, ',');
-			if (!n)
-				break;
-			a = n;
-			b = p->name;
+	char *q, buffer[strlen(pfm_cfg.blacklist_pmus) + 1];
+
+	strcpy (buffer, pfm_cfg.blacklist_pmus);
+	for (q = strtok (buffer, ","); q != NULL; q = strtok (NULL, ",")) {
+		if (strstr (p->name, q) != NULL) {
+			return 1;
 		}
 	}
-	return *a == ',' || !*a;
+	return 0;
 }
 
 static int
diff --git a/src/libpfm4/lib/pfmlib_intel_rapl.c b/src/libpfm4/lib/pfmlib_intel_rapl.c
index 4570d65..1215731 100644
--- a/src/libpfm4/lib/pfmlib_intel_rapl.c
+++ b/src/libpfm4/lib/pfmlib_intel_rapl.c
@@ -51,7 +51,12 @@ extern pfmlib_pmu_t intel_rapl_support;
   }
 
 static const intel_x86_entry_t intel_rapl_cln_pe[]={
-	RAPL_COMMON_EVENTS
+  RAPL_COMMON_EVENTS,
+  { .name   = "RAPL_ENERGY_GPU",
+    .desc   = "Number of Joules consumed by the builtin GPU. Unit is 2^-32 Joules",
+    .cntmsk = 0x8,
+    .code   = 0x4,
+  }
 };
 
 static const intel_x86_entry_t intel_rapl_srv_pe[]={
diff --git a/src/libpfm4/perf_examples/Makefile b/src/libpfm4/perf_examples/Makefile
index bc90559..3e03fb7 100644
--- a/src/libpfm4/perf_examples/Makefile
+++ b/src/libpfm4/perf_examples/Makefile
@@ -55,7 +55,7 @@ TARGETS+=self self_basic self_count task task_attach_timeout syst \
 	notify_self notify_group task_smpl self_smpl_multi \
 	self_pipe syst_count task_cpu syst_smpl evt2raw
 
-EXAMPLESDIR=$(DOCDIR)/perf_examples
+EXAMPLESDIR=$(DESTDIR)$(DOCDIR)/perf_examples
 
 all: $(TARGETS)
 	@set -e ; for d in $(DIRS) ; do $(MAKE) -C $$d $@ ; done
-- 
2.1.0

From 43e9f4f8904b88935fc66d8bb973c30a666e4bfb Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Wed, 5 Feb 2014 11:02:54 -0500
Subject: [PATCH 11/24] libpfm4 update: add ARM Qualcomm Krait support

Brings us in line with:
commit 71166e2e72370922002edf023c5ed69943e71506
Author: Vince Weaver <vincent.weaver@maine.edu>
Date:   Thu Jan 23 14:26:36 2014 -0500

    add support for ARM Qualcomm Krait PMU

diff --git a/src/libpfm4/README b/src/libpfm4/README
index a765cb4..334c78a 100644
--- a/src/libpfm4/README
+++ b/src/libpfm4/README
@@ -57,6 +57,7 @@ The library supports many PMUs. The current version can handle:
 		ARMV7 Cortex A8
 		ARMV7 Cortex A9
 		ARMV7 Cortex A15
+		Qualcomm Krait
 
 	- For SPARC
 		Ultra I, II
diff --git a/src/libpfm4/docs/Makefile b/src/libpfm4/docs/Makefile
index f24999f..45180d5 100644
--- a/src/libpfm4/docs/Makefile
+++ b/src/libpfm4/docs/Makefile
@@ -66,7 +66,7 @@ endif
 endif
 
 ifeq ($(CONFIG_PFMLIB_ARCH_ARM),y)
-ARCH_MAN += libpfm_arm_ac15.3 libpfm_arm_ac8.3 libpfm_arm_ac9.3
+ARCH_MAN += libpfm_arm_ac15.3 libpfm_arm_ac8.3 libpfm_arm_ac9.3 libpfm_arm_qcom_krait.3
 endif
 
 
diff --git a/src/libpfm4/docs/man3/libpfm_arm_qcom_krait.3 b/src/libpfm4/docs/man3/libpfm_arm_qcom_krait.3
new file mode 100644
index 0000000..b31eba6
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_arm_qcom_krait.3
@@ -0,0 +1,35 @@
+.TH LIBPFM 3  "January, 2014" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_arm_ac15 - support for Qualcomm Krait PMU
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: qcom_krait
+.B PMU desc: Qualcomm Krait
+.sp
+.SH DESCRIPTION
+The library supports the Qualcomm Krait core PMU.
+
+This PMU supports 5 counters and privilege levels filtering.
+
+.SH MODIFIERS
+The following modifiers are supported on this PMU:
+.TP
+.B u
+Measure at the user level. This corresponds to \fBPFM_PLM3\fR.
+This is a boolean modifier.
+.TP
+.B k
+Measure at the kernel level. This corresponds to \fBPFM_PLM0\fR.
+This is a boolean modifier.
+.TP
+.B hv
+Measure at the hypervisor level. This corresponds to \fBPFM_PLMH\fR.
+This is a boolean modifier.
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.PP
diff --git a/src/libpfm4/include/perfmon/pfmlib.h b/src/libpfm4/include/perfmon/pfmlib.h
index ac9ed03..5434a96 100644
--- a/src/libpfm4/include/perfmon/pfmlib.h
+++ b/src/libpfm4/include/perfmon/pfmlib.h
@@ -196,6 +196,8 @@ typedef enum {
 	PFM_PMU_INTEL_SLM,		/* Intel Silvermont */
 	PFM_PMU_AMD64_FAM15H_NB,	/* AMD AMD64 Fam15h NorthBridge */
 
+	PFM_PMU_ARM_QCOM_KRAIT,		/* Qualcomm Krait */
+
 	/* MUST ADD NEW PMU MODELS HERE */
 
 	PFM_PMU_MAX			/* end marker */
diff --git a/src/libpfm4/lib/events/arm_qcom_krait_events.h b/src/libpfm4/lib/events/arm_qcom_krait_events.h
new file mode 100644
index 0000000..90f46db
--- /dev/null
+++ b/src/libpfm4/lib/events/arm_qcom_krait_events.h
@@ -0,0 +1,66 @@
+/*
+ * Copyright (c) 2014 by Vince Weaver <vincent.weaver@maine.edu>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Qualcomm Krait Chips
+ * based on info in the thread on linux-kernel:
+ *   [PATCH 0/7] Support Krait CPU PMUs
+ */
+static const arm_entry_t arm_qcom_krait_pe[]={
+	{.name = "L1D_CACHE_REFILL",
+	 .modmsk = ARMV7_A15_ATTRS,
+	 .code = 0x03,
+	 .desc = "Level 1 data cache refill"
+	},
+	{.name = "L1D_CACHE_ACCESS",
+	 .modmsk = ARMV7_A15_ATTRS,
+	 .code = 0x04,
+	 .desc = "Level 1 data cache access"
+	},
+	{.name = "INSTR_EXECUTED",
+	 .modmsk = ARMV7_A15_ATTRS,
+	 .code = 0x08,
+	 .desc = "Instructions architecturally executed"
+	},
+	{.name = "PC_WRITE",
+	 .modmsk = ARMV7_A15_ATTRS,
+	 .code = 0x0c,
+	 .desc = "Software change of PC.  Equivalent to branches"
+	},
+	{.name = "PC_BRANCH_MIS_PRED",
+	 .modmsk = ARMV7_A15_ATTRS,
+	 .code = 0x10,
+	 .desc = "Branches mispredicted or not predicted"
+	},
+	{.name = "CLOCK_CYCLES",
+	 .modmsk = ARMV7_A15_ATTRS,
+	 .code = 0x11,
+	 .desc = "Cycles"
+	},
+	{.name = "BRANCH_PRED",
+	 .modmsk = ARMV7_A15_ATTRS,
+	 .code = 0x12,
+	 .desc = "Predictable branch speculatively executed"
+	},
+	{.name = "CPU_CYCLES",
+	 .modmsk = ARMV7_A15_ATTRS,
+	 .code = 0xff,
+	 .desc = "Cycles"
+	},
+};
diff --git a/src/libpfm4/lib/pfmlib_arm_armv7_pmuv1.c b/src/libpfm4/lib/pfmlib_arm_armv7_pmuv1.c
index 943101a..5fb14ca 100644
--- a/src/libpfm4/lib/pfmlib_arm_armv7_pmuv1.c
+++ b/src/libpfm4/lib/pfmlib_arm_armv7_pmuv1.c
@@ -36,6 +36,7 @@
 #include "events/arm_cortex_a8_events.h"        /* event tables */
 #include "events/arm_cortex_a9_events.h"
 #include "events/arm_cortex_a15_events.h"
+#include "events/arm_qcom_krait_events.h"
 
 static int
 pfm_arm_detect_cortex_a8(void *this)
@@ -88,6 +89,29 @@ pfm_arm_detect_cortex_a15(void *this)
 	return PFM_ERR_NOTSUPP;
 }
 
+static int
+pfm_arm_detect_krait(void *this)
+{
+
+	int ret;
+
+	ret = pfm_arm_detect(this);
+	if (ret != PFM_SUCCESS)
+		return PFM_ERR_NOTSUPP;
+
+	/* Check for Qualcomm */
+	if (pfm_arm_cfg.implementer == 0x51) {
+		/* Check that [15:10] of midr is 0x01 which	*/
+		/* indicates Krait rather than Scorpion	CPU	*/
+		/* pfm_arm_cfg.part is (midr>>4)&0xfff		*/
+		if (pfm_arm_cfg.part >> 6 == 0x1) {
+			return PFM_SUCCESS;
+		}
+	}
+	return PFM_ERR_NOTSUPP;
+}
+
+
 /* Cortex A8 support */
 pfmlib_pmu_t arm_cortex_a8_support={
 	.desc			= "ARM Cortex A8",
@@ -163,3 +187,29 @@ pfmlib_pmu_t arm_cortex_a15_support={
 	 PFMLIB_VALID_PERF_PATTRS(pfm_arm_perf_validate_pattrs),
 	.get_event_nattrs	= pfm_arm_get_event_nattrs,
 };
+
+/* Qualcomm Krait support */
+pfmlib_pmu_t arm_qcom_krait_support={
+	.desc			= "ARM Qualcomm Krait",
+	.name			= "qcom_krait",
+	.pmu			= PFM_PMU_ARM_QCOM_KRAIT,
+	.pme_count		= LIBPFM_ARRAY_SIZE(arm_qcom_krait_pe),
+	.type			= PFM_PMU_TYPE_CORE,
+	.pe			= arm_qcom_krait_pe,
+
+	.pmu_detect		= pfm_arm_detect_krait,
+	.max_encoding		= 1,
+	.num_cntrs		= 5,
+	.supported_plm		= ARMV7_A15_PLM,
+
+	.get_event_encoding[PFM_OS_NONE] = pfm_arm_get_encoding,
+	 PFMLIB_ENCODE_PERF(pfm_arm_get_perf_encoding),
+	.get_event_first	= pfm_arm_get_event_first,
+	.get_event_next		= pfm_arm_get_event_next,
+	.event_is_valid		= pfm_arm_event_is_valid,
+	.validate_table		= pfm_arm_validate_table,
+	.get_event_info		= pfm_arm_get_event_info,
+	.get_event_attr_info	= pfm_arm_get_event_attr_info,
+	 PFMLIB_VALID_PERF_PATTRS(pfm_arm_perf_validate_pattrs),
+	.get_event_nattrs	= pfm_arm_get_event_nattrs,
+};
diff --git a/src/libpfm4/lib/pfmlib_common.c b/src/libpfm4/lib/pfmlib_common.c
index ea05e37..861f475 100644
--- a/src/libpfm4/lib/pfmlib_common.c
+++ b/src/libpfm4/lib/pfmlib_common.c
@@ -163,6 +163,7 @@ static pfmlib_pmu_t *pfmlib_pmus[]=
 	&arm_cortex_a9_support,
 	&arm_cortex_a15_support,
 	&arm_1176_support,
+	&arm_qcom_krait_support,
 #endif
 #ifdef CONFIG_PFMLIB_ARCH_S390X
 	&s390x_cpum_cf_support,
diff --git a/src/libpfm4/lib/pfmlib_priv.h b/src/libpfm4/lib/pfmlib_priv.h
index f44ffe5..287222d 100644
--- a/src/libpfm4/lib/pfmlib_priv.h
+++ b/src/libpfm4/lib/pfmlib_priv.h
@@ -291,6 +291,7 @@ extern pfmlib_pmu_t arm_cortex_a8_support;
 extern pfmlib_pmu_t arm_cortex_a9_support;
 extern pfmlib_pmu_t arm_cortex_a15_support;
 extern pfmlib_pmu_t arm_1176_support;
+extern pfmlib_pmu_t arm_qcom_krait_support;
 extern pfmlib_pmu_t mips_74k_support;
 extern pfmlib_pmu_t s390x_cpum_cf_support;
 
diff --git a/src/libpfm4/tests/validate_arm.c b/src/libpfm4/tests/validate_arm.c
index 3fd9671..fe97aa9 100644
--- a/src/libpfm4/tests/validate_arm.c
+++ b/src/libpfm4/tests/validate_arm.c
@@ -138,6 +138,27 @@ static const test_event_t arm_test_events[]={
 	  .codes[0] = 0x07,
 	  .fstr = "arm_1176::INSTR_EXEC",
 	},
+	{ SRC_LINE,
+	  .name = "qcom_krait::CPU_CYCLES",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x80000ff,
+	  .fstr = "qcom_krait::CPU_CYCLES:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "qcom_krait::CPU_CYCLES:k:u",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x80000ff,
+	  .fstr = "qcom_krait::CPU_CYCLES:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "qcom_krait::CPU_CYCLES:u",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x480000ff,
+	  .fstr = "qcom_krait::CPU_CYCLES:k=0:u=1:hv=0",
+	},
 };
 #define NUM_TEST_EVENTS (int)(sizeof(arm_test_events)/sizeof(test_event_t))
 
-- 
2.1.0

From 7e8c2691210f8efcd9d3f0f4829c63844fb82492 Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Fri, 21 Feb 2014 11:49:35 -0500
Subject: [PATCH 12/24] Update libpfm4 to release version 4.5

---
commit 0f81ba644fea868ed2c224091a296a38e10f348d
Author: Stephane Eranian <eranian@gmail.com>
Date:   Fri Feb 21 14:14:15 2014 +0100

    update library to 4.5.0

    Signed-off-by: Stephane Eranian <eranian@gmail.com>
---

diff --git a/src/libpfm4/config.mk b/src/libpfm4/config.mk
index 6c010c0..457d943 100644
--- a/src/libpfm4/config.mk
+++ b/src/libpfm4/config.mk
@@ -45,6 +45,9 @@ endif
 ifeq (i86pc,$(findstring i86pc,$(ARCH)))
 override ARCH=i386
 endif
+ifeq (x86,$(findstring x86,$(ARCH)))
+override ARCH=x86_64
+endif
 ifeq ($(ARCH),x86_64)
 override ARCH=x86_64
 endif
diff --git a/src/libpfm4/debian/changelog b/src/libpfm4/debian/changelog
index 1177830..ec0f7eb 100644
--- a/src/libpfm4/debian/changelog
+++ b/src/libpfm4/debian/changelog
@@ -1,3 +1,16 @@
+libpfm4 (5.0) unstable; urgency=low
+  * Intel IVB-EP uncore PMU support
+  * Intel Silvermont support
+  * Perf raw event syntax support
+  * Intel RAPL event support
+  * AMD Fam15h northbridge support
+  * Qualcomm Krait support
+  * IBM Power 8 support
+  * IBM s390 updates
+  * AMD Fam15h fixes
+  * various IVB, SNB, HSW event table updates
+  * more bug fixes
+
 libpfm4 (4.0) unstable; urgency=low
   * Intel IVB-EP support
   * Intel IVB updates support
diff --git a/src/libpfm4/docs/Makefile b/src/libpfm4/docs/Makefile
index 45180d5..ecf6769 100644
--- a/src/libpfm4/docs/Makefile
+++ b/src/libpfm4/docs/Makefile
@@ -28,6 +28,7 @@ include $(TOPDIR)/rules.mk
 .PHONY: all clean distclean depend
 
 ARCH_MAN=
+SYS_MAN=
 
 ifeq ($(CONFIG_PFMLIB_ARCH_X86),y)
 ARCH_MAN=libpfm_intel_core.3	\
@@ -57,6 +58,15 @@ ARCH_MAN=libpfm_intel_core.3	\
 	 libpfm_intel_snbep_unc_ubo.3 \
 	 libpfm_intel_snbep_unc_r2pcie.3 \
 	 libpfm_intel_snbep_unc_r3qpi.3 \
+	 libpfm_intel_ivbep_unc_cbo.3 \
+	 libpfm_intel_ivbep_unc_ha.3 \
+	 libpfm_intel_ivbep_unc_imc.3 \
+	 libpfm_intel_ivbep_unc_pcu.3 \
+	 libpfm_intel_ivbep_unc_qpi.3 \
+	 libpfm_intel_ivbep_unc_ubo.3 \
+	 libpfm_intel_ivbep_unc_r2pcie.3 \
+	 libpfm_intel_ivbep_unc_r3qpi.3 \
+	 libpfm_intel_ivbep_unc_irp.3 \
 	 libpfm_intel_knc.3
 
 ifeq ($(CONFIG_PFMLIB_ARCH_I386),y)
@@ -69,7 +79,6 @@ ifeq ($(CONFIG_PFMLIB_ARCH_ARM),y)
 ARCH_MAN += libpfm_arm_ac15.3 libpfm_arm_ac8.3 libpfm_arm_ac9.3 libpfm_arm_qcom_krait.3
 endif
 
-
 ifeq ($(CONFIG_PFMLIB_ARCH_MIPS),y)
 ARCH_MAN += libpfm_mips_74k.3
 endif
@@ -81,14 +90,17 @@ GEN_MAN= libpfm.3 \
 	pfm_get_event_encoding.3 \
 	pfm_get_event_next.3 \
 	pfm_get_pmu_info.3 \
-	pfm_get_perf_event_encoding.3 \
 	pfm_get_os_event_encoding.3 \
 	pfm_get_version.3 \
 	pfm_initialize.3 \
 	pfm_terminate.3 \
 	pfm_strerror.3
 
-MAN=$(GEN_MAN) $(ARCH_MAN)
+ifeq ($(SYS),Linux)
+SYS_MAN=pfm_get_perf_event_encoding.3 libpfm_perf_event_raw.3
+endif
+
+MAN=$(GEN_MAN) $(ARCH_MAN) $(SYS_MAN)
 
 install:
 
diff --git a/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_cbo.3 b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_cbo.3
new file mode 100644
index 0000000..e417a46
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_cbo.3
@@ -0,0 +1,68 @@
+.TH LIBPFM 3  "February, 2014" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_intel_ivbep_unc_cbo - support for Intel Ivy Bridge-EP C-Box uncore PMU
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: ivbep_unc_cbo[0-7]
+.B PMU desc: Intel Ivy Bridge-EP C-Box uncore PMU
+.sp
+.SH DESCRIPTION
+The library supports the Intel Ivy Bridge C-Box (coherency engine) uncore PMU.
+This PMU model only exists on Ivy Bridge model 45. There is one C-box
+PMU per physical core. Therefore there are up to fifteen identical C-Box PMU instances
+numbered from 0 to 14. On dual-socket systems, the number refers to the C-Box
+PMU on the socket where the program runs. For instance, if running on CPU15, then
+ivbep_unc_cbo0 refers to the C-Box for physical core 0 on socket 1. Conversely,
+if running on CPU0, then the same ivbep_unc_cbo0 refers to the C-Box for physical
+core 0 but on socket 0.
+
+Each C-Box PMU implements 4 generic counters and two filter registers used only
+with certain events and umasks.
+
+.SH MODIFIERS
+The following modifiers are supported on Intel Ivy Bridge C-Box uncore PMU:
+.TP
+.B e
+Enable edge detection, i.e., count only when there is a state transition from no occurrence of the event to at least one occurrence. This modifier must be combined with a threshold modifier (t) with a value greater or equal to one.  This is a boolean modifier.
+.TP
+.B t
+Set the threshold value. When set to a non-zero value, the counter counts the number
+of C-Box cycles in which the number of occurrences of the event is greater or equal to
+the threshold.  This is an integer modifier with values in the range [0:255].
+.TP
+.B nf
+Node filter. Certain events, such as UNC_C_LLC_LOOKUP, UNC_C_LLC_VICTIMS, provide a \fBNID\fR umask.
+Sometimes the \fBNID\fR is combined with other filtering capabilities, such as opcodes.
+The node filter is an 8-bit max bitmask. A node corresponds to a processor
+socket. The legal values therefore depdend on the underlying hardware configuration. For
+dual-socket systems, the bitmask has two valid bits [0:1].
+.TP
+.B cf
+Core Filter. This is a 3-bit filter which is used to filter based on phyiscal core origin
+of the C-Box request. Possible values are 0-7. If the filter is not specified, then no
+filtering takes place.
+.TP
+.B tf
+Thread Filter. This is a 1-bit filter which is used to filter C-Box requests based on logical
+processor (hyper-thread) identification. Possibles values are 0-1. If the filter is not
+specified, then no filtering takes place.
+
+.SH Opcode filtering
+
+Certain events, such as UNC_C_TOR_INSERTS supports opcode matching on the C-BOX transaction
+type. To use this feature, first an opcode matching umask must be selected, e.g., MISS_OPCODE.
+Second, the opcode to match on must be selected via a second umasks amongs the OPC_* umasks.
+For instance, UNC_C_TOR_INSERTS:OPCODE:OPC_RFO, counts the number of TOR insertions for RFO
+transactions. 
+
+Opcode matching may be combined with node filtering with certain umasks. In general, the
+filtering support is encoded into the umask name, e.g., NID_OPCODE supports both
+node and opcode filtering. For instance, UNC_C_TOR_INSERTS:NID_OPCODE:OPC_RFO:nf=1.
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.PP
diff --git a/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_ha.3 b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_ha.3
new file mode 100644
index 0000000..0d4d4e2
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_ha.3
@@ -0,0 +1,30 @@
+.TH LIBPFM 3  "February, 2014" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_intel_ivbep_unc_ha - support for Intel Ivy Bridge-EP Home Agent (HA) uncore PMU
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: ivbep_unc_ha0, ivbep_unc_ha1
+.B PMU desc: Intel Ivy Bridge-EP HA uncore PMU
+.sp
+.SH DESCRIPTION
+The library supports the Intel Ivy Bridge Home Agent (HA) uncore PMU.
+This PMU model only exists on Ivy Bridge model 62.
+
+.SH MODIFIERS
+The following modifiers are supported on Intel Ivy Bridge HA uncore PMU:
+.TP
+.B e
+Enable edge detection, i.e., count only when there is a state transition from no occurrence of the event to at least one occurrence. This modifier must be combined with a threshold modifier (t) with a value greater or equal to one.  This is a boolean modifier.
+.TP
+.B t
+Set the threshold value. When set to a non-zero value, the counter counts the number
+of HA cycles in which the number of occurrences of the event is greater or equal to
+the threshold.  This is an integer modifier with values in the range [0:255].
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.PP
diff --git a/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_imc.3 b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_imc.3
new file mode 100644
index 0000000..0050bcb
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_imc.3
@@ -0,0 +1,30 @@
+.TH LIBPFM 3  "February, 2014" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_intel_ivbep_unc_imc - support for Intel Ivy Bridge-EP Integrated Memory Controller (IMC)  uncore PMU
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: ivbep_unc_imc[0-7]
+.B PMU desc: Intel Ivy Bridge-EP IMC uncore PMU
+.sp
+.SH DESCRIPTION
+The library supports the Intel Ivy Bridge Integrated Memory Controller (IMC) uncore PMU.
+This PMU model only exists on Ivy Bridge model 62.
+
+.SH MODIFIERS
+The following modifiers are supported on Intel Ivy Bridge C-Box uncore PMU:
+.TP
+.B e
+Enable edge detection, i.e., count only when there is a state transition from no occurrence of the event to at least one occurrence. This modifier must be combined with a threshold modifier (t) with a value greater or equal to one.  This is a boolean modifier.
+.TP
+.B t
+Set the threshold value. When set to a non-zero value, the counter counts the number
+of IMC cycles in which the number of occurrences of the event is greater or equal to
+the threshold.  This is an integer modifier with values in the range [0:255].
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.PP
diff --git a/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_irp.3 b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_irp.3
new file mode 100644
index 0000000..7f4f8b0
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_irp.3
@@ -0,0 +1,30 @@
+.TH LIBPFM 3  "February, 2014" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_intel_ivbep_unc_irp - support for Intel Ivy Bridge-EP IRP uncore PMU
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: ivbep_unc_irp
+.B PMU desc: Intel Ivy Bridge-EP IRP uncore PMU
+.sp
+.SH DESCRIPTION
+The library supports the Intel Ivy Bridge uncore PMU.
+This PMU model only exists on Ivy Bridge model 62.
+
+.SH MODIFIERS
+The following modifiers are supported on Intel Ivy Bridge IRP uncore PMU:
+.TP
+.B e
+Enable edge detection, i.e., count only when there is a state transition from no occurrence of the event to at least one occurrence. This modifier must be combined with a threshold modifier (t) with a value greater or equal to one.  This is a boolean modifier.
+.TP
+.B t
+Set the threshold value. When set to a non-zero value, the counter counts the number
+of cycles in which the number of occurrences of the event is greater or equal to
+the threshold.  This is an integer modifier with values in the range [0:255].
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.PP
diff --git a/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_pcu.3 b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_pcu.3
new file mode 100644
index 0000000..65ec6a3
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_pcu.3
@@ -0,0 +1,44 @@
+.TH LIBPFM 3  "February, 2014" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_intel_ivbep_unc_pcu - support for Intel Ivy Bridge-EP Power Controller Unit (PCU) uncore PMU
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: ivbep_unc_pcu
+.B PMU desc: Intel Ivy Bridge-EP PCU uncore PMU
+.sp
+.SH DESCRIPTION
+The library supports the Intel Ivy Bridge Power Controller Unit uncore PMU.
+This PMU model only exists on Ivy Bridge model 62.
+
+.SH MODIFIERS
+The following modifiers are supported on Intel Ivy Bridge C-Box uncore PMU:
+.TP
+.B e
+Enable edge detection, i.e., count only when there is a state transition from no occurrence of the event to at least one occurrence. This modifier must be combined with a threshold modifier (t) with a value greater or equal to one.  This is a boolean modifier.
+.TP
+.B t
+Set the threshold value. When set to a non-zero value, the counter counts the number
+of HA cycles in which the number of occurrences of the event is greater or equal to
+the threshold.  This is an integer modifier with values in the range [0:15].
+.TP
+.B ff
+Enable frequency band filtering. This modifier applies only to the UNC_P_FREQ_BANDx_CYCLES events, where x is [0-3].
+The modifiers expects an integer in the range [0-255]. The value is interpreted as a frequency value to be
+multipled by 100Mhz. Thus if the value is 32, then all cycles where the processor is running at 3.2GHz and more are
+counted.
+
+.SH Frequency band filtering
+
+There are 3 events which support frequency band filtering, namely, UNC_P_FREQ_BAND0_CYCLES, UNC_P_FREQ_BAND1_CYCLES,
+UNC_P_FREQ_BAND2_CYCLES, UNC_P_FREQ_BAND3_CYCLES. The frequency filter (available via the ff modifier) is stored into
+a PMU shared register which hold all 4 possible frequency bands, one per event. However, the library generate the
+encoding for each event individually because it processes events one at a time. The caller or the underlying kernel
+interface may have to merge the band filter settings to program the filter register properly.
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.PP
diff --git a/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_qpi.3 b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_qpi.3
new file mode 100644
index 0000000..2b33f47
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_qpi.3
@@ -0,0 +1,30 @@
+.TH LIBPFM 3  "February, 2014" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_intel_ivbep_unc_qpi - support for Intel Ivy Bridge-EP QPI uncore PMU
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: ivbep_unc_qpi0, ivbep_unc_qpi1
+.B PMU desc: Intel Ivy Bridge-EP QPI uncore PMU
+.sp
+.SH DESCRIPTION
+The library supports the Intel Ivy Bridge Power QPI uncore PMU.
+This PMU model only exists on Ivy Bridge model 62.
+
+.SH MODIFIERS
+The following modifiers are supported on Intel Ivy Bridge QPI uncore PMU:
+.TP
+.B e
+Enable edge detection, i.e., count only when there is a state transition from no occurrence of the event to at least one occurrence. This modifier must be combined with a threshold modifier (t) with a value greater or equal to one.  This is a boolean modifier.
+.TP
+.B t
+Set the threshold value. When set to a non-zero value, the counter counts the number
+of QPI cycles in which the number of occurrences of the event is greater or equal to
+the threshold.  This is an integer modifier with values in the range [0:255].
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.PP
diff --git a/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_r2pcie.3 b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_r2pcie.3
new file mode 100644
index 0000000..196e46e
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_r2pcie.3
@@ -0,0 +1,30 @@
+.TH LIBPFM 3  "February, 2014" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_intel_ivbep_unc_r2pcie - support for Intel Ivy Bridge-EP R2 PCIe  uncore PMU
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: ivbep_unc_r2pcie
+.B PMU desc: Intel Ivy Bridge-EP R2 PCIe  uncore PMU
+.sp
+.SH DESCRIPTION
+The library supports the Intel Ivy Bridge R2 PCIe uncore PMU.
+This PMU model only exists on Ivy Bridge model 62.
+
+.SH MODIFIERS
+The following modifiers are supported on Intel Ivy Bridge R2PCIe uncore PMU:
+.TP
+.B e
+Enable edge detection, i.e., count only when there is a state transition from no occurrence of the event to at least one occurrence. This modifier must be combined with a threshold modifier (t) with a value greater or equal to one.  This is a boolean modifier.
+.TP
+.B t
+Set the threshold value. When set to a non-zero value, the counter counts the number
+of R2PCIe cycles in which the number of occurrences of the event is greater or equal to
+the threshold.  This is an integer modifier with values in the range [0:15].
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.PP
diff --git a/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_r3qpi.3 b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_r3qpi.3
new file mode 100644
index 0000000..1f7f48b
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_r3qpi.3
@@ -0,0 +1,30 @@
+.TH LIBPFM 3  "February, 2014" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_intel_ivbep_unc_r3qpi - support for Intel Ivy Bridge-EP R3QPI uncore PMU
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: ivbep_unc_r3qpi0, ivbep_unc_r3qpi1, ivbep_unc_r3qpi2
+.B PMU desc: Intel Ivy Bridge-EP R3QPI uncore PMU
+.sp
+.SH DESCRIPTION
+The library supports the Intel Ivy Bridge R3QPI uncore PMU.
+This PMU model only exists on Ivy Bridge model 62.
+
+.SH MODIFIERS
+The following modifiers are supported on Intel Ivy Bridge R3PQI  uncore PMU:
+.TP
+.B e
+Enable edge detection, i.e., count only when there is a state transition from no occurrence of the event to at least one occurrence. This modifier must be combined with a threshold modifier (t) with a value greater or equal to one.  This is a boolean modifier.
+.TP
+.B t
+Set the threshold value. When set to a non-zero value, the counter counts the number
+of R3QPI cycles in which the number of occurrences of the event is greater or equal to
+the threshold.  This is an integer modifier with values in the range [0:15].
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.PP
diff --git a/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_ubo.3 b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_ubo.3
new file mode 100644
index 0000000..2c4a6c1
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_ubo.3
@@ -0,0 +1,54 @@
+.TH LIBPFM 3  "February, 2014" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_intel_ivbep_unc_ubo - support for Intel Ivy Bridge-EP U-Box uncore PMU
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: ivbep_unc_ubo
+.B PMU desc: Intel Ivy Bridge-EP U-Box uncore PMU
+.sp
+.SH DESCRIPTION
+The library supports the Intel Ivy Bridge system configuration unit (U-Box) uncore PMU.
+This PMU model only exists on Ivy Bridge model 62.
+
+.SH MODIFIERS
+The following modifiers are supported on Intel Ivy Bridge U-Box uncore PMU:
+.TP
+.B e
+Enable edge detection, i.e., count only when there is a state transition from no occurrence of the event to at least one occurrence. This modifier must be combined with a threshold modifier (t) with a value greater or equal to one.  This is a boolean modifier.
+.TP
+.B t
+Set the threshold value. When set to a non-zero value, the counter counts the number
+of HA cycles in which the number of occurrences of the event is greater or equal to
+the threshold.  This is an integer modifier with values in the range [0:15].
+.TP
+.B oi
+Invert the meaning of the occupancy event POWER_STATE_OCCUPANCY. The counter will now count PCU cycles in which the
+event is \fBnot\fR occurring. This is a boolean modifier
+.TP
+.B oe
+Enable edge detection for the occupancy event POWER_STATE_OCCUPANCY. The event now counts only when there is a state
+transition from no occurrence of the event to at least one occurrence. This modifier must be combined with a threshold
+modifier (t) with a value greater or equal to one.  This is a boolean modifier.
+
+.TP
+.B ff
+Enable frequency band filtering. This modifier applies only to the UNC_P_FREQ_BANDx_CYCLES events, where x is [0-3].
+The modifiers expects an integer in the range [0-255]. The value is interpreted as a frequency value to be
+multipled by 100Mhz. Thus if the value is 32, then all cycles where the processor is running at 3.2GHz and more are
+counted.
+
+.SH Frequency band filtering
+
+There are 3 events which support frequency band filtering, namely, UNC_P_FREQ_BAND0_CYCLES, UNC_P_FREQ_BAND1_CYCLES,
+UNC_P_FREQ_BAND2_CYCLES, UNC_P_FREQ_BAND3_CYCLES. The frequency filter (available via the ff modifier) is stored into
+a PMU shared register which hold all 4 possible frequency bands, one per event. However, the library generate the
+encoding for each event individually because it processes events one at a time. The caller or the underlying kernel
+interface may have to merge the band filter settings to program the filter register properly.
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.PP
diff --git a/src/libpfm4/docs/man3/libpfm_perf_event_raw.3 b/src/libpfm4/docs/man3/libpfm_perf_event_raw.3
new file mode 100644
index 0000000..2f8b535
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_perf_event_raw.3
@@ -0,0 +1,76 @@
+.TH LIBPFM 3  "February, 2014" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_perf_event_raw - support for perf_events raw events syntax
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: perf_raw
+.B PMU desc: Raw perf_events event syntax
+.sp
+.SH DESCRIPTION
+The library supports a pseudo PMU model to allow raw encodings of PMU events
+for the Linux perf_events kernel interface.
+
+With this PMU, it is possible to provide the raw hexadecimal encoding of any
+hardware event for any PMU models. The raw encoding is passed as is to the
+kernel. All events are encoded as \fBPERF_TYPE_RAW\fR. As such, perf_events
+generic events, such as cycles, instructions, cannot be encoded by this
+PMU.
+
+The syntax is very simple: rX. X is the hexadecimal 64-bit value for the event.
+It may include event filters on some PMU models. The hexadecimal number is passed
+without the 0x prefix, e.g., r01c4.
+
+The library's standard perf_events attributes are supported oby this PMU model.
+They are separated with colons as is customary with the library.
+
+.SH MODIFIERS
+The following modifiers are supported by this PMU model:
+.TP
+.B u
+Measure at user level which includes privilege levels 1, 2, 3. This corresponds to \fBPFM_PLM3\fR.
+This is a boolean modifier.
+.TP
+.B k
+Measure at kernel level which includes privilege level 0. This corresponds to \fBPFM_PLM0\fR.
+This is a boolean modifier.
+.TP
+.B h
+Measure at the hypervisor level. This corresponds to \fBPFM_PLMH\fR.
+This is a boolean modifier
+.TP
+.B mg 
+Measure guest execution only. This is a boolean modifier
+.TP
+.B mh
+Measure host execution only. This is a boolean modifier
+.TP
+.B period
+Specify the the sampling period value. Value can be expressed in decimal or hexadecimal.
+Value is 64-bit wide. This option is mutually exclusive with
+\fBfreq\fR. The period is expressed in the unit of the event. There is no default value.
+.TP
+.B freq
+Specify the the sampling frequency value. Value can be expressed in decimal or hexadecimal.
+Value is 64-bit wide. This options is mutually exclusive with
+\fBperiod\fR. The value is expressed in Hertz. For instance, freq=100, means that the
+event should be sampled 100 times per second on average. There is no default value.
+.TP
+.B excl
+The associated event is the only event measured on the PMU. This applies only to hardware
+events. This atrtribute requires admin privileges. Default is off.
+.TP
+.B precise
+Enables precise sampling mode. This option is only valid on sampling events. This is an
+integer value. It can have the following values: 1 enable precise sampling, 2 enable precise
+sampling and eliminate skid. Not all events necessarily support precise mode, this is dependent
+on the underlying PMU. Eliminating skid is a best effort feature. It may not work for all
+samples.
+
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.PP
diff --git a/src/libpfm4/include/perfmon/pfmlib.h b/src/libpfm4/include/perfmon/pfmlib.h
index 5434a96..dfdd471 100644
--- a/src/libpfm4/include/perfmon/pfmlib.h
+++ b/src/libpfm4/include/perfmon/pfmlib.h
@@ -197,6 +197,45 @@ typedef enum {
 	PFM_PMU_AMD64_FAM15H_NB,	/* AMD AMD64 Fam15h NorthBridge */
 
 	PFM_PMU_ARM_QCOM_KRAIT,		/* Qualcomm Krait */
+	PFM_PMU_PERF_EVENT_RAW,		/* perf_events RAW event syntax */
+
+	PFM_PMU_INTEL_IVBEP_UNC_CB0,	/* Intel IvyBridge-EP C-Box core 0 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_CB1,	/* Intel IvyBridge-EP C-Box core 1 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_CB2,	/* Intel IvyBridge-EP C-Box core 2 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_CB3,	/* Intel IvyBridge-EP C-Box core 3 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_CB4,	/* Intel IvyBridge-EP C-Box core 4 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_CB5,	/* Intel IvyBridge-EP C-Box core 5 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_CB6,	/* Intel IvyBridge-EP C-Box core 6 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_CB7,	/* Intel IvyBridge-EP C-Box core 7 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_CB8,	/* Intel IvyBridge-EP C-Box core 8 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_CB9,	/* Intel IvyBridge-EP C-Box core 9 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_CB10,	/* Intel IvyBridge-EP C-Box core 10 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_CB11,	/* Intel IvyBridge-EP C-Box core 11 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_CB12,	/* Intel IvyBridge-EP C-Box core 12 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_CB13,	/* Intel IvyBridge-EP C-Box core 13 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_CB14,	/* Intel IvyBridge-EP C-Box core 14 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_HA0,	/* Intel IvyBridge-EP HA 0 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_HA1,	/* Intel IvyBridge-EP HA 1 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_IMC0,	/* Intel IvyBridge-EP IMC socket 0 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_IMC1,	/* Intel IvyBridge-EP IMC socket 1 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_IMC2,	/* Intel IvyBridge-EP IMC socket 2 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_IMC3,	/* Intel IvyBridge-EP IMC socket 3 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_IMC4,	/* Intel IvyBridge-EP IMC socket 4 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_IMC5,	/* Intel IvyBridge-EP IMC socket 5 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_IMC6,	/* Intel IvyBridge-EP IMC socket 6 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_IMC7,	/* Intel IvyBridge-EP IMC socket 7 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_PCU,	/* Intel IvyBridge-EP PCU uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_QPI0,	/* Intel IvyBridge-EP QPI link 0 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_QPI1,	/* Intel IvyBridge-EP QPI link 1 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_QPI2,	/* Intel IvyBridge-EP QPI link 2 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_UBOX,	/* Intel IvyBridge-EP U-Box uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_R2PCIE,	/* Intel IvyBridge-EP R2PCIe uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_R3QPI0,	/* Intel IvyBridge-EP R3QPI 0 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_R3QPI1,	/* Intel IvyBridge-EP R3QPI 1 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_R3QPI2,	/* Intel IvyBridge-EP R3QPI 2 uncore */
+	PFM_PMU_INTEL_IVBEP_UNC_IRP,	/* Intel IvyBridge-EP IRP uncore */
+
+	PFM_PMU_S390X_CPUM_SF,		/* s390x: CPU-M sampling facility */
 
 	/* MUST ADD NEW PMU MODELS HERE */
 
diff --git a/src/libpfm4/lib/Makefile b/src/libpfm4/lib/Makefile
index 02dcfbb..531167e 100644
--- a/src/libpfm4/lib/Makefile
+++ b/src/libpfm4/lib/Makefile
@@ -30,7 +30,7 @@ include $(TOPDIR)/rules.mk
 SRCS=pfmlib_common.c
 
 ifeq ($(SYS),Linux)
-SRCS += pfmlib_perf_event_pmu.c pfmlib_perf_event.c
+SRCS += pfmlib_perf_event_pmu.c pfmlib_perf_event.c pfmlib_perf_event_raw.c
 endif
 
 CFLAGS+=-D_REENTRANT -I.
@@ -70,6 +70,15 @@ SRCS   += pfmlib_amd64.c pfmlib_intel_core.c pfmlib_intel_x86.c \
 	  pfmlib_intel_snbep_unc_ubo.c \
 	  pfmlib_intel_snbep_unc_r2pcie.c \
 	  pfmlib_intel_snbep_unc_r3qpi.c \
+	  pfmlib_intel_ivbep_unc_cbo.c \
+	  pfmlib_intel_ivbep_unc_ha.c \
+	  pfmlib_intel_ivbep_unc_imc.c \
+	  pfmlib_intel_ivbep_unc_pcu.c \
+	  pfmlib_intel_ivbep_unc_qpi.c \
+	  pfmlib_intel_ivbep_unc_ubo.c \
+	  pfmlib_intel_ivbep_unc_r2pcie.c \
+	  pfmlib_intel_ivbep_unc_r3qpi.c \
+	  pfmlib_intel_ivbep_unc_irp.c \
 	  pfmlib_intel_knc.c \
 	  pfmlib_intel_slm.c \
 	  pfmlib_intel_netburst.c \
@@ -219,6 +228,15 @@ INC_X86= pfmlib_intel_x86_priv.h	\
 	events/intel_snbep_unc_r2pcie_events.h \
 	events/intel_snbep_unc_r3qpi_events.h \
 	events/intel_knc_events.h \
+	events/intel_ivbep_unc_cbo_events.h \
+	events/intel_ivbep_unc_ha_events.h \
+	events/intel_ivbep_unc_imc_events.h \
+	events/intel_ivbep_unc_pcu_events.h \
+	events/intel_ivbep_unc_qpi_events.h \
+	events/intel_ivbep_unc_ubo_events.h \
+	events/intel_ivbep_unc_r2pcie_events.h \
+	events/intel_ivbep_unc_r3qpi_events.h \
+	events/intel_ivbep_unc_irp_events.h \
 	events/intel_slm_events.h
 
 INC_MIPS=events/mips_74k_events.h events/mips_74k_events.h
diff --git a/src/libpfm4/lib/events/intel_ivbep_unc_cbo_events.h b/src/libpfm4/lib/events/intel_ivbep_unc_cbo_events.h
new file mode 100644
index 0000000..ee8959f
--- /dev/null
+++ b/src/libpfm4/lib/events/intel_ivbep_unc_cbo_events.h
@@ -0,0 +1,981 @@
+/*
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * This file is part of libpfm, a performance monitoring support library for
+ * applications on Linux.
+ *
+ * PMU: ivbep_unc_cbo (Intel IvyBridge-EP C-Box uncore PMU)
+ */
+
+#define CBO_FILT_MESIF(a, b, c, d) \
+   { .uname  = "STATE_"#a,\
+     .udesc  = #b" cacheline state",\
+     .ufilters[0] = 1ULL << (17 + (c)),\
+     .grpid = d, \
+   }
+
+#define CBO_FILT_MESIFS(d) \
+   CBO_FILT_MESIF(I, Invalid, 0, d), \
+   CBO_FILT_MESIF(S, Shared, 1, d), \
+   CBO_FILT_MESIF(E, Exclusive, 2, d), \
+   CBO_FILT_MESIF(M, Modified, 3, d), \
+   CBO_FILT_MESIF(F, Forward, 4, d), \
+   { .uname  = "STATE_MESIF",\
+     .udesc  = "Any cache line state",\
+     .ufilters[0] = 0x3fULL << 17,\
+     .grpid = d, \
+     .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL, \
+   }
+
+#define CBO_FILT_OPC(d) \
+   { .uname  = "OPC_RFO",\
+     .udesc  = "Demand data RFO (combine with any OPCODE umask)",\
+     .ufilters[1] = 0x180ULL << 20, \
+     .uflags = INTEL_X86_NCOMBO, \
+     .grpid = d, \
+   }, \
+   { .uname  = "OPC_CRD",\
+     .udesc  = "Demand code read (combine with any OPCODE umask)",\
+     .ufilters[1] = 0x181ULL << 20, \
+     .uflags = INTEL_X86_NCOMBO, \
+     .grpid = d, \
+   }, \
+   { .uname  = "OPC_DRD",\
+     .udesc  = "Demand data read (combine with any OPCODE umask)",\
+     .ufilters[1] = 0x182ULL << 20, \
+     .uflags = INTEL_X86_NCOMBO, \
+     .grpid = d, \
+   }, \
+   { .uname  = "OPC_PRD",\
+     .udesc  = "Partial reads (UC) (combine with any OPCODE umask)",\
+     .ufilters[1] = 0x187ULL << 20, \
+     .uflags = INTEL_X86_NCOMBO, \
+     .grpid = d, \
+   }, \
+   { .uname  = "OPC_WCILF",\
+     .udesc  = "Full Stream store (combine with any OPCODE umask)", \
+     .ufilters[1] = 0x18cULL << 20, \
+     .uflags = INTEL_X86_NCOMBO, \
+     .grpid = d, \
+   }, \
+   { .uname  = "OPC_WCIL",\
+     .udesc  = "Partial Stream store (combine with any OPCODE umask)", \
+     .ufilters[1] = 0x18dULL << 20, \
+     .uflags = INTEL_X86_NCOMBO, \
+     .grpid = d, \
+   }, \
+   { .uname  = "OPC_PF_RFO",\
+     .udesc  = "Prefetch RFO into LLC but do not pass to L2 (includes hints) (combine with any OPCODE umask)", \
+     .ufilters[1] = 0x190ULL << 20, \
+     .uflags = INTEL_X86_NCOMBO, \
+     .grpid = d, \
+   }, \
+   { .uname  = "OPC_PF_CODE",\
+     .udesc  = "Prefetch code into LLC but do not pass to L2 (includes hints) (combine with any OPCODE umask)", \
+     .ufilters[1] = 0x191ULL << 20, \
+     .uflags = INTEL_X86_NCOMBO, \
+     .grpid = d, \
+   }, \
+   { .uname  = "OPC_PF_DATA",\
+     .udesc  = "Prefetch data into LLC but do not pass to L2 (includes hints) (combine with any OPCODE umask)", \
+     .ufilters[1] = 0x192ULL << 20, \
+     .uflags = INTEL_X86_NCOMBO, \
+     .grpid = d, \
+   }, \
+   { .uname  = "OPC_PCIWILF",\
+     .udesc  = "PCIe write (non-allocating) (combine with any OPCODE umask)", \
+     .ufilters[1] = 0x194ULL << 20, \
+     .uflags = INTEL_X86_NCOMBO, \
+     .grpid = d, \
+   }, \
+   { .uname  = "OPC_PCIPRD",\
+     .udesc  = "PCIe UC read (combine with any OPCODE umask)", \
+     .ufilters[1] = 0x195ULL << 20, \
+     .uflags = INTEL_X86_NCOMBO, \
+     .grpid = d, \
+   }, \
+   { .uname  = "OPC_PCIITOM",\
+     .udesc  = "PCIe write (allocating) (combine with any OPCODE umask)", \
+     .ufilters[1] = 0x19cULL << 20, \
+     .uflags = INTEL_X86_NCOMBO, \
+     .grpid = d, \
+   }, \
+   { .uname  = "OPC_PCIRDCUR",\
+     .udesc  = "PCIe read current (combine with any OPCODE umask)", \
+     .ufilters[1] = 0x19eULL << 20, \
+     .uflags = INTEL_X86_NCOMBO, \
+     .grpid = d, \
+   }, \
+   { .uname  = "OPC_WBMTOI",\
+     .udesc  = "Request writeback modified invalidate line (combine with any OPCODE umask)", \
+     .ufilters[1] = 0x1c4ULL << 20, \
+     .uflags = INTEL_X86_NCOMBO, \
+     .grpid = d, \
+   }, \
+   { .uname  = "OPC_WBMTOE",\
+     .udesc  = "Request writeback modified set to exclusive (combine with any OPCODE umask)", \
+     .ufilters[1] = 0x1c5ULL << 20, \
+     .uflags = INTEL_X86_NCOMBO, \
+     .grpid = d, \
+   }, \
+   { .uname  = "OPC_ITOM",\
+     .udesc  = "Request invalidate line (combine with any OPCODE umask)", \
+     .ufilters[1] = 0x1c8ULL << 20, \
+     .uflags = INTEL_X86_NCOMBO, \
+     .grpid = d, \
+   }, \
+   { .uname  = "OPC_PCINSRD",\
+     .udesc  = "PCIe non-snoop read (combine with any OPCODE umask)", \
+     .ufilters[1] = 0x1e4ULL << 20, \
+     .uflags = INTEL_X86_NCOMBO, \
+     .grpid = d, \
+   }, \
+   { .uname  = "OPC_PCINSWR",\
+     .udesc  = "PCIe non-snoop write (partial) (combine with any OPCODE umask)", \
+     .ufilters[1] = 0x1e5ULL << 20, \
+     .uflags = INTEL_X86_NCOMBO, \
+     .grpid = d, \
+   }, \
+   { .uname  = "OPC_PCINSWRF",\
+     .udesc  = "PCIe non-snoop write (full) (combine with any OPCODE umask)", \
+     .ufilters[1] = 0x1e6ULL << 20, \
+     .uflags = INTEL_X86_NCOMBO, \
+     .grpid = d, \
+   }
+
+static const intel_x86_umask_t ivbep_unc_c_llc_lookup[]={
+   { .uname  = "DATA_READ",
+     .udesc  = "Data read requests",
+     .grpid  = 0,
+     .ucode = 0x300,
+     .uflags = INTEL_X86_NCOMBO,
+   },
+   { .uname  = "WRITE",
+     .udesc  = "Write requests. Includes all write transactions (cached, uncached)",
+     .grpid  = 0,
+     .ucode = 0x500,
+     .uflags = INTEL_X86_NCOMBO,
+   },
+   { .uname  = "REMOTE_SNOOP",
+     .udesc  = "External snoop request",
+     .grpid  = 0,
+     .ucode = 0x900,
+     .uflags = INTEL_X86_NCOMBO,
+   },
+   { .uname  = "ANY",
+     .udesc  = "Any request",
+     .grpid  = 0,
+     .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+     .ucode = 0x1100,
+   },
+   { .uname  = "NID",
+     .udesc  = "Match a given RTID destination NID",
+     .umodmsk_req = _SNBEP_UNC_ATTR_NF1,
+     .grpid  = 1,
+     .ucode = 0x4100,
+     .uflags = INTEL_X86_GRP_DFL_NONE
+   },
+   CBO_FILT_MESIFS(2),
+};
+
+static const intel_x86_umask_t ivbep_unc_c_llc_victims[]={
+   { .uname  = "STATE_M",
+     .udesc  = "Lines in M state",
+     .ucode = 0x100,
+     .grpid  = 0,
+   },
+   { .uname  = "STATE_E",
+     .udesc  = "Lines in E state",
+     .ucode = 0x200,
+     .grpid  = 0,
+   },
+   { .uname  = "STATE_S",
+     .udesc  = "Lines in S state",
+     .ucode = 0x400,
+     .grpid  = 0,
+   },
+   { .uname  = "MISS",
+     .udesc  = "TBD",
+     .ucode = 0x800,
+     .grpid  = 0,
+   },
+   { .uname  = "NID",
+     .udesc  = "Victimized Lines matching the NID filter",
+     .ucode = 0x4000,
+     .uflags = INTEL_X86_GRP_DFL_NONE,
+     .umodmsk_req = _SNBEP_UNC_ATTR_NF1,
+     .grpid  = 1,
+   },
+};
+
+static const intel_x86_umask_t ivbep_unc_c_ring_ad_used[]={
+   { .uname  = "UP_VR0_EVEN",
+     .udesc  = "Up and Even ring polarity filter on virutal ring 0",
+     .ucode = 0x100,
+   },
+   { .uname  = "UP_VR0_ODD",
+     .udesc  = "Up and odd ring polarity filter on virtual ring 0",
+     .ucode = 0x200,
+   },
+   { .uname  = "DOWN_VR0_EVEN",
+     .udesc  = "Down and even ring polarity filter on virtual ring 0",
+     .ucode = 0x400,
+   },
+   { .uname  = "DOWN_VR0_ODD",
+     .udesc  = "Down and odd ring polarity filter on virtual ring 0",
+     .ucode = 0x800,
+   },
+   { .uname  = "UP_VR1_EVEN",
+     .udesc  = "Up and Even ring polarity filter on virutal ring 1",
+     .ucode = 0x1000,
+   },
+   { .uname  = "UP_VR1_ODD",
+     .udesc  = "Up and odd ring polarity filter on virtual ring 1",
+     .ucode = 0x2000,
+   },
+   { .uname  = "DOWN_VR1_EVEN",
+     .udesc  = "Down and even ring polarity filter on virtual ring 1",
+     .ucode = 0x4000,
+   },
+   { .uname  = "DOWN_VR1_ODD",
+     .udesc  = "Down and odd ring polarity filter on virtual ring 1",
+     .ucode = 0x8000,
+   },
+   { .uname  = "UP",
+     .udesc  = "Up on any virtual ring",
+     .ucode = 0x3300,
+   },
+   { .uname  = "DOWN",
+     .udesc  = "Down any virtual ring",
+     .ucode = 0xcc00,
+   },
+};
+
+static const intel_x86_umask_t ivbep_unc_c_ring_bounces[]={
+   { .uname  = "AD_IRQ",
+     .udesc  = "TBD",
+     .ucode = 0x200,
+   },
+   { .uname  = "AK",
+     .udesc  = "Acknowledgments to core",
+     .ucode = 0x400,
+   },
+
+   { .uname  = "BL",
+     .udesc  = "Data responses to core",
+     .ucode = 0x800,
+   },
+   { .uname  = "IV",
+     .udesc  = "Snoops of processor cache",
+     .ucode = 0x1000,
+   },
+};
+
+static const intel_x86_umask_t ivbep_unc_c_ring_iv_used[]={
+   { .uname  = "ANY",
+     .udesc  = "Any filter",
+     .ucode = 0xf00,
+     .uflags = INTEL_X86_DFL,
+   },
+   { .uname  = "UP",
+     .udesc  = "Filter on any up polarity",
+     .ucode = 0x3300,
+   },
+   { .uname  = "DOWN",
+     .udesc  = "Filter on any down polarity",
+     .ucode = 0xcc00,
+   },
+};
+
+static const intel_x86_umask_t ivbep_unc_c_rxr_ext_starved[]={
+   { .uname  = "IRQ",
+     .udesc  = "Irq externally starved, therefore blocking the IPQ",
+     .ucode = 0x100,
+   },
+   { .uname  = "IPQ",
+     .udesc  = "IPQ externally starved, therefore blocking the IRQ",
+     .ucode = 0x200,
+   },
+   { .uname  = "PRQ",
+     .udesc  = "IRQ is blocking the ingress queue and causing starvation",
+     .ucode = 0x400,
+   },
+   { .uname  = "ISMQ_BIDS",
+     .udesc  = "Number of time the ISMQ bids",
+     .ucode = 0x800,
+   },
+};
+
+static const intel_x86_umask_t ivbep_unc_c_rxr_inserts[]={
+  { .uname = "IPQ",
+    .udesc  = "IPQ",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "IRQ",
+    .udesc  = "IRQ",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "IRQ_REJECTED",
+    .udesc  = "IRQ rejected",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "VFIFO",
+    .udesc  = "Counts the number of allocated into the IRQ ordering FIFO",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_c_rxr_ipq_retry[]={
+  { .uname = "ADDR_CONFLICT",
+    .udesc  = "Address conflict",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ANY",
+    .udesc  = "Any Reject",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "FULL",
+    .udesc  = "No Egress credits",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "QPI_CREDITS",
+    .udesc  = "No QPI credits",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_c_rxr_irq_retry[]={
+  { .uname = "ADDR_CONFLICT",
+    .udesc  = "Address conflict",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ANY",
+    .udesc  = "Any reject",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "FULL",
+    .udesc  = "No Egress credits",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "QPI_CREDITS",
+    .udesc  = "No QPI credits",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RTID",
+    .udesc  = "No RTIDs",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "IIO_CREDITS",
+    .udesc  = "No IIO Credits",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_c_rxr_ismq_retry[]={
+  { .uname = "ANY",
+    .udesc  = "Any reject",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "FULL",
+    .udesc  = "No Egress credits",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "IIO_CREDITS",
+    .udesc  = "No IIO credits",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "QPI_CREDITS",
+    .udesc  = "NO QPI credits",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RTID",
+    .udesc  = "No RTIDs",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WB_CREDITS",
+    .udesc  = "No WB credits",
+    .ucode  = 0x8000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_c_rxr_occupancy[]={
+  { .uname = "IPQ",
+    .udesc  = "IPQ",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "IRQ",
+    .udesc  = "IRQ",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "IRQ_REJECTED",
+    .udesc  = "IRQ rejected",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "VFIFO",
+    .udesc  = "Number of used entries in the IRQ ordering FIFO in each cycle",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_c_tor_inserts[]={
+  { .uname = "OPCODE",
+    .udesc  = "Number of transactions inserted into the TOR that match an opcode (must provide opc_* umask)",
+    .ucode  = 0x100,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MISS_OPCODE",
+    .udesc  = "Number of miss transactions inserted into the TOR that match an opcode (must provide opc_* umask)",
+    .ucode  = 0x300,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "EVICTION",
+    .udesc  = "Number of Evictions transactions inserted into TOR",
+    .ucode  = 0x400,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "ALL",
+    .udesc  = "Number of transactions inserted in TOR",
+    .ucode  = 0x800,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "WB",
+    .udesc  = "Number of write transactions inserted into the TOR",
+    .ucode  = 0x1000,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "LOCAL_OPCODE",
+    .udesc  = "Number of opcode-matched transactions inserted into the TOR that are satisfied by locally homed memory",
+    .ucode  = 0x2100,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MISS_LOCAL_OPCODE",
+    .udesc  = "Number of miss opcode-matched transactions inserted into the TOR that are satisfied by locally homed memory",
+    .ucode  = 0x2300,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "LOCAL",
+    .udesc  = "Number of transactions inserted into the TOR that are satisfied by locally homed memory",
+    .ucode  = 0x2800,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "MISS_LOCAL",
+    .udesc  = "Number of miss transactions inserted into the TOR that are satisfied by locally homed memory",
+    .ucode  = 0x2a00,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "NID_OPCODE",
+    .udesc  = "Number of transactions inserted into the TOR that match a NID and opcode (must provide opc_* umask and nf=X modifier)",
+    .ucode  = 0x4100,
+    .grpid  = 0,
+    .umodmsk_req = _SNBEP_UNC_ATTR_NF1,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NID_MISS_OPCODE",
+    .udesc  = "Number of NID and opcode matched miss transactions inserted into the TOR (must provide opc_* umask and nf=X modifier)",
+    .ucode  = 0x4300,
+    .grpid  = 0,
+    .umodmsk_req = _SNBEP_UNC_ATTR_NF1,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NID_EVICTION",
+    .udesc  = "Number of NID-matched eviction transactions inserted into the TOR (must provide nf=X modifier)",
+    .ucode  = 0x4400,
+    .grpid  = 0,
+    .umodmsk_req = _SNBEP_UNC_ATTR_NF1,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "NID_ALL",
+    .udesc  = "Number of NID-matched transactions inserted into the TOR",
+    .ucode  = 0x4800,
+    .grpid  = 0,
+    .umodmsk_req = _SNBEP_UNC_ATTR_NF1,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "NID_MISS_ALL",
+    .udesc  = "Number of NID-matched miss transactions that were inserted into the TOR (must provide nf=X modifier)",
+    .ucode  = 0x4a00,
+    .grpid  = 0,
+    .umodmsk_req = _SNBEP_UNC_ATTR_NF1,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "NID_WB",
+    .udesc  = "Number of NID-matched write back transactions inserted into the TOR (must provide nf=X modifier)",
+    .ucode  = 0x5000,
+    .grpid  = 0,
+    .umodmsk_req = _SNBEP_UNC_ATTR_NF1,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "REMOTE_OPCODE",
+    .udesc  = "Number of opcode-matched transactions inserted into the TOR that are satisfied by remote caches or memory",
+    .ucode  = 0x8100,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MISS_REMOTE_OPCODE",
+    .udesc  = "Number of miss opcode-matched transactions inserted into the TOR that are satisfied by remote caches or memory",
+    .ucode  = 0x8300,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "REMOTE",
+    .udesc  = "Number of transactions inserted into the TOR that are satisfied by remote caches or memory",
+    .ucode  = 0x8800,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "MISS_REMOTE",
+    .udesc  = "Number of miss transactions inserted into the TOR that are satisfied by remote caches or memory",
+    .ucode  = 0x8a00,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  CBO_FILT_OPC(1)
+};
+
+static const intel_x86_umask_t ivbep_unc_c_tor_occupancy[]={
+  { .uname = "OPCODE",
+    .udesc  = "Number of TOR entries that match an opcode (must provide opc_* umask)",
+    .ucode  = 0x100,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MISS_OPCODE",
+    .udesc  = "Number of TOR entries that match a NID and an opcode (must provide opc_* umask)",
+    .ucode  = 0x300,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "EVICTION",
+    .udesc  = "Number of outstanding eviction transactions in the TOR",
+    .ucode  = 0x400,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "ALL",
+    .udesc  = "All valid TOR entries",
+    .ucode  = 0x800,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "MISS_ALL",
+    .udesc  = "Number of outstanding miss requests in the TOR",
+    .ucode  = 0xa00,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "WB",
+    .udesc  = "Number of write transactions in the TOR. Does not include RFO, but actual operations that contain data being sent from the core",
+    .ucode  = 0x1000,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "LOCAL_OPCODE",
+    .udesc  = "Number of opcode-matched transactions in the TOR that are satisfied by locally homed memory",
+    .ucode  = 0x2100,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MISS_LOCAL_OPCODE",
+    .udesc  = "Number of miss opcode-matched transactions in the TOR that are satisfied by locally homed memory",
+    .ucode  = 0x2300,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "LOCAL",
+    .udesc  = "Number of transactions in the TOR that are satisfied by locally homed memory",
+    .ucode  = 0x2800,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "MISS_LOCAL",
+    .udesc  = "Number of miss transactions in the TOR that are satisfied by locally homed memory",
+    .ucode  = 0x2a00,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "NID_OPCODE",
+    .udesc  = "Number of NID-matched TOR entries that an opcode (must provide nf=X modifier and opc_* umask)",
+    .ucode  = 0x4100,
+    .grpid  = 0,
+    .umodmsk_req = _SNBEP_UNC_ATTR_NF1,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NID_MISS_OPCODE",
+    .udesc  = "Number of NID-matched outstanding miss requests in the TOR that an opcode (must provide nf=X modifier and opc_* umask)",
+    .ucode  = 0x4300,
+    .grpid  = 0,
+    .umodmsk_req = _SNBEP_UNC_ATTR_NF1,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NID_EVICTION",
+    .udesc  = "Number of NID-matched outstanding requests in the TOR (must provide a nf=X modifier)",
+    .ucode  = 0x4400,
+    .grpid  = 0,
+    .umodmsk_req = _SNBEP_UNC_ATTR_NF1,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "NID_ALL",
+    .udesc  = "Number of NID-matched outstanding requests in the TOR (must provide nf=X modifier)",
+    .ucode  = 0x4800,
+    .grpid  = 0,
+    .umodmsk_req = _SNBEP_UNC_ATTR_NF1,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "NID_MISS_ALL",
+    .udesc  = "Number of NID-matched outstanding miss requests in the TOR (must provide a nf=X modifier)",
+    .ucode  = 0x4a00,
+    .grpid  = 0,
+    .umodmsk_req = _SNBEP_UNC_ATTR_NF1,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "NID_WB",
+    .udesc  = "Number of NID-matched write transactions in the TOR (must provide a nf=X modifier)",
+    .ucode  = 0x5000,
+    .grpid  = 0,
+    .umodmsk_req = _SNBEP_UNC_ATTR_NF1,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "REMOTE_OPCODE",
+    .udesc  = "Number of opcode-matched transactions in the TOR that are satisfied by remote caches or memory",
+    .ucode  = 0x8100,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MISS_REMOTE_OPCODE",
+    .udesc  = "Number of miss opcode-matched transactions in the TOR that are satisfied by remote caches or memory",
+    .ucode  = 0x8300,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "REMOTE",
+    .udesc  = "Number of transactions in the TOR that are satisfied by remote caches or memory",
+    .ucode  = 0x8800,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  { .uname = "MISS_REMOTE",
+    .udesc  = "Number of miss transactions inserted into the TOR that are satisfied by remote caches or memory",
+    .ucode  = 0x8a00,
+    .grpid  = 0,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
+  },
+  CBO_FILT_OPC(1)
+};
+
+static const intel_x86_umask_t ivbep_unc_c_txr_inserts[]={
+  { .uname = "AD_CACHE",
+    .udesc  = "Counts the number of ring transactions from Cachebo to AD ring",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "AK_CACHE",
+    .udesc  = "Counts the number of ring transactions from Cachebo to AK ring",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "BL_CACHE",
+    .udesc  = "Counts the number of ring transactions from Cachebo to BL ring",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "IV_CACHE",
+    .udesc  = "Counts the number of ring transactions from Cachebo ton IV ring",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "AD_CORE",
+    .udesc  = "Counts the number of ring transactions from Corebo to AD ring",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "AK_CORE",
+    .udesc  = "Counts the number of ring transactions from Corebo to AK ring",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "BL_CORE",
+    .udesc  = "Counts the number of ring transactions from Corebo to BL ring",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_c_txr_ads_used[]={
+  { .uname = "AD",
+    .udesc  = "onto AD ring",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "AK",
+    .udesc  = "Onto AK ring",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "BL",
+    .udesc  = "Onto BL ring",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  }
+};
+
+static const intel_x86_umask_t ivbep_unc_c_misc[]={
+  { .uname = "RSPI_WAS_FSE",
+    .udesc  = "Counts the number of times when a SNoop hit in FSE states and triggered a silent eviction. This is useful because this information is lost in the PRE encodings",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WC_ALIASING",
+    .udesc  = "Counts the number of times a USWC write (WCIL(F)) transaction hits in the LLC in M state, triggering a WBMTOI followed by the USWC write. This occurs when there is WC aliasing",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "STARTED",
+    .udesc  = "TBD",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RFO_HIT_S",
+    .udesc  = "Counts the number of times that an RFO hits in S state. This is usfeul for determining if it might be good for a workload to use RSPIWB instead of RSPSWB",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_entry_t intel_ivbep_unc_c_pe[]={
+  { .name   = "UNC_C_CLOCKTICKS",
+    .desc   = "C-box Uncore clockticks",
+    .modmsk = 0x0,
+    .cntmsk = 0xf,
+    .code = 0x00,
+    .flags = INTEL_X86_FIXED,
+  },
+  { .name   = "UNC_C_COUNTER0_OCCUPANCY",
+    .desc   = "Counter 0 occupancy. Counts the occupancy related information by filtering CB0 occupancy count captured in counter 0.",
+    .modmsk = IVBEP_UNC_CBO_ATTRS,
+    .cntmsk = 0xe,
+    .code = 0x1f,
+  },
+  { .name   = "UNC_C_LLC_LOOKUP",
+    .desc   = "Cache lookups",
+    .modmsk = IVBEP_UNC_CBO_NID_ATTRS,
+    .cntmsk = 0x3,
+    .code = 0x34,
+    .ngrp = 3,
+    .flags = INTEL_X86_NO_AUTOENCODE,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_llc_lookup),
+    .umasks = ivbep_unc_c_llc_lookup,
+  },
+  { .name   = "UNC_C_LLC_VICTIMS",
+    .desc   = "Lines victimized",
+    .modmsk = IVBEP_UNC_CBO_NID_ATTRS,
+    .cntmsk = 0x3,
+    .code = 0x37,
+    .flags = INTEL_X86_NO_AUTOENCODE,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_llc_victims),
+    .ngrp = 2,
+    .umasks = ivbep_unc_c_llc_victims,
+  },
+  { .name   = "UNC_C_MISC",
+    .desc   = "Miscelleanous C-Box events",
+    .modmsk = IVBEP_UNC_CBO_ATTRS,
+    .cntmsk = 0x3,
+    .code = 0x39,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_misc),
+    .ngrp = 1,
+    .umasks = ivbep_unc_c_misc,
+  },
+  { .name   = "UNC_C_RING_AD_USED",
+    .desc   = "Address ring in use. Counts number of cycles ring is being used at this ring stop",
+    .modmsk = IVBEP_UNC_CBO_ATTRS,
+    .cntmsk = 0xc,
+    .code = 0x1b,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_ring_ad_used),
+    .ngrp = 1,
+    .umasks = ivbep_unc_c_ring_ad_used,
+  },
+  { .name   = "UNC_C_RING_AK_USED",
+    .desc   = "Acknowledgement ring in use. Counts number of cycles ring is being used at this ring stop",
+    .modmsk = IVBEP_UNC_CBO_ATTRS,
+    .cntmsk = 0xc,
+    .code = 0x1c,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_ring_ad_used), /* identical to RING_AD_USED */
+    .ngrp = 1,
+    .umasks = ivbep_unc_c_ring_ad_used,
+  },
+  { .name   = "UNC_C_RING_BL_USED",
+    .desc   = "Bus or Data ring in use. Counts number of cycles ring is being used at this ring stop",
+    .modmsk = IVBEP_UNC_CBO_ATTRS,
+    .cntmsk = 0xc,
+    .code = 0x1d,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_ring_ad_used), /* identical to RING_AD_USED */
+    .ngrp = 1,
+    .umasks = ivbep_unc_c_ring_ad_used,
+  },
+  { .name   = "UNC_C_RING_BOUNCES",
+    .desc   = "Number of LLC responses that bounced in the ring",
+    .modmsk = IVBEP_UNC_CBO_ATTRS,
+    .cntmsk = 0x3,
+    .code = 0x05,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_ring_bounces),
+    .ngrp = 1,
+    .umasks = ivbep_unc_c_ring_bounces,
+  },
+  { .name   = "UNC_C_RING_IV_USED",
+    .desc   = "Invalidate ring in use. Counts number of cycles ring is being used at this ring stop",
+    .modmsk = IVBEP_UNC_CBO_ATTRS,
+    .cntmsk = 0xc,
+    .code = 0x1e,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_ring_iv_used),
+    .ngrp = 1,
+    .umasks = ivbep_unc_c_ring_iv_used,
+  },
+  { .name   = "UNC_C_RING_SRC_THRTL",
+    .desc   = "TDB",
+    .modmsk = IVBEP_UNC_CBO_ATTRS,
+    .cntmsk = 0x3,
+    .code = 0x07,
+  },
+  { .name   = "UNC_C_RXR_EXT_STARVED",
+    .desc   = "Ingress arbiter blocking cycles",
+    .modmsk = IVBEP_UNC_CBO_ATTRS,
+    .cntmsk = 0x3,
+    .code = 0x12,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_rxr_ext_starved),
+    .ngrp = 1,
+    .umasks = ivbep_unc_c_rxr_ext_starved,
+  },
+  { .name = "UNC_C_RXR_INSERTS",
+    .desc = "Ingress Allocations",
+    .code = 0x13,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_CBO_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_rxr_inserts),
+    .umasks  = ivbep_unc_c_rxr_inserts
+  },
+  { .name = "UNC_C_RXR_IPQ_RETRY",
+    .desc = "Probe Queue Retries",
+    .code = 0x31,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_CBO_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_rxr_ipq_retry),
+    .umasks  = ivbep_unc_c_rxr_ipq_retry
+  },
+  { .name = "UNC_C_RXR_IRQ_RETRY",
+    .desc = "Ingress Request Queue Rejects",
+    .code = 0x32,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_CBO_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_rxr_irq_retry),
+    .umasks  = ivbep_unc_c_rxr_irq_retry
+  },
+  { .name = "UNC_C_RXR_ISMQ_RETRY",
+    .desc = "ISMQ Retries",
+    .code = 0x33,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_CBO_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_rxr_ismq_retry),
+    .umasks  = ivbep_unc_c_rxr_ismq_retry
+  },
+  { .name = "UNC_C_RXR_OCCUPANCY",
+    .desc = "Ingress Occupancy",
+    .code = 0x11,
+    .cntmsk = 0x1,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_CBO_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_rxr_inserts),
+    .umasks  = ivbep_unc_c_rxr_inserts, /* identical to ivbep_unc_c_rxr_inserts */
+  },
+  { .name = "UNC_C_TOR_INSERTS",
+    .desc = "TOR Inserts",
+    .code = 0x35,
+    .cntmsk = 0x3,
+    .ngrp = 2,
+    .modmsk = IVBEP_UNC_CBO_NID_ATTRS,
+    .flags  = INTEL_X86_NO_AUTOENCODE,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_tor_inserts),
+    .umasks  = ivbep_unc_c_tor_inserts
+  },
+  { .name = "UNC_C_TOR_OCCUPANCY",
+    .desc = "TOR Occupancy",
+    .code = 0x36,
+    .cntmsk = 0x1,
+    .ngrp = 2,
+    .modmsk = IVBEP_UNC_CBO_NID_ATTRS,
+    .flags  = INTEL_X86_NO_AUTOENCODE,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_tor_occupancy),
+    .umasks  = ivbep_unc_c_tor_occupancy
+  },
+  { .name = "UNC_C_TXR_ADS_USED",
+    .desc = "Egress events",
+    .code = 0x04,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_CBO_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_txr_ads_used),
+    .umasks  = ivbep_unc_c_txr_ads_used
+  },
+  { .name = "UNC_C_TXR_INSERTS",
+    .desc = "Egress allocations",
+    .code = 0x02,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_CBO_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_txr_inserts),
+    .umasks  = ivbep_unc_c_txr_inserts
+  },
+};
diff --git a/src/libpfm4/lib/events/intel_ivbep_unc_ha_events.h b/src/libpfm4/lib/events/intel_ivbep_unc_ha_events.h
new file mode 100644
index 0000000..58f0e06
--- /dev/null
+++ b/src/libpfm4/lib/events/intel_ivbep_unc_ha_events.h
@@ -0,0 +1,925 @@
+/*
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * This file is part of libpfm, a performance monitoring support library for
+ * applications on Linux.
+ *
+ * This file has been automatically generated.
+ *
+ * PMU: ivbep_unc_ha (Intel IvyBridge-EP HA uncore PMU)
+ */
+
+static const intel_x86_umask_t ivbep_unc_h_conflict_cycles[]={
+  { .uname = "CONFLICT",
+    .udesc  = "Number of cycles that we are handling conflicts",
+    .ucode  = 0x200,
+  },
+  { .uname = "LAST",
+    .udesc  = "Count every last conflictor in conflict chain. Can be used to compute average conflict chain length",
+    .ucode  = 0x400,
+  },
+  { .uname = "CMP_FWDS",
+    .udesc  = "Count the number of cmp_fwd. This gives the number of late conflicts",
+    .ucode  = 0x1000,
+  },
+  { .uname = "ACKCNFLTS",
+    .udesc  = "Count the number Acknflts",
+    .ucode  = 0x800,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_directory_lookup[]={
+  { .uname = "NO_SNP",
+    .udesc  = "Snoop not needed",
+    .ucode  = 0x200,
+  },
+  { .uname = "SNOOP",
+    .udesc  = "SNooop needed",
+    .ucode  = 0x100,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_bypass_imc[]={
+  { .uname = "TAKEN",
+    .udesc  = "Bypass taken",
+    .ucode  = 0x200,
+  },
+  { .uname = "NOT_TAKEN",
+    .udesc  = "Bypass not taken",
+    .ucode  = 0x100,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_directory_update[]={
+  { .uname = "ANY",
+    .udesc  = "Counts any directory update",
+    .ucode  = 0x300,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "CLEAR",
+    .udesc  = "Directory clears",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SET",
+    .udesc  = "Directory set",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_igr_no_credit_cycles[]={
+  { .uname = "AD_QPI0",
+    .udesc  = "AD to QPI link 0",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "AD_QPI1",
+    .udesc  = "AD to QPI link 1",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "BL_QPI0",
+    .udesc  = "BL to QPI link 0",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "BL_QPI1",
+    .udesc  = "BL to QPI link 1",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_imc_writes[]={
+  { .uname = "ALL",
+    .udesc  = "Counts all writes",
+    .ucode  = 0xf00,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "FULL",
+    .udesc  = "Counts full line non ISOCH",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "FULL_ISOCH",
+    .udesc  = "Counts ISOCH full line",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "PARTIAL",
+    .udesc  = "Counts partial non-ISOCH",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "PARTIAL_ISOCH",
+    .udesc  = "Counts ISOCH partial",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_imc_reads[]={
+  { .uname = "NORMAL",
+    .udesc  = "Normal priority",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_requests[]={
+  { .uname = "READS",
+    .udesc  = "Counts incoming read requests. Good proxy for LLC read misses, incl. RFOs",
+    .ucode  = 0x300,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "READS_LOCAL",
+    .udesc  = "Counts incoming read requests coming from local socket. Good proxy for LLC read misses, incl. RFOs from the local socket",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "READS_REMOTE",
+    .udesc  = "Counts incoming read requests coming from remote socket. Good proxy for LLC read misses, incl. RFOs from the remote socket",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WRITES",
+    .udesc  = "Counts incoming writes",
+    .ucode  = 0xc00,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WRITES_LOCAL",
+    .udesc  = "Counts incoming writes from local socket",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WRITES_REMOTE",
+    .udesc  = "Counts incoming writes from remote socket",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "INVITOE_LOCAL",
+    .udesc  = "Counts InvItoE coming from local socket",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "INVITOE_REMOTE",
+    .udesc  = "Counts InvItoE coming from remote socket",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  }
+};
+
+static const intel_x86_umask_t ivbep_unc_h_rpq_cycles_no_reg_credits[]={
+  { .uname = "CHN0",
+    .udesc  = "Channel 0",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "CHN1",
+    .udesc  = "Channel 1",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "CHN2",
+    .udesc  = "channel 2",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "CHN3",
+    .udesc  = "Chanell 3",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_tad_requests_g0[]={
+  { .uname = "REGION0",
+    .udesc  = "Counts for TAD Region 0",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "REGION1",
+    .udesc  = "Counts for TAD Region 1",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "REGION2",
+    .udesc  = "Counts for TAD Region 2",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "REGION3",
+    .udesc  = "Counts for TAD Region 3",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "REGION4",
+    .udesc  = "Counts for TAD Region 4",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "REGION5",
+    .udesc  = "Counts for TAD Region 5",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "REGION6",
+    .udesc  = "Counts for TAD Region 6",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "REGION7",
+    .udesc  = "Counts for TAD Region 7",
+    .ucode  = 0x8000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_tad_requests_g1[]={
+  { .uname = "REGION8",
+    .udesc  = "Counts for TAD Region 8",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "REGION9",
+    .udesc  = "Counts for TAD Region 9",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "REGION10",
+    .udesc  = "Counts for TAD Region 10",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "REGION11",
+    .udesc  = "Counts for TAD Region 11",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_snoop_resp[]={
+  { .uname = "RSPI",
+    .udesc  = "Filters for snoop responses of RspI. RspI is returned when the remote cache does not have the data or when the remote cache silently evicts data (e.g. RFO hit non-modified line)",
+    .ucode  = 0x100,
+  },
+  { .uname = "RSPS",
+    .udesc  = "Filters for snoop responses of RspS. RspS is returned when the remote cache has the data but is not forwarding it. It is a way to let the requesting socket know that it cannot allocate the data in E-state",
+    .ucode  = 0x200,
+  },
+  { .uname = "RSPIFWD",
+    .udesc  = "Filters for snoop responses of RspIFwd. RspIFwd is returned when the remote cache agent forwards data and the requesting agent is able to acquire the data in E or M state. This is commonly returned with RFO transacations. It can be either HitM or HitFE",
+    .ucode  = 0x400,
+  },
+  { .uname = "RSPSFWD",
+    .udesc  = "Filters for snoop responses of RspSFwd. RspSFwd is returned when the remote cache agent forwards data  but holds on to its current copy. This is common for data and code reads that hit in a remote socket in E or F state",
+    .ucode  = 0x800,
+  },
+  { .uname = "RSP_WB",
+    .udesc  = "Filters for snoop responses of RspIWB or RspSWB. This is returned when a non-RFO requests hits in M-state. Data and code reads can return either RspIWB or RspSWB depending on how the system has been configured. InvItoE transactions will also return RspIWB because they must acquire ownership",
+    .ucode  = 0x1000,
+  },
+  { .uname = "RSP_FWD_WB",
+    .udesc  = "Filters for snoop responses of RspxFwdxWB. This snoop response is only used in 4s systems. It is used when a snoop HITM in a remote caching agent and it directly forwards data to a requester and simultaneously returns data to the home to be written back to memory",
+    .ucode  = 0x2000,
+  },
+  { .uname = "RSPCNFLCT",
+    .udesc  = "Filters for snoop responses of RspConflict. This is returned when a snoop finds an existing outstanding transaction in a remote caching agent when it CMAs that caching agent. This triggers the conflict resolution hardware. This covers both RspConflct and RspCnflctWBI",
+    .ucode  = 0x4000,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_txr_ad[]={
+  { .uname = "NDR",
+    .udesc  = "Counts non-data responses",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SNP",
+    .udesc  = "Counts outbound snoops send on the ring",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_txr_ad_cycles_full[]={
+  { .uname = "ALL",
+    .udesc  = "Counts cycles full from both schedulers",
+    .ucode  = 0x300,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "SCHED0",
+    .udesc  = "Counts cycles full from scheduler bank 0",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SCHED1",
+    .udesc  = "Counts cycles full from scheduler bank 1",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_txr_bl_occupancy[]={
+  { .uname = "SCHED0",
+    .udesc  = "Counts cycles full from scheduler bank 0",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SCHED1",
+    .udesc  = "Counts cycles full from scheduler bank 1",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_txr_ak_cycles_full[]={
+  { .uname = "ALL",
+    .udesc  = "Counts cycles from both schedulers",
+    .ucode  = 0x300,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "SCHED0",
+    .udesc  = "Counts cycles from scheduler bank 0",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SCHED1",
+    .udesc  = "Counts cycles from scheduler bank 1",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_txr_bl[]={
+  { .uname = "DRS_CACHE",
+    .udesc  = "Counts data being sent to the cache",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "DRS_CORE",
+    .udesc  = "Counts data being sent directly to the requesting core",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "DRS_QPI",
+    .udesc  = "Counts data being sent to a remote socket over QPI",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_txr_bl_cycles_full[]={
+  { .uname = "ALL",
+    .udesc  = "BL Egress Full",
+    .ucode  = 0x300,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SCHED0",
+    .udesc  = "BL Egress Full",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SCHED1",
+    .udesc  = "BL Egress Full",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+#if 0
+static const intel_x86_umask_t ivbep_unc_h_addr_opc_match[]={
+  { .uname = "FILT",
+    .udesc  = "Number of addr and opcode matches (opc via opc= or address via addr= modifiers)",
+    .ucode  = 0x300,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL | INTEL_X86_ADDR,
+  },
+};
+#endif
+
+static const intel_x86_umask_t ivbep_unc_h_bt_occupancy[]={
+  { .uname = "LOCAL",
+    .udesc  = "Local",
+    .ucode  = 0x100,
+  },
+  { .uname = "REMOTE",
+    .udesc  = "Remote",
+    .ucode  = 0x200,
+  },
+  { .uname = "READS_REMOTE",
+    .udesc  = "Reads remote",
+    .ucode  = 0x800,
+  },
+  { .uname = "WRITES_LOCAL",
+    .udesc  = "Writes local",
+    .ucode  = 0x1000,
+  },
+  { .uname = "WRITES_REMOTE",
+    .udesc  = "Writes remote",
+    .ucode  = 0x2000,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_bt_to_ht_not_issued[]={
+  { .uname = "INCOMING_SNP_HAZARD",
+    .udesc  = "Number of cycles unable to issue from BT due to incoming snoop hazard",
+    .ucode  = 0x200,
+  },
+  { .uname = "INCOMING_BL_HAZARD",
+    .udesc  = "Number of cycles unable to issue from BT due to incoming BL data hazard",
+    .ucode  = 0x400,
+  }
+};
+
+static const intel_x86_umask_t ivbep_unc_h_osb[]={
+  { .uname = "REMOTE",
+    .udesc  = "Remote",
+    .ucode  = 0x800,
+  },
+  { .uname = "READS_LOCAL",
+    .udesc  = "Local reads",
+    .ucode  = 0x200,
+  },
+  { .uname = "INVITOE_LOCAL",
+    .udesc  = "Local InvItoE",
+    .ucode  = 0x400,
+  }
+};
+static const intel_x86_umask_t ivbep_unc_h_osb_edr[]={
+  { .uname = "ALL",
+    .udesc  = "All data returns",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_DFL | INTEL_X86_NCOMBO,
+  },
+  { .uname = "READS_LOCAL_I",
+    .udesc  = "Reads to local I",
+    .ucode  = 0x200,
+  },
+  { .uname = "READS_REMOTE_I",
+    .udesc  = "Reads to remote I",
+    .ucode  = 0x400,
+  },
+  { .uname = "READS_LOCAL_S",
+    .udesc  = "Reads to local S",
+    .ucode  = 0x800,
+  },
+  { .uname = "READS_REMOTE_S",
+    .udesc  = "Reads to remote S",
+    .ucode  = 01000,
+  }
+};
+
+static const intel_x86_umask_t ivbep_unc_h_ring_ad_used[]={
+  { .uname = "CCW_VR0_EVEN",
+    .udesc  = "Counter-clockwise and even ring polarity on virtual ring 0",
+    .ucode  = 0x400,
+  },
+  { .uname = "CCW_VR0_ODD",
+    .udesc  = "Counter-clockwise and odd ring polarity on virtual ring 0",
+    .ucode  = 0x800,
+  },
+  { .uname = "CW_VR0_EVEN",
+    .udesc  = "Clockwise and even ring polarity on virtual ring 0",
+    .ucode  = 0x100,
+  },
+  { .uname = "CW_VR0_ODD",
+    .udesc  = "Clockwise and odd ring polarity on virtual ring 0",
+    .ucode  = 0x200,
+  },
+  { .uname = "CCW_VR1_EVEN",
+    .udesc  = "Counter-clockwise and even ring polarity on virtual ring 1",
+    .ucode  = 0x400,
+  },
+  { .uname = "CCW_VR1_ODD",
+    .udesc  = "Counter-clockwise and odd ring polarity on virtual ring 1",
+    .ucode  = 0x800,
+  },
+  { .uname = "CW_VR1_EVEN",
+    .udesc  = "Clockwise and even ring polarity on virtual ring 1",
+    .ucode  = 0x100,
+  },
+  { .uname = "CW_VR1_ODD",
+    .udesc  = "Clockwise and odd ring polarity on virtual ring 1",
+    .ucode  = 0x200,
+  },
+  { .uname = "CW",
+    .udesc  = "Clockwise with any polarity on either virtual rings",
+    .ucode  = 0x3300,
+  },
+  { .uname = "CCW",
+    .udesc  = "Counter-clockwise with any polarity on either virtual rings",
+    .ucode  = 0xcc00,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_snp_resp_recv_local[]={
+  { .uname = "RSPI",
+    .udesc  = "Filters for snoop responses of RspI. RspI is returned when the remote cache does not have the data or when the remote cache silently evicts data (e.g. RFO hit non-modified line)",
+    .ucode  = 0x100,
+  },
+  { .uname = "RSPS",
+    .udesc  = "Filters for snoop responses of RspS. RspS is returned when the remote cache has the data but is not forwarding it. It is a way to let the requesting socket know that it cannot allocate the data in E-state",
+    .ucode  = 0x200,
+  },
+  { .uname = "RSPIFWD",
+    .udesc  = "Filters for snoop responses of RspIFwd. RspIFwd is returned when the remote cache agent forwards data and the requesting agent is able to acquire the data in E or M state. This is commonly returned with RFO transacations. It can be either HitM or HitFE",
+    .ucode  = 0x400,
+  },
+  { .uname = "RSPSFWD",
+    .udesc  = "Filters for snoop responses of RspSFwd. RspSFwd is returned when the remote cache agent forwards data  but holds on to its current copy. This is common for data and code reads that hit in a remote socket in E or F state",
+    .ucode  = 0x800,
+  },
+  { .uname = "RSP_WB",
+    .udesc  = "Filters for snoop responses of RspIWB or RspSWB. This is returned when a non-RFO requests hits in M-state. Data and code reads can return either RspIWB or RspSWB depending on how the system has been configured. InvItoE transactions will also return RspIWB because they must acquire ownership",
+    .ucode  = 0x1000,
+  },
+  { .uname = "RSP_FWD_WB",
+    .udesc  = "Filters for snoop responses of RspxFwdxWB. This snoop response is only used in 4s systems. It is used when a snoop HITM in a remote caching agent and it directly forwards data to a requester and simultaneously returns data to the home to be written back to memory",
+    .ucode  = 0x2000,
+  },
+  { .uname = "RSPCNFLCT",
+    .udesc  = "Filters for snoop responses of RspConflict. This is returned when a snoop finds an existing outstanding transaction in a remote caching agent when it CMAs that caching agent. This triggers the conflict resolution hardware. This covers both RspConflct and RspCnflctWBI",
+    .ucode  = 0x4000,
+  },
+  { .uname = "OTHER",
+    .udesc  = "Filters all other snoop responses",
+    .ucode  = 0x8000,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_tracker_cycles_full[]={
+  { .uname = "GP",
+    .udesc  = "Number of cycles when the general purpose (GP) HA trakcer pool is completely used. It will not return valid count when BT is disabled",
+    .ucode  = 0x100,
+  },
+  { .uname = "ALL",
+    .udesc  = "Number of cycles when the general purpose (GP) HA trakcer pool is completely used including reserved HT entries. It will not return vaid count when BT is disabled",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_txr_ak[]={
+  { .uname = "NDR",
+    .udesc  = "Number of outbound NDR (non-data response) transactions send on the AK ring. AK NDR is used for messages to the local socket",
+    .ucode  = 0x100,
+  },
+  { .uname = "CRD_CBO",
+    .udesc  = "Number of outbound CDR transactions send on the AK ring to CBO",
+    .ucode  = 0x200,
+  },
+  { .uname = "CRD_QPI",
+    .udesc  = "Number of outbound CDR transactions send on the AK ring to QPI",
+    .ucode  = 0x400,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_h_iodc_conflicts[]={
+  { .uname = "ANY",
+    .udesc  = "Any conflict",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_DFL | INTEL_X86_NCOMBO,
+  },
+  { .uname = "LAST",
+    .udesc  = "Last conflict",
+    .ucode  = 0x400,
+  }
+};
+
+static const intel_x86_entry_t intel_ivbep_unc_h_pe[]={
+  { .name   = "UNC_H_CLOCKTICKS",
+    .desc   = "HA Uncore clockticks",
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .cntmsk = 0xf,
+    .code = 0x00,
+  },
+  { .name = "UNC_H_CONFLICT_CYCLES",
+    .desc = "Conflict Checks",
+    .code = 0xb,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_conflict_cycles),
+    .umasks  = ivbep_unc_h_conflict_cycles,
+  },
+  { .name = "UNC_H_DIRECT2CORE_COUNT",
+    .desc = "Direct2Core Messages Sent",
+    .code = 0x11,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+  },
+  { .name = "UNC_H_DIRECT2CORE_CYCLES_DISABLED",
+    .desc = "Cycles when Direct2Core was Disabled",
+    .code = 0x12,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+  },
+  { .name = "UNC_H_DIRECT2CORE_TXN_OVERRIDE",
+    .desc = "Number of Reads that had Direct2Core Overridden",
+    .code = 0x13,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+  },
+  { .name = "UNC_H_DIRECTORY_LOOKUP",
+    .desc = "Directory Lookups",
+    .code = 0xc,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_directory_lookup),
+    .umasks  = ivbep_unc_h_directory_lookup
+  },
+  { .name = "UNC_H_DIRECTORY_UPDATE",
+    .desc = "Directory Updates",
+    .code = 0xd,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_directory_update),
+    .umasks  = ivbep_unc_h_directory_update
+  },
+  { .name = "UNC_H_IGR_NO_CREDIT_CYCLES",
+    .desc = "Cycles without QPI Ingress Credits",
+    .code = 0x22,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_igr_no_credit_cycles),
+    .umasks  = ivbep_unc_h_igr_no_credit_cycles
+  },
+  { .name = "UNC_H_IMC_RETRY",
+    .desc = "Retry Events",
+    .code = 0x1e,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+  },
+  { .name = "UNC_H_IMC_WRITES",
+    .desc = "HA to IMC Full Line Writes Issued",
+    .code = 0x1a,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_imc_writes),
+    .umasks  = ivbep_unc_h_imc_writes
+  },
+  { .name = "UNC_H_IMC_READS",
+    .desc = "HA to IMC normal priority reads issued",
+    .code = 0x17,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_imc_reads),
+    .umasks  = ivbep_unc_h_imc_reads
+  },
+  { .name = "UNC_H_REQUESTS",
+    .desc = "Read and Write Requests",
+    .code = 0x1,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_requests),
+    .umasks  = ivbep_unc_h_requests
+  },
+  { .name = "UNC_H_RPQ_CYCLES_NO_REG_CREDITS",
+    .desc = "IMC RPQ Credits Empty",
+    .code = 0x15,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_rpq_cycles_no_reg_credits),
+    .umasks  = ivbep_unc_h_rpq_cycles_no_reg_credits
+  },
+  { .name = "UNC_H_TAD_REQUESTS_G0",
+    .desc = "HA Requests to a TAD Region",
+    .code = 0x1b,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_tad_requests_g0),
+    .umasks  = ivbep_unc_h_tad_requests_g0
+  },
+  { .name = "UNC_H_TAD_REQUESTS_G1",
+    .desc = "HA Requests to a TAD Region",
+    .code = 0x1c,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_tad_requests_g1),
+    .umasks  = ivbep_unc_h_tad_requests_g1
+  },
+  { .name = "UNC_H_TXR_AD_CYCLES_FULL",
+    .desc = "AD Egress Full",
+    .code = 0x2a,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_txr_ad_cycles_full),
+    .umasks  = ivbep_unc_h_txr_ad_cycles_full
+  },
+  { .name = "UNC_H_TXR_AK_CYCLES_FULL",
+    .desc = "AK Egress Full",
+    .code = 0x32,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_txr_ak_cycles_full),
+    .umasks  = ivbep_unc_h_txr_ak_cycles_full
+  },
+  { .name = "UNC_H_TXR_AK",
+    .desc = "Outbound Ring Transactions on AK",
+    .code = 0xe,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_txr_ak),
+    .umasks  = ivbep_unc_h_txr_ak
+  },
+  { .name = "UNC_H_TXR_BL",
+    .desc = "Outbound DRS Ring Transactions to Cache",
+    .code = 0x10,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_txr_bl),
+    .umasks  = ivbep_unc_h_txr_bl
+  },
+  { .name = "UNC_H_TXR_BL_CYCLES_FULL",
+    .desc = "BL Egress Full",
+    .code = 0x36,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_txr_ak_cycles_full),
+    .umasks  = ivbep_unc_h_txr_ak_cycles_full, /* identical to snbep_unc_h_txr_ak_cycles_full */
+  },
+  { .name = "UNC_H_WPQ_CYCLES_NO_REG_CREDITS",
+    .desc = "HA IMC CHN0 WPQ Credits Empty",
+    .code = 0x18,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_rpq_cycles_no_reg_credits),
+    .umasks  = ivbep_unc_h_rpq_cycles_no_reg_credits, /* shared */
+  },
+  { .name = "UNC_H_BT_BYPASS",
+    .desc = "Backup Tracker bypass",
+    .code = 0x52,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+  },
+  { .name = "UNC_H_BYPASS_IMC",
+    .desc = "HA to IMC bypass",
+    .code = 0x14,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_bypass_imc),
+    .umasks  = ivbep_unc_h_bypass_imc,
+  },
+  { .name = "UNC_H_BT_CYCLES_NE",
+    .desc = "Backup Tracker cycles not empty",
+    .code = 0x42,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+  },
+  { .name = "UNC_H_BT_OCCUPANCY",
+    .desc = "Backup Tracker inserts",
+    .code = 0x43,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_bt_occupancy),
+    .umasks  = ivbep_unc_h_bt_occupancy,
+  },
+  { .name = "UNC_H_IGR_AD_QPI2",
+    .desc = "AD QPI Link 2 credit accumulator",
+    .code = 0x59,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+  },
+  { .name = "UNC_H_IGR_BL_QPI2",
+    .desc = "BL QPI Link 2 credit accumulator",
+    .code = 0x5a,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+  },
+  { .name = "UNC_H_IODC_INSERTS",
+    .desc = "IODC inserts",
+    .code = 0x56,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+  },
+  { .name = "UNC_H_IODC_CONFLICTS",
+    .desc = "IODC conflicts",
+    .code = 0x57,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_iodc_conflicts),
+    .umasks  = ivbep_unc_h_iodc_conflicts,
+  },
+  { .name = "UNC_H_IODC_OLEN_WBMTOI",
+    .desc = "IODC zero length writes",
+    .code = 0x58,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+  },
+  { .name = "UNC_H_OSB",
+    .desc = "OSB snoop broadcast",
+    .code = 0x53,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_osb),
+    .umasks  = ivbep_unc_h_osb,
+  },
+  { .name = "UNC_H_OSB_EDR",
+    .desc = "OSB early data return",
+    .code = 0x54,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_osb_edr),
+    .umasks  = ivbep_unc_h_osb_edr,
+  },
+  { .name = "UNC_H_RING_AD_USED",
+    .desc = "AD ring in use",
+    .code = 0x3e,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_ring_ad_used),
+    .umasks  = ivbep_unc_h_ring_ad_used,
+  },
+  { .name = "UNC_H_RING_AK_USED",
+    .desc = "AK ring in use",
+    .code = 0x3f,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_ring_ad_used), /* shared */
+    .umasks  = ivbep_unc_h_ring_ad_used,
+  },
+  { .name = "UNC_H_RING_BL_USED",
+    .desc = "BL ring in use",
+    .code = 0x40,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_ring_ad_used), /* shared */
+    .umasks  = ivbep_unc_h_ring_ad_used,
+  },
+  { .name = "UNC_H_DIRECTORY_LAT_OPT",
+    .desc = "Directory latency optimization data return path taken",
+    .code = 0x41,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+  },
+
+  { .name = "UNC_H_SNP_RESP_RECV_LOCAL",
+    .desc = "Snoop responses received local",
+    .code = 0x60,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_snp_resp_recv_local),
+    .umasks  = ivbep_unc_h_snp_resp_recv_local,
+  },
+  { .name = "UNC_H_TXR_BL_OCCUPANCY",
+    .desc = "BL Egress occupancy",
+    .code = 0x34,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_txr_bl_occupancy),
+    .umasks  = ivbep_unc_h_txr_bl_occupancy,
+  },
+  { .name = "UNC_H_SNOOP_RESP",
+    .desc = "Snoop responses received",
+    .code = 0x21,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_HA_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_h_snoop_resp),
+    .umasks  = ivbep_unc_h_snoop_resp
+  },
+};
diff --git a/src/libpfm4/lib/events/intel_ivbep_unc_imc_events.h b/src/libpfm4/lib/events/intel_ivbep_unc_imc_events.h
new file mode 100644
index 0000000..ac8ef41
--- /dev/null
+++ b/src/libpfm4/lib/events/intel_ivbep_unc_imc_events.h
@@ -0,0 +1,644 @@
+/*
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * This file is part of libpfm, a performance monitoring support library for
+ * applications on Linux.
+ *
+ * PMU: ivbep_unc_imc (Intel IvyBridge-EP IMC uncore PMU)
+ */
+
+static const intel_x86_umask_t ivbep_unc_m_cas_count[]={
+  { .uname = "ALL",
+    .udesc  = "Counts total number of DRAM CAS commands issued on this channel",
+    .ucode  = 0xf00,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "RD",
+    .udesc  = "Counts all DRAM reads on this channel, incl. underfills",
+    .ucode  = 0x300,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RD_REG",
+    .udesc  = "Counts number of DRAM read CAS commands issued on this channel, incl. regular read CAS and those with implicit precharge",
+    .ucode  = 0x100,
+  },
+  { .uname = "RD_UNDERFILL",
+    .udesc  = "Counts number of underfill reads issued by the memory controller",
+    .ucode  = 0x200,
+  },
+  { .uname = "WR",
+    .udesc  = "Counts number of DRAM write CAS commands on this channel",
+    .ucode  = 0xc00,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WR_RMM",
+    .udesc  = "Counts Number of opportunistic DRAM write CAS commands issued on this channel",
+    .ucode  = 0x800,
+  },
+  { .uname = "WR_WMM",
+    .udesc  = "Counts number of DRAM write CAS commands issued on this channel while in Write-Major mode",
+    .ucode  = 0x400,
+  },
+  { .uname = "RD_RMM",
+    .udesc  = "Counts Number of opportunistic DRAM read CAS commands issued on this channel",
+    .ucode  = 0x1000,
+  },
+  { .uname = "RD_WMM",
+    .udesc  = "Counts number of DRAM read CAS commands issued on this channel while in Write-Major mode",
+    .ucode  = 0x2000,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_m_dram_refresh[]={
+  { .uname = "HIGH",
+    .udesc  = "TBD",
+    .ucode  = 0x400,
+  },
+  { .uname = "PANIC",
+    .udesc  = "TBD",
+    .ucode  = 0x200,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_m_major_modes[]={
+  { .uname = "ISOCH",
+    .udesc  = "Counts cycles in ISOCH Major maode",
+    .ucode  = 0x800,
+  },
+  { .uname = "PARTIAL",
+    .udesc  = "Counts cycles in Partial Major mode",
+    .ucode  = 0x400,
+  },
+  { .uname = "READ",
+    .udesc  = "Counts cycles in Read Major mode",
+    .ucode  = 0x100,
+  },
+  { .uname = "WRITE",
+    .udesc  = "Counts cycles in Write Major mode",
+    .ucode  = 0x200,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_m_power_cke_cycles[]={
+  { .uname = "RANK0",
+    .udesc  = "Count cycles for rank 0",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RANK1",
+    .udesc  = "Count cycles for rank 1",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RANK2",
+    .udesc  = "Count cycles for rank 2",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RANK3",
+    .udesc  = "Count cycles for rank 3",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RANK4",
+    .udesc  = "Count cycles for rank 4",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RANK5",
+    .udesc  = "Count cycles for rank 5",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RANK6",
+    .udesc  = "Count cycles for rank 6",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RANK7",
+    .udesc  = "Count cycles for rank 7",
+    .ucode  = 0x8000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_m_preemption[]={
+  { .uname = "RD_PREEMPT_RD",
+    .udesc  = "Counts read over read preemptions",
+    .ucode  = 0x100,
+  },
+  { .uname = "RD_PREEMPT_WR",
+    .udesc  = "Counts read over write preemptions",
+    .ucode  = 0x200,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_m_pre_count[]={
+  { .uname = "PAGE_CLOSE",
+    .udesc  = "Counts number of DRAM precharge commands sent on this channel as a result of the page close counter expiring",
+    .ucode  = 0x200,
+  },
+  { .uname = "PAGE_MISS",
+    .udesc  = "Counts number of DRAM precharge commands sent on this channel as a result of page misses",
+    .ucode  = 0x100,
+  },
+  { .uname = "RD",
+    .udesc  = "Precharge due to read",
+    .ucode  = 0x100,
+  },
+  { .uname = "WR",
+    .udesc  = "Precharhe due to write",
+    .ucode  = 0x200,
+  },
+  { .uname = "BYP",
+    .udesc  = "Precharge due to bypass",
+    .ucode  = 0x800,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_m_act_count[]={
+  { .uname = "RD",
+    .udesc  = "Activate due to read",
+    .ucode  = 0x100,
+  },
+  { .uname = "WR",
+    .udesc  = "Activate due to write",
+    .ucode  = 0x200,
+  },
+  { .uname = "BYP",
+    .udesc  = "Activate due to bypass",
+    .ucode  = 0x800,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_m_byp_cmds[]={
+  { .uname = "ACT",
+    .udesc  = "ACT command issued by 2 cycle bypass",
+    .ucode  = 0x100,
+  },
+  { .uname = "CAS",
+    .udesc  = "CAS command issued by 2 cycle bypass",
+    .ucode  = 0x200,
+  },
+  { .uname = "PRE",
+    .udesc  = "PRE command issued by 2 cycle bypass",
+    .ucode  = 0x400,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_m_rd_cas_prio[]={
+  { .uname = "LOW",
+    .udesc  = "Read CAS issued with low priority",
+    .ucode  = 0x100,
+  },
+  { .uname = "MED",
+    .udesc  = "Read CAS issued with medium priority",
+    .ucode  = 0x200,
+  },
+  { .uname = "HIGH",
+    .udesc  = "Read CAS issued with high priority",
+    .ucode  = 0x400,
+  },
+  { .uname = "PANIC",
+    .udesc  = "Read CAS issued with panic non isoch priority (starved)",
+    .ucode  = 0x800,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_m_rd_cas_rank0[]={
+  { .uname = "BANK0",
+    .udesc  = "Bank 0",
+    .ucode  = 0x100,
+  },
+  { .uname = "BANK1",
+    .udesc  = "Bank 1",
+    .ucode  = 0x200,
+  },
+  { .uname = "BANK2",
+    .udesc  = "Bank 2",
+    .ucode  = 0x400,
+  },
+  { .uname = "BANK3",
+    .udesc  = "Bank 3",
+    .ucode  = 0x800,
+  },
+  { .uname = "BANK4",
+    .udesc  = "Bank 4",
+    .ucode  = 0x1000,
+  },
+  { .uname = "BANK5",
+    .udesc  = "Bank 5",
+    .ucode  = 0x2000,
+  },
+  { .uname = "BANK6",
+    .udesc  = "Bank 6",
+    .ucode  = 0x4000,
+  },
+  { .uname = "BANK7",
+    .udesc  = "Bank 7",
+    .ucode  = 0x8000,
+  }
+};
+
+static const intel_x86_umask_t ivbep_unc_m_vmse_wr_push[]={
+  { .uname = "WMM",
+    .udesc  = "VMSE write push issued in WMM",
+    .ucode  = 0x100,
+  },
+  { .uname = "RMM",
+    .udesc  = "VMSE write push issued in RMM",
+    .ucode  = 0x200,
+  }
+};
+
+static const intel_x86_umask_t ivbep_unc_m_wmm_to_rmm[]={
+  { .uname = "LOW_THRES",
+    .udesc  = "Transition from WMM to RMM because of starve counter",
+    .ucode  = 0x100,
+  },
+  { .uname = "STARVE",
+    .udesc  = "TBD",
+    .ucode  = 0x200,
+  },
+  { .uname = "VMSE_RETRY",
+    .udesc  = "TBD",
+    .ucode  = 0x400,
+  }
+};
+
+
+static const intel_x86_entry_t intel_ivbep_unc_m_pe[]={
+  { .name   = "UNC_M_CLOCKTICKS",
+    .desc   = "IMC Uncore clockticks (fixed counter)",
+    .modmsk = 0x0,
+    .cntmsk = 0x100000000ull,
+    .code   = 0xff, /* perf pseudo encoding for fixed counter */
+    .flags  = INTEL_X86_FIXED,
+  },
+  { .name   = "UNC_M_DCLOCKTICKS",
+    .desc   = "IMC Uncore clockticks (generic counters)",
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .cntmsk = 0xf,
+    .code   = 0x00, /*encoding for generic counters */
+  },
+  { .name = "UNC_M_ACT_COUNT",
+    .desc = "DRAM Activate Count",
+    .code = 0x1,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_act_count),
+    .umasks  = ivbep_unc_m_act_count
+  },
+  { .name = "UNC_M_CAS_COUNT",
+    .desc = "DRAM RD_CAS and WR_CAS Commands.",
+    .code = 0x4,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_cas_count),
+    .umasks  = ivbep_unc_m_cas_count
+  },
+  { .name = "UNC_M_DRAM_PRE_ALL",
+    .desc = "DRAM Precharge All Commands",
+    .code = 0x6,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+  },
+  { .name = "UNC_M_DRAM_REFRESH",
+    .desc = "Number of DRAM Refreshes Issued",
+    .code = 0x5,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_dram_refresh),
+    .umasks  = ivbep_unc_m_dram_refresh
+  },
+  { .name = "UNC_M_ECC_CORRECTABLE_ERRORS",
+    .desc = "ECC Correctable Errors",
+    .code = 0x9,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+  },
+  { .name = "UNC_M_MAJOR_MODES",
+    .desc = "Cycles in a Major Mode",
+    .code = 0x7,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_major_modes),
+    .umasks  = ivbep_unc_m_major_modes
+  },
+  { .name = "UNC_M_POWER_CHANNEL_DLLOFF",
+    .desc = "Channel DLLOFF Cycles",
+    .code = 0x84,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+  },
+  { .name = "UNC_M_POWER_CHANNEL_PPD",
+    .desc = "Channel PPD Cycles",
+    .code = 0x85,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+  },
+  { .name = "UNC_M_POWER_CKE_CYCLES",
+    .desc = "CKE_ON_CYCLES by Rank",
+    .code = 0x83,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_power_cke_cycles),
+    .umasks  = ivbep_unc_m_power_cke_cycles
+  },
+  { .name = "UNC_M_POWER_CRITICAL_THROTTLE_CYCLES",
+    .desc = "Critical Throttle Cycles",
+    .code = 0x86,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+  },
+  { .name = "UNC_M_POWER_SELF_REFRESH",
+    .desc = "Clock-Enabled Self-Refresh",
+    .code = 0x43,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+  },
+  { .name = "UNC_M_POWER_THROTTLE_CYCLES",
+    .desc = "Throttle Cycles",
+    .code = 0x41,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_power_cke_cycles),
+    .umasks  = ivbep_unc_m_power_cke_cycles /* identical to snbep_unc_m_power_cke_cycles */
+  },
+  { .name = "UNC_M_PREEMPTION",
+    .desc = "Read Preemption Count",
+    .code = 0x8,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_preemption),
+    .umasks  = ivbep_unc_m_preemption
+  },
+  { .name = "UNC_M_PRE_COUNT",
+    .desc = "DRAM Precharge commands.",
+    .code = 0x2,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_pre_count),
+    .umasks  = ivbep_unc_m_pre_count
+  },
+  { .name = "UNC_M_RPQ_CYCLES_NE",
+    .desc = "Read Pending Queue Not Empty",
+    .code = 0x11,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+  },
+  { .name = "UNC_M_RPQ_INSERTS",
+    .desc = "Read Pending Queue Allocations",
+    .code = 0x10,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+  },
+  { .name = "UNC_M_WPQ_CYCLES_FULL",
+    .desc = "Write Pending Queue Full Cycles",
+    .code = 0x22,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+  },
+  { .name = "UNC_M_WPQ_CYCLES_NE",
+    .desc = "Write Pending Queue Not Empty",
+    .code = 0x21,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+  },
+  { .name = "UNC_M_WPQ_INSERTS",
+    .desc = "Write Pending Queue Allocations",
+    .code = 0x20,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+  },
+  { .name = "UNC_M_WPQ_READ_HIT",
+    .desc = "Write Pending Queue CAM Match",
+    .code = 0x23,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+  },
+  { .name = "UNC_M_WPQ_WRITE_HIT",
+    .desc = "Write Pending Queue CAM Match",
+    .code = 0x24,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+  },
+  { .name = "UNC_M_BYP_CMDS",
+    .desc = "Bypass command event",
+    .code = 0xa1,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_byp_cmds),
+    .umasks  = ivbep_unc_m_byp_cmds
+  },
+  { .name = "UNC_M_RD_CAS_PRIO",
+    .desc = "Read CAS priority",
+    .code = 0xa0,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_rd_cas_prio),
+    .umasks  = ivbep_unc_m_rd_cas_prio
+  },
+  { .name = "UNC_M_RD_CAS_RANK0",
+    .desc = "Read CAS access to Rank 0",
+    .code = 0xb0,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_rd_cas_rank0),
+    .umasks  = ivbep_unc_m_rd_cas_rank0
+  },
+  { .name = "UNC_M_RD_CAS_RANK1",
+    .desc = "Read CAS access to Rank 1",
+    .code = 0xb1,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_rd_cas_rank0), /* shared */
+    .umasks  = ivbep_unc_m_rd_cas_rank0
+  },
+  { .name = "UNC_M_RD_CAS_RANK2",
+    .desc = "Read CAS access to Rank 2",
+    .code = 0xb2,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_rd_cas_rank0), /* shared */
+    .umasks  = ivbep_unc_m_rd_cas_rank0
+  },
+  { .name = "UNC_M_RD_CAS_RANK3",
+    .desc = "Read CAS access to Rank 3",
+    .code = 0xb3,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_rd_cas_rank0), /* shared */
+    .umasks  = ivbep_unc_m_rd_cas_rank0
+  },
+  { .name = "UNC_M_RD_CAS_RANK4",
+    .desc = "Read CAS access to Rank 4",
+    .code = 0xb4,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_rd_cas_rank0), /* shared */
+    .umasks  = ivbep_unc_m_rd_cas_rank0
+  },
+  { .name = "UNC_M_RD_CAS_RANK5",
+    .desc = "Read CAS access to Rank 5",
+    .code = 0xb5,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_rd_cas_rank0), /* shared */
+    .umasks  = ivbep_unc_m_rd_cas_rank0
+  },
+  { .name = "UNC_M_RD_CAS_RANK6",
+    .desc = "Read CAS access to Rank 6",
+    .code = 0xb6,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_rd_cas_rank0), /* shared */
+    .umasks  = ivbep_unc_m_rd_cas_rank0
+  },
+  { .name = "UNC_M_RD_CAS_RANK7",
+    .desc = "Read CAS access to Rank 7",
+    .code = 0xb7,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_rd_cas_rank0), /* shared */
+    .umasks  = ivbep_unc_m_rd_cas_rank0
+  },
+  { .name = "UNC_M_VMSE_MXB_WR_OCCUPANCY",
+    .desc = "VMSE MXB write buffer occupancy",
+    .code = 0x91,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+  },
+  { .name = "UNC_M_VMSE_WR_PUSH",
+    .desc = "VMSE WR push issued",
+    .code = 0x90,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_vmse_wr_push),
+    .umasks  = ivbep_unc_m_vmse_wr_push
+  },
+  { .name = "UNC_M_WMM_TO_RMM",
+    .desc = "Transitions from WMM to RMM because of low threshold",
+    .code = 0xc0,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_wmm_to_rmm),
+    .umasks  = ivbep_unc_m_wmm_to_rmm
+  },
+  { .name = "UNC_M_WRONG_MM",
+    .desc = "Not getting the requested major mode",
+    .code = 0xc1,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+  },
+  { .name = "UNC_M_WR_CAS_RANK0",
+    .desc = "Write CAS access to Rank 0",
+    .code = 0xb8,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_rd_cas_rank0), /* shared */
+    .umasks  = ivbep_unc_m_rd_cas_rank0
+  },
+  { .name = "UNC_M_WR_CAS_RANK1",
+    .desc = "Write CAS access to Rank 1",
+    .code = 0xb9,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_rd_cas_rank0), /* shared */
+    .umasks  = ivbep_unc_m_rd_cas_rank0
+  },
+  { .name = "UNC_M_WR_CAS_RANK2",
+    .desc = "Write CAS access to Rank 2",
+    .code = 0xba,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_rd_cas_rank0), /* shared */
+    .umasks  = ivbep_unc_m_rd_cas_rank0
+  },
+  { .name = "UNC_M_WR_CAS_RANK3",
+    .desc = "Write CAS access to Rank 3",
+    .code = 0xbb,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_rd_cas_rank0), /* shared */
+    .umasks  = ivbep_unc_m_rd_cas_rank0
+  },
+  { .name = "UNC_M_WR_CAS_RANK4",
+    .desc = "Write CAS access to Rank 4",
+    .code = 0xbc,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_rd_cas_rank0), /* shared */
+    .umasks  = ivbep_unc_m_rd_cas_rank0
+  },
+  { .name = "UNC_M_WR_CAS_RANK5",
+    .desc = "Write CAS access to Rank 5",
+    .code = 0xbd,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_rd_cas_rank0), /* shared */
+    .umasks  = ivbep_unc_m_rd_cas_rank0
+  },
+  { .name = "UNC_M_WR_CAS_RANK6",
+    .desc = "Write CAS access to Rank 6",
+    .code = 0xbe,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_rd_cas_rank0), /* shared */
+    .umasks  = ivbep_unc_m_rd_cas_rank0
+  },
+  { .name = "UNC_M_WR_CAS_RANK7",
+    .desc = "Write CAS access to Rank 7",
+    .code = 0xbf,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_IMC_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_m_rd_cas_rank0), /* shared */
+    .umasks  = ivbep_unc_m_rd_cas_rank0
+  },
+};
diff --git a/src/libpfm4/lib/events/intel_ivbep_unc_irp_events.h b/src/libpfm4/lib/events/intel_ivbep_unc_irp_events.h
new file mode 100644
index 0000000..86b5168
--- /dev/null
+++ b/src/libpfm4/lib/events/intel_ivbep_unc_irp_events.h
@@ -0,0 +1,267 @@
+/*
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * This file is part of libpfm, a performance monitoring support library for
+ * applications on Linux.
+ *
+ * This file has been automatically generated.
+ *
+ * PMU: ivbep_unc_irp (Intel IvyBridge-EP IRP uncore)
+ */
+
+static const intel_x86_umask_t ivbep_unc_i_address_match[]={
+  { .uname = "STALL_COUNT",
+    .udesc  = "Number of time when it is not possible to merge two conflicting requests, a stall event occurs",
+    .ucode  = 0x100,
+  },
+  { .uname = "MERGE_COUNT",
+    .udesc  = "Number of times when two reuqests to the same address from the same source are received back to back, it is possible to merge them",
+    .ucode  = 0x200,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_i_cache_ack_pending_occupancy[]={
+  { .uname = "ANY",
+    .udesc  = "Any source",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "SOURCE",
+    .udesc  = "Track all requests from any source port",
+    .ucode  = 0x200,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_i_tickles[]={
+  { .uname = "LOST_OWNERSHIP",
+    .udesc  = "Number of request that lost ownership as a result of a tickle",
+    .ucode  = 0x100,
+  },
+  { .uname = "TOP_OF_QUEUE",
+    .udesc  = "Number of cases when a tickle was received but the request was at the head of the queue in the switch. In this case data is returned rather than releasing ownership",
+    .ucode  = 0x200,
+  },
+};
+
+
+static const intel_x86_umask_t ivbep_unc_i_transactions[]={
+  { .uname = "READS",
+    .udesc  = "Number of read requests (not including read prefetches)",
+    .ucode  = 0x100,
+  },
+  { .uname = "WRITES",
+    .udesc  = "Number of write requests. Each write should have a prefetch, so there is no need to explicitly track these requests",
+    .ucode  = 0x200,
+  },
+  { .uname = "RD_PREFETCHES",
+    .udesc  = "Number of read prefetches",
+    .ucode  = 0x400,
+  },
+};
+
+static const intel_x86_entry_t intel_ivbep_unc_i_pe[]={
+  { .name = "UNC_I_CLOCKTICKS",
+    .desc = "Number of uclks in domain",
+    .code = 0x0,
+    .cntmsk = 0x3,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+  },
+  { .name = "UNC_I_ADDRESS_MATCH",
+    .desc = "Address match conflict count",
+    .code = 0x17,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_i_address_match),
+    .umasks  = ivbep_unc_i_address_match
+  },
+  { .name = "UNC_I_CACHE_ACK_PENDING_OCCUPANCY",
+    .desc = "Write ACK pending occupancy",
+    .code = 0x14,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_i_cache_ack_pending_occupancy),
+    .umasks  = ivbep_unc_i_cache_ack_pending_occupancy
+  },
+  { .name = "UNC_I_CACHE_OWN_OCCUPANCY",
+    .desc = "Outstanding write ownership occupancy",
+    .code = 0x13,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_i_cache_ack_pending_occupancy),
+    .umasks  = ivbep_unc_i_cache_ack_pending_occupancy /* shared */
+  },
+  { .name = "UNC_I_CACHE_READ_OCCUPANCY",
+    .desc = "Outstanding read occupancy",
+    .code = 0x10,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_i_cache_ack_pending_occupancy),
+    .umasks  = ivbep_unc_i_cache_ack_pending_occupancy /* shared */
+  },
+  { .name = "UNC_I_CACHE_TOTAL_OCCUPANCY",
+    .desc = "Total write cache occupancy",
+    .code = 0x12,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_i_cache_ack_pending_occupancy),
+    .umasks  = ivbep_unc_i_cache_ack_pending_occupancy /* shared */
+  },
+  { .name = "UNC_I_CACHE_WRITE_OCCUPANCY",
+    .desc = "Outstanding write occupancy",
+    .code = 0x11,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_i_cache_ack_pending_occupancy),
+    .umasks  = ivbep_unc_i_cache_ack_pending_occupancy /* shared */
+  },
+  { .name = "UNC_I_RXR_AK_CYCLES_FULL",
+    .desc = "TBD",
+    .code = 0xb,
+    .cntmsk = 0x3,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+  },
+  { .name = "UNC_I_RXR_AK_INSERTS",
+    .desc = "Egress cycles full",
+    .code = 0xa,
+    .cntmsk = 0x3,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+  },
+  { .name = "UNC_I_RXR_AK_OCCUPANCY",
+    .desc = "TBD",
+    .code = 0x0c,
+    .cntmsk = 0x3,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+  },
+  { .name = "UNC_I_RXR_BL_DRS_CYCLES_FULL",
+    .desc = "TBD",
+    .code = 0x4,
+    .cntmsk = 0x3,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+  },
+  { .name = "UNC_I_RXR_BL_DRS_INSERTS",
+    .desc = "BL Ingress occupancy DRS",
+    .code = 0x1,
+    .cntmsk = 0x3,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+  },
+  { .name = "UNC_I_RXR_BL_DRS_OCCUPANCY",
+    .desc = "TBD",
+    .code = 0x7,
+    .cntmsk = 0x3,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+  },
+  { .name = "UNC_I_RXR_BL_NCB_CYCLES_FULL",
+    .desc = "TBD",
+    .code = 0x5,
+    .cntmsk = 0x3,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+  },
+  { .name = "UNC_I_RXR_BL_NCB_INSERTS",
+    .desc = "BL Ingress occupancy NCB",
+    .code = 0x2,
+    .cntmsk = 0x3,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+  },
+  { .name = "UNC_I_RXR_BL_NCB_OCCUPANCY",
+    .desc = "TBD",
+    .code = 0x8,
+    .cntmsk = 0x3,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+  },
+  { .name = "UNC_I_RXR_BL_NCS_CYCLES_FULL",
+    .desc = "TBD",
+    .code = 0x6,
+    .cntmsk = 0x3,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+  },
+  { .name = "UNC_I_RXR_BL_NCS_INSERTS",
+    .desc = "BL Ingress Occupancy NCS",
+    .code = 0x3,
+    .cntmsk = 0x3,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+  },
+  { .name = "UNC_I_RXR_BL_NCS_OCCUPANCY",
+    .desc = "TBD",
+    .code = 0x9,
+    .cntmsk = 0x3,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+  },
+  { .name = "UNC_I_TICKLES",
+    .desc = "Tickle count",
+    .code = 0x16,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_i_tickles),
+    .umasks  = ivbep_unc_i_tickles
+  },
+  { .name = "UNC_I_TRANSACTIONS",
+    .desc = "Inbound transaction count",
+    .code = 0x15,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_i_transactions),
+    .umasks  = ivbep_unc_i_transactions
+  },
+  { .name = "UNC_I_TXR_AD_STALL_CREDIT_CYCLES",
+    .desc = "No AD Egress credit stalls",
+    .code = 0x18,
+    .cntmsk = 0x3,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+  },
+  { .name = "UNC_I_TXR_BL_STALL_CREDIT_CYCLES",
+    .desc = "No BL Egress credit stalls",
+    .code = 0x19,
+    .cntmsk = 0x3,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+  },
+  { .name = "UNC_I_TXR_DATA_INSERTS_NCB",
+    .desc = "Outbound read requests",
+    .code = 0xe,
+    .cntmsk = 0x3,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+  },
+  { .name = "UNC_I_TXR_DATA_INSERTS_NCS",
+    .desc = "Outbound read requests",
+    .code = 0xf,
+    .cntmsk = 0x3,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+  },
+  { .name = "UNC_I_TXR_REQUEST_OCCUPANCY",
+    .desc = "Outbound request queue occupancy",
+    .code = 0xd,
+    .cntmsk = 0x3,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+  },
+  { .name = "UNC_I_WRITE_ORDERING_STALL_CYCLES",
+    .desc = "Write ordering stalls",
+    .code = 0x1a,
+    .cntmsk = 0x3,
+    .modmsk = SNBEP_UNC_IRP_ATTRS,
+  },
+};
diff --git a/src/libpfm4/lib/events/intel_ivbep_unc_pcu_events.h b/src/libpfm4/lib/events/intel_ivbep_unc_pcu_events.h
new file mode 100644
index 0000000..14188e5
--- /dev/null
+++ b/src/libpfm4/lib/events/intel_ivbep_unc_pcu_events.h
@@ -0,0 +1,485 @@
+/*
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * This file is part of libpfm, a performance monitoring support library for
+ * applications on Linux.
+ *
+ * PMU: ivbep_unc_pcu (Intel IvyBridge-EP PCU uncore)
+ */
+
+static const intel_x86_umask_t ivbep_unc_p_power_state_occupancy[]={
+  { .uname = "CORES_C0",
+    .udesc  = "Counts number of cores in C0",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "CORES_C3",
+    .udesc  = "Counts number of cores in C3",
+    .ucode  = 0x8000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "CORES_C6",
+    .udesc  = "Counts number of cores in C6",
+    .ucode  = 0xc000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_p_occupancy_counters[]={
+  { .uname = "C0",
+    .udesc  = "Counts number of cores in C0",
+    .ucode  = 0x0100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "C3",
+    .udesc  = "Counts number of cores in C3",
+    .ucode  = 0x0200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "C6",
+    .udesc  = "Counts number of cores in C6",
+    .ucode  = 0x0300,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_entry_t intel_ivbep_unc_p_pe[]={
+  { .name   = "UNC_P_CLOCKTICKS",
+    .desc   = "PCU Uncore clockticks",
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+    .cntmsk = 0xf,
+    .code = 0x00,
+  },
+  { .name = "UNC_P_CORE0_TRANSITION_CYCLES",
+    .desc = "Core 0 C State Transition Cycles",
+    .code = 0x70,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_CORE1_TRANSITION_CYCLES",
+    .desc = "Core 1 C State Transition Cycles",
+    .code = 0x71,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_CORE2_TRANSITION_CYCLES",
+    .desc = "Core 2 C State Transition Cycles",
+    .code = 0x72,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_CORE3_TRANSITION_CYCLES",
+    .desc = "Core 3 C State Transition Cycles",
+    .code = 0x73,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_CORE4_TRANSITION_CYCLES",
+    .desc = "Core 4 C State Transition Cycles",
+    .code = 0x74,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_CORE5_TRANSITION_CYCLES",
+    .desc = "Core 5 C State Transition Cycles",
+    .code = 0x75,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_CORE6_TRANSITION_CYCLES",
+    .desc = "Core 6 C State Transition Cycles",
+    .code = 0x76,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_CORE7_TRANSITION_CYCLES",
+    .desc = "Core 7 C State Transition Cycles",
+    .code = 0x77,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_CORE8_TRANSITION_CYCLES",
+    .desc = "Core 8 C State Transition Cycles",
+    .code = 0x78,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_CORE9_TRANSITION_CYCLES",
+    .desc = "Core 9 C State Transition Cycles",
+    .code = 0x79,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_CORE10_TRANSITION_CYCLES",
+    .desc = "Core 10 C State Transition Cycles",
+    .code = 0x7a,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_CORE11_TRANSITION_CYCLES",
+    .desc = "Core 11 C State Transition Cycles",
+    .code = 0x7b,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_CORE12_TRANSITION_CYCLES",
+    .desc = "Core 12 C State Transition Cycles",
+    .code = 0x7c,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_CORE13_TRANSITION_CYCLES",
+    .desc = "Core 13 C State Transition Cycles",
+    .code = 0x7d,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_CORE14_TRANSITION_CYCLES",
+    .desc = "Core 14 C State Transition Cycles",
+    .code = 0x7e,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DELAYED_C_STATE_ABORT_CORE0",
+    .desc = "Deep C state rejection Core 0",
+    .code = 0x17 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DELAYED_C_STATE_ABORT_CORE1",
+    .desc = "Deep C state rejection Core 1",
+    .code = 0x18 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DELAYED_C_STATE_ABORT_CORE2",
+    .desc = "Deep C state rejection Core 2",
+    .code = 0x19 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DELAYED_C_STATE_ABORT_CORE3",
+    .desc = "Deep C state rejection Core 3",
+    .code = 0x1a | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DELAYED_C_STATE_ABORT_CORE4",
+    .desc = "Deep C state rejection Core 4",
+    .code = 0x1b | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DELAYED_C_STATE_ABORT_CORE5",
+    .desc = "Deep C state rejection Core 5",
+    .code = 0x1c | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DELAYED_C_STATE_ABORT_CORE6",
+    .desc = "Deep C state rejection Core 6",
+    .code = 0x1d | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DELAYED_C_STATE_ABORT_CORE7",
+    .desc = "Deep C state rejection Core 7",
+    .code = 0x1e | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DELAYED_C_STATE_ABORT_CORE8",
+    .desc = "Deep C state rejection Core 8",
+    .code = 0x1f | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DELAYED_C_STATE_ABORT_CORE9",
+    .desc = "Deep C state rejection Core 9",
+    .code = 0x20 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DELAYED_C_STATE_ABORT_CORE10",
+    .desc = "Deep C state rejection Core 10",
+    .code = 0x21 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DELAYED_C_STATE_ABORT_CORE11",
+    .desc = "Deep C state rejection Core 11",
+    .code = 0x22 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DELAYED_C_STATE_ABORT_CORE12",
+    .desc = "Deep C state rejection Core 12",
+    .code = 0x23 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DELAYED_C_STATE_ABORT_CORE13",
+    .desc = "Deep C state rejection Core 13",
+    .code = 0x24 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DELAYED_C_STATE_ABORT_CORE14",
+    .desc = "Deep C state rejection Core 14",
+    .code = 0x25 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DEMOTIONS_CORE0",
+    .desc = "Core 0 C State Demotions",
+    .code = 0x1e,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DEMOTIONS_CORE1",
+    .desc = "Core 1 C State Demotions",
+    .code = 0x1f,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DEMOTIONS_CORE2",
+    .desc = "Core 2 C State Demotions",
+    .code = 0x20,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DEMOTIONS_CORE3",
+    .desc = "Core 3 C State Demotions",
+    .code = 0x21,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DEMOTIONS_CORE4",
+    .desc = "Core 4 C State Demotions",
+    .code = 0x22,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DEMOTIONS_CORE5",
+    .desc = "Core 5 C State Demotions",
+    .code = 0x23,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DEMOTIONS_CORE6",
+    .desc = "Core 6 C State Demotions",
+    .code = 0x24,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DEMOTIONS_CORE7",
+    .desc = "Core 7 C State Demotions",
+    .code = 0x25,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DEMOTIONS_CORE8",
+    .desc = "Core 8 C State Demotions",
+    .code = 0x40,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DEMOTIONS_CORE9",
+    .desc = "Core 9 C State Demotions",
+    .code = 0x41,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DEMOTIONS_CORE10",
+    .desc = "Core 10 C State Demotions",
+    .code = 0x42,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DEMOTIONS_CORE11",
+    .desc = "Core 11 C State Demotions",
+    .code = 0x43,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DEMOTIONS_CORE12",
+    .desc = "Core 12 C State Demotions",
+    .code = 0x44,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DEMOTIONS_CORE13",
+    .desc = "Core 13 C State Demotions",
+    .code = 0x45,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DEMOTIONS_CORE14",
+    .desc = "Core 14 C State Demotions",
+    .code = 0x46,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_DEMOTIONS_CORE14",
+    .desc = "Core 14 C State Demotions",
+    .code = 0x2d,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_FREQ_BAND0_CYCLES",
+    .desc = "Frequency Residency",
+    .code = 0xb,
+    .cntmsk = 0xf,
+    .flags = INTEL_X86_NO_AUTOENCODE,
+    .modmsk = IVBEP_UNC_PCU_BAND_ATTRS,
+    .modmsk_req = _SNBEP_UNC_ATTR_FF,
+  },
+  { .name = "UNC_P_FREQ_BAND1_CYCLES",
+    .desc = "Frequency Residency",
+    .code = 0xc,
+    .cntmsk = 0xf,
+    .flags = INTEL_X86_NO_AUTOENCODE,
+    .modmsk = IVBEP_UNC_PCU_BAND_ATTRS,
+    .modmsk_req = _SNBEP_UNC_ATTR_FF,
+  },
+  { .name = "UNC_P_FREQ_BAND2_CYCLES",
+    .desc = "Frequency Residency",
+    .code = 0xd,
+    .cntmsk = 0xf,
+    .flags = INTEL_X86_NO_AUTOENCODE,
+    .modmsk = IVBEP_UNC_PCU_BAND_ATTRS,
+    .modmsk_req = _SNBEP_UNC_ATTR_FF,
+  },
+  { .name = "UNC_P_FREQ_BAND3_CYCLES",
+    .desc = "Frequency Residency",
+    .code = 0xe,
+    .cntmsk = 0xf,
+    .flags = INTEL_X86_NO_AUTOENCODE,
+    .modmsk = IVBEP_UNC_PCU_BAND_ATTRS,
+    .modmsk_req = _SNBEP_UNC_ATTR_FF,
+  },
+  { .name = "UNC_P_FREQ_MAX_CURRENT_CYCLES",
+    .desc = "Current Strongest Upper Limit Cycles",
+    .code = 0x7,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_FREQ_MAX_LIMIT_THERMAL_CYCLES",
+    .desc = "Thermal Strongest Upper Limit Cycles",
+    .code = 0x4,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_FREQ_MAX_OS_CYCLES",
+    .desc = "OS Strongest Upper Limit Cycles",
+    .code = 0x6,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_FREQ_MAX_POWER_CYCLES",
+    .desc = "Power Strongest Upper Limit Cycles",
+    .code = 0x5,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_FREQ_MIN_PERF_P_CYCLES",
+    .desc = "Perf P Limit Strongest Lower Limit Cycles",
+    .code = 0x02 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+
+  { .name = "UNC_P_FREQ_MIN_IO_P_CYCLES",
+    .desc = "IO P Limit Strongest Lower Limit Cycles",
+    .code = 0x61,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_FREQ_TRANS_CYCLES",
+    .desc = "Cycles spent changing Frequency",
+    .code = 0x60,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_MEMORY_PHASE_SHEDDING_CYCLES",
+    .desc = "Memory Phase Shedding Cycles",
+    .code = 0x2f,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_PKG_C_EXIT_LATENCY",
+    .desc = "Package C state exit latency. Counts cycles the package is transitioning from C2 to C3",
+    .code = 0x26 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_POWER_STATE_OCCUPANCY",
+    .desc = "Number of cores in C0",
+    .code = 0x80,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_p_power_state_occupancy),
+    .umasks  = ivbep_unc_p_power_state_occupancy
+  },
+  { .name = "UNC_P_PROCHOT_EXTERNAL_CYCLES",
+    .desc = "External Prochot",
+    .code = 0xa,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_PROCHOT_INTERNAL_CYCLES",
+    .desc = "Internal Prochot",
+    .code = 0x9,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_TOTAL_TRANSITION_CYCLES",
+    .desc = "Total Core C State Transition Cycles",
+    .code = 0x63,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_VOLT_TRANS_CYCLES_CHANGE",
+    .desc = "Cycles Changing Voltage",
+    .code = 0x3,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_VOLT_TRANS_CYCLES_DECREASE",
+    .desc = "Cycles Decreasing Voltage",
+    .code = 0x2,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_VOLT_TRANS_CYCLES_INCREASE",
+    .desc = "Cycles Increasing Voltage",
+    .code = 0x1,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+  { .name = "UNC_P_VR_HOT_CYCLES",
+    .desc = "VR Hot",
+    .code = 0x32,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_PCU_ATTRS,
+  },
+};
diff --git a/src/libpfm4/lib/events/intel_ivbep_unc_qpi_events.h b/src/libpfm4/lib/events/intel_ivbep_unc_qpi_events.h
new file mode 100644
index 0000000..cfb3469
--- /dev/null
+++ b/src/libpfm4/lib/events/intel_ivbep_unc_qpi_events.h
@@ -0,0 +1,696 @@
+/*
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * This file is part of libpfm, a performance monitoring support library for
+ * applications on Linux.
+ *
+ * This file has been automatically generated.
+ *
+ * PMU: ivbep_unc_qpi (Intel IvyBridge-EP QPI uncore)
+ */
+
+static const intel_x86_umask_t ivbep_unc_q_direct2core[]={
+  { .uname = "FAILURE_CREDITS",
+    .udesc  = "Number of spawn failures due to lack of Egress credits",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "FAILURE_CREDITS_RBT",
+    .udesc  = "Number of spawn failures due to lack of Egress credit and route-back table (RBT) bit was not set",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "FAILURE_RBT_HIT",
+    .udesc  = "Number of spawn failures because route-back table (RBT) specified that the transaction should not trigger a direct2core transaction",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SUCCESS_RBT_HIT",
+    .udesc  = "Number of spawn successes",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "FAILURE_MISS",
+    .udesc  = "Number of spawn failures due to RBT tag not matching although the valid bit was set and there was enough Egress credits",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "FAILURE_CREDITS_MISS",
+    .udesc  = "Number of spawn failures due to RBT tag not matching and they were not enough Egress credits. The valid bit was set",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "FAILURE_RBT_MISS",
+    .udesc  = "Number of spawn failures due to RBT tag not matching, the valid bit was not set but there were enough Egress credits",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "FAILURE_CREDITS_RBT_MISS",
+    .udesc  = "Number of spawn failures due to RBT tag not matching, the valid bit was not set and there were not enough Egress credits",
+    .ucode  = 0x8000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_q_rxl_credits_consumed_vn0[]={
+  { .uname = "DRS",
+    .udesc  = "Number of times VN0 consumed for DRS message class",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "HOM",
+    .udesc  = "Number of times VN0 consumed for HOM message class",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NCB",
+    .udesc  = "Number of times VN0 consumed for NCB message class",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NCS",
+    .udesc  = "Number of times VN0 consumed for NCS message class",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NDR",
+    .udesc  = "Number of times VN0 consumed for NDR message class",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SNP",
+    .udesc  = "Number of times VN0 consumed for SNP message class",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_q_rxl_credits_consumed_vn1[]={
+  { .uname = "DRS",
+    .udesc  = "Number of times VN1 consumed for DRS message class",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "HOM",
+    .udesc  = "Number of times VN1 consumed for HOM message class",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NCB",
+    .udesc  = "Number of times VN1 consumed for NCB message class",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NCS",
+    .udesc  = "Number of times VN1 consumed for NCS message class",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NDR",
+    .udesc  = "Number of times VN1 consumed for NDR message class",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SNP",
+    .udesc  = "Number of times VN1 consumed for SNP message class",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+
+static const intel_x86_umask_t ivbep_unc_q_rxl_flits_g0[]={
+  { .uname = "DATA",
+    .udesc  = "Number of data flits over QPI",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "IDLE",
+    .udesc  = "Number of flits over QPI that do not hold protocol payload",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NON_DATA",
+    .udesc  = "Number of non-NULL non-data flits over QPI",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_q_txl_flits_g0[]={
+  { .uname = "DATA",
+    .udesc  = "Number of data flits over QPI",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NON_DATA",
+    .udesc  = "Number of non-NULL non-data flits over QPI",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_q_rxl_flits_g1[]={
+  { .uname = "DRS",
+    .udesc  = "Number of flits over QPI on the Data Response (DRS) channel",
+    .ucode  = 0x1800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "DRS_DATA",
+    .udesc  = "Number of data flits over QPI on the Data Response (DRS) channel",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "DRS_NONDATA",
+    .udesc  = "Number of protocol flits over QPI on the Data Response (DRS) channel",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "HOM",
+    .udesc  = "Number of flits over QPI on the home channel",
+    .ucode  = 0x600,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "HOM_NONREQ",
+    .udesc  = "Number of non-request flits over QPI on the home channel",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "HOM_REQ",
+    .udesc  = "Number of data requests over QPI on the home channel",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SNP",
+    .udesc  = "Number of snoop requests flits over QPI",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_q_rxl_flits_g2[]={
+  { .uname = "NCB",
+    .udesc  = "Number of non-coherent bypass flits",
+    .ucode  = 0xc00,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NCB_DATA",
+    .udesc  = "Number of non-coherent data flits",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NCB_NONDATA",
+    .udesc  = "Number of bypass non-data flits",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NCS",
+    .udesc  = "Number of non-coherent standard (NCS) flits",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NDR_AD",
+    .udesc  = "Number of flits received over Non-data response (NDR) channel",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NDR_AK",
+    .udesc  = "Number of flits received on the Non-data response (NDR) channel)",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_q_txr_ad_hom_credit_acquired[]={
+  { .uname = "VN0",
+    .udesc  = "for VN0",
+    .ucode  = 0x100,
+  },
+  { .uname = "VN1",
+    .udesc  = "for VN1",
+    .ucode  = 0x200,
+  },
+};
+
+ static const intel_x86_umask_t ivbep_unc_q_txr_bl_drs_credit_acquired[]={
+  { .uname = "VN0",
+    .udesc  = "for VN0",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "VN1",
+    .udesc  = "for VN1",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "VN_SHR",
+    .udesc  = "for shared VN",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_entry_t intel_ivbep_unc_q_pe[]={
+  { .name = "UNC_Q_CLOCKTICKS",
+    .desc = "Number of qfclks",
+    .code = 0x14,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+  },
+  { .name = "UNC_Q_CTO_COUNT",
+    .desc = "Count of CTO Events",
+    .code = 0x38 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+  },
+  { .name = "UNC_Q_DIRECT2CORE",
+    .desc = "Direct 2 Core Spawning",
+    .code = 0x13,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_direct2core),
+    .umasks  = ivbep_unc_q_direct2core
+  },
+  { .name = "UNC_Q_L1_POWER_CYCLES",
+    .desc = "Cycles in L1",
+    .code = 0x12,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+  },
+  { .name = "UNC_Q_RXL0P_POWER_CYCLES",
+    .desc = "Cycles in L0p",
+    .code = 0x10,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+  },
+  { .name = "UNC_Q_RXL0_POWER_CYCLES",
+    .desc = "Cycles in L0",
+    .code = 0xf,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+  },
+  { .name = "UNC_Q_RXL_BYPASSED",
+    .desc = "Rx Flit Buffer Bypassed",
+    .code = 0x9,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+  },
+  { .name = "UNC_Q_RXL_CREDITS_CONSUMED_VN0",
+    .desc = "VN0 Credit Consumed",
+    .code = 0x1e | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_rxl_credits_consumed_vn0),
+    .umasks  = ivbep_unc_q_rxl_credits_consumed_vn0
+  },
+  { .name = "UNC_Q_RXL_CREDITS_CONSUMED_VN1",
+    .desc = "VN1 Credit Consumed",
+    .code = 0x39 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_rxl_credits_consumed_vn1),
+    .umasks  = ivbep_unc_q_rxl_credits_consumed_vn1
+  },
+  { .name = "UNC_Q_RXL_CREDITS_CONSUMED_VNA",
+    .desc = "VNA Credit Consumed",
+    .code = 0x1d | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+  },
+  { .name = "UNC_Q_RXL_CYCLES_NE",
+    .desc = "RxQ Cycles Not Empty",
+    .code = 0xa,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+  },
+  { .name = "UNC_Q_RXL_FLITS_G0",
+    .desc = "Flits Received - Group 0",
+    .code = 0x1,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_rxl_flits_g0),
+    .umasks  = ivbep_unc_q_rxl_flits_g0
+  },
+  { .name = "UNC_Q_RXL_FLITS_G1",
+    .desc = "Flits Received - Group 1",
+    .code = 0x2 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_rxl_flits_g1),
+    .umasks  = ivbep_unc_q_rxl_flits_g1
+  },
+
+  { .name = "UNC_Q_RXL_FLITS_G2",
+    .desc = "Flits Received - Group 2",
+    .code = 0x3 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_rxl_flits_g2),
+    .umasks  = ivbep_unc_q_rxl_flits_g2
+  },
+  { .name = "UNC_Q_RXL_INSERTS",
+    .desc = "Rx Flit Buffer Allocations",
+    .code = 0x8,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+  },
+  { .name = "UNC_Q_RXL_INSERTS_DRS",
+    .desc = "Rx Flit Buffer Allocations - DRS",
+    .code = 0x9 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .ngrp = 1,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired),
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_RXL_INSERTS_HOM",
+    .desc = "Rx Flit Buffer Allocations - HOM",
+    .code = 0xc | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .ngrp = 1,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired),
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_RXL_INSERTS_NCB",
+    .desc = "Rx Flit Buffer Allocations - NCB",
+    .code = 0xa | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .ngrp = 1,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired),
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_RXL_INSERTS_NCS",
+    .desc = "Rx Flit Buffer Allocations - NCS",
+    .code = 0xb | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .ngrp = 1,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired),
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_RXL_INSERTS_NDR",
+    .desc = "Rx Flit Buffer Allocations - NDR",
+    .code = 0xe | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .ngrp = 1,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired),
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_RXL_INSERTS_SNP",
+    .desc = "Rx Flit Buffer Allocations - SNP",
+    .code = 0xd | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .ngrp = 1,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired),
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_RXL_OCCUPANCY",
+    .desc = "RxQ Occupancy - All Packets",
+    .code = 0xb,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+  },
+  { .name = "UNC_Q_RXL_OCCUPANCY_DRS",
+    .desc = "RxQ Occupancy - DRS",
+    .code = 0x15 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .ngrp = 1,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired),
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_RXL_OCCUPANCY_HOM",
+    .desc = "RxQ Occupancy - HOM",
+    .code = 0x18 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .ngrp = 1,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired),
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_RXL_OCCUPANCY_NCB",
+    .desc = "RxQ Occupancy - NCB",
+    .code = 0x16 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .ngrp = 1,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired),
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_RXL_OCCUPANCY_NCS",
+    .desc = "RxQ Occupancy - NCS",
+    .code = 0x17 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .ngrp = 1,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired),
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_RXL_OCCUPANCY_NDR",
+    .desc = "RxQ Occupancy - NDR",
+    .code = 0x1a | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .ngrp = 1,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired),
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_RXL_OCCUPANCY_SNP",
+    .desc = "RxQ Occupancy - SNP",
+    .code = 0x19 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .ngrp = 1,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired),
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_TXL0P_POWER_CYCLES",
+    .desc = "Cycles in L0p",
+    .code = 0xd,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+  },
+  { .name = "UNC_Q_TXL0_POWER_CYCLES",
+    .desc = "Cycles in L0",
+    .code = 0xc,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+  },
+  { .name = "UNC_Q_TXL_BYPASSED",
+    .desc = "Tx Flit Buffer Bypassed",
+    .code = 0x5,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+  },
+  { .name = "UNC_Q_TXL_CYCLES_NE",
+    .desc = "Tx Flit Buffer Cycles not Empty",
+    .code = 0x6,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+  },
+  { .name = "UNC_Q_TXL_FLITS_G0",
+    .desc = "Flits Transferred - Group 0",
+    .code = 0x0,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txl_flits_g0),
+    .umasks  = ivbep_unc_q_txl_flits_g0
+  },
+  { .name = "UNC_Q_TXL_FLITS_G1",
+    .desc = "Flits Transferred - Group 1",
+    .code = 0x0 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_rxl_flits_g1),
+    .umasks  = ivbep_unc_q_rxl_flits_g1 /* shared with rxl_flits_g1 */
+  },
+  { .name = "UNC_Q_TXL_FLITS_G2",
+    .desc = "Flits Transferred - Group 2",
+    .code = 0x1 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_rxl_flits_g2),
+    .umasks  = ivbep_unc_q_rxl_flits_g2 /* shared with rxl_flits_g2 */
+  },
+  { .name = "UNC_Q_TXL_INSERTS",
+    .desc = "Tx Flit Buffer Allocations",
+    .code = 0x4,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+  },
+  { .name = "UNC_Q_TXL_OCCUPANCY",
+    .desc = "Tx Flit Buffer Occupancy",
+    .code = 0x7,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+  },
+  { .name = "UNC_Q_VNA_CREDIT_RETURNS",
+    .desc = "VNA Credits Returned",
+    .code = 0x1c | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+  },
+  { .name = "UNC_Q_VNA_CREDIT_RETURN_OCCUPANCY",
+    .desc = "VNA Credits Pending Return - Occupancy",
+    .code = 0x1b | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+  },
+  { .name = "UNC_Q_TXR_AD_HOM_CREDIT_ACQUIRED",
+    .desc = "R3QPI Egress credit occupancy AD HOM",
+    .code = 0x26 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired),
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_TXR_AD_HOM_CREDIT_OCCUPANCY",
+    .desc = "R3QPI Egress credit occupancy AD HOM",
+    .code = 0x22 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired), /* shared */
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_TXR_AD_NDR_CREDIT_ACQUIRED",
+    .desc = "R3QPI Egress credit occupancy AD NDR",
+    .code = 0x28 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired),
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_TXR_AD_NDR_CREDIT_OCCUPANCY",
+    .desc = "R3QPI Egress credit occupancy AD NDR",
+    .code = 0x24 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired), /* shared */
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_TXR_AD_SNP_CREDIT_ACQUIRED",
+    .desc = "R3QPI Egress credit occupancy AD SNP",
+    .code = 0x27 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired),
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_TXR_AD_SNP_CREDIT_OCCUPANCY",
+    .desc = "R3QPI Egress credit occupancy AD SNP",
+    .code = 0x23 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired), /* shared */
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_TXR_AK_NDR_CREDIT_ACQUIRED",
+    .desc = "R3QPI Egress credit occupancy AK NDR",
+    .code = 0x29 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired),
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_TXR_AK_NDR_CREDIT_OCCUPANCY",
+    .desc = "R3QPI Egress credit occupancy AD NDR",
+    .code = 0x25 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired), /* shared */
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_TXR_BL_DRS_CREDIT_ACQUIRED",
+    .desc = "R3QPI Egress credit occupancy BL DRS",
+    .code = 0x2a | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_bl_drs_credit_acquired),
+    .umasks  = ivbep_unc_q_txr_bl_drs_credit_acquired,
+  },
+  { .name = "UNC_Q_TXR_BL_DRS_CREDIT_OCCUPANCY",
+    .desc = "R3QPI Egress credit occupancy BL DRS",
+    .code = 0x1f | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_bl_drs_credit_acquired), /* shared */
+    .umasks  = ivbep_unc_q_txr_bl_drs_credit_acquired,
+  },
+  { .name = "UNC_Q_TXR_BL_NCB_CREDIT_ACQUIRED",
+    .desc = "R3QPI Egress credit occupancy BL NCB",
+    .code = 0x2b | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired),
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_TXR_BL_NCB_CREDIT_OCCUPANCY",
+    .desc = "R3QPI Egress credit occupancy BL NCB",
+    .code = 0x20 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired), /* shared */
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_TXR_BL_NCS_CREDIT_ACQUIRED",
+    .desc = "R3QPI Egress credit occupancy BL NCS",
+    .code = 0x2c | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired),
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+  { .name = "UNC_Q_TXR_BL_NCS_CREDIT_OCCUPANCY",
+    .desc = "R3QPI Egress credit occupancy BL NCS",
+    .code = 0x21 | (1ULL << 21), /* sel_ext */
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_q_txr_ad_hom_credit_acquired), /* shared */
+    .umasks  = ivbep_unc_q_txr_ad_hom_credit_acquired,
+  },
+};
diff --git a/src/libpfm4/lib/events/intel_ivbep_unc_r2pcie_events.h b/src/libpfm4/lib/events/intel_ivbep_unc_r2pcie_events.h
new file mode 100644
index 0000000..59d96b9
--- /dev/null
+++ b/src/libpfm4/lib/events/intel_ivbep_unc_r2pcie_events.h
@@ -0,0 +1,253 @@
+/*
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * This file is part of libpfm, a performance monitoring support library for
+ * applications on Linux.
+ *
+ * This file has been automatically generated.
+ *
+ * PMU: ivbep_unc_r2pcie (Intel IvyBridge-EP R2PCIe uncore)
+ */
+
+static const intel_x86_umask_t ivbep_unc_r2_ring_ad_used[]={
+  { .uname = "CCW_VR0_EVEN",
+    .udesc  = "Counter-clockwise and even ring polarity on virtual ring 0",
+    .ucode  = 0x400,
+  },
+  { .uname = "CCW_VR0_ODD",
+    .udesc  = "Counter-clockwise and odd ring polarity on virtual ring 0",
+    .ucode  = 0x800,
+  },
+  { .uname = "CW_VR0_EVEN",
+    .udesc  = "Clockwise and even ring polarity on virtual ring 0",
+    .ucode  = 0x100,
+  },
+  { .uname = "CW_VR0_ODD",
+    .udesc  = "Clockwise and odd ring polarity on virtual ring 0",
+    .ucode  = 0x200,
+  },
+  { .uname = "CCW_VR1_EVEN",
+    .udesc  = "Counter-clockwise and even ring polarity on virtual ring 1",
+    .ucode  = 0x400,
+  },
+  { .uname = "CCW_VR1_ODD",
+    .udesc  = "Counter-clockwise and odd ring polarity on virtual ring 1",
+    .ucode  = 0x800,
+  },
+  { .uname = "CW_VR1_EVEN",
+    .udesc  = "Clockwise and even ring polarity on virtual ring 1",
+    .ucode  = 0x100,
+  },
+  { .uname = "CW_VR1_ODD",
+    .udesc  = "Clockwise and odd ring polarity on virtual ring 1",
+    .ucode  = 0x200,
+  },
+  { .uname = "CW",
+    .udesc  = "Clockwise with any polarity on either virtual rings",
+    .ucode  = 0x3300,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "CCW",
+    .udesc  = "Counter-clockwise with any polarity on either virtual rings",
+    .ucode  = 0xcc00,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_r2_rxr_ak_bounces[]={
+  { .uname = "CW",
+    .udesc  = "Clockwise",
+    .ucode  = 0x100,
+  },
+  { .uname = "CCW",
+    .udesc  = "Counter-clockwise",
+    .ucode  = 0x200,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_r2_rxr_occupancy[]={
+  { .uname = "DRS",
+    .udesc  = "DRS Ingress queue",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_r2_ring_iv_used[]={
+  { .uname = "CW",
+    .udesc  = "Clockwise with any polarity on either virtual rings",
+    .ucode  = 0x3300,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "CCW",
+    .udesc  = "Counter-clockwise with any polarity on either virtual rings",
+    .ucode  = 0xcc00,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ANY",
+    .udesc  = "any direction and any polarity on any virtual ring",
+    .ucode  = 0xff00,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_r2_rxr_cycles_ne[]={
+  { .uname = "NCB",
+    .udesc  = "NCB Ingress queue",
+    .ucode  = 0x1000,
+  },
+  { .uname = "NCS",
+    .udesc  = "NCS Ingress queue",
+    .ucode  = 0x2000,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_r2_txr_cycles_full[]={
+  { .uname = "AD",
+    .udesc  = "AD Egress queue",
+    .ucode  = 0x100,
+  },
+  { .uname = "AK",
+    .udesc  = "AK Egress queue",
+    .ucode  = 0x200,
+  },
+  { .uname = "BL",
+    .udesc  = "BL Egress queue",
+    .ucode  = 0x400,
+  },
+};
+
+static const intel_x86_entry_t intel_ivbep_unc_r2_pe[]={
+  { .name = "UNC_R2_CLOCKTICKS",
+    .desc = "Number of uclks in domain",
+    .code = 0x1,
+    .cntmsk = 0xf,
+    .modmsk = IVBEP_UNC_R2PCIE_ATTRS,
+  },
+  { .name = "UNC_R2_RING_AD_USED",
+    .desc = "R2 AD Ring in Use",
+    .code = 0x7,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R2PCIE_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r2_ring_ad_used),
+    .umasks  = ivbep_unc_r2_ring_ad_used
+  },
+  { .name = "UNC_R2_RING_AK_USED",
+    .desc = "R2 AK Ring in Use",
+    .code = 0x8,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R2PCIE_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r2_ring_ad_used),
+    .umasks  = ivbep_unc_r2_ring_ad_used /* shared */
+  },
+  { .name = "UNC_R2_RING_BL_USED",
+    .desc = "R2 BL Ring in Use",
+    .code = 0x9,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R2PCIE_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r2_ring_ad_used),
+    .umasks  = ivbep_unc_r2_ring_ad_used /* shared */
+  },
+  { .name = "UNC_R2_RING_IV_USED",
+    .desc = "R2 IV Ring in Use",
+    .code = 0xa,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R2PCIE_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r2_ring_iv_used),
+    .umasks  = ivbep_unc_r2_ring_iv_used
+  },
+  { .name = "UNC_R2_RXR_AK_BOUNCES",
+    .desc = "AK Ingress Bounced",
+    .code = 0x12,
+    .cntmsk = 0x1,
+    .modmsk = IVBEP_UNC_R2PCIE_ATTRS,
+    .ngrp = 1,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r2_rxr_ak_bounces),
+    .umasks  = ivbep_unc_r2_rxr_ak_bounces
+  },
+  { .name = "UNC_R2_RXR_OCCUPANCY",
+    .desc = "Ingress occpancy accumulator",
+    .code = 0x13,
+    .cntmsk = 0x1,
+    .modmsk = IVBEP_UNC_R2PCIE_ATTRS,
+    .ngrp = 1,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r2_rxr_occupancy),
+    .umasks  = ivbep_unc_r2_rxr_occupancy
+  },
+  { .name = "UNC_R2_RXR_CYCLES_NE",
+    .desc = "Ingress Cycles Not Empty",
+    .code = 0x10,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R2PCIE_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r2_rxr_cycles_ne),
+    .umasks  = ivbep_unc_r2_rxr_cycles_ne
+  },
+  { .name = "UNC_R2_RXR_INSERTS",
+    .desc = "Ingress inserts",
+    .code = 0x11,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R2PCIE_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r2_rxr_cycles_ne),
+    .umasks  = ivbep_unc_r2_rxr_cycles_ne, /* shared */
+  },
+  { .name = "UNC_R2_TXR_CYCLES_FULL",
+    .desc = "Egress Cycles Full",
+    .code = 0x25,
+    .cntmsk = 0x1,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R2PCIE_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r2_txr_cycles_full),
+    .umasks  = ivbep_unc_r2_txr_cycles_full
+  },
+  { .name = "UNC_R2_TXR_CYCLES_NE",
+    .desc = "Egress Cycles Not Empty",
+    .code = 0x23,
+    .cntmsk = 0x1,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R2PCIE_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r2_txr_cycles_full),
+    .umasks  = ivbep_unc_r2_txr_cycles_full /* shared */
+  },
+  { .name = "UNC_R2_TXR_NACK_CCW",
+    .desc = "Egress counter-clockwise BACK",
+    .code = 0x28,
+    .cntmsk = 0x1,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R2PCIE_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r2_txr_cycles_full),
+    .umasks  = ivbep_unc_r2_txr_cycles_full /* shared */
+  },
+  { .name = "UNC_R2_TXR_NACK_CW",
+    .desc = "Egress clockwise BACK",
+    .code = 0x26,
+    .cntmsk = 0x1,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R2PCIE_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r2_txr_cycles_full),
+    .umasks  = ivbep_unc_r2_txr_cycles_full /* shared */
+  },
+};
diff --git a/src/libpfm4/lib/events/intel_ivbep_unc_r3qpi_events.h b/src/libpfm4/lib/events/intel_ivbep_unc_r3qpi_events.h
new file mode 100644
index 0000000..75cb533
--- /dev/null
+++ b/src/libpfm4/lib/events/intel_ivbep_unc_r3qpi_events.h
@@ -0,0 +1,552 @@
+/*
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * This file is part of libpfm, a performance monitoring support library for
+ * applications on Linux.
+ *
+ * This file has been automatically generated.
+ *
+ * PMU: ivbep_unc_r3qpi (Intel IvyBridge-EP R3QPI uncore)
+ */
+
+static const intel_x86_umask_t ivbep_unc_r3_iio_credits_acquired[]={
+  { .uname = "DRS",
+    .udesc  = "DRS",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NCB",
+    .udesc  = "NCB",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NCS",
+    .udesc  = "NCS",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_r3_ring_ad_used[]={
+  { .uname = "CCW_VR0_EVEN",
+    .udesc  = "Counter-Clockwise and even ring polarity on virtual ring 0",
+    .ucode  = 0x400,
+  },
+  { .uname = "CCW_VR0_ODD",
+    .udesc  = "Counter-Clockwise and odd ring polarity on virtual ring 0",
+    .ucode  = 0x800,
+  },
+  { .uname = "CW_VR0_EVEN",
+    .udesc  = "Clockwise and even ring polarity on virtual ring 0",
+    .ucode  = 0x100,
+  },
+  { .uname = "CW_VR0_ODD",
+    .udesc  = "Clockwise and odd ring polarity on virtual ring 0",
+    .ucode  = 0x200,
+  },
+  { .uname = "CW",
+    .udesc  = "Clockwise with any polarity on either virtual rings",
+    .ucode  = 0x3300,
+  },
+  { .uname = "CCW",
+    .udesc  = "Counter-clockwise with any polarity on either virtual rings",
+    .ucode  = 0xcc00,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_r3_ring_iv_used[]={
+  { .uname = "CW",
+    .udesc  = "Clockwise with any polarity on either virtual rings",
+    .ucode  = 0x3300,
+  },
+  { .uname = "CCW",
+    .udesc  = "Counter-clockwise with any polarity on either virtual rings",
+    .ucode  = 0xcc00,
+  },
+  { .uname = "ANY",
+    .udesc  = "Counter-clockwise with any polarity on either virtual rings",
+    .ucode  = 0xff00,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_r3_rxr_cycles_ne[]={
+  { .uname = "HOM",
+    .udesc  = "HOM Ingress queue",
+    .ucode  = 0x100,
+  },
+  { .uname = "SNP",
+    .udesc  = "SNP Ingress queue",
+    .ucode  = 0x200,
+  },
+  { .uname = "NDR",
+    .udesc  = "NDR Ingress queue",
+    .ucode  = 0x400,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_r3_rxr_inserts[]={
+  { .uname = "DRS",
+    .udesc  = "DRS Ingress queue",
+    .ucode  = 0x800,
+  },
+  { .uname = "HOM",
+    .udesc  = "HOM Ingress queue",
+    .ucode  = 0x100,
+  },
+  { .uname = "NCB",
+    .udesc  = "NCB Ingress queue",
+    .ucode  = 0x1000,
+  },
+  { .uname = "NCS",
+    .udesc  = "NCS Ingress queue",
+    .ucode  = 0x2000,
+  },
+  { .uname = "NDR",
+    .udesc  = "NDR Ingress queue",
+    .ucode  = 0x400,
+  },
+  { .uname = "SNP",
+    .udesc  = "SNP Ingress queue",
+    .ucode  = 0x200,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_r3_vn0_credits_used[]={
+  { .uname = "HOM",
+    .udesc  = "Filter HOM message class",
+    .ucode  = 0x100,
+  },
+  { .uname = "SNP",
+    .udesc  = "Filter SNP message class",
+    .ucode  = 0x200,
+  },
+  { .uname = "NDR",
+    .udesc  = "Filter NDR message class",
+    .ucode  = 0x400,
+  },
+  { .uname = "DRS",
+    .udesc  = "Filter DRS message class",
+    .ucode  = 0x800,
+  },
+  { .uname = "NCB",
+    .udesc  = "Filter NCB message class",
+    .ucode  = 0x1000,
+  },
+  { .uname = "NCS",
+    .udesc  = "Filter NCS message class",
+    .ucode  = 0x2000,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_r3_c_hi_ad_credits_empty[]={
+  { .uname = "CBO8",
+    .udesc  = "CBox 8",
+    .ucode  = 0x100,
+  },
+  { .uname = "CBO9",
+    .udesc  = "CBox 9",
+    .ucode  = 0x200,
+  },
+  { .uname = "CBO10",
+    .udesc  = "CBox 10",
+    .ucode  = 0x400,
+  },
+  { .uname = "CBO11",
+    .udesc  = "CBox 11",
+    .ucode  = 0x800,
+  },
+  { .uname = "CBO12",
+    .udesc  = "CBox 12",
+    .ucode  = 0x1000,
+  },
+  { .uname = "CBO13",
+    .udesc  = "CBox 13",
+    .ucode  = 0x2000,
+  },
+  { .uname = "CBO14",
+    .udesc  = "CBox 14 & 16",
+    .ucode  = 0x4000,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_r3_c_lo_ad_credits_empty[]={
+  { .uname = "CBO0",
+    .udesc  = "CBox 0",
+    .ucode  = 0x100,
+  },
+  { .uname = "CBO1",
+    .udesc  = "CBox 1",
+    .ucode  = 0x200,
+  },
+  { .uname = "CBO2",
+    .udesc  = "CBox 2",
+    .ucode  = 0x400,
+  },
+  { .uname = "CBO3",
+    .udesc  = "CBox 3",
+    .ucode  = 0x800,
+  },
+  { .uname = "CBO4",
+    .udesc  = "CBox 4",
+    .ucode  = 0x1000,
+  },
+  { .uname = "CBO5",
+    .udesc  = "CBox 5",
+    .ucode  = 0x2000,
+  },
+  { .uname = "CBO6",
+    .udesc  = "CBox 6",
+    .ucode  = 0x4000,
+  },
+  { .uname = "CBO7",
+    .udesc  = "CBox 7",
+    .ucode  = 0x8000,
+  }
+};
+
+static const intel_x86_umask_t ivbep_unc_r3_ha_r2_bl_credits_empty[]={
+  { .uname = "HA0",
+    .udesc  = "HA0",
+    .ucode  = 0x100,
+  },
+  { .uname = "HA1",
+    .udesc  = "HA1",
+    .ucode  = 0x200,
+  },
+  { .uname = "R2_NCB",
+    .udesc  = "R2 NCB messages",
+    .ucode  = 0x400,
+  },
+  { .uname = "R2_NCS",
+    .udesc  = "R2 NCS messages",
+    .ucode  = 0x800,
+  }
+};
+
+static const intel_x86_umask_t ivbep_unc_r3_qpi0_ad_credits_empty[]={
+  { .uname = "VNA",
+    .udesc  = "VNA",
+    .ucode  = 0x100,
+  },
+  { .uname = "VN0_HOM",
+    .udesc  = "VN0 HOM messages",
+    .ucode  = 0x200,
+  },
+  { .uname = "VN0_SNP",
+    .udesc  = "VN0 SNP messages",
+    .ucode  = 0x400,
+  },
+  { .uname = "VN0_NDR",
+    .udesc  = "VN0 NDR messages",
+    .ucode  = 0x800,
+  },
+  { .uname = "VN1_HOM",
+    .udesc  = "VN1 HOM messages",
+    .ucode  = 0x1000,
+  },
+  { .uname = "VN1_SNP",
+    .udesc  = "VN1 SNP messages",
+    .ucode  = 0x2000,
+  },
+  { .uname = "VN1_NDR",
+    .udesc  = "VN1 NDR messages",
+    .ucode  = 0x4000,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_r3_txr_nack_ccw[]={
+  { .uname = "AD",
+    .udesc  = "BL counter-clockwise Egress queue",
+    .ucode  = 0x100,
+  },
+  { .uname = "AK",
+    .udesc  = "AD clockwise Egress queue",
+    .ucode  = 0x200,
+  },
+  { .uname = "BL",
+    .udesc  = "AD counter-clockwise Egress queue",
+    .ucode  = 0x400,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_r3_txr_nack_cw[]={
+  { .uname = "AD",
+    .udesc  = "AD clockwise Egress queue",
+    .ucode  = 0x100,
+  },
+  { .uname = "AK",
+    .udesc  = "AD counter-clockwise Egress queue",
+    .ucode  = 0x200,
+  },
+  { .uname = "BL",
+    .udesc  = "BL clockwise Egress queue",
+    .ucode  = 0x400,
+  },
+};
+
+static const intel_x86_umask_t ivbep_unc_r3_vna_credits_acquired[]={
+  { .uname = "AD",
+    .udesc  = "For AD ring",
+    .ucode  = 0x100,
+  },
+  { .uname = "BL",
+    .udesc  = "For BL ring",
+    .ucode  = 0x400,
+  },
+};
+
+static const intel_x86_entry_t intel_ivbep_unc_r3_pe[]={
+  { .name = "UNC_R3_CLOCKTICKS",
+    .desc = "Number of uclks in domain",
+    .code = 0x1,
+    .cntmsk = 0x7,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+  },
+  { .name = "UNC_R3_RING_AD_USED",
+    .desc = "R3 AD Ring in Use",
+    .code = 0x7,
+    .cntmsk = 0x7,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_ring_ad_used),
+    .umasks  = ivbep_unc_r3_ring_ad_used
+  },
+  { .name = "UNC_R3_RING_AK_USED",
+    .desc = "R3 AK Ring in Use",
+    .code = 0x8,
+    .cntmsk = 0x7,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_ring_ad_used),
+    .umasks  = ivbep_unc_r3_ring_ad_used /* shared */
+  },
+  { .name = "UNC_R3_RING_BL_USED",
+    .desc = "R3 BL Ring in Use",
+    .code = 0x9,
+    .cntmsk = 0x7,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_ring_ad_used),
+    .umasks  = ivbep_unc_r3_ring_ad_used /* shared */
+  },
+  { .name = "UNC_R3_RING_IV_USED",
+    .desc = "R3 IV Ring in Use",
+    .code = 0xa,
+    .cntmsk = 0x7,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_ring_iv_used),
+    .umasks  = ivbep_unc_r3_ring_iv_used
+  },
+  { .name = "UNC_R3_RXR_AD_BYPASSED",
+    .desc = "Ingress Bypassed",
+    .code = 0x12,
+    .cntmsk = 0x3,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+  },
+  { .name = "UNC_R3_RXR_CYCLES_NE",
+    .desc = "Ingress Cycles Not Empty",
+    .code = 0x10,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_rxr_cycles_ne),
+    .umasks  = ivbep_unc_r3_rxr_cycles_ne
+  },
+  { .name = "UNC_R3_RXR_INSERTS",
+    .desc = "Ingress Allocations",
+    .code = 0x11,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_rxr_inserts),
+    .umasks  = ivbep_unc_r3_rxr_inserts
+  },
+  { .name = "UNC_R3_RXR_OCCUPANCY",
+    .desc = "Ingress Occupancy Accumulator",
+    .code = 0x13,
+    .cntmsk = 0x1,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_rxr_inserts),
+    .umasks  = ivbep_unc_r3_rxr_inserts/* shared */
+  },
+  { .name = "UNC_R3_TXR_CYCLES_FULL",
+    .desc = "Egress cycles full",
+    .code = 0x25,
+    .cntmsk = 0x3,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+  },
+  { .name = "UNC_R3_VN0_CREDITS_REJECT",
+    .desc = "VN0 Credit Acquisition Failed",
+    .code = 0x37,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_vn0_credits_used),
+    .umasks  = ivbep_unc_r3_vn0_credits_used
+  },
+  { .name = "UNC_R3_VN0_CREDITS_USED",
+    .desc = "VN0 Credit Used",
+    .code = 0x36,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_vn0_credits_used),
+    .umasks  = ivbep_unc_r3_vn0_credits_used
+  },
+  { .name = "UNC_R3_VNA_CREDITS_ACQUIRED",
+    .desc = "VNA credit Acquisitions",
+    .code = 0x33,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_vna_credits_acquired),
+    .umasks  = ivbep_unc_r3_vna_credits_acquired
+  },
+  { .name = "UNC_R3_VNA_CREDITS_REJECT",
+    .desc = "VNA Credit Reject",
+    .code = 0x34,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_vn0_credits_used),
+    .umasks  = ivbep_unc_r3_vn0_credits_used /* shared */
+  },
+  { .name = "UNC_R3_VNA_CREDIT_CYCLES_OUT",
+    .desc = "Cycles with no VNA credits available",
+    .code = 0x31,
+    .cntmsk = 0x3,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+  },
+  { .name = "UNC_R3_VNA_CREDIT_CYCLES_USED",
+    .desc = "Cycles with 1 or more VNA credits in use",
+    .code = 0x32,
+    .cntmsk = 0x3,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+  },
+  { .name = "UNC_R3_C_HI_AD_CREDITS_EMPTY",
+    .desc = "Cbox AD credits empty",
+    .code = 0x2c,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_c_hi_ad_credits_empty),
+    .umasks  = ivbep_unc_r3_c_hi_ad_credits_empty
+  },
+  { .name = "UNC_R3_C_LO_AD_CREDITS_EMPTY",
+    .desc = "Cbox AD credits empty",
+    .code = 0x2b,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_c_lo_ad_credits_empty),
+    .umasks  = ivbep_unc_r3_c_lo_ad_credits_empty
+  },
+  { .name = "UNC_R3_HA_R2_BL_CREDITS_EMPTY",
+    .desc = "HA/R2 AD credits  empty",
+    .code = 0x2f,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_ha_r2_bl_credits_empty),
+    .umasks  = ivbep_unc_r3_ha_r2_bl_credits_empty
+  },
+  { .name = "UNC_R3_QPI0_AD_CREDITS_EMPTY",
+    .desc = "QPI0 AD credits empty",
+    .code = 0x29,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_qpi0_ad_credits_empty),
+    .umasks  = ivbep_unc_r3_qpi0_ad_credits_empty
+  },
+  { .name = "UNC_R3_QPI0_BL_CREDITS_EMPTY",
+    .desc = "QPI0 BL credits empty",
+    .code = 0x2d,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_qpi0_ad_credits_empty), /* shared */
+    .umasks  = ivbep_unc_r3_qpi0_ad_credits_empty
+  },
+  { .name = "UNC_R3_QPI1_AD_CREDITS_EMPTY",
+    .desc = "QPI1 AD credits empty",
+    .code = 0x2a,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_qpi0_ad_credits_empty), /* shared */
+    .umasks  = ivbep_unc_r3_qpi0_ad_credits_empty
+  },
+  { .name = "UNC_R3_QPI1_BL_CREDITS_EMPTY",
+    .desc = "QPI1 BL credits empty",
+    .code = 0x2e,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_qpi0_ad_credits_empty), /* shared */
+    .umasks  = ivbep_unc_r3_qpi0_ad_credits_empty
+  },
+  { .name = "UNC_R3_TXR_CYCLES_NE",
+    .desc = "Egress cycles not empty",
+    .code = 0x23,
+    .cntmsk = 0x3,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+  },
+  { .name = "UNC_R3_TXR_NACK_CCW",
+    .desc = "Egress NACK counter-clockwise",
+    .code = 0x28,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_txr_nack_ccw),
+    .umasks  = ivbep_unc_r3_txr_nack_ccw
+  },
+  { .name = "UNC_R3_TXR_NACK_CW",
+    .desc = "Egress NACK counter-clockwise",
+    .code = 0x26,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_txr_nack_cw),
+    .umasks  = ivbep_unc_r3_txr_nack_cw
+  },
+  { .name = "UNC_R3_VN1_CREDITS_REJECT",
+    .desc = "VN1 Credit Acquisition Failed",
+    .code = 0x39,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_vn0_credits_used), /* shared */
+    .umasks  = ivbep_unc_r3_vn0_credits_used
+  },
+  { .name = "UNC_R3_VN1_CREDITS_USED",
+    .desc = "VN0 Credit Used",
+    .code = 0x38,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_R3QPI_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_r3_vn0_credits_used), /* shared */
+    .umasks  = ivbep_unc_r3_vn0_credits_used
+  },
+};
diff --git a/src/libpfm4/lib/events/intel_ivbep_unc_ubo_events.h b/src/libpfm4/lib/events/intel_ivbep_unc_ubo_events.h
new file mode 100644
index 0000000..ce08bde
--- /dev/null
+++ b/src/libpfm4/lib/events/intel_ivbep_unc_ubo_events.h
@@ -0,0 +1,101 @@
+/*
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * This file is part of libpfm, a performance monitoring support library for
+ * applications on Linux.
+ *
+ * PMU: ivbep_unc_ubo (Intel IvyBridge-EP U-Box uncore PMU)
+ */
+
+static const intel_x86_umask_t ivbep_unc_u_event_msg[]={
+  { .uname = "DOORBELL_RCVD",
+    .udesc  = "TBD",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "INT_PRIO",
+    .udesc  = "TBD",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "IPI_RCVD",
+    .udesc  = "TBD",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MSI_RCVD",
+    .udesc  = "TBD",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "VLW_RCVD",
+    .udesc  = "TBD",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+
+static const intel_x86_umask_t ivbep_unc_u_phold_cycles[]={
+  { .uname = "ASSERT_TO_ACK",
+    .udesc  = "Number of cycles asserted to ACK",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ACK_TO_DEASSERT",
+    .udesc  = "Number of cycles ACK to deassert",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_entry_t intel_ivbep_unc_u_pe[]={
+  { .name = "UNC_U_EVENT_MSG",
+    .desc = "VLW Received",
+    .code = 0x42,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_UBO_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_u_event_msg),
+    .umasks  = ivbep_unc_u_event_msg
+  },
+  { .name = "UNC_U_LOCK_CYCLES",
+    .desc = "IDI Lock/SplitLock Cycles",
+    .code = 0x44,
+    .cntmsk = 0x3,
+    .modmsk = IVBEP_UNC_UBO_ATTRS,
+  },
+  { .name = "UNC_U_PHOLD_CYCLES",
+    .desc = "Cycles PHOLD asserts to Ack",
+    .code = 0x45,
+    .cntmsk = 0x3,
+    .ngrp = 1,
+    .modmsk = IVBEP_UNC_UBO_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_u_phold_cycles),
+    .umasks  = ivbep_unc_u_phold_cycles
+  },
+  { .name = "UNC_U_RACU_REQUESTS",
+    .desc = "RACU requests",
+    .code = 0x46,
+    .cntmsk = 0x3,
+    .modmsk = IVBEP_UNC_UBO_ATTRS,
+  },
+};
diff --git a/src/libpfm4/lib/events/intel_snbep_unc_cbo_events.h b/src/libpfm4/lib/events/intel_snbep_unc_cbo_events.h
index b2f0878..40d3e37 100644
--- a/src/libpfm4/lib/events/intel_snbep_unc_cbo_events.h
+++ b/src/libpfm4/lib/events/intel_snbep_unc_cbo_events.h
@@ -165,7 +165,7 @@ static const intel_x86_umask_t snbep_unc_c_llc_lookup[]={
    { .uname  = "DATA_READ",
      .udesc  = "Data read requests",
      .grpid  = 0,
-     .uflags = INTEL_X86_NCOMBO,
+     .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
      .ucode = 0x300,
    },
    { .uname  = "WRITE",
@@ -182,12 +182,12 @@ static const intel_x86_umask_t snbep_unc_c_llc_lookup[]={
    },
    { .uname  = "NID",
      .udesc  = "Match a given RTID destination NID",
-     .uflags = INTEL_X86_NCOMBO,
+     .uflags = INTEL_X86_NCOMBO | INTEL_X86_GRP_DFL_NONE,
      .umodmsk_req = _SNBEP_UNC_ATTR_NF,
-     .grpid  = 0,
+     .grpid  = 1,
      .ucode = 0x4100,
    },
-   CBO_FILT_MESIFS(1),
+   CBO_FILT_MESIFS(2),
 };
 
 static const intel_x86_umask_t snbep_unc_c_llc_victims[]={
@@ -626,7 +626,7 @@ static const intel_x86_entry_t intel_snbep_unc_c_pe[]={
     .modmsk = SNBEP_UNC_CBO_NID_ATTRS,
     .cntmsk = 0x3,
     .code = 0x34,
-    .ngrp = 2,
+    .ngrp = 3,
     .flags = INTEL_X86_NO_AUTOENCODE,
     .numasks = LIBPFM_ARRAY_SIZE(snbep_unc_c_llc_lookup),
     .umasks = snbep_unc_c_llc_lookup,
diff --git a/src/libpfm4/lib/events/s390x_cpumf_events.h b/src/libpfm4/lib/events/s390x_cpumf_events.h
index 9628cee..e00b088 100644
--- a/src/libpfm4/lib/events/s390x_cpumf_events.h
+++ b/src/libpfm4/lib/events/s390x_cpumf_events.h
@@ -6,14 +6,14 @@
 #define STRINGIFY(x)		__stringify(x)
 
 /* CPUMF counter sets */
-#define CPUMF_CTRSET_BASIC	      0
-#define CPUMF_CTRSET_PROBLEM_STATE    1
-#define CPUMF_CTRSET_CRYPTO	      2
-#define CPUMF_CTRSET_EXTENDED	      3
+#define CPUMF_CTRSET_NONE               0
+#define CPUMF_CTRSET_BASIC              2
+#define CPUMF_CTRSET_PROBLEM_STATE      4
+#define CPUMF_CTRSET_CRYPTO             8
+#define CPUMF_CTRSET_EXTENDED           1
 
 
-static const pme_cpumf_ctr_t cpumf_generic_ctr[] = {
-	/* Basic counter set */
+static const pme_cpumf_ctr_t cpumcf_generic_counters[] = {
 	{
 		.ctrnum = 0,
 		.ctrset = CPUMF_CTRSET_BASIC,
@@ -29,7 +29,7 @@ static const pme_cpumf_ctr_t cpumf_generic_ctr[] = {
 	{
 		.ctrnum = 2,
 		.ctrset = CPUMF_CTRSET_BASIC,
-		.name = "L1I_DRCT_WRITES",
+		.name = "L1I_DIR_WRITES",
 		.desc = "Level-1 I-Cache Directory Write Count",
 	},
 	{
@@ -41,7 +41,7 @@ static const pme_cpumf_ctr_t cpumf_generic_ctr[] = {
 	{
 		.ctrnum = 4,
 		.ctrset = CPUMF_CTRSET_BASIC,
-		.name = "L1D_DRCT_WRITES",
+		.name = "L1D_DIR_WRITES",
 		.desc = "Level-1 D-Cache Directory Write Count",
 	},
 	{
@@ -50,7 +50,6 @@ static const pme_cpumf_ctr_t cpumf_generic_ctr[] = {
 		.name = "L1D_PENALTY_CYCLES",
 		.desc = "Level-1 D-Cache Penalty Cycle Count",
 	},
-	/* Problem-state counter set */
 	{
 		.ctrnum = 32,
 		.ctrset = CPUMF_CTRSET_PROBLEM_STATE,
@@ -66,7 +65,7 @@ static const pme_cpumf_ctr_t cpumf_generic_ctr[] = {
 	{
 		.ctrnum = 34,
 		.ctrset = CPUMF_CTRSET_PROBLEM_STATE,
-		.name = "PROBLEM_STATE_L1I_DRCT_WRITES",
+		.name = "PROBLEM_STATE_L1I_DIR_WRITES",
 		.desc = "Problem-State Level-1 I-Cache Directory Write Count",
 	},
 	{
@@ -78,7 +77,7 @@ static const pme_cpumf_ctr_t cpumf_generic_ctr[] = {
 	{
 		.ctrnum = 36,
 		.ctrset = CPUMF_CTRSET_PROBLEM_STATE,
-		.name = "PROBLEM_STATE_L1D_DRCT_WRITES",
+		.name = "PROBLEM_STATE_L1D_DIR_WRITES",
 		.desc = "Problem-State Level-1 D-Cache Directory Write Count",
 	},
 	{
@@ -87,38 +86,38 @@ static const pme_cpumf_ctr_t cpumf_generic_ctr[] = {
 		.name = "PROBLEM_STATE_L1D_PENALTY_CYCLES",
 		.desc = "Problem-State Level-1 D-Cache Penalty Cycle Count",
 	},
-	/* Crypto-activity counter set */
 	{
 		.ctrnum = 64,
 		.ctrset = CPUMF_CTRSET_CRYPTO,
 		.name = "PRNG_FUNCTIONS",
-		.desc = "Total number of the PRNG functions issued by the CPU",
+		.desc = "Total number of the PRNG functions issued by the"
+			" CPU",
 	},
 	{
 		.ctrnum = 65,
 		.ctrset = CPUMF_CTRSET_CRYPTO,
 		.name = "PRNG_CYCLES",
-		.desc = "Total number of CPU cycles when the DEA/AES "
-			"coprocessor is busy performing PRNG functions "
-			"issued by the CPU",
+		.desc = "Total number of CPU cycles when the DEA/AES"
+			" coprocessor is busy performing PRNG functions"
+			" issued by the CPU",
 	},
 	{
 		.ctrnum = 66,
 		.ctrset = CPUMF_CTRSET_CRYPTO,
 		.name = "PRNG_BLOCKED_FUNCTIONS",
-		.desc = "Total number of the PRNG functions that are issued "
-			"by the CPU and are blocked because the DEA/AES "
-			"coprocessor is busy performing a function issued "
-			"by another CPU",
+		.desc = "Total number of the PRNG functions that are issued"
+			" by the CPU and are blocked because the DEA/AES"
+			" coprocessor is busy performing a function issued by"
+			" another CPU",
 	},
 	{
 		.ctrnum = 67,
 		.ctrset = CPUMF_CTRSET_CRYPTO,
 		.name = "PRNG_BLOCKED_CYCLES",
-		.desc = "Total number of CPU cycles blocked for the PRNG "
-			"functions issued by the CPU because the DEA/AES "
-			"coprocessor is busy performing a function issued "
-			"by another CPU",
+		.desc = "Total number of CPU cycles blocked for the PRNG"
+			" functions issued by the CPU because the DEA/AES"
+			" coprocessor is busy performing a function issued by"
+			" another CPU",
 	},
 	{
 		.ctrnum = 68,
@@ -130,26 +129,27 @@ static const pme_cpumf_ctr_t cpumf_generic_ctr[] = {
 		.ctrnum = 69,
 		.ctrset = CPUMF_CTRSET_CRYPTO,
 		.name = "SHA_CYCLES",
-		.desc = "Total number of CPU cycles when the SHA coprocessor "
-			"is busy performing the SHA functions issued by the "
-			"CPU",
+		.desc = "Total number of CPU cycles when the SHA coprocessor"
+			" is busy performing the SHA functions issued by the"
+			" CPU",
 	},
 	{
 		.ctrnum = 70,
 		.ctrset = CPUMF_CTRSET_CRYPTO,
 		.name = "SHA_BLOCKED_FUNCTIONS",
-		.desc = "Total number of the SHA functions that are issued by "
-			"the CPU and are blocked because the SHA coprocessor "
-			"is busy performing a function issued by another CPU",
+		.desc = "Total number of the SHA functions that are issued"
+			" by the CPU and are blocked because the SHA"
+			" coprocessor is busy performing a function issued by"
+			" another CPU",
 	},
 	{
 		.ctrnum = 71,
 		.ctrset = CPUMF_CTRSET_CRYPTO,
 		.name = "SHA_BLOCKED_CYCLES",
-		.desc = "Total number of CPU cycles blocked for the SHA "
-			"functions issued by the CPU because the SHA "
-			"coprocessor is busy performing a function issued by "
-			"another CPU",
+		.desc = "Total number of CPU cycles blocked for the SHA"
+			" functions issued by the CPU because the SHA"
+			" coprocessor is busy performing a function issued by"
+			" another CPU",
 	},
 	{
 		.ctrnum = 72,
@@ -161,24 +161,27 @@ static const pme_cpumf_ctr_t cpumf_generic_ctr[] = {
 		.ctrnum = 73,
 		.ctrset = CPUMF_CTRSET_CRYPTO,
 		.name = "DEA_CYCLES",
-		.desc = "Total number of CPU cycles when the DEA/AES coprocessor"
-			" is busy performing the DEA functions issued by the CPU",
+		.desc = "Total number of CPU cycles when the DEA/AES"
+			" coprocessor is busy performing the DEA functions"
+			" issued by the CPU",
 	},
 	{
 		.ctrnum = 74,
 		.ctrset = CPUMF_CTRSET_CRYPTO,
 		.name = "DEA_BLOCKED_FUNCTIONS",
-		.desc = "Total number of the DEA functions that are issued by "
-			"the CPU and are blocked because the DEA/AES coprocessor"
-			" is busy performing a function issued by another CPU",
+		.desc = "Total number of the DEA functions that are issued"
+			" by the CPU and are blocked because the DEA/AES"
+			" coprocessor is busy performing a function issued by"
+			" another CPU",
 	},
 	{
 		.ctrnum = 75,
 		.ctrset = CPUMF_CTRSET_CRYPTO,
 		.name = "DEA_BLOCKED_CYCLES",
-		.desc = "Total number of CPU cycles blocked for the DEA functions"
-			" issued by the CPU because the DEA/AES coprocessor is "
-			"busy performing a function issued by another CPU",
+		.desc = "Total number of CPU cycles blocked for the DEA"
+			" functions issued by the CPU because the DEA/AES"
+			" coprocessor is busy performing a function issued by"
+			" another CPU",
 	},
 	{
 		.ctrnum = 76,
@@ -190,29 +193,31 @@ static const pme_cpumf_ctr_t cpumf_generic_ctr[] = {
 		.ctrnum = 77,
 		.ctrset = CPUMF_CTRSET_CRYPTO,
 		.name = "AES_CYCLES",
-		.desc = "Total number of CPU cycles when the DEA/AES coprocessor"
-			" is busy performing the AES functions issued by the CPU",
+		.desc = "Total number of CPU cycles when the DEA/AES"
+			" coprocessor is busy performing the AES functions"
+			" issued by the CPU",
 	},
 	{
 		.ctrnum = 78,
 		.ctrset = CPUMF_CTRSET_CRYPTO,
 		.name = "AES_BLOCKED_FUNCTIONS",
-		.desc = "Total number of AES functions that are issued by the CPU"
-			" and are blocked because the DEA/AES coprocessor is"
-			" busy performing a function issued by another CPU",
+		.desc = "Total number of AES functions that are issued by"
+			" the CPU and are blocked because the DEA/AES"
+			" coprocessor is busy performing a function issued by"
+			" another CPU",
 	},
 	{
 		.ctrnum = 79,
 		.ctrset = CPUMF_CTRSET_CRYPTO,
 		.name = "AES_BLOCKED_CYCLES",
-		.desc = "Total number of CPU cycles blocked for the AES functions"
-			" issued by the CPU because the DEA/AES coprocessor is"
-			" busy performing a function issued by another CPU",
+		.desc = "Total number of CPU cycles blocked for the AES"
+			" functions issued by the CPU because the DEA/AES"
+			" coprocessor is busy performing a function issued by"
+			" another CPU",
 	},
 };
 
-/* Extended counter set for IBM System z10 */
-static const pme_cpumf_ctr_t cpumf_ctr_set_ext_z10[] = {
+static const pme_cpumf_ctr_t cpumcf_z10_counters[] = {
 	{
 		.ctrnum = 128,
 		.ctrset = CPUMF_CTRSET_EXTENDED,
@@ -243,9 +248,9 @@ static const pme_cpumf_ctr_t cpumf_ctr_set_ext_z10[] = {
 		.ctrset = CPUMF_CTRSET_EXTENDED,
 		.name = "L1D_L3_LOCAL_WRITES",
 		.desc = "A directory write to the Level-1 D-Cache directory"
-			" where the installtion cache line was source from the"
-			" Level-3 cache that is on the same book as the Data"
-			" cache (Local L2 cache)",
+			" where the installtion cache line was source from"
+			" the Level-3 cache that is on the same book as the"
+			" Data cache (Local L2 cache)",
 	},
 	{
 		.ctrnum = 132,
@@ -297,15 +302,15 @@ static const pme_cpumf_ctr_t cpumf_ctr_set_ext_z10[] = {
 		.ctrset = CPUMF_CTRSET_EXTENDED,
 		.name = "L1I_CACHELINE_INVALIDATES",
 		.desc = "A cache line in the Level-1 I-Cache has been"
-			" invalidated by a store on the same CPU as the Level-1"
-			" I-Cache",
+			" invalidated by a store on the same CPU as the"
+			" Level-1 I-Cache",
 	},
 	{
 		.ctrnum = 138,
 		.ctrset = CPUMF_CTRSET_EXTENDED,
 		.name = "ITLB1_WRITES",
-		.desc = "A translation entry has been written into the Level-1"
-			" Instruction Translation Lookaside Buffer",
+		.desc = "A translation entry has been written into the"
+			" Level-1 Instruction Translation Lookaside Buffer",
 	},
 	{
 		.ctrnum = 139,
@@ -340,27 +345,27 @@ static const pme_cpumf_ctr_t cpumf_ctr_set_ext_z10[] = {
 		.ctrnum = 145,
 		.ctrset = CPUMF_CTRSET_EXTENDED,
 		.name = "ITLB1_MISSES",
-		.desc = "Level-1 Instruction TLB miss in progress. Incremented"
-			" by one for every cycle an ITLB1 miss is in progress",
+		.desc = "Level-1 Instruction TLB miss in progress."
+			" Incremented by one for every cycle an ITLB1 miss is"
+			" in progress",
 	},
 	{
 		.ctrnum = 146,
 		.ctrset = CPUMF_CTRSET_EXTENDED,
 		.name = "DTLB1_MISSES",
-		.desc = "Level-1 Data TLB miss in progress. Incremented by one"
-			" for every cycle an DTLB1 miss is in progress",
+		.desc = "Level-1 Data TLB miss in progress. Incremented by"
+			" one for every cycle an DTLB1 miss is in progress",
 	},
 	{
 		.ctrnum = 147,
 		.ctrset = CPUMF_CTRSET_EXTENDED,
 		.name = "L2C_STORES_SENT",
-		.desc = "Incremented by one for every store sent to"
-			" Level-2 (L1.5) cache",
+		.desc = "Incremented by one for every store sent to Level-2"
+			" (L1.5) cache",
 	},
 };
 
-/* Extended counter set for IBM zEnterprise 196 */
-static const pme_cpumf_ctr_t cpumf_ctr_set_ext_z196[] = {
+static const pme_cpumf_ctr_t cpumcf_z196_counters[] = {
 	{
 		.ctrnum = 128,
 		.ctrset = CPUMF_CTRSET_EXTENDED,
@@ -374,29 +379,30 @@ static const pme_cpumf_ctr_t cpumf_ctr_set_ext_z196[] = {
 		.ctrset = CPUMF_CTRSET_EXTENDED,
 		.name = "L1I_L2_SOURCED_WRITES",
 		.desc = "A directory write to the Level-1 I-Cache directory"
-			" where the returned cache line was sourced from"
-			" the Level-2 cache",
+			" where the returned cache line was sourced from the"
+			" Level-2 cache",
 	},
 	{
 		.ctrnum = 130,
 		.ctrset = CPUMF_CTRSET_EXTENDED,
 		.name = "DTLB1_MISSES",
-		.desc = "Level-1 Data TLB miss in progress. Incremented by one"
-			" for every cycle a DTLB1 miss is in progress.",
+		.desc = "Level-1 Data TLB miss in progress. Incremented by"
+			" one for every cycle a DTLB1 miss is in progress.",
 	},
 	{
 		.ctrnum = 131,
 		.ctrset = CPUMF_CTRSET_EXTENDED,
 		.name = "ITLB1_MISSES",
-		.desc = "Level-1 Instruction TLB miss in progress. Incremented"
-			" by one for every cycle a ITLB1 miss is in progress.",
+		.desc = "Level-1 Instruction TLB miss in progress."
+			" Incremented by one for every cycle a ITLB1 miss is"
+			" in progress.",
 	},
 	{
 		.ctrnum = 133,
 		.ctrset = CPUMF_CTRSET_EXTENDED,
 		.name = "L2C_STORES_SENT",
-		.desc = "Incremented by one for every store sent to"
-			" Level-2 cache",
+		.desc = "Incremented by one for every store sent to Level-2"
+			" cache",
 	},
 	{
 		.ctrnum = 134,
@@ -452,8 +458,8 @@ static const pme_cpumf_ctr_t cpumf_ctr_set_ext_z196[] = {
 		.ctrset = CPUMF_CTRSET_EXTENDED,
 		.name = "DTLB1_HPAGE_WRITES",
 		.desc = "A translation entry has been written to the Level-1"
-			" Data Translation Lookaside Buffer for a one-megabyte"
-			" page",
+			" Data Translation Lookaside Buffer for a one-"
+			" megabyte page",
 	},
 	{
 		.ctrnum = 141,
@@ -520,7 +526,7 @@ static const pme_cpumf_ctr_t cpumf_ctr_set_ext_z196[] = {
 	{
 		.ctrnum = 150,
 		.ctrset = CPUMF_CTRSET_EXTENDED,
-		.name = "L1D_ONCHIP_L3_WRITES",
+		.name = "L1D_ONCHIP_L3_SOURCED_WRITES",
 		.desc = "A directory write to the Level-1 D-Cache directory"
 			" where the returned cache line was sourced from an"
 			" On Chip Level-3 cache",
@@ -528,7 +534,7 @@ static const pme_cpumf_ctr_t cpumf_ctr_set_ext_z196[] = {
 	{
 		.ctrnum = 152,
 		.ctrset = CPUMF_CTRSET_EXTENDED,
-		.name = "L1D_OFFCHIP_L3_WRITES",
+		.name = "L1D_OFFCHIP_L3_SOURCED_WRITES",
 		.desc = "A directory write to the Level-1 D-Cache directory"
 			" where the returned cache line was sourced from an"
 			" Off Chip/On Book Level-3 cache",
@@ -536,7 +542,7 @@ static const pme_cpumf_ctr_t cpumf_ctr_set_ext_z196[] = {
 	{
 		.ctrnum = 153,
 		.ctrset = CPUMF_CTRSET_EXTENDED,
-		.name = "L1I_ONCHIP_L3_WRITES",
+		.name = "L1I_ONCHIP_L3_SOURCED_WRITES",
 		.desc = "A directory write to the Level-1 I-Cache directory"
 			" where the returned cache line was sourced from an"
 			" On Chip Level-3 cache",
@@ -544,19 +550,310 @@ static const pme_cpumf_ctr_t cpumf_ctr_set_ext_z196[] = {
 	{
 		.ctrnum = 155,
 		.ctrset = CPUMF_CTRSET_EXTENDED,
-		.name = "L1I_OFFCHIP_L3_WRITES",
+		.name = "L1I_OFFCHIP_L3_SOURCED_WRITES",
 		.desc = "A directory write to the Level-1 I-Cache directory"
 			" where the returned cache line was sourced from an"
 			" Off Chip/On Book Level-3 cache",
 	},
 };
 
-#if 0
+static const pme_cpumf_ctr_t cpumcf_zec12_counters[] = {
+	{
+		.ctrnum = 128,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "DTLB1_MISSES",
+		.desc = "Level-1 Data TLB miss in progress. Incremented by"
+			" one for every cycle a DTLB1 miss is in progress.",
+	},
+	{
+		.ctrnum = 129,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "ITLB1_MISSES",
+		.desc = "Level-1 Instruction TLB miss in progress."
+			" Incremented by one for every cycle a ITLB1 miss is"
+			" in progress.",
+	},
+	{
+		.ctrnum = 130,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1D_L2I_SOURCED_WRITES",
+		.desc = "A directory write to the Level-1 Data cache"
+			" directory where the returned cache line was sourced"
+			" from the Level-2 Instruction cache",
+	},
+	{
+		.ctrnum = 131,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1I_L2I_SOURCED_WRITES",
+		.desc = "A directory write to the Level-1 Instruction cache"
+			" directory where the returned cache line was sourced"
+			" from the Level-2 Instruction cache",
+	},
+	{
+		.ctrnum = 132,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1D_L2D_SOURCED_WRITES",
+		.desc = "A directory write to the Level-1 Data cache"
+			" directory where the returned cache line was sourced"
+			" from the Level-2 Data cache",
+	},
+	{
+		.ctrnum = 133,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "DTLB1_WRITES",
+		.desc = "A translation entry has been written to the Level-1"
+			" Data Translation Lookaside Buffer",
+	},
+	{
+		.ctrnum = 135,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1D_LMEM_SOURCED_WRITES",
+		.desc = "A directory write to the Level-1 Data cache where"
+			" the installed cache line was sourced from memory"
+			" that is attached to the same book as the Data cache"
+			" (Local Memory)",
+	},
+	{
+		.ctrnum = 137,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1I_LMEM_SOURCED_WRITES",
+		.desc = "A directory write to the Level-1 Instruction cache"
+			" where the installed cache line was sourced from"
+			" memory that is attached to the same book as the"
+			" Instruction cache (Local Memory)",
+	},
+	{
+		.ctrnum = 138,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1D_RO_EXCL_WRITES",
+		.desc = "A directory write to the Level-1 D-Cache where the"
+			" line was originally in a Read-Only state in the"
+			" cache but has been updated to be in the Exclusive"
+			" state that allows stores to the cache line",
+	},
+	{
+		.ctrnum = 139,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "DTLB1_HPAGE_WRITES",
+		.desc = "A translation entry has been written to the Level-1"
+			" Data Translation Lookaside Buffer for a one-"
+			" megabyte page",
+	},
+	{
+		.ctrnum = 140,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "ITLB1_WRITES",
+		.desc = "A translation entry has been written to the Level-1"
+			" Instruction Translation Lookaside Buffer",
+	},
+	{
+		.ctrnum = 141,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "TLB2_PTE_WRITES",
+		.desc = "A translation entry has been written to the Level-2"
+			" TLB Page Table Entry arrays",
+	},
+	{
+		.ctrnum = 142,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "TLB2_CRSTE_HPAGE_WRITES",
+		.desc = "A translation entry has been written to the Level-2"
+			" TLB Common Region Segment Table Entry arrays for a"
+			" one-megabyte large page translation",
+	},
+	{
+		.ctrnum = 143,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "TLB2_CRSTE_WRITES",
+		.desc = "A translation entry has been written to the Level-2"
+			" TLB Common Region Segment Table Entry arrays",
+	},
+	{
+		.ctrnum = 144,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1D_ONCHIP_L3_SOURCED_WRITES",
+		.desc = "A directory write to the Level-1 Data cache"
+			" directory where the returned cache line was sourced"
+			" from an On Chip Level-3 cache without intervention",
+	},
+	{
+		.ctrnum = 145,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1D_OFFCHIP_L3_SOURCED_WRITES",
+		.desc = "A directory write to the Level-1 Data cache"
+			" directory where the returned cache line was sourced"
+			" from an Off Chip/On Book Level-3 cache without"
+			" intervention",
+	},
+	{
+		.ctrnum = 146,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1D_OFFBOOK_L3_SOURCED_WRITES",
+		.desc = "A directory write to the Level-1 Data cache"
+			" directory where the returned cache line was sourced"
+			" from an Off Book Level-3 cache without intervention",
+	},
+	{
+		.ctrnum = 147,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1D_ONBOOK_L4_SOURCED_WRITES",
+		.desc = "A directory write to the Level-1 Data cache"
+			" directory where the returned cache line was sourced"
+			" from an On Book Level-4 cache",
+	},
 	{
-		.ctrnum = ,
+		.ctrnum = 148,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1D_OFFBOOK_L4_SOURCED_WRITES",
+		.desc = "A directory write to the Level-1 Data cache"
+			" directory where the returned cache line was sourced"
+			" from an Off Book Level-4 cache",
+	},
+	{
+		.ctrnum = 149,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "TX_NC_TEND",
+		.desc = "A TEND instruction has completed in a"
+			" nonconstrained transactional-execution mode",
+	},
+	{
+		.ctrnum = 150,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1D_ONCHIP_L3_SOURCED_WRITES_IV",
+		.desc = "A directory write to the Level-1 Data cache"
+			" directory where the returned cache line was sourced"
+			" from a On Chip Level-3 cache with intervention",
+	},
+	{
+		.ctrnum = 151,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1D_OFFCHIP_L3_SOURCED_WRITES_IV",
+		.desc = "A directory write to the Level-1 Data cache"
+			" directory where the returned cache line was sourced"
+			" from an Off Chip/On Book Level-3 cache with"
+			" intervention",
+	},
+	{
+		.ctrnum = 152,
 		.ctrset = CPUMF_CTRSET_EXTENDED,
-		.name = "",
-		.desc = "",
+		.name = "L1D_OFFBOOK_L3_SOURCED_WRITES_IV",
+		.desc = "A directory write to the Level-1 Data cache"
+			" directory where the returned cache line was sourced"
+			" from an Off Book Level-3 cache with intervention",
 	},
-#endif
+	{
+		.ctrnum = 153,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1I_ONCHIP_L3_SOURCED_WRITES",
+		.desc = "A directory write to the Level-1 Instruction cache"
+			" directory where the returned cache line was sourced"
+			" from an On Chip Level-3 cache without intervention",
+	},
+	{
+		.ctrnum = 154,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1I_OFFCHIP_L3_SOURCED_WRITES",
+		.desc = "A directory write to the Level-1 Instruction cache"
+			" directory where the returned cache line was sourced"
+			" from an Off Chip/On Book Level-3 cache without"
+			" intervention",
+	},
+	{
+		.ctrnum = 155,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1I_OFFBOOK_L3_SOURCED_WRITES",
+		.desc = "A directory write to the Level-1 Instruction cache"
+			" directory where the returned cache line was sourced"
+			" from an Off Book Level-3 cache without intervention",
+	},
+	{
+		.ctrnum = 156,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1I_ONBOOK_L4_SOURCED_WRITES",
+		.desc = "A directory write to the Level-1 Instruction cache"
+			" directory where the returned cache line was sourced"
+			" from an On Book Level-4 cache",
+	},
+	{
+		.ctrnum = 157,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1I_OFFBOOK_L4_SOURCED_WRITES",
+		.desc = "A directory write to the Level-1 Instruction cache"
+			" directory where the returned cache line was sourced"
+			" from an Off Book Level-4 cache",
+	},
+	{
+		.ctrnum = 158,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "TX_C_TEND",
+		.desc = "A TEND instruction has completed in a constrained"
+			" transactional-execution mode",
+	},
+	{
+		.ctrnum = 159,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1I_ONCHIP_L3_SOURCED_WRITES_IV",
+		.desc = "A directory write to the Level-1 Instruction cache"
+			" directory where the returned cache line was sourced"
+			" from an On Chip Level-3 cache with intervention",
+	},
+	{
+		.ctrnum = 160,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1I_OFFCHIP_L3_SOURCED_WRITES_IV",
+		.desc = "A directory write to the Level-1 Instruction cache"
+			" directory where the returned cache line was sourced"
+			" from an Off Chip/On Book Level-3 cache with"
+			" intervention",
+	},
+	{
+		.ctrnum = 161,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "L1I_OFFBOOK_L3_SOURCED_WRITES_IV",
+		.desc = "A directory write to the Level-1 Instruction cache"
+			" directory where the returned cache line was sourced"
+			" from an Off Book Level-3 cache with intervention",
+	},
+	{
+		.ctrnum = 177,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "TX_NC_TABORT",
+		.desc = "A transaction abort has occurred in a"
+			" nonconstrained transactional-execution mode",
+	},
+	{
+		.ctrnum = 178,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "TX_C_TABORT_NO_SPECIAL",
+		.desc = "A transaction abort has occurred in a constrained"
+			" transactional-execution mode and the CPU is not"
+			" using any special logic to allow the transaction to"
+			" complete",
+	},
+	{
+		.ctrnum = 179,
+		.ctrset = CPUMF_CTRSET_EXTENDED,
+		.name = "TX_C_TABORT_SPECIAL",
+		.desc = "A transaction abort has occurred in a constrained"
+			" transactional-execution mode and the CPU is using"
+			" special logic to allow the transaction to complete",
+	},
+};
+
+static const pme_cpumf_ctr_t cpumsf_counters[] = {
+	{
+		.ctrnum = 720896,
+		.ctrset = CPUMF_CTRSET_NONE,
+		.name = "SF_CYCLES_BASIC",
+		.desc = "Sample CPU cycles using basic-sampling mode",
+	},
+	{
+		.ctrnum = 774144,
+		.ctrset = CPUMF_CTRSET_NONE,
+		.name = "SF_CYCLES_BASIC_DIAG",
+		.desc = "Sample CPU cycle using diagnostic-sampling mode"
+			" (not for ordinary use)",
+	},
+};
+
 #endif /* __S390X_CPUMF_EVENTS_H__ */
diff --git a/src/libpfm4/lib/pfmlib_common.c b/src/libpfm4/lib/pfmlib_common.c
index 861f475..8e4b1a1 100644
--- a/src/libpfm4/lib/pfmlib_common.c
+++ b/src/libpfm4/lib/pfmlib_common.c
@@ -121,6 +121,41 @@ static pfmlib_pmu_t *pfmlib_pmus[]=
 	&intel_snbep_unc_r3qpi1_support,
 	&intel_knc_support,
 	&intel_slm_support,
+	&intel_ivbep_unc_cb0_support,
+	&intel_ivbep_unc_cb1_support,
+	&intel_ivbep_unc_cb2_support,
+	&intel_ivbep_unc_cb3_support,
+	&intel_ivbep_unc_cb4_support,
+	&intel_ivbep_unc_cb5_support,
+	&intel_ivbep_unc_cb6_support,
+	&intel_ivbep_unc_cb7_support,
+	&intel_ivbep_unc_cb8_support,
+	&intel_ivbep_unc_cb9_support,
+	&intel_ivbep_unc_cb10_support,
+	&intel_ivbep_unc_cb11_support,
+	&intel_ivbep_unc_cb12_support,
+	&intel_ivbep_unc_cb13_support,
+	&intel_ivbep_unc_cb14_support,
+	&intel_ivbep_unc_ha0_support,
+	&intel_ivbep_unc_ha1_support,
+	&intel_ivbep_unc_imc0_support,
+	&intel_ivbep_unc_imc1_support,
+	&intel_ivbep_unc_imc2_support,
+	&intel_ivbep_unc_imc3_support,
+	&intel_ivbep_unc_imc4_support,
+	&intel_ivbep_unc_imc5_support,
+	&intel_ivbep_unc_imc6_support,
+	&intel_ivbep_unc_imc7_support,
+	&intel_ivbep_unc_pcu_support,
+	&intel_ivbep_unc_qpi0_support,
+	&intel_ivbep_unc_qpi1_support,
+	&intel_ivbep_unc_qpi2_support,
+	&intel_ivbep_unc_ubo_support,
+	&intel_ivbep_unc_r2pcie_support,
+	&intel_ivbep_unc_r3qpi0_support,
+	&intel_ivbep_unc_r3qpi1_support,
+	&intel_ivbep_unc_r3qpi2_support,
+	&intel_ivbep_unc_irp_support,
 	&intel_x86_arch_support, /* must always be last for x86 */
 #endif
 
@@ -167,9 +202,11 @@ static pfmlib_pmu_t *pfmlib_pmus[]=
 #endif
 #ifdef CONFIG_PFMLIB_ARCH_S390X
 	&s390x_cpum_cf_support,
+	&s390x_cpum_sf_support,
 #endif
 #ifdef __linux__
 	&perf_event_support,
+	&perf_event_raw_support,
 #endif
 };
 #define PFMLIB_NUM_PMUS	(int)(sizeof(pfmlib_pmus)/sizeof(pfmlib_pmu_t *))
@@ -1026,10 +1063,17 @@ pfmlib_release_event(pfmlib_event_desc_t *e)
 }
 
 static int
+match_event(void *this, pfmlib_event_desc_t *d, const char *e, const char *s)
+{
+	return strcasecmp(e, s);
+}
+
+static int
 pfmlib_parse_equiv_event(const char *event, pfmlib_event_desc_t *d)
 {
 	pfmlib_pmu_t *pmu = d->pmu;
 	pfm_event_info_t einfo;
+	int (*match)(void *this, pfmlib_event_desc_t *d, const char *e, const char *s);
 	char *str, *s, *p;
 	int i;
 	int ret;
@@ -1045,11 +1089,13 @@ pfmlib_parse_equiv_event(const char *event, pfmlib_event_desc_t *d)
 	if (p)
 		*p++ = '\0';
 
+	match = pmu->match_event ? pmu->match_event : match_event;
+
 	pfmlib_for_each_pmu_event(pmu, i) {
 		ret = pmu->get_event_info(pmu, i, &einfo);
 		if (ret != PFM_SUCCESS)
 			goto error;
-		if (!strcasecmp(einfo.name, s))
+		if (!match(pmu, d, einfo.name, s))
 			goto found;
 	}
 	free(str);
@@ -1085,6 +1131,7 @@ pfmlib_parse_event(const char *event, pfmlib_event_desc_t *d)
 	pfm_event_info_t einfo;
 	char *str, *s, *p;
 	pfmlib_pmu_t *pmu;
+	int (*match)(void *this, pfmlib_event_desc_t *d, const char *e, const char *s);
 	const char *pname = NULL;
 	int i, j, ret;
 
@@ -1138,6 +1185,8 @@ pfmlib_parse_event(const char *event, pfmlib_event_desc_t *d)
 		 */
 		if (pname && !pfmlib_pmu_active(pmu) && !pfm_cfg.inactive)
 			continue;
+
+		match = pmu->match_event ? pmu->match_event : match_event;
 		/*
 		 * for each event
 		 */
@@ -1145,7 +1194,7 @@ pfmlib_parse_event(const char *event, pfmlib_event_desc_t *d)
 			ret = pmu->get_event_info(pmu, i, &einfo);
 			if (ret != PFM_SUCCESS)
 				goto error;
-			if (!strcasecmp(einfo.name, s))
+			if (!match(pmu, d, einfo.name, s))
 				goto found;
 		}
 	}
diff --git a/src/libpfm4/lib/pfmlib_intel_ivbep_unc_cbo.c b/src/libpfm4/lib/pfmlib_intel_ivbep_unc_cbo.c
new file mode 100644
index 0000000..6053aa5
--- /dev/null
+++ b/src/libpfm4/lib/pfmlib_intel_ivbep_unc_cbo.c
@@ -0,0 +1,125 @@
+/*
+ * pfmlib_intel_ivbep_unc_cbo.c : Intel IvyBridge-EP C-Box uncore PMU
+ *
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+#include <sys/types.h>
+#include <ctype.h>
+#include <string.h>
+#include <stdlib.h>
+#include <stdio.h>
+
+/* private headers */
+#include "pfmlib_priv.h"
+#include "pfmlib_intel_x86_priv.h"
+#include "pfmlib_intel_snbep_unc_priv.h"
+#include "events/intel_ivbep_unc_cbo_events.h"
+
+static void
+display_cbo(void *this, pfmlib_event_desc_t *e, void *val)
+{
+	const intel_x86_entry_t *pe = this_pe(this);
+	pfm_snbep_unc_reg_t *reg = val;
+	pfm_snbep_unc_reg_t f;
+
+	__pfm_vbprintf("[UNC_CBO=0x%"PRIx64" event=0x%x umask=0x%x en=%d "
+		       "inv=%d edge=%d thres=%d tid_en=%d] %s\n",
+			reg->val,
+			reg->cbo.unc_event,
+			reg->cbo.unc_umask,
+			reg->cbo.unc_en,
+			reg->cbo.unc_inv,
+			reg->cbo.unc_edge,
+			reg->cbo.unc_thres,
+			reg->cbo.unc_tid,
+			pe[e->event].name);
+
+	if (e->count == 1)
+		return;
+
+	f.val = e->codes[1];
+
+	__pfm_vbprintf("[UNC_CBOX_FILTER0=0x%"PRIx64" tid=%d core=0x%x"
+		       " state=0x%x]\n",
+			f.val,
+			f.ivbep_cbo_filt0.tid,
+			f.ivbep_cbo_filt0.cid,
+			f.ivbep_cbo_filt0.state);
+
+	if (e->count == 2)
+		return;
+
+	f.val = e->codes[2];
+
+	__pfm_vbprintf("[UNC_CBOX_FILTER1=0x%"PRIx64" nid=%d opc=0x%x"
+		       " nc=0x%x isoc=0x%x]\n",
+			f.val,
+			f.ivbep_cbo_filt1.nid,
+			f.ivbep_cbo_filt1.opc,
+			f.ivbep_cbo_filt1.nc,
+			f.ivbep_cbo_filt1.isoc);
+}
+
+#define DEFINE_C_BOX(n) \
+pfmlib_pmu_t intel_ivbep_unc_cb##n##_support = {\
+	.desc			= "Intel Ivy Bridge-EP C-Box "#n" uncore",\
+	.name			= "ivbep_unc_cbo"#n,\
+	.perf_name		= "uncore_cbox_"#n,\
+	.pmu			= PFM_PMU_INTEL_IVBEP_UNC_CB##n,\
+	.pme_count		= LIBPFM_ARRAY_SIZE(intel_ivbep_unc_c_pe),\
+	.type			= PFM_PMU_TYPE_UNCORE,\
+	.num_cntrs		= 4,\
+	.num_fixed_cntrs	= 0,\
+	.max_encoding		= 2,\
+	.pe			= intel_ivbep_unc_c_pe,\
+	.atdesc			= snbep_unc_mods,\
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK|INTEL_PMU_FL_UNC_CBO,\
+	.pmu_detect		= pfm_intel_ivbep_unc_detect,\
+	.get_event_encoding[PFM_OS_NONE] = pfm_intel_snbep_unc_get_encoding,\
+	 PFMLIB_ENCODE_PERF(pfm_intel_snbep_unc_get_perf_encoding),\
+	 PFMLIB_OS_DETECT(pfm_intel_x86_perf_detect), \
+	.get_event_first	= pfm_intel_x86_get_event_first,\
+	.get_event_next		= pfm_intel_x86_get_event_next,\
+	.event_is_valid		= pfm_intel_x86_event_is_valid,\
+	.validate_table		= pfm_intel_x86_validate_table,\
+	.get_event_info		= pfm_intel_x86_get_event_info,\
+	.get_event_attr_info	= pfm_intel_x86_get_event_attr_info,\
+	PFMLIB_VALID_PERF_PATTRS(pfm_intel_snbep_unc_perf_validate_pattrs),\
+	.get_event_nattrs	= pfm_intel_x86_get_event_nattrs,\
+	.can_auto_encode	= pfm_intel_x86_can_auto_encode, \
+	.display_reg		= display_cbo,\
+}
+
+DEFINE_C_BOX(0);
+DEFINE_C_BOX(1);
+DEFINE_C_BOX(2);
+DEFINE_C_BOX(3);
+DEFINE_C_BOX(4);
+DEFINE_C_BOX(5);
+DEFINE_C_BOX(6);
+DEFINE_C_BOX(7);
+DEFINE_C_BOX(8);
+DEFINE_C_BOX(9);
+DEFINE_C_BOX(10);
+DEFINE_C_BOX(11);
+DEFINE_C_BOX(12);
+DEFINE_C_BOX(13);
+DEFINE_C_BOX(14);
diff --git a/src/libpfm4/lib/pfmlib_intel_ivbep_unc_ha.c b/src/libpfm4/lib/pfmlib_intel_ivbep_unc_ha.c
new file mode 100644
index 0000000..d4bd6f9
--- /dev/null
+++ b/src/libpfm4/lib/pfmlib_intel_ivbep_unc_ha.c
@@ -0,0 +1,97 @@
+/*
+ * pfmlib_intel_ivbep_unc_ha.c : Intel IvyBridge-EP Home Agent (HA) uncore PMU
+ *
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+#include <sys/types.h>
+#include <ctype.h>
+#include <string.h>
+#include <stdlib.h>
+#include <stdio.h>
+
+/* private headers */
+#include "pfmlib_priv.h"
+#include "pfmlib_intel_x86_priv.h"
+#include "pfmlib_intel_snbep_unc_priv.h"
+#include "events/intel_ivbep_unc_ha_events.h"
+
+static void
+display_ha(void *this, pfmlib_event_desc_t *e, void *val)
+{
+	const intel_x86_entry_t *pe = this_pe(this);
+	pfm_snbep_unc_reg_t *reg = val;
+	pfm_snbep_unc_reg_t f;
+
+	__pfm_vbprintf("[UNC_HA=0x%"PRIx64" event=0x%x umask=0x%x en=%d "
+		       "inv=%d edge=%d thres=%d] %s\n",
+			reg->val,
+			reg->com.unc_event,
+			reg->com.unc_umask,
+			reg->com.unc_en,
+			reg->com.unc_inv,
+			reg->com.unc_edge,
+			reg->com.unc_thres,
+			pe[e->event].name);
+
+	if (e->count == 1)
+		return;
+
+	f.val = e->codes[1];
+	__pfm_vbprintf("[UNC_HA_ADDR=0x%"PRIx64" lo_addr=0x%x hi_addr=0x%x]\n",
+			f.val,
+			f.ha_addr.lo_addr,
+			f.ha_addr.hi_addr);
+
+	f.val = e->codes[2];
+	__pfm_vbprintf("[UNC_HA_OPC=0x%"PRIx64" opc=0x%x]\n", f.val, f.ha_opc.opc);
+}
+
+#define DEFINE_HA_BOX(n) \
+pfmlib_pmu_t intel_ivbep_unc_ha##n##_support = {\
+	.desc			= "Intel Ivy Bridge-EP HA "#n" uncore",\
+	.name			= "ivbep_unc_ha"#n,\
+	.perf_name		= "uncore_ha_"#n,\
+	.pmu			= PFM_PMU_INTEL_IVBEP_UNC_HA##n,\
+	.pme_count		= LIBPFM_ARRAY_SIZE(intel_ivbep_unc_h_pe),\
+	.type			= PFM_PMU_TYPE_UNCORE,\
+	.num_cntrs		= 4,\
+	.num_fixed_cntrs	= 0,\
+	.max_encoding		= 3, /* address matchers */\
+	.pe			= intel_ivbep_unc_h_pe,\
+	.atdesc			= snbep_unc_mods,\
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK,\
+	.pmu_detect		= pfm_intel_ivbep_unc_detect,\
+	.get_event_encoding[PFM_OS_NONE] = pfm_intel_snbep_unc_get_encoding,\
+	 PFMLIB_ENCODE_PERF(pfm_intel_snbep_unc_get_perf_encoding),\
+	 PFMLIB_OS_DETECT(pfm_intel_x86_perf_detect), \
+	.get_event_first	= pfm_intel_x86_get_event_first,\
+	.get_event_next		= pfm_intel_x86_get_event_next,\
+	.event_is_valid		= pfm_intel_x86_event_is_valid,\
+	.validate_table		= pfm_intel_x86_validate_table,\
+	.get_event_info		= pfm_intel_x86_get_event_info,\
+	.get_event_attr_info	= pfm_intel_x86_get_event_attr_info,\
+	PFMLIB_VALID_PERF_PATTRS(pfm_intel_snbep_unc_perf_validate_pattrs),\
+	.get_event_nattrs	= pfm_intel_x86_get_event_nattrs,\
+	.display_reg		= display_ha,\
+}
+
+DEFINE_HA_BOX(0);
+DEFINE_HA_BOX(1);
diff --git a/src/libpfm4/lib/pfmlib_intel_ivbep_unc_imc.c b/src/libpfm4/lib/pfmlib_intel_ivbep_unc_imc.c
new file mode 100644
index 0000000..aa7d3a8
--- /dev/null
+++ b/src/libpfm4/lib/pfmlib_intel_ivbep_unc_imc.c
@@ -0,0 +1,71 @@
+/*
+ * pfmlib_intel_ivbep_unc_imc.c : Intel IvyBridge-EP Integrated Memory Controller (IMC) uncore PMU
+ *
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+#include <sys/types.h>
+#include <ctype.h>
+#include <string.h>
+#include <stdlib.h>
+#include <stdio.h>
+
+/* private headers */
+#include "pfmlib_priv.h"
+#include "pfmlib_intel_x86_priv.h"
+#include "pfmlib_intel_snbep_unc_priv.h"
+#include "events/intel_ivbep_unc_imc_events.h"
+
+#define DEFINE_IMC_BOX(n) \
+pfmlib_pmu_t intel_ivbep_unc_imc##n##_support = { \
+	.desc			= "Intel Iyy Bridge-EP IMC"#n" uncore", \
+	.name			= "ivbep_unc_imc"#n, \
+	.perf_name		= "uncore_imc_"#n, \
+	.pmu			= PFM_PMU_INTEL_IVBEP_UNC_IMC##n, \
+	.pme_count		= LIBPFM_ARRAY_SIZE(intel_ivbep_unc_m_pe), \
+	.type			= PFM_PMU_TYPE_UNCORE, \
+	.num_cntrs		= 4, \
+	.num_fixed_cntrs	= 1, \
+	.max_encoding		= 1, \
+	.pe			= intel_ivbep_unc_m_pe, \
+	.atdesc			= snbep_unc_mods, \
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK, \
+	.pmu_detect		= pfm_intel_ivbep_unc_detect, \
+	.get_event_encoding[PFM_OS_NONE] = pfm_intel_snbep_unc_get_encoding, \
+	 PFMLIB_ENCODE_PERF(pfm_intel_snbep_unc_get_perf_encoding), \
+	 PFMLIB_OS_DETECT(pfm_intel_x86_perf_detect), \
+	.get_event_first	= pfm_intel_x86_get_event_first, \
+	.get_event_next		= pfm_intel_x86_get_event_next, \
+	.event_is_valid		= pfm_intel_x86_event_is_valid, \
+	.validate_table		= pfm_intel_x86_validate_table, \
+	.get_event_info		= pfm_intel_x86_get_event_info, \
+	.get_event_attr_info	= pfm_intel_x86_get_event_attr_info, \
+	PFMLIB_VALID_PERF_PATTRS(pfm_intel_snbep_unc_perf_validate_pattrs), \
+	.get_event_nattrs	= pfm_intel_x86_get_event_nattrs, \
+};
+
+DEFINE_IMC_BOX(0);
+DEFINE_IMC_BOX(1);
+DEFINE_IMC_BOX(2);
+DEFINE_IMC_BOX(3);
+DEFINE_IMC_BOX(4);
+DEFINE_IMC_BOX(5);
+DEFINE_IMC_BOX(6);
+DEFINE_IMC_BOX(7);
diff --git a/src/libpfm4/lib/pfmlib_intel_ivbep_unc_irp.c b/src/libpfm4/lib/pfmlib_intel_ivbep_unc_irp.c
new file mode 100644
index 0000000..84fc22f
--- /dev/null
+++ b/src/libpfm4/lib/pfmlib_intel_ivbep_unc_irp.c
@@ -0,0 +1,79 @@
+/*
+ * pfmlib_intel_ivbep_irp.c : Intel IvyBridge-EP IRP uncore PMU
+ *
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+#include <sys/types.h>
+#include <ctype.h>
+#include <string.h>
+#include <stdlib.h>
+#include <stdio.h>
+
+/* private headers */
+#include "pfmlib_priv.h"
+#include "pfmlib_intel_x86_priv.h"
+#include "pfmlib_intel_snbep_unc_priv.h"
+#include "events/intel_ivbep_unc_irp_events.h"
+
+static void
+display_irp(void *this, pfmlib_event_desc_t *e, void *val)
+{
+	const intel_x86_entry_t *pe = this_pe(this);
+	pfm_snbep_unc_reg_t *reg = val;
+
+	__pfm_vbprintf("[UNC_IRP=0x%"PRIx64" event=0x%x umask=0x%x en=%d "
+		       "edge=%d thres=%d] %s\n",
+			reg->val,
+			reg->irp.unc_event,
+			reg->irp.unc_umask,
+			reg->irp.unc_en,
+			reg->irp.unc_edge,
+			reg->irp.unc_thres,
+			pe[e->event].name);
+}
+
+pfmlib_pmu_t intel_ivbep_unc_irp_support = {
+	.desc			= "Intel Ivy Bridge-EP IRP uncore",
+	.name			= "ivbep_unc_irp",
+	.perf_name		= "uncore_irp",
+	.pmu			= PFM_PMU_INTEL_IVBEP_UNC_IRP,
+	.pme_count		= LIBPFM_ARRAY_SIZE(intel_ivbep_unc_i_pe),
+	.type			= PFM_PMU_TYPE_UNCORE,
+	.num_cntrs		= 4,
+	.num_fixed_cntrs	= 0,
+	.max_encoding		= 3,
+	.pe			= intel_ivbep_unc_i_pe,
+	.atdesc			= snbep_unc_mods,
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK,
+	.pmu_detect		= pfm_intel_ivbep_unc_detect,
+	.get_event_encoding[PFM_OS_NONE] = pfm_intel_snbep_unc_get_encoding,
+	 PFMLIB_ENCODE_PERF(pfm_intel_snbep_unc_get_perf_encoding),
+	 PFMLIB_OS_DETECT(pfm_intel_x86_perf_detect),
+	.get_event_first	= pfm_intel_x86_get_event_first,
+	.get_event_next		= pfm_intel_x86_get_event_next,
+	.event_is_valid		= pfm_intel_x86_event_is_valid,
+	.validate_table		= pfm_intel_x86_validate_table,
+	.get_event_info		= pfm_intel_x86_get_event_info,
+	.get_event_attr_info	= pfm_intel_x86_get_event_attr_info,
+	PFMLIB_VALID_PERF_PATTRS(pfm_intel_snbep_unc_perf_validate_pattrs),
+	.get_event_nattrs	= pfm_intel_x86_get_event_nattrs,
+	.display_reg		= display_irp,
+};
diff --git a/src/libpfm4/lib/pfmlib_intel_ivbep_unc_pcu.c b/src/libpfm4/lib/pfmlib_intel_ivbep_unc_pcu.c
new file mode 100644
index 0000000..782f881
--- /dev/null
+++ b/src/libpfm4/lib/pfmlib_intel_ivbep_unc_pcu.c
@@ -0,0 +1,97 @@
+/*
+ * pfmlib_intel_ivbep_unc_pcu.c : Intel IvyBridge-EP Power Control Unit (PCU) uncore PMU
+ *
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+#include <sys/types.h>
+#include <ctype.h>
+#include <string.h>
+#include <stdlib.h>
+#include <stdio.h>
+
+/* private headers */
+#include "pfmlib_priv.h"
+#include "pfmlib_intel_x86_priv.h"
+#include "pfmlib_intel_snbep_unc_priv.h"
+#include "events/intel_ivbep_unc_pcu_events.h"
+
+static void
+display_pcu(void *this, pfmlib_event_desc_t *e, void *val)
+{
+	const intel_x86_entry_t *pe = this_pe(this);
+	pfm_snbep_unc_reg_t *reg = val;
+	pfm_snbep_unc_reg_t f;
+
+	__pfm_vbprintf("[UNC_PCU=0x%"PRIx64" event=0x%x sel_ext=%d occ_sel=0x%x en=%d "
+			"edge=%d thres=%d occ_inv=%d occ_edge=%d] %s\n",
+			reg->val,
+			reg->ivbep_pcu.unc_event,
+			reg->ivbep_pcu.unc_sel_ext,
+			reg->ivbep_pcu.unc_occ,
+			reg->ivbep_pcu.unc_en,
+			reg->ivbep_pcu.unc_edge,
+			reg->ivbep_pcu.unc_thres,
+			reg->ivbep_pcu.unc_occ_inv,
+			reg->ivbep_pcu.unc_occ_edge,
+			pe[e->event].name);
+
+	if (e->count == 1)
+		return;
+
+	f.val = e->codes[1];
+
+	__pfm_vbprintf("[UNC_PCU_FILTER=0x%"PRIx64" band0=%u band1=%u band2=%u band3=%u]\n",
+			f.val,
+			f.pcu_filt.filt0,
+			f.pcu_filt.filt1,
+			f.pcu_filt.filt2,
+			f.pcu_filt.filt3);
+}
+
+
+pfmlib_pmu_t intel_ivbep_unc_pcu_support = {
+	.desc			= "Intel Ivy Bridge-EP PCU uncore",
+	.name			= "ivbep_unc_pcu",
+	.perf_name		= "uncore_pcu",
+	.pmu			= PFM_PMU_INTEL_IVBEP_UNC_PCU,
+	.pme_count		= LIBPFM_ARRAY_SIZE(intel_ivbep_unc_p_pe),
+	.type			= PFM_PMU_TYPE_UNCORE,
+	.num_cntrs		= 4,
+	.num_fixed_cntrs	= 0,
+	.max_encoding		= 2,
+	.pe			= intel_ivbep_unc_p_pe,
+	.atdesc			= snbep_unc_mods,
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK,
+	.pmu_detect		= pfm_intel_ivbep_unc_detect,
+	.get_event_encoding[PFM_OS_NONE] = pfm_intel_snbep_unc_get_encoding,
+	 PFMLIB_ENCODE_PERF(pfm_intel_snbep_unc_get_perf_encoding),
+	 PFMLIB_OS_DETECT(pfm_intel_x86_perf_detect),
+	.get_event_first	= pfm_intel_x86_get_event_first,
+	.get_event_next		= pfm_intel_x86_get_event_next,
+	.event_is_valid		= pfm_intel_x86_event_is_valid,
+	.validate_table		= pfm_intel_x86_validate_table,
+	.get_event_info		= pfm_intel_x86_get_event_info,
+	.get_event_attr_info	= pfm_intel_x86_get_event_attr_info,
+	PFMLIB_VALID_PERF_PATTRS(pfm_intel_snbep_unc_perf_validate_pattrs),
+	.get_event_nattrs	= pfm_intel_x86_get_event_nattrs,
+	.can_auto_encode	= pfm_intel_snbep_unc_can_auto_encode,
+	.display_reg		= display_pcu,
+};
diff --git a/src/libpfm4/lib/pfmlib_intel_ivbep_unc_qpi.c b/src/libpfm4/lib/pfmlib_intel_ivbep_unc_qpi.c
new file mode 100644
index 0000000..e68eb75
--- /dev/null
+++ b/src/libpfm4/lib/pfmlib_intel_ivbep_unc_qpi.c
@@ -0,0 +1,85 @@
+/*
+ * pfmlib_intel_ivbep_qpi.c : Intel IvyBridge-EP QPI uncore PMU
+ *
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+#include <sys/types.h>
+#include <ctype.h>
+#include <string.h>
+#include <stdlib.h>
+#include <stdio.h>
+
+/* private headers */
+#include "pfmlib_priv.h"
+#include "pfmlib_intel_x86_priv.h"
+#include "pfmlib_intel_snbep_unc_priv.h"
+#include "events/intel_ivbep_unc_qpi_events.h"
+
+static void
+display_qpi(void *this, pfmlib_event_desc_t *e, void *val)
+{
+	const intel_x86_entry_t *pe = this_pe(this);
+	pfm_snbep_unc_reg_t *reg = val;
+
+	__pfm_vbprintf("[UNC_QPI=0x%"PRIx64" event=0x%x sel_ext=%d umask=0x%x en=%d "
+		       "inv=%d edge=%d thres=%d] %s\n",
+			reg->val,
+			reg->qpi.unc_event,
+			reg->qpi.unc_event_ext,
+			reg->qpi.unc_umask,
+			reg->qpi.unc_en,
+			reg->qpi.unc_inv,
+			reg->qpi.unc_edge,
+			reg->qpi.unc_thres,
+			pe[e->event].name);
+}
+
+#define DEFINE_QPI_BOX(n) \
+pfmlib_pmu_t intel_ivbep_unc_qpi##n##_support = {\
+	.desc			= "Intel Ivy Bridge-EP QPI"#n" uncore",\
+	.name			= "ivbep_unc_qpi"#n,\
+	.perf_name		= "uncore_qpi_"#n,\
+	.pmu			= PFM_PMU_INTEL_IVBEP_UNC_QPI##n,\
+	.pme_count		= LIBPFM_ARRAY_SIZE(intel_ivbep_unc_q_pe),\
+	.type			= PFM_PMU_TYPE_UNCORE,\
+	.num_cntrs		= 4,\
+	.num_fixed_cntrs	= 0,\
+	.max_encoding		= 3,\
+	.pe			= intel_ivbep_unc_q_pe,\
+	.atdesc			= snbep_unc_mods,\
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK,\
+	.pmu_detect		= pfm_intel_ivbep_unc_detect,\
+	.get_event_encoding[PFM_OS_NONE] = pfm_intel_snbep_unc_get_encoding,\
+	 PFMLIB_ENCODE_PERF(pfm_intel_snbep_unc_get_perf_encoding),\
+	 PFMLIB_OS_DETECT(pfm_intel_x86_perf_detect), \
+	.get_event_first	= pfm_intel_x86_get_event_first,\
+	.get_event_next		= pfm_intel_x86_get_event_next,\
+	.event_is_valid		= pfm_intel_x86_event_is_valid,\
+	.validate_table		= pfm_intel_x86_validate_table,\
+	.get_event_info		= pfm_intel_x86_get_event_info,\
+	.get_event_attr_info	= pfm_intel_x86_get_event_attr_info,\
+	PFMLIB_VALID_PERF_PATTRS(pfm_intel_snbep_unc_perf_validate_pattrs),\
+	.get_event_nattrs	= pfm_intel_x86_get_event_nattrs,\
+	.display_reg		= display_qpi,\
+}
+DEFINE_QPI_BOX(0);
+DEFINE_QPI_BOX(1);
+DEFINE_QPI_BOX(2);
diff --git a/src/libpfm4/lib/pfmlib_intel_ivbep_unc_r2pcie.c b/src/libpfm4/lib/pfmlib_intel_ivbep_unc_r2pcie.c
new file mode 100644
index 0000000..87c680c
--- /dev/null
+++ b/src/libpfm4/lib/pfmlib_intel_ivbep_unc_r2pcie.c
@@ -0,0 +1,61 @@
+/*
+ * pfmlib_intel_ivbep_r2pcie.c : Intel IvyBridge-EP R2PCIe uncore PMU
+ *
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+#include <sys/types.h>
+#include <ctype.h>
+#include <string.h>
+#include <stdlib.h>
+#include <stdio.h>
+
+/* private headers */
+#include "pfmlib_priv.h"
+#include "pfmlib_intel_x86_priv.h"
+#include "pfmlib_intel_snbep_unc_priv.h"
+#include "events/intel_ivbep_unc_r2pcie_events.h"
+
+pfmlib_pmu_t intel_ivbep_unc_r2pcie_support = {
+	.desc			= "Intel Ivy Bridge-EP R2PCIe uncore",
+	.name			= "ivbep_unc_r2pcie",
+	.perf_name		= "uncore_r2pcie",
+	.pmu			= PFM_PMU_INTEL_IVBEP_UNC_R2PCIE,
+	.pme_count		= LIBPFM_ARRAY_SIZE(intel_ivbep_unc_r2_pe),
+	.type			= PFM_PMU_TYPE_UNCORE,
+	.num_cntrs		= 4,
+	.num_fixed_cntrs	= 0,
+	.max_encoding		= 1,
+	.pe			= intel_ivbep_unc_r2_pe,
+	.atdesc			= snbep_unc_mods,
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK,
+	.pmu_detect		= pfm_intel_ivbep_unc_detect,
+	.get_event_encoding[PFM_OS_NONE] = pfm_intel_snbep_unc_get_encoding,
+	 PFMLIB_ENCODE_PERF(pfm_intel_snbep_unc_get_perf_encoding),
+	 PFMLIB_OS_DETECT(pfm_intel_x86_perf_detect),
+	.get_event_first	= pfm_intel_x86_get_event_first,
+	.get_event_next		= pfm_intel_x86_get_event_next,
+	.event_is_valid		= pfm_intel_x86_event_is_valid,
+	.validate_table		= pfm_intel_x86_validate_table,
+	.get_event_info		= pfm_intel_x86_get_event_info,
+	.get_event_attr_info	= pfm_intel_x86_get_event_attr_info,
+	PFMLIB_VALID_PERF_PATTRS(pfm_intel_snbep_unc_perf_validate_pattrs),
+	.get_event_nattrs	= pfm_intel_x86_get_event_nattrs,
+};
diff --git a/src/libpfm4/lib/pfmlib_intel_ivbep_unc_r3qpi.c b/src/libpfm4/lib/pfmlib_intel_ivbep_unc_r3qpi.c
new file mode 100644
index 0000000..5ed7e4d
--- /dev/null
+++ b/src/libpfm4/lib/pfmlib_intel_ivbep_unc_r3qpi.c
@@ -0,0 +1,65 @@
+/*
+ * pfmlib_intel_ivbep_r3qpi.c : Intel IvyBridge-EP R3QPI uncore PMU
+ *
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+#include <sys/types.h>
+#include <ctype.h>
+#include <string.h>
+#include <stdlib.h>
+#include <stdio.h>
+
+/* private headers */
+#include "pfmlib_priv.h"
+#include "pfmlib_intel_x86_priv.h"
+#include "pfmlib_intel_snbep_unc_priv.h"
+#include "events/intel_ivbep_unc_r3qpi_events.h"
+
+#define DEFINE_R3QPI_BOX(n) \
+pfmlib_pmu_t intel_ivbep_unc_r3qpi##n##_support = {\
+	.desc			= "Intel Ivy Bridge-EP R3QPI"#n" uncore", \
+	.name			= "ivbep_unc_r3qpi"#n,\
+	.perf_name		= "uncore_r3qpi_"#n, \
+	.pmu			= PFM_PMU_INTEL_IVBEP_UNC_R3QPI##n, \
+	.pme_count		= LIBPFM_ARRAY_SIZE(intel_ivbep_unc_r3_pe),\
+	.type			= PFM_PMU_TYPE_UNCORE,\
+	.num_cntrs		= 3,\
+	.num_fixed_cntrs	= 0,\
+	.max_encoding		= 1,\
+	.pe			= intel_ivbep_unc_r3_pe,\
+	.atdesc			= snbep_unc_mods,\
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK,\
+	.pmu_detect		= pfm_intel_ivbep_unc_detect,\
+	.get_event_encoding[PFM_OS_NONE] = pfm_intel_snbep_unc_get_encoding,\
+	 PFMLIB_ENCODE_PERF(pfm_intel_snbep_unc_get_perf_encoding),\
+	 PFMLIB_OS_DETECT(pfm_intel_x86_perf_detect), \
+	.get_event_first	= pfm_intel_x86_get_event_first,\
+	.get_event_next		= pfm_intel_x86_get_event_next,\
+	.event_is_valid		= pfm_intel_x86_event_is_valid,\
+	.validate_table		= pfm_intel_x86_validate_table,\
+	.get_event_info		= pfm_intel_x86_get_event_info,\
+	.get_event_attr_info	= pfm_intel_x86_get_event_attr_info,\
+	PFMLIB_VALID_PERF_PATTRS(pfm_intel_snbep_unc_perf_validate_pattrs),\
+	.get_event_nattrs	= pfm_intel_x86_get_event_nattrs,\
+}
+DEFINE_R3QPI_BOX(0);
+DEFINE_R3QPI_BOX(1);
+DEFINE_R3QPI_BOX(2);
diff --git a/src/libpfm4/lib/pfmlib_intel_ivbep_unc_ubo.c b/src/libpfm4/lib/pfmlib_intel_ivbep_unc_ubo.c
new file mode 100644
index 0000000..db7f629
--- /dev/null
+++ b/src/libpfm4/lib/pfmlib_intel_ivbep_unc_ubo.c
@@ -0,0 +1,61 @@
+/*
+ * pfmlib_intel_ivbep_unc_ubo.c : Intel IvyBridge-EP U-Box uncore PMU
+ *
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+#include <sys/types.h>
+#include <ctype.h>
+#include <string.h>
+#include <stdlib.h>
+#include <stdio.h>
+
+/* private headers */
+#include "pfmlib_priv.h"
+#include "pfmlib_intel_x86_priv.h"
+#include "pfmlib_intel_snbep_unc_priv.h"
+#include "events/intel_ivbep_unc_ubo_events.h"
+
+pfmlib_pmu_t intel_ivbep_unc_ubo_support = {
+	.desc			= "Intel Ivy Bridge-EP U-Box uncore",
+	.name			= "ivbep_unc_ubo",
+	.perf_name		= "uncore_ubox",
+	.pmu			= PFM_PMU_INTEL_IVBEP_UNC_UBOX,
+	.pme_count		= LIBPFM_ARRAY_SIZE(intel_ivbep_unc_u_pe),
+	.type			= PFM_PMU_TYPE_UNCORE,
+	.num_cntrs		= 2,
+	.num_fixed_cntrs	= 1,
+	.max_encoding		= 1,
+	.pe			= intel_ivbep_unc_u_pe,
+	.atdesc			= snbep_unc_mods,
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK,
+	.pmu_detect		= pfm_intel_ivbep_unc_detect,
+	.get_event_encoding[PFM_OS_NONE] = pfm_intel_snbep_unc_get_encoding,
+	 PFMLIB_ENCODE_PERF(pfm_intel_snbep_unc_get_perf_encoding),
+	 PFMLIB_OS_DETECT(pfm_intel_x86_perf_detect),
+	.get_event_first	= pfm_intel_x86_get_event_first,
+	.get_event_next		= pfm_intel_x86_get_event_next,
+	.event_is_valid		= pfm_intel_x86_event_is_valid,
+	.validate_table		= pfm_intel_x86_validate_table,
+	.get_event_info		= pfm_intel_x86_get_event_info,
+	.get_event_attr_info	= pfm_intel_x86_get_event_attr_info,
+	PFMLIB_VALID_PERF_PATTRS(pfm_intel_snbep_unc_perf_validate_pattrs),
+	.get_event_nattrs	= pfm_intel_x86_get_event_nattrs,
+};
diff --git a/src/libpfm4/lib/pfmlib_intel_snbep_unc.c b/src/libpfm4/lib/pfmlib_intel_snbep_unc.c
index 9813e1c..8fb6472 100644
--- a/src/libpfm4/lib/pfmlib_intel_snbep_unc.c
+++ b/src/libpfm4/lib/pfmlib_intel_snbep_unc.c
@@ -39,9 +39,10 @@ const pfmlib_attr_desc_t snbep_unc_mods[]={
 	PFM_ATTR_I("t", "threshold in range [0-31]"),	/* threshold */
 	PFM_ATTR_I("tf", "thread id filter [0-1]"),	/* thread id */
 	PFM_ATTR_I("cf", "core id filter [0-7]"),	/* core id */
-	PFM_ATTR_I("nf", "node id bitmask filter [0-255]"),/* nodeid mask */
+	PFM_ATTR_I("nf", "node id bitmask filter [0-255]"),/* nodeid mask filter0 */
 	PFM_ATTR_I("ff", "frequency >= 100Mhz * [0-255]"),/* freq filter */
 	PFM_ATTR_I("addr", "physical address matcher [40 bits]"),/* address matcher */
+	PFM_ATTR_I("nf", "node id bitmask filter [0-255]"),/* nodeid mask filter1 */
 	PFM_ATTR_NULL
 };
 
@@ -65,6 +66,26 @@ pfm_intel_snbep_unc_detect(void *this)
 	return PFM_SUCCESS;
 }
 
+int
+pfm_intel_ivbep_unc_detect(void *this)
+{
+       int ret;
+
+       ret = pfm_intel_x86_detect();
+       if (ret != PFM_SUCCESS)
+
+       if (pfm_intel_x86_cfg.family != 6)
+               return PFM_ERR_NOTSUPP;
+
+       switch(pfm_intel_x86_cfg.model) {
+               case 62: /* SandyBridge-EP */
+                         break;
+               default:
+                       return PFM_ERR_NOTSUPP;
+       }
+       return PFM_SUCCESS;
+}
+
 static void
 display_com(void *this, pfmlib_event_desc_t *e, void *val)
 {
@@ -113,7 +134,7 @@ int
 snbep_unc_add_defaults(void *this, pfmlib_event_desc_t *e,
 			   unsigned int msk,
 			   uint64_t *umask,
-			   pfm_snbep_unc_reg_t *filter,
+			   pfm_snbep_unc_reg_t *filters,
 			   unsigned int max_grpid)
 {
 	const intel_x86_entry_t *pe = this_pe(this);
@@ -149,15 +170,27 @@ snbep_unc_add_defaults(void *this, pfmlib_event_desc_t *e,
 				continue;
 			}
 
+			if (intel_x86_uflag(this, e->event, idx, INTEL_X86_GRP_DFL_NONE)) {
+				skip = 1;
+				continue;
+			}
+
 			/* umask is default for group */
 			if (intel_x86_uflag(this, e->event, idx, INTEL_X86_DFL)) {
-				DPRINT("added default %s for group %d j=%d idx=%d\n", ent->umasks[idx].uname, i, j, idx);
+				DPRINT("added default %s for group %d j=%d idx=%d ucode=0x%"PRIx64"\n",
+					ent->umasks[idx].uname,
+					i,	
+					j,
+					idx,
+					ent->umasks[idx].ucode);
 				/*
 				 * default could be an alias, but
 				 * ucode must reflect actual code
 				 */
 				*umask |= ent->umasks[idx].ucode >> 8;
-				filter->val |= pe[e->event].umasks[idx].ufilters[0];
+
+				filters[0].val |= pe[e->event].umasks[idx].ufilters[0];
+				filters[1].val |= pe[e->event].umasks[idx].ufilters[1];
 
 				e->attrs[k].id = j; /* pattrs index */
 				e->attrs[k].ival = 0;
@@ -181,7 +214,7 @@ snbep_unc_add_defaults(void *this, pfmlib_event_desc_t *e,
 			return PFM_ERR_UMASK;
 		}
 	}
-	DPRINT("max_grpid=%d nattrs=%d k=%d\n", max_grpid, e->nattrs, k);
+	DPRINT("max_grpid=%d nattrs=%d k=%d umask=0x%"PRIx64"\n", max_grpid, e->nattrs, k, *umask);
 done:
 	e->nattrs = k;
 	return PFM_SUCCESS;
@@ -201,7 +234,7 @@ pfm_intel_snbep_unc_get_encoding(void *this, pfmlib_event_desc_t *e)
 	int umodmsk = 0, modmsk_r = 0;
 	int pcu_filt_band = -1;
 	pfm_snbep_unc_reg_t reg;
-	pfm_snbep_unc_reg_t filter;
+	pfm_snbep_unc_reg_t filters[INTEL_X86_MAX_FILTERS];
 	pfm_snbep_unc_reg_t addr;
 	pfm_event_attr_info_t *a;
 	uint64_t val, umask1, umask2;
@@ -214,8 +247,8 @@ pfm_intel_snbep_unc_get_encoding(void *this, pfmlib_event_desc_t *e)
 
 	memset(grpcounts, 0, sizeof(grpcounts));
 	memset(ncombo, 0, sizeof(ncombo));
+	memset(filters, 0, sizeof(filters));
 
-	filter.val = 0;
 	addr.val = 0;
 
 	pe = this_pe(this);
@@ -300,10 +333,12 @@ pfm_intel_snbep_unc_get_encoding(void *this, pfmlib_event_desc_t *e)
 			last_grpid = grpid;
 
 			um = pe[e->event].umasks[a->idx].ucode;
-			filter.val |= pe[e->event].umasks[a->idx].ufilters[0];
+			filters[0].val |= pe[e->event].umasks[a->idx].ufilters[0];
+			filters[1].val |= pe[e->event].umasks[a->idx].ufilters[1];
 
 			um >>= 8;
 			umask2  |= um;
+
 			ugrpmsk |= 1 << pe[e->event].umasks[a->idx].grpid;
 
 			/* PCU occ event */
@@ -367,30 +402,38 @@ pfm_intel_snbep_unc_get_encoding(void *this, pfmlib_event_desc_t *e)
 					}
 					reg.cbo.unc_tid = 1;
 					has_cbo_tid = 1;
-					filter.cbo_filt.tid = ival;
+					filters[0].cbo_filt.tid = ival;
 					umodmsk |= _SNBEP_UNC_ATTR_TF;
 					break;
 				case SNBEP_UNC_ATTR_CF: /* core id */
 					if (ival > 7)
 						return PFM_ERR_ATTR_VAL;
 					reg.cbo.unc_tid = 1;
-					filter.cbo_filt.cid = ival;
+					filters[0].cbo_filt.cid = ival;
 					has_cbo_tid = 1;
 					umodmsk |= _SNBEP_UNC_ATTR_CF;
 					break;
-				case SNBEP_UNC_ATTR_NF: /* node id */
+				case SNBEP_UNC_ATTR_NF: /* node id filter0 */
 					if (ival > 255 || ival == 0) {
 						DPRINT("invalid nf,  0 < nf < 256\n");
 						return PFM_ERR_ATTR_VAL;
 					}
-					filter.cbo_filt.nid = ival;
+					filters[0].cbo_filt.nid = ival;
 					umodmsk |= _SNBEP_UNC_ATTR_NF;
 					break;
+				case SNBEP_UNC_ATTR_NF1: /* node id filter1 */
+					if (ival > 255 || ival == 0) {
+						DPRINT("invalid nf,  0 < nf < 256\n");
+						return PFM_ERR_ATTR_VAL;
+					}
+					filters[1].ivbep_cbo_filt1.nid = ival;
+					umodmsk |= _SNBEP_UNC_ATTR_NF1;
+					break;
 				case SNBEP_UNC_ATTR_FF: /* freq band filter */
 					if (ival > 255)
 						return PFM_ERR_ATTR_VAL;
 					pcu_filt_band = get_pcu_filt_band(this, reg);
-					filter.val = ival << (pcu_filt_band * 8);
+					filters[0].val = ival << (pcu_filt_band * 8);
 					umodmsk |= _SNBEP_UNC_ATTR_FF;
 					break;
 				case SNBEP_UNC_ATTR_A: /* addr filter */
@@ -411,11 +454,10 @@ pfm_intel_snbep_unc_get_encoding(void *this, pfmlib_event_desc_t *e)
 	if (pe[e->event].numasks && (ugrpmsk != grpmsk || ugrpmsk == 0)) {
 		uint64_t um = 0;
 		ugrpmsk ^= grpmsk;
-		ret = snbep_unc_add_defaults(this, e, ugrpmsk, &um, &filter, max_grpid);
+		ret = snbep_unc_add_defaults(this, e, ugrpmsk, &um, filters, max_grpid);
 		if (ret != PFM_SUCCESS)
 			return ret;
-		um >>= 8;
-		umask2 = um;
+		umask2 |= um;
 	}
 
 	/*
@@ -425,6 +467,10 @@ pfm_intel_snbep_unc_get_encoding(void *this, pfmlib_event_desc_t *e)
 		DPRINT("using nf= on an umask which does not require it\n");
 		return PFM_ERR_ATTR;
 	}
+	if (!(modmsk_r & _SNBEP_UNC_ATTR_NF1) && (umodmsk & _SNBEP_UNC_ATTR_NF1)) {
+		DPRINT("using nf= on an umask which does not require it\n");
+		return PFM_ERR_ATTR;
+	}
 
 	if (modmsk_r && !(umodmsk & modmsk_r)) {
 		DPRINT("required modifiers missing: 0x%x\n", modmsk_r);
@@ -443,6 +489,7 @@ pfm_intel_snbep_unc_get_encoding(void *this, pfmlib_event_desc_t *e)
 		else if (a->type == PFM_ATTR_RAW_UMASK)
 			evt_strcat(e->fstr, ":0x%x", a->idx);
 	}
+	DPRINT("umask2=0x%"PRIx64" umask1=0x%"PRIx64"\n", umask2, umask1);
 	e->count = 0;
 	reg.val |= (umask1 | umask2)  << 8;
 
@@ -451,8 +498,10 @@ pfm_intel_snbep_unc_get_encoding(void *this, pfmlib_event_desc_t *e)
 	/*
 	 * handles C-box filter
 	 */
-	if (filter.val || has_cbo_tid)
-		e->codes[e->count++] = filter.val;
+	if (filters[0].val || filters[1].val || has_cbo_tid)
+		e->codes[e->count++] = filters[0].val;
+	if (filters[1].val)
+		e->codes[e->count++] = filters[1].val;
 
 	/* HA address matcher */
 	if (addr.val)
@@ -491,10 +540,15 @@ pfm_intel_snbep_unc_get_encoding(void *this, pfmlib_event_desc_t *e)
 			evt_strcat(e->fstr, ":%s=%lu", snbep_unc_mods[idx].name, reg.cbo.unc_tid);
 			break;
 		case SNBEP_UNC_ATTR_FF:
-			evt_strcat(e->fstr, ":%s=%lu", snbep_unc_mods[idx].name, (filter.val >> (pcu_filt_band*8)) & 0xff);
+			evt_strcat(e->fstr, ":%s=%lu", snbep_unc_mods[idx].name, (filters[0].val >> (pcu_filt_band*8)) & 0xff);
 			break;
 		case SNBEP_UNC_ATTR_NF:
-			evt_strcat(e->fstr, ":%s=%lu", snbep_unc_mods[idx].name, filter.cbo_filt.nid);
+			if (modmsk_r & _SNBEP_UNC_ATTR_NF)
+				evt_strcat(e->fstr, ":%s=%lu", snbep_unc_mods[idx].name, filters[0].cbo_filt.nid);
+			break;
+		case SNBEP_UNC_ATTR_NF1:
+			if (modmsk_r & _SNBEP_UNC_ATTR_NF1)
+				evt_strcat(e->fstr, ":%s=%lu", snbep_unc_mods[idx].name, filters[1].ivbep_cbo_filt1.nid);
 			break;
 		case SNBEP_UNC_ATTR_A:
 			evt_strcat(e->fstr, ":%s=0x%lx", snbep_unc_mods[idx].name,
diff --git a/src/libpfm4/lib/pfmlib_intel_snbep_unc_perf_event.c b/src/libpfm4/lib/pfmlib_intel_snbep_unc_perf_event.c
index e6cc625..2b06cb2 100644
--- a/src/libpfm4/lib/pfmlib_intel_snbep_unc_perf_event.c
+++ b/src/libpfm4/lib/pfmlib_intel_snbep_unc_perf_event.c
@@ -83,14 +83,21 @@ pfm_intel_snbep_unc_get_perf_encoding(void *this, pfmlib_event_desc_t *e)
 
 	attr->config = reg.val;
 
-	/*
-	 * various filters
-	 */
-	if (e->count == 2)
-		attr->config1 = e->codes[1];
-
-	if (e->count == 3)
-		attr->config2 = e->codes[2];
+	if (is_cbo_filt_event(this, reg) && e->count > 1) {
+		if (e->count >= 2)
+			attr->config1 = e->codes[1];
+		if (e->count >= 3)
+			attr->config1 |= e->codes[2] << 32;
+	} else {
+		/*
+		 * various filters
+		 */
+		if (e->count >= 2)
+			attr->config1 = e->codes[1];
+
+		if (e->count >= 3)
+			attr->config2 = e->codes[2];
+	}
 
 	/*
 	 * uncore measures at all priv levels
diff --git a/src/libpfm4/lib/pfmlib_intel_snbep_unc_priv.h b/src/libpfm4/lib/pfmlib_intel_snbep_unc_priv.h
index 3631930..d93b5f8 100644
--- a/src/libpfm4/lib/pfmlib_intel_snbep_unc_priv.h
+++ b/src/libpfm4/lib/pfmlib_intel_snbep_unc_priv.h
@@ -1,5 +1,5 @@
 /*
- * pfmlib_intel_snbep_unc_priv.c : Intel SandyBridge-EP common definitions
+ * pfmlib_intel_snbep_unc_priv.c : Intel SandyBridge/IvyBridge-EP common definitions
  *
  * Copyright (c) 2012 Google, Inc
  * Contributed by Stephane Eranian <eranian@gmail.com>
@@ -28,6 +28,7 @@
  * Intel x86 specific pmu flags (pmu->flags 16 MSB)
  */
 #define INTEL_PMU_FL_UNC_OCC 0x10000	/* PMU has occupancy counter filters */
+#define INTEL_PMU_FL_UNC_CBO 0x20000	/* PMU is Cbox */
 
 
 #define SNBEP_UNC_ATTR_E		0
@@ -36,9 +37,10 @@
 #define SNBEP_UNC_ATTR_T5		3
 #define SNBEP_UNC_ATTR_TF		4
 #define SNBEP_UNC_ATTR_CF		5
-#define SNBEP_UNC_ATTR_NF		6
+#define SNBEP_UNC_ATTR_NF		6 /* for filter0 */
 #define SNBEP_UNC_ATTR_FF		7
 #define SNBEP_UNC_ATTR_A		8
+#define SNBEP_UNC_ATTR_NF1		9 /* for filter1 */
 
 #define _SNBEP_UNC_ATTR_I	(1 << SNBEP_UNC_ATTR_I)
 #define _SNBEP_UNC_ATTR_E	(1 << SNBEP_UNC_ATTR_E)
@@ -49,41 +51,79 @@
 #define _SNBEP_UNC_ATTR_NF	(1 << SNBEP_UNC_ATTR_NF)
 #define _SNBEP_UNC_ATTR_FF	(1 << SNBEP_UNC_ATTR_FF)
 #define _SNBEP_UNC_ATTR_A	(1 << SNBEP_UNC_ATTR_A)
+#define _SNBEP_UNC_ATTR_NF1	(1 << SNBEP_UNC_ATTR_NF1)
+
+#define SNBEP_UNC_IRP_ATTRS \
+	(_SNBEP_UNC_ATTR_E|_SNBEP_UNC_ATTR_T8)
 
 #define SNBEP_UNC_R3QPI_ATTRS \
 	(_SNBEP_UNC_ATTR_I|_SNBEP_UNC_ATTR_E|_SNBEP_UNC_ATTR_T8)
 
+#define IVBEP_UNC_R3QPI_ATTRS \
+	(_SNBEP_UNC_ATTR_E|_SNBEP_UNC_ATTR_T8)
+
 #define SNBEP_UNC_R2PCIE_ATTRS \
 	(_SNBEP_UNC_ATTR_I|_SNBEP_UNC_ATTR_E|_SNBEP_UNC_ATTR_T8)
 
+#define IVBEP_UNC_R2PCIE_ATTRS \
+	(_SNBEP_UNC_ATTR_E|_SNBEP_UNC_ATTR_T8)
+
 #define SNBEP_UNC_QPI_ATTRS \
 	(_SNBEP_UNC_ATTR_I|_SNBEP_UNC_ATTR_E|_SNBEP_UNC_ATTR_T8)
 
+#define IVBEP_UNC_QPI_ATTRS \
+	(_SNBEP_UNC_ATTR_E|_SNBEP_UNC_ATTR_T8)
+
 #define SNBEP_UNC_UBO_ATTRS \
 	(_SNBEP_UNC_ATTR_I|_SNBEP_UNC_ATTR_E|_SNBEP_UNC_ATTR_T8)
 
+#define IVBEP_UNC_UBO_ATTRS \
+	(_SNBEP_UNC_ATTR_E|_SNBEP_UNC_ATTR_T8)
+
+
 #define SNBEP_UNC_PCU_ATTRS \
 	(_SNBEP_UNC_ATTR_I|_SNBEP_UNC_ATTR_E|_SNBEP_UNC_ATTR_T5)
 
+#define IVBEP_UNC_PCU_ATTRS \
+	(_SNBEP_UNC_ATTR_E|_SNBEP_UNC_ATTR_T5)
+
 #define SNBEP_UNC_PCU_BAND_ATTRS \
 	(SNBEP_UNC_PCU_ATTRS | _SNBEP_UNC_ATTR_FF)
 
+#define IVBEP_UNC_PCU_BAND_ATTRS \
+	(IVBEP_UNC_PCU_ATTRS | _SNBEP_UNC_ATTR_FF)
+
 #define SNBEP_UNC_IMC_ATTRS \
 	(_SNBEP_UNC_ATTR_I|_SNBEP_UNC_ATTR_E|_SNBEP_UNC_ATTR_T8)
 
-#define SNBEP_UNC_CBO_ATTRS	\
+#define IVBEP_UNC_IMC_ATTRS \
+	(_SNBEP_UNC_ATTR_E|_SNBEP_UNC_ATTR_T8)
+
+#define SNBEP_UNC_CBO_ATTRS   \
 	(_SNBEP_UNC_ATTR_I   |\
 	 _SNBEP_UNC_ATTR_E   |\
 	 _SNBEP_UNC_ATTR_T8  |\
 	 _SNBEP_UNC_ATTR_CF  |\
 	 _SNBEP_UNC_ATTR_TF)
 
+#define IVBEP_UNC_CBO_ATTRS   \
+	(_SNBEP_UNC_ATTR_E   |\
+	 _SNBEP_UNC_ATTR_T8  |\
+	 _SNBEP_UNC_ATTR_CF  |\
+	 _SNBEP_UNC_ATTR_TF)
+
 #define SNBEP_UNC_CBO_NID_ATTRS	\
 	(SNBEP_UNC_CBO_ATTRS|_SNBEP_UNC_ATTR_NF)
 
+#define IVBEP_UNC_CBO_NID_ATTRS	\
+	(IVBEP_UNC_CBO_ATTRS|_SNBEP_UNC_ATTR_NF1)
+
 #define SNBEP_UNC_HA_ATTRS \
 	(_SNBEP_UNC_ATTR_I|_SNBEP_UNC_ATTR_E|_SNBEP_UNC_ATTR_T8)
 
+#define IVBEP_UNC_HA_ATTRS \
+	(_SNBEP_UNC_ATTR_E|_SNBEP_UNC_ATTR_T8)
+
 #define SNBEP_UNC_HA_OPC_ATTRS \
 	(SNBEP_UNC_HA_ATTRS|_SNBEP_UNC_ATTR_A)
 
@@ -133,6 +173,24 @@ typedef union {
 	} pcu; /* covers pcu */
 	struct {
 		unsigned long unc_event:8;	/* event code */
+		unsigned long unc_res1:6;	/* reserved */
+		unsigned long unc_occ:2;	/* occ select */
+		unsigned long unc_res2:1;	/* reserved */
+		unsigned long unc_rst:1;	/* reset */
+		unsigned long unc_edge:1;	/* edge detec */
+		unsigned long unc_res3:1;	/* reserved */
+		unsigned long unc_ov_en:1;	/* overflow enable */
+		unsigned long unc_sel_ext:1;	/* event_sel extension */
+		unsigned long unc_en:1;		/* enable */
+		unsigned long unc_res4:1;	/* reserved */
+		unsigned long unc_thres:5;	/* threshold */
+		unsigned long unc_res5:1;	/* reserved */
+		unsigned long unc_occ_inv:1;	/* occupancy invert */
+		unsigned long unc_occ_edge:1;	/* occupancy edge detect */
+		unsigned long unc_res6:32;	/* reserved */
+	} ivbep_pcu; /* covers ivb-ep pcu */
+	struct {
+		unsigned long unc_event:8;	/* event code */
 		unsigned long unc_umask:8;	/* unit maks */
 		unsigned long unc_res1:1;	/* reserved */
 		unsigned long unc_rst:1;	/* reset */
@@ -158,6 +216,23 @@ typedef union {
 		unsigned long res4:32;
 	} cbo_filt; /* cbox filter */
 	struct {
+		unsigned long tid:1;
+		unsigned long cid:4;
+		unsigned long res0:12;
+		unsigned long state:6;
+		unsigned long res1:9;
+		unsigned long res2:32;
+	} ivbep_cbo_filt0; /* ivbep cbox filter0 */
+	struct {
+		unsigned long nid:16;
+		unsigned long res0:4;
+		unsigned long opc:9;
+		unsigned long res1:1;
+		unsigned long nc:1;
+		unsigned long isoc:1;
+		unsigned long res2:32;
+	} ivbep_cbo_filt1; /* ivbep cbox filter1 */
+	struct {
 		unsigned long filt0:8; /* band0 freq filter */
 		unsigned long filt1:8; /* band1 freq filter */
 		unsigned long filt2:8; /* band2 freq filter */
@@ -175,13 +250,43 @@ typedef union {
 		unsigned long res1:26; /* reserved */
 		unsigned long res2:32; /* reserved */
 	} ha_opc;
+	struct {
+		unsigned long unc_event:8;	/* event code */
+		unsigned long unc_umask:8;	/* unit mask */
+		unsigned long unc_res1:1;	/* reserved */
+		unsigned long unc_rst:1;	/* reset */
+		unsigned long unc_edge:1;	/* edge detec */
+		unsigned long unc_res2:3;	/* reserved */
+		unsigned long unc_en:1;		/* enable */
+		unsigned long unc_res3:1;	/* reserved */
+		unsigned long unc_thres:8;	/* counter mask */
+		unsigned long unc_res4:32;	/* reserved */
+	} irp; /* covers irp */
 } pfm_snbep_unc_reg_t;
 
 extern void pfm_intel_snbep_unc_perf_validate_pattrs(void *this, pfmlib_event_desc_t *e);
 extern int  pfm_intel_snbep_unc_get_encoding(void *this, pfmlib_event_desc_t *e);
 extern const pfmlib_attr_desc_t snbep_unc_mods[];
 extern int  pfm_intel_snbep_unc_detect(void *this);
+extern int  pfm_intel_ivbep_unc_detect(void *this);
 extern int  pfm_intel_snbep_unc_get_perf_encoding(void *this, pfmlib_event_desc_t *e);
 extern int  pfm_intel_snbep_unc_can_auto_encode(void *this, int pidx, int uidx);
 extern int pfm_intel_snbep_unc_get_event_attr_info(void *this, int pidx, int attr_idx, pfm_event_attr_info_t *info);
+
+static inline int
+is_cbo_filt_event(void *this, pfm_intel_x86_reg_t reg)
+{
+	pfmlib_pmu_t *pmu = this;
+	uint64_t sel = reg.sel_event_select;
+	/*
+	 * umask bit 0 must be 1 (OPCODE)
+	 * TOR_INSERT: event code 0x35
+	 * TOR_OCCUPANCY: event code 0x36
+	 * LLC_LOOKUP : event code 0x34
+	 */
+	return (pmu->flags & INTEL_PMU_FL_UNC_CBO)
+		&& (reg.sel_unit_mask & 0x1)
+		&& (sel == 0x35 || sel == 0x36 || sel == 0x34);
+}
+
 #endif /* __PFMLIB_INTEL_SNBEP_UNC_PRIV_H__ */
diff --git a/src/libpfm4/lib/pfmlib_intel_x86.c b/src/libpfm4/lib/pfmlib_intel_x86.c
index baa9f63..cfa1730 100644
--- a/src/libpfm4/lib/pfmlib_intel_x86.c
+++ b/src/libpfm4/lib/pfmlib_intel_x86.c
@@ -215,9 +215,19 @@ pfm_intel_x86_add_defaults(void *this, pfmlib_event_desc_t *e,
 				continue;
 			}
 
+			if (intel_x86_uflag(this, e->event, idx, INTEL_X86_GRP_DFL_NONE)) {
+				skip = 1;
+				continue;
+			}
+
 			/* umask is default for group */
 			if (intel_x86_uflag(this, e->event, idx, INTEL_X86_DFL)) {
-				DPRINT("added default %s for group %d j=%d idx=%d\n", ent->umasks[idx].uname, i, j, idx);
+				DPRINT("added default %s for group %d j=%d idx=%d ucode=0x%"PRIx64"\n",
+					ent->umasks[idx].uname,
+					i,	
+					j,
+					idx,
+					ent->umasks[idx].ucode);
 				/*
 				 * default could be an alias, but
 				 * ucode must reflect actual code
@@ -246,7 +256,7 @@ pfm_intel_x86_add_defaults(void *this, pfmlib_event_desc_t *e,
 			return PFM_ERR_UMASK;
 		}
 	}
-	DPRINT("max_grpid=%d nattrs=%d k=%d\n", max_grpid, e->nattrs, k);
+	DPRINT("max_grpid=%d nattrs=%d k=%d umask=0x%"PRIx64"\n", max_grpid, e->nattrs, k, *umask);
 done:
 	e->nattrs = k;
 	return PFM_SUCCESS;
diff --git a/src/libpfm4/lib/pfmlib_intel_x86_priv.h b/src/libpfm4/lib/pfmlib_intel_x86_priv.h
index 0f0c1f5..3b077b1 100644
--- a/src/libpfm4/lib/pfmlib_intel_x86_priv.h
+++ b/src/libpfm4/lib/pfmlib_intel_x86_priv.h
@@ -34,7 +34,7 @@
  * maximum number of unit masks groups per event
  */
 #define INTEL_X86_NUM_GRP	8
-#define INTEL_X86_MAX_FILTERS	2
+#define INTEL_X86_MAX_FILTERS	3
 
 /*
  * unit mask description
@@ -86,6 +86,7 @@ typedef struct {
 #define INTEL_X86_NO_AUTOENCODE		0x100	/* does not support auto encoding validation */
 #define INTEL_X86_CODE_OVERRIDE		0x200	/* umask overrides event code */
 #define INTEL_X86_LDLAT			0x400	/* needs load latency modifier (ldlat) */
+#define INTEL_X86_GRP_DFL_NONE		0x800	/* ok if umask group defaults to no umask */
 
 typedef union pfm_intel_x86_reg {
 	unsigned long long val;			/* complete register value */
diff --git a/src/libpfm4/lib/pfmlib_perf_event_raw.c b/src/libpfm4/lib/pfmlib_perf_event_raw.c
new file mode 100644
index 0000000..e10d215
--- /dev/null
+++ b/src/libpfm4/lib/pfmlib_perf_event_raw.c
@@ -0,0 +1,175 @@
+/*
+ * pfmlib_perf_events_raw.c: support for raw event syntax
+ *
+ * Copyright (c) 2014 Google, Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@google.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+#include <sys/types.h>
+#include <string.h>
+#include <stdlib.h>
+#include <stdio.h>
+#include <unistd.h>
+#include <ctype.h>
+
+#include "pfmlib_priv.h"
+#include "pfmlib_perf_event_priv.h"
+
+static int
+pfm_perf_raw_detect(void *this)
+{
+#ifdef __linux__
+	/* ought to find a better way of detecting PERF */
+#define PERF_OLD_PROC_FILE "/proc/sys/kernel/perf_counter_paranoid"
+#define PERF_PROC_FILE "/proc/sys/kernel/perf_event_paranoid"
+	return !(access(PERF_PROC_FILE, F_OK)
+		  && access(PERF_OLD_PROC_FILE, F_OK)) ? PFM_SUCCESS: PFM_ERR_NOTSUPP;
+#else
+	return PFM_SUCCESS;
+#endif
+}
+
+static int
+pfm_perf_raw_get_event_first(void *this)
+{
+	return 0;
+}
+
+static int
+pfm_perf_raw_get_event_next(void *this, int idx)
+{
+	/* only one pseudo event */
+	return -1;
+}
+
+static int
+pfm_perf_raw_get_encoding(void *this, pfmlib_event_desc_t *e)
+{
+	/*
+	 * actual enoding done in pfm_perf_raw_match_event()
+	 */
+	e->fstr[0] = '\0';
+	evt_strcat(e->fstr, "r%"PRIx64, e->codes[0]);
+	return PFM_SUCCESS;
+}
+
+static int
+pfm_perf_raw_get_perf_encoding(void *this, pfmlib_event_desc_t *e)
+{
+	struct perf_event_attr *attr;
+
+	attr = e->os_data;
+	attr->type = PERF_TYPE_RAW;
+	attr->config = e->codes[0];
+
+	attr->config1 = e->codes[1];
+	attr->config2 = e->codes[2];
+
+	return PFM_SUCCESS;
+}
+
+static int
+pfm_perf_raw_event_is_valid(void *this, int idx)
+{
+	return idx == 0;
+}
+
+static int
+pfm_perf_raw_get_event_attr_info(void *this, int idx, int attr_idx, pfm_event_attr_info_t *info)
+{
+	return PFM_ERR_ATTR;
+}
+
+static int
+pfm_perf_raw_get_event_info(void *this, int idx, pfm_event_info_t *info)
+{
+	pfmlib_pmu_t *pmu = this;
+
+	info->name  = "r0000";
+	info->desc  = "perf_events raw event syntax: r[0-9a-fA-F]+",
+	info->code  = 0;
+	info->equiv = NULL;
+	info->idx   = 0;
+	info->pmu   = pmu->pmu;
+	info->is_precise = 0;
+
+	/* unit masks + modifiers */
+	info->nattrs  = 0;
+
+	return PFM_SUCCESS;
+}
+
+static unsigned int
+pfm_perf_raw_get_event_nattrs(void *this, int idx)
+{
+	return 0;
+}
+
+/*
+ * remove attrs which are in conflicts (or duplicated) with os layer
+ */
+static void
+pfm_perf_raw_perf_validate_pattrs(void *this, pfmlib_event_desc_t *e)
+{
+}
+
+/*
+ * returns 0 if match (like strcmp())
+ */
+static int
+pfm_perf_raw_match_event(void *this, pfmlib_event_desc_t *d, const char *e, const char *s)
+{
+	uint64_t code;
+	int ret;
+
+	if (*s != 'r'  || !isxdigit(*(s+1)))
+		return 1;
+
+	ret = sscanf(s+1, "%"PRIx64, &code);
+	if (ret != 1)
+		return 1;
+	/*
+	 * stash code in final position
+	 */
+	d->codes[0] = code;
+	d->count = 1;
+
+	return 0;
+}
+
+pfmlib_pmu_t perf_event_raw_support={
+	.desc			= "perf_events raw PMU",
+	.name			= "perf_raw",
+	.pmu			= PFM_PMU_PERF_EVENT_RAW,
+	.pme_count		= 1,
+	.type			= PFM_PMU_TYPE_OS_GENERIC,
+	.max_encoding		= 1,
+	.supported_plm		= PERF_PLM_ALL,
+	.pmu_detect		= pfm_perf_raw_detect,
+	.get_event_encoding[PFM_OS_NONE] = pfm_perf_raw_get_encoding,
+	 PFMLIB_ENCODE_PERF(pfm_perf_raw_get_perf_encoding),
+	.get_event_first	= pfm_perf_raw_get_event_first,
+	.get_event_next		= pfm_perf_raw_get_event_next,
+	.event_is_valid		= pfm_perf_raw_event_is_valid,
+	.get_event_info		= pfm_perf_raw_get_event_info,
+	.get_event_attr_info	= pfm_perf_raw_get_event_attr_info,
+	.get_event_nattrs	= pfm_perf_raw_get_event_nattrs,
+	.match_event		= pfm_perf_raw_match_event,
+	 PFMLIB_VALID_PERF_PATTRS(pfm_perf_raw_perf_validate_pattrs),
+};
diff --git a/src/libpfm4/lib/pfmlib_priv.h b/src/libpfm4/lib/pfmlib_priv.h
index 287222d..715c4b0 100644
--- a/src/libpfm4/lib/pfmlib_priv.h
+++ b/src/libpfm4/lib/pfmlib_priv.h
@@ -132,8 +132,12 @@ typedef struct pfmlib_pmu {
 	void		 (*validate_pattrs[PFM_OS_MAX])(void *this, pfmlib_event_desc_t *e);
 	int		 (*os_detect[PFM_OS_MAX])(void *this);
 	int		 (*validate_table)(void *this, FILE *fp);
-	int 		 (*get_num_events)(void *this);	/* optional */
-	void		 (*display_reg)(void *this, pfmlib_event_desc_t *e, void *val); /* optional */
+	/*
+	 * optional callbacks
+	 */
+	int 		 (*get_num_events)(void *this);
+	void		 (*display_reg)(void *this, pfmlib_event_desc_t *e, void *val);
+	int 		 (*match_event)(void *this, pfmlib_event_desc_t *d, const char *e, const char *s);
 } pfmlib_pmu_t;
 
 typedef struct {
@@ -263,6 +267,41 @@ extern pfmlib_pmu_t intel_snbep_unc_ubo_support;
 extern pfmlib_pmu_t intel_snbep_unc_r2pcie_support;
 extern pfmlib_pmu_t intel_snbep_unc_r3qpi0_support;
 extern pfmlib_pmu_t intel_snbep_unc_r3qpi1_support;
+extern pfmlib_pmu_t intel_ivbep_unc_cb0_support;
+extern pfmlib_pmu_t intel_ivbep_unc_cb1_support;
+extern pfmlib_pmu_t intel_ivbep_unc_cb2_support;
+extern pfmlib_pmu_t intel_ivbep_unc_cb3_support;
+extern pfmlib_pmu_t intel_ivbep_unc_cb4_support;
+extern pfmlib_pmu_t intel_ivbep_unc_cb5_support;
+extern pfmlib_pmu_t intel_ivbep_unc_cb6_support;
+extern pfmlib_pmu_t intel_ivbep_unc_cb7_support;
+extern pfmlib_pmu_t intel_ivbep_unc_cb8_support;
+extern pfmlib_pmu_t intel_ivbep_unc_cb9_support;
+extern pfmlib_pmu_t intel_ivbep_unc_cb10_support;
+extern pfmlib_pmu_t intel_ivbep_unc_cb11_support;
+extern pfmlib_pmu_t intel_ivbep_unc_cb12_support;
+extern pfmlib_pmu_t intel_ivbep_unc_cb13_support;
+extern pfmlib_pmu_t intel_ivbep_unc_cb14_support;
+extern pfmlib_pmu_t intel_ivbep_unc_ha0_support;
+extern pfmlib_pmu_t intel_ivbep_unc_ha1_support;
+extern pfmlib_pmu_t intel_ivbep_unc_imc0_support;
+extern pfmlib_pmu_t intel_ivbep_unc_imc1_support;
+extern pfmlib_pmu_t intel_ivbep_unc_imc2_support;
+extern pfmlib_pmu_t intel_ivbep_unc_imc3_support;
+extern pfmlib_pmu_t intel_ivbep_unc_imc4_support;
+extern pfmlib_pmu_t intel_ivbep_unc_imc5_support;
+extern pfmlib_pmu_t intel_ivbep_unc_imc6_support;
+extern pfmlib_pmu_t intel_ivbep_unc_imc7_support;
+extern pfmlib_pmu_t intel_ivbep_unc_pcu_support;
+extern pfmlib_pmu_t intel_ivbep_unc_qpi0_support;
+extern pfmlib_pmu_t intel_ivbep_unc_qpi1_support;
+extern pfmlib_pmu_t intel_ivbep_unc_qpi2_support;
+extern pfmlib_pmu_t intel_ivbep_unc_ubo_support;
+extern pfmlib_pmu_t intel_ivbep_unc_r2pcie_support;
+extern pfmlib_pmu_t intel_ivbep_unc_r3qpi0_support;
+extern pfmlib_pmu_t intel_ivbep_unc_r3qpi1_support;
+extern pfmlib_pmu_t intel_ivbep_unc_r3qpi2_support;
+extern pfmlib_pmu_t intel_ivbep_unc_irp_support;
 extern pfmlib_pmu_t intel_knc_support;
 extern pfmlib_pmu_t intel_slm_support;
 extern pfmlib_pmu_t power4_support;
@@ -284,6 +323,7 @@ extern pfmlib_pmu_t sparc_niagara1_support;
 extern pfmlib_pmu_t sparc_niagara2_support;
 extern pfmlib_pmu_t cell_support;
 extern pfmlib_pmu_t perf_event_support;
+extern pfmlib_pmu_t perf_event_raw_support;
 extern pfmlib_pmu_t intel_wsm_sp_support;
 extern pfmlib_pmu_t intel_wsm_dp_support;
 extern pfmlib_pmu_t intel_wsm_unc_support;
@@ -294,6 +334,7 @@ extern pfmlib_pmu_t arm_1176_support;
 extern pfmlib_pmu_t arm_qcom_krait_support;
 extern pfmlib_pmu_t mips_74k_support;
 extern pfmlib_pmu_t s390x_cpum_cf_support;
+extern pfmlib_pmu_t s390x_cpum_sf_support;
 
 extern pfmlib_os_t *pfmlib_os;
 extern pfmlib_os_t pfmlib_os_perf;
diff --git a/src/libpfm4/lib/pfmlib_s390x_cpumf.c b/src/libpfm4/lib/pfmlib_s390x_cpumf.c
index d424466..db2a215 100644
--- a/src/libpfm4/lib/pfmlib_s390x_cpumf.c
+++ b/src/libpfm4/lib/pfmlib_s390x_cpumf.c
@@ -1,7 +1,7 @@
 /*
- * PMU support for the CPU-measurement counter facility
+ * PMU support for the CPU-measurement facilities
  *
- * Copyright IBM Corp. 2012
+ * Copyright IBM Corp. 2012, 2014
  * Contributed by Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
  *
  * Permission is hereby granted, free of charge, to any person obtaining a copy
@@ -34,17 +34,25 @@
 #include "events/s390x_cpumf_events.h"
 
 
-#define CPUMF_DEVICE_DIR  "/sys/bus/event_source/devices/cpum_cf"
-#define SYS_INFO	  "/proc/sysinfo"
+#define CPUM_CF_DEVICE_DIR  "/sys/bus/event_source/devices/cpum_cf"
+#define CPUM_SF_DEVICE_DIR  "/sys/bus/event_source/devices/cpum_sf"
+#define SYS_INFO	    "/proc/sysinfo"
 
 
 /* CPU-measurement counter list (pmu events) */
 static pme_cpumf_ctr_t *cpumcf_pe = NULL;
 
-/* Detect the CPU-measurement facility */
+/* Detect the CPU-measurement counter and sampling facilities */
 static int pfm_cpumcf_detect(void *this)
 {
-	if (access(CPUMF_DEVICE_DIR, R_OK))
+	if (access(CPUM_CF_DEVICE_DIR, R_OK))
+		return PFM_ERR_NOTSUPP;
+	return PFM_SUCCESS;
+}
+
+static int pfm_cpumsf_detect(void *this)
+{
+	if (access(CPUM_SF_DEVICE_DIR, R_OK))
 		return PFM_ERR_NOTSUPP;
 	return PFM_SUCCESS;
 }
@@ -107,13 +115,18 @@ static int pfm_cpumcf_init(void *this)
 	switch (get_machine_type()) {
 	case 2097:  /* IBM System z10 EC */
 	case 2098:  /* IBM System z10 BC */
-		ext_set = cpumf_ctr_set_ext_z10;
-		ext_set_count = LIBPFM_ARRAY_SIZE(cpumf_ctr_set_ext_z10);
+		ext_set = cpumcf_z10_counters,
+		ext_set_count = LIBPFM_ARRAY_SIZE(cpumcf_z10_counters);
 		break;
 	case 2817:  /* IBM zEnterprise 196 */
 	case 2818:  /* IBM zEnterprise 114 */
-		ext_set = cpumf_ctr_set_ext_z196;
-		ext_set_count = LIBPFM_ARRAY_SIZE(cpumf_ctr_set_ext_z196);
+		ext_set = cpumcf_z196_counters;
+		ext_set_count = LIBPFM_ARRAY_SIZE(cpumcf_z196_counters);
+		break;
+	case 2827:  /* IBM zEnterprise EC12 */
+	case 2828:  /* IBM zEnterprise BC12 */
+		ext_set = cpumcf_zec12_counters;
+		ext_set_count = LIBPFM_ARRAY_SIZE(cpumcf_zec12_counters);
 		break;
 	default:
 		/* No extended counter set for this machine type or there
@@ -123,13 +136,14 @@ static int pfm_cpumcf_init(void *this)
 		break;
 	}
 
-	generic_count = LIBPFM_ARRAY_SIZE(cpumf_generic_ctr);
+	generic_count = LIBPFM_ARRAY_SIZE(cpumcf_generic_counters);
 
 	cpumcf_pe = calloc(sizeof(*cpumcf_pe), generic_count + ext_set_count);
 	if (cpumcf_pe == NULL)
 		return PFM_ERR_NOMEM;
 
-	memcpy(cpumcf_pe, cpumf_generic_ctr, sizeof(*cpumcf_pe) * generic_count);
+	memcpy(cpumcf_pe, cpumcf_generic_counters,
+	       sizeof(*cpumcf_pe) * generic_count);
 	if (ext_set_count)
 		memcpy((void *) (cpumcf_pe + generic_count),
 		       ext_set, sizeof(*cpumcf_pe) * ext_set_count);
@@ -150,7 +164,7 @@ static void pfm_cpumcf_exit(void *this)
 	free(cpumcf_pe);
 }
 
-static int pfm_cpumcf_get_encoding(void *this, pfmlib_event_desc_t *e)
+static int pfm_cpumf_get_encoding(void *this, pfmlib_event_desc_t *e)
 {
 	const pme_cpumf_ctr_t *pe = this_pe(this);
 
@@ -161,12 +175,12 @@ static int pfm_cpumcf_get_encoding(void *this, pfmlib_event_desc_t *e)
 	return PFM_SUCCESS;
 }
 
-static int pfm_cpumcf_get_event_first(void *this)
+static int pfm_cpumf_get_event_first(void *this)
 {
 	return 0;
 }
 
-static int pfm_cpumcf_get_event_next(void *this, int idx)
+static int pfm_cpumf_get_event_next(void *this, int idx)
 {
 	pfmlib_pmu_t *pmu = this;
 
@@ -175,26 +189,20 @@ static int pfm_cpumcf_get_event_next(void *this, int idx)
 	return idx + 1;
 }
 
-static int pfm_cpumcf_event_is_valid(void *this, int idx)
+static int pfm_cpumf_event_is_valid(void *this, int idx)
 {
 	pfmlib_pmu_t *pmu = this;
 
 	return (idx >= 0 && idx < pmu->pme_count);
 }
 
-static int pfm_cpumcf_validate_table(void *this, FILE *fp)
+static int pfm_cpumf_validate_table(void *this, FILE *fp)
 {
 	pfmlib_pmu_t *pmu = this;
 	const pme_cpumf_ctr_t *pe = this_pe(this);
 	int i, rc;
 
 	rc = PFM_ERR_INVAL;
-	if (pmu->pme_count > CPUMF_COUNTER_MAX) {
-		fprintf(fp, "pmu: %s: pme number exceeded maximum\n",
-			pmu->name);
-		goto failed;
-	}
-
 	for (i = 0; i < pmu->pme_count; i++) {
 		if (!pe[i].name) {
 			fprintf(fp, "pmu: %s event: %i: No name\n",
@@ -213,7 +221,20 @@ failed:
 	return rc;
 }
 
-static int pfm_cpumcf_get_event_info(void *this, int idx,
+static int pfm_cpumcf_validate_table(void *this, FILE *fp)
+{
+	pfmlib_pmu_t *pmu = this;
+
+	if (pmu->pme_count > CPUMF_COUNTER_MAX) {
+		fprintf(fp, "pmu: %s: pme number exceeded maximum\n",
+			pmu->name);
+		return PFM_ERR_INVAL;
+	}
+
+	return pfm_cpumf_validate_table(this, fp);
+}
+
+static int pfm_cpumf_get_event_info(void *this, int idx,
 				    pfm_event_info_t *info)
 {
 	pfmlib_pmu_t *pmu = this;
@@ -232,7 +253,7 @@ static int pfm_cpumcf_get_event_info(void *this, int idx,
 	return PFM_SUCCESS;
 }
 
-static int pfm_cpumcf_get_event_attr_info(void *this, int idx, int umask_idx,
+static int pfm_cpumf_get_event_attr_info(void *this, int idx, int umask_idx,
 					 pfm_event_attr_info_t *info)
 {
 	/* Attributes are not supported */
@@ -250,19 +271,45 @@ pfmlib_pmu_t s390x_cpum_cf_support = {
 	.num_fixed_cntrs = CPUMF_COUNTER_MAX,	/* fixed counters only */
 	.max_encoding	 = 1,
 
-	.pe		 = cpumf_generic_ctr,
-	.pme_count	 = LIBPFM_ARRAY_SIZE(cpumf_generic_ctr),
+	.pe		 = cpumcf_generic_counters,
+	.pme_count	 = LIBPFM_ARRAY_SIZE(cpumcf_generic_counters),
 
 	.pmu_detect    = pfm_cpumcf_detect,
 	.pmu_init      = pfm_cpumcf_init,
 	.pmu_terminate = pfm_cpumcf_exit,
 
-	.get_event_encoding[PFM_OS_NONE] = pfm_cpumcf_get_encoding,
+	.get_event_encoding[PFM_OS_NONE] = pfm_cpumf_get_encoding,
 		PFMLIB_ENCODE_PERF(pfm_s390x_get_perf_encoding),
-	.get_event_first	= pfm_cpumcf_get_event_first,
-	.get_event_next		= pfm_cpumcf_get_event_next,
-	.event_is_valid		= pfm_cpumcf_event_is_valid,
+	.get_event_first	= pfm_cpumf_get_event_first,
+	.get_event_next		= pfm_cpumf_get_event_next,
+	.event_is_valid		= pfm_cpumf_event_is_valid,
 	.validate_table		= pfm_cpumcf_validate_table,
-	.get_event_info		= pfm_cpumcf_get_event_info,
-	.get_event_attr_info	= pfm_cpumcf_get_event_attr_info,
+	.get_event_info		= pfm_cpumf_get_event_info,
+	.get_event_attr_info	= pfm_cpumf_get_event_attr_info,
+};
+
+pfmlib_pmu_t s390x_cpum_sf_support = {
+	.desc	   = "CPU-measurement sampling facility",
+	.name	   = "cpum_sf",
+	.pmu	   = PFM_PMU_S390X_CPUM_SF,
+	.type	   = PFM_PMU_TYPE_CORE,
+	.flags	   = PFMLIB_PMU_FL_ARCH_DFL,
+
+	.num_cntrs	 = 0,	/* no general-purpose counters */
+	.num_fixed_cntrs = 2,	/* fixed counters only */
+	.max_encoding	 = 1,
+
+	.pe	   = cpumsf_counters,
+	.pme_count = LIBPFM_ARRAY_SIZE(cpumsf_counters),
+
+	.pmu_detect = pfm_cpumsf_detect,
+
+	.get_event_encoding[PFM_OS_NONE] = pfm_cpumf_get_encoding,
+		PFMLIB_ENCODE_PERF(pfm_s390x_get_perf_encoding),
+	.get_event_first	= pfm_cpumf_get_event_first,
+	.get_event_next		= pfm_cpumf_get_event_next,
+	.event_is_valid		= pfm_cpumf_event_is_valid,
+	.validate_table		= pfm_cpumf_validate_table,
+	.get_event_info		= pfm_cpumf_get_event_info,
+	.get_event_attr_info	= pfm_cpumf_get_event_attr_info,
 };
diff --git a/src/libpfm4/lib/pfmlib_s390x_priv.h b/src/libpfm4/lib/pfmlib_s390x_priv.h
index 45259f2..22c775a 100644
--- a/src/libpfm4/lib/pfmlib_s390x_priv.h
+++ b/src/libpfm4/lib/pfmlib_s390x_priv.h
@@ -1,7 +1,7 @@
 #ifndef __PFMLIB_S390X_PRIV_H__
 #define __PFMLIB_S390X_PRIV_H__
 
-#define CPUMF_COUNTER_MAX	    160
+#define CPUMF_COUNTER_MAX	    256
 typedef struct {
 	uint64_t ctrnum;	    /* counter number */
 	unsigned int ctrset;	    /* counter set */
diff --git a/src/libpfm4/libpfm.spec b/src/libpfm4/libpfm.spec
index 31756dd..82b6958 100644
--- a/src/libpfm4/libpfm.spec
+++ b/src/libpfm4/libpfm.spec
@@ -3,7 +3,7 @@
 %define python_prefix %(python -c "import sys; print sys.prefix")
 
 Name:		libpfm
-Version:	4.4.0
+Version:	4.5.0
 Release:	1%{?dist}
 
 Summary:	Library to encode performance events for use by perf tool
diff --git a/src/libpfm4/tests/validate_x86.c b/src/libpfm4/tests/validate_x86.c
index 8dc222b..2edacd5 100644
--- a/src/libpfm4/tests/validate_x86.c
+++ b/src/libpfm4/tests/validate_x86.c
@@ -1251,7 +1251,7 @@ static const test_event_t x86_test_events[]={
 	  .count = 2,
 	  .codes[0] = 0x334,
 	  .codes[1] = 0x7c0000,
-	  .fstr = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:STATE_MESIF:e=0:i=0:t=0:tf=0:nf=0",
+	  .fstr = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:STATE_MESIF:e=0:i=0:t=0:tf=0",
 	},
 	{ SRC_LINE,
 	  .name = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:nf=1",
@@ -1269,17 +1269,17 @@ static const test_event_t x86_test_events[]={
 	  .name = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:NID:nf=3",
 	  .ret  = PFM_SUCCESS,
 	  .count = 2,
-	  .codes[0] = 0x4134,
+	  .codes[0] = 0x4334,
 	  .codes[1] = 0x7c0c00,
-	  .fstr = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:NID:STATE_MESIF:e=0:i=0:t=0:tf=0:nf=3",
+	  .fstr = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:NID:STATE_MESIF:e=0:i=0:t=0:tf=0:nf=3",
 	},
 	{ SRC_LINE,
 	  .name = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:NID:STATE_M:nf=3",
 	  .ret  = PFM_SUCCESS,
 	  .count = 2,
-	  .codes[0] = 0x4134,
+	  .codes[0] = 0x4334,
 	  .codes[1] = 0x200c00,
-	  .fstr = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:NID:STATE_M:e=0:i=0:t=0:tf=0:nf=3",
+	  .fstr = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:NID:STATE_M:e=0:i=0:t=0:tf=0:nf=3",
 	},
 	{ SRC_LINE,
 	  .name = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:NID:nf=3:tid=1",
@@ -1294,7 +1294,7 @@ static const test_event_t x86_test_events[]={
 	  .ret  = PFM_SUCCESS,
 	  .count = 1,
 	  .codes[0] = 0x1035,
-	  .fstr = "snbep_unc_cbo0::UNC_C_TOR_INSERTS:WB:e=0:i=0:t=0:tf=0:nf=0",
+	  .fstr = "snbep_unc_cbo0::UNC_C_TOR_INSERTS:WB:e=0:i=0:t=0:tf=0",
 	},
 	{ SRC_LINE,
 	  .name = "snbep_unc_cbo0::UNC_C_TOR_INSERTS:OPCODE:OPC_PCIWILF",
@@ -1302,7 +1302,7 @@ static const test_event_t x86_test_events[]={
 	  .count = 2,
 	  .codes[0] = 0x135,
 	  .codes[1] = 0xca000000,
-	  .fstr = "snbep_unc_cbo0::UNC_C_TOR_INSERTS:OPCODE:OPC_PCIWILF:e=0:i=0:t=0:tf=0:nf=0",
+	  .fstr = "snbep_unc_cbo0::UNC_C_TOR_INSERTS:OPCODE:OPC_PCIWILF:e=0:i=0:t=0:tf=0",
 	},
 	{ SRC_LINE,
 	  .name = "snbep_unc_cbo0::UNC_C_TOR_INSERTS:OPCODE:OPC_PCIWILF:nf=1",
@@ -2185,7 +2185,513 @@ static const test_event_t x86_test_events[]={
 	  .name = "slm::no_alloc_cycles:any:t=1",
 	  .ret = PFM_ERR_ATTR
 	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_irp::unc_i_clockticks",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x0,
+	  .fstr = "ivbep_unc_irp::UNC_I_CLOCKTICKS:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_irp::unc_i_tickles:lost_ownership",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x116,
+	  .fstr = "ivbep_unc_irp::UNC_I_TICKLES:LOST_OWNERSHIP:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_irp::unc_i_transactions:reads",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x115,
+	  .fstr = "ivbep_unc_irp::UNC_I_TRANSACTIONS:READS:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_irp::unc_i_transactions:reads:c=1:i",
+	  .ret  = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_irp::unc_i_transactions:reads:t=6",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x6000115,
+	  .fstr = "ivbep_unc_irp::UNC_I_TRANSACTIONS:READS:e=0:t=6",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo1::UNC_C_CLOCKTICKS:u",
+	  .ret  = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_CLOCKTICKS",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x00,
+	  .fstr = "ivbep_unc_cbo0::UNC_C_CLOCKTICKS",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x334,
+	  .codes[1] = 0x7e0000,
+	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:STATE_MESIF:e=0:t=0:tf=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:nf=1",
+	  .ret  = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x1134,
+	  .codes[1] = 0x7e0000,
+	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:ANY:STATE_MESIF:e=0:t=0:tf=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:NID:STATE_M",
+	  .ret  = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:NID:nf=3",
+	  .ret  = PFM_SUCCESS,
+	  .count = 3,
+	  .codes[0] = 0x5134,
+	  .codes[1] = 0x7e0000,
+	  .codes[2] = 0x3,
+	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:ANY:NID:STATE_MESIF:e=0:t=0:tf=0:nf=3",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:NID:STATE_M:tid=1",
+	  .ret  = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:WRITE",
+	  .ret  = PFM_ERR_FEATCOMB,
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:WRITE:NID:nf=3:tf=1:e:t=1",
+	  .ret  = PFM_SUCCESS,
+	  .count = 3,
+	  .codes[0] = 0x10c4534,
+	  .codes[1] = 0x7e0001,
+	  .codes[2] = 0x3,
+	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:WRITE:NID:STATE_MESIF:e=1:t=1:tf=1:nf=3",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_LLC_VICTIMS",
+	  .ret  = PFM_ERR_UMASK,
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_LLC_VICTIMS:NID",
+	  .ret  = PFM_ERR_UMASK,
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_LLC_VICTIMS:NID:nf=1",
+	  .ret  = PFM_ERR_UMASK,
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_LLC_VICTIMS:STATE_M",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x137,
+	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_VICTIMS:STATE_M:e=0:t=0:tf=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_LLC_VICTIMS:STATE_M:STATE_S",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x537,
+	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_VICTIMS:STATE_M:STATE_S:e=0:t=0:tf=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_LLC_VICTIMS:STATE_M:STATE_S:NID:nf=1",
+	  .ret  = PFM_SUCCESS,
+	  .count = 3,
+	  .codes[0] = 0x4537,
+	  .codes[1] = 0x0,
+	  .codes[2] = 0x1,
+	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_VICTIMS:STATE_M:STATE_S:NID:e=0:t=0:tf=0:nf=1",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:OPCODE",
+	  .ret  = PFM_ERR_UMASK,
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:WB",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x1035,
+	  .fstr = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:WB:e=0:t=0:tf=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:OPCODE:OPC_PCIWILF",
+	  .ret  = PFM_SUCCESS,
+	  .count = 3,
+	  .codes[0] = 0x135,
+	  .codes[1] = 0x0,
+	  .codes[2] = 0x19400000ull,
+	  .fstr = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:OPCODE:OPC_PCIWILF:e=0:t=0:tf=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:OPCODE:OPC_PCIWILF:nf=1",
+	  .ret  = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:NID_OPCODE:OPC_PCIRDCUR:nf=1",
+	  .ret  = PFM_SUCCESS,
+	  .count = 3,
+	  .codes[0] = 0x4135,
+	  .codes[1] = 0x0,
+	  .codes[2] = 0x19e00001ull,
+	  .fstr = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:NID_OPCODE:OPC_PCIRDCUR:e=0:t=0:tf=0:nf=1",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:OPC_RFO:NID_OPCODE:nf=1",
+	  .ret  = PFM_SUCCESS,
+	  .count = 3,
+	  .codes[0] = 0x4135,
+	  .codes[1] = 0x0,
+	  .codes[2] = 0x18000001ull,
+	  .fstr = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:NID_OPCODE:OPC_RFO:e=0:t=0:tf=0:nf=1",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_TOR_OCCUPANCY:MISS_REMOTE",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8a36,
+	  .fstr = "ivbep_unc_cbo0::UNC_C_TOR_OCCUPANCY:MISS_REMOTE:e=0:t=0:tf=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_pcu::UNC_P_CLOCKTICKS",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x0,
+	  .fstr = "ivbep_unc_pcu::UNC_P_CLOCKTICKS:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_pcu::UNC_P_CLOCKTICKS:t=1",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x1000000,
+	  .fstr = "ivbep_unc_pcu::UNC_P_CLOCKTICKS:e=0:t=1",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_pcu::UNC_P_CORE0_TRANSITION_CYCLES",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x70,
+	  .fstr = "ivbep_unc_pcu::UNC_P_CORE0_TRANSITION_CYCLES:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_pcu::UNC_P_FREQ_BAND0_CYCLES",
+	  .ret  = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_pcu::UNC_P_FREQ_BAND1_CYCLES",
+	  .ret  = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_pcu::UNC_P_FREQ_BAND2_CYCLES",
+	  .ret  = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_pcu::UNC_P_FREQ_BAND3_CYCLES",
+	  .ret  = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_pcu::UNC_P_FREQ_BAND0_CYCLES:ff=32",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0xb,
+	  .codes[1] = 0x20,
+	  .fstr = "ivbep_unc_pcu::UNC_P_FREQ_BAND0_CYCLES:e=0:t=0:ff=32",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_pcu::UNC_P_FREQ_BAND1_CYCLES:ff=16",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0xc,
+	  .codes[1] = 0x1000,
+	  .fstr = "ivbep_unc_pcu::UNC_P_FREQ_BAND1_CYCLES:e=0:t=0:ff=16",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_pcu::UNC_P_FREQ_BAND2_CYCLES:ff=8",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0xd,
+	  .codes[1] = 0x80000,
+	  .fstr = "ivbep_unc_pcu::UNC_P_FREQ_BAND2_CYCLES:e=0:t=0:ff=8",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_pcu::UNC_P_FREQ_BAND3_CYCLES:ff=40",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0xe,
+	  .codes[1] = 0x28000000,
+	  .fstr = "ivbep_unc_pcu::UNC_P_FREQ_BAND3_CYCLES:e=0:t=0:ff=40",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_pcu::UNC_P_FREQ_BAND0_CYCLES:ff=32:e",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x4000b,
+	  .codes[1] = 0x20,
+	  .fstr = "ivbep_unc_pcu::UNC_P_FREQ_BAND0_CYCLES:e=1:t=0:ff=32",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_pcu::UNC_P_FREQ_BAND0_CYCLES:ff=32:t=24",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x1800000b,
+	  .codes[1] = 0x20,
+	  .fstr = "ivbep_unc_pcu::UNC_P_FREQ_BAND0_CYCLES:e=0:t=24:ff=32",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_pcu::UNC_P_FREQ_BAND0_CYCLES:ff=32:e:t=4",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x404000b,
+	  .codes[1] = 0x20,
+	  .fstr = "ivbep_unc_pcu::UNC_P_FREQ_BAND0_CYCLES:e=1:t=4:ff=32",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_pcu::UNC_P_POWER_STATE_OCCUPANCY:CORES_C0",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x4080,
+	  .fstr = "ivbep_unc_pcu::UNC_P_POWER_STATE_OCCUPANCY:CORES_C0:e=0:t=0"
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_pcu::UNC_P_POWER_STATE_OCCUPANCY:CORES_C3",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8080,
+	  .fstr = "ivbep_unc_pcu::UNC_P_POWER_STATE_OCCUPANCY:CORES_C3:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "IVBEP_UNC_PCU::UNC_P_POWER_STATE_OCCUPANCY:CORES_C6",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0xc080,
+	  .fstr = "ivbep_unc_pcu::UNC_P_POWER_STATE_OCCUPANCY:CORES_C6:e=0:t=0"
+	},
+	{ SRC_LINE,
+	  .name = "IVBEP_UNC_PCU::UNC_P_POWER_STATE_OCCUPANCY:CORES_C0:t=6",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x6004080,
+	  .fstr = "ivbep_unc_pcu::UNC_P_POWER_STATE_OCCUPANCY:CORES_C0:e=0:t=6"
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_pcu::UNC_P_DEMOTIONS_CORE10",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x42,
+	  .fstr = "ivbep_unc_pcu::UNC_P_DEMOTIONS_CORE10:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_pcu::UNC_P_DEMOTIONS_CORE14",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x46,
+	  .fstr = "ivbep_unc_pcu::UNC_P_DEMOTIONS_CORE14:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_ha0::UNC_H_CLOCKTICKS",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x0,
+	  .fstr = "ivbep_unc_ha0::UNC_H_CLOCKTICKS:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_ha1::UNC_H_CLOCKTICKS",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x0,
+	  .fstr = "ivbep_unc_ha1::UNC_H_CLOCKTICKS:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_ha1::UNC_H_REQUESTS:READS:t=1",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x1000301,
+	  .fstr = "ivbep_unc_ha1::UNC_H_REQUESTS:READS:e=0:t=1",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_ha0::UNC_H_IMC_WRITES:t=1",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x1000f1a,
+	  .fstr = "ivbep_unc_ha0::UNC_H_IMC_WRITES:ALL:e=0:t=1",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_ha0::UNC_H_IMC_READS:t=1",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x1000117,
+	  .fstr = "ivbep_unc_ha0::UNC_H_IMC_READS:NORMAL:e=0:t=1",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_imc0::UNC_M_CLOCKTICKS",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0xff,
+	  .fstr = "ivbep_unc_imc0::UNC_M_CLOCKTICKS",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_imc0::UNC_M_CLOCKTICKS:t=1",
+	  .ret  = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_imc0::UNC_M_DCLOCKTICKS",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x00,
+	  .fstr = "ivbep_unc_imc0::UNC_M_DCLOCKTICKS:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_imc4::UNC_M_DCLOCKTICKS",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x00,
+	  .fstr = "ivbep_unc_imc4::UNC_M_DCLOCKTICKS:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_imc0::UNC_M_CAS_COUNT:RD",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x0304,
+	  .fstr = "ivbep_unc_imc0::UNC_M_CAS_COUNT:RD:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_imc0::UNC_M_POWER_CKE_CYCLES:RANK0",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x183,
+	  .fstr = "ivbep_unc_imc0::UNC_M_POWER_CKE_CYCLES:RANK0:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_imc0::UNC_M_CAS_COUNT:WR",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0xc04,
+	  .fstr = "ivbep_unc_imc0::UNC_M_CAS_COUNT:WR:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_imc0::UNC_M_RD_CAS_RANK0:BANK0",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x1b0,
+	  .fstr = "ivbep_unc_imc0::UNC_M_RD_CAS_RANK0:BANK0:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_imc0::UNC_M_RD_CAS_RANK4:BANK7",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x80b4,
+	  .fstr = "ivbep_unc_imc0::UNC_M_RD_CAS_RANK4:BANK7:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_imc0::UNC_M_RD_CAS_RANK4:BANK7:t=1",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x10080b4,
+	  .fstr = "ivbep_unc_imc0::UNC_M_RD_CAS_RANK4:BANK7:e=0:t=1",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_qpi0::UNC_Q_CLOCKTICKS",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x14,
+	  .fstr = "ivbep_unc_qpi0::UNC_Q_CLOCKTICKS:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_qpi0::UNC_Q_RXL_FLITS_G0:DATA",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x201,
+	  .fstr = "ivbep_unc_qpi0::UNC_Q_RXL_FLITS_G0:DATA:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_qpi0::UNC_Q_RXL_FLITS_G0:IDLE:t=1",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x1000101,
+	  .fstr = "ivbep_unc_qpi0::UNC_Q_RXL_FLITS_G0:IDLE:e=0:t=1",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_qpi0::UNC_Q_TXL_FLITS_G0:DATA",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x200,
+	  .fstr = "ivbep_unc_qpi0::UNC_Q_TXL_FLITS_G0:DATA:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_qpi0::UNC_Q_RXL_FLITS_G1:HOM",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x200602,
+	  .fstr = "ivbep_unc_qpi0::UNC_Q_RXL_FLITS_G1:HOM:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_qpi0::UNC_Q_TXL_FLITS_G1:HOM",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x200600,
+	  .fstr = "ivbep_unc_qpi0::UNC_Q_TXL_FLITS_G1:HOM:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_ubo::UNC_U_LOCK_CYCLES",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x44,
+	  .fstr = "ivbep_unc_ubo::UNC_U_LOCK_CYCLES:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_r2pcie::UNC_R2_CLOCKTICKS",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x1,
+	  .fstr = "ivbep_unc_r2pcie::UNC_R2_CLOCKTICKS:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_r2pcie::UNC_R2_RING_AD_USED:CW",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x3307,
+	  .fstr = "ivbep_unc_r2pcie::UNC_R2_RING_AD_USED:CW:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_r3qpi0::UNC_R3_CLOCKTICKS",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x1,
+	  .fstr = "ivbep_unc_r3qpi0::UNC_R3_CLOCKTICKS:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_r3qpi0::UNC_R3_TXR_CYCLES_FULL:e=0:t=0",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x25,
+	  .fstr = "ivbep_unc_r3qpi0::UNC_R3_TXR_CYCLES_FULL:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_r3qpi1::UNC_R3_CLOCKTICKS",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x1,
+	  .fstr = "ivbep_unc_r3qpi1::UNC_R3_CLOCKTICKS:e=0:t=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_r3qpi1::UNC_R3_TXR_CYCLES_FULL:e=0:t=0",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x25,
+	  .fstr = "ivbep_unc_r3qpi1::UNC_R3_TXR_CYCLES_FULL:e=0:t=0",
+	},
 };
+
 #define NUM_TEST_EVENTS (int)(sizeof(x86_test_events)/sizeof(test_event_t))
 
 static int
-- 
2.1.0

From 44570317546f0b3c0fb68ef95c82d62fc79f4aff Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Fri, 4 Apr 2014 15:28:26 -0400
Subject: [PATCH 13/24] libpfm4 update

commit a2e7213dc9e0a3f6736e6149a21cee089a604714
Author: Stephane Eranian <eranian@gmail.com>
Date:   Wed Mar 12 23:42:32 2014 +0100

    add DSB2MITE_SWITCHES event

    Was missing and is public.

    Signed-off-by: Stephane Eranian <eranian@gmail.com>

diff --git a/src/libpfm4/lib/events/intel_hsw_events.h b/src/libpfm4/lib/events/intel_hsw_events.h
index 0491fdd..78b2800 100644
--- a/src/libpfm4/lib/events/intel_hsw_events.h
+++ b/src/libpfm4/lib/events/intel_hsw_events.h
@@ -1737,6 +1737,14 @@ static const intel_x86_umask_t hsw_lsd[]={
    },
 };
 
+static const intel_x86_umask_t hsw_dsb2mite_switches[]={
+   { .uname  = "PENALTY_CYCLES",
+     .udesc  = "Number of DSB to MITE switch true penalty cycles",
+     .ucode = 0x0200,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+   },
+};
+
 static const intel_x86_entry_t intel_hsw_pe[]={
   { .name   = "UNHALTED_CORE_CYCLES",
     .desc   = "Count core clock cycles whenever the clock signal on the specific core is running (not halted)",
@@ -2301,6 +2309,15 @@ static const intel_x86_entry_t intel_hsw_pe[]={
     .ngrp = 1,
     .umasks = hsw_page_walker_loads,
   },
+{ .name   = "DSB2MITE_SWITCHES",
+  .desc   = "Number of DSB to MITE switches",
+  .modmsk = INTEL_V4_ATTRS,
+  .cntmsk = 0xff,
+  .code = 0xab,
+  .numasks = LIBPFM_ARRAY_SIZE(hsw_dsb2mite_switches),
+  .ngrp = 1,
+  .umasks = hsw_dsb2mite_switches,
+},
   { .name   = "OFFCORE_RESPONSE_0",
     .desc   = "Offcore response event (must provide at least one request type and either any_response or any combination of supplier + snoop)",
     .modmsk = INTEL_V4_ATTRS,
diff --git a/src/libpfm4/lib/events/intel_ivb_events.h b/src/libpfm4/lib/events/intel_ivb_events.h
index 28e0216..4e1b600 100644
--- a/src/libpfm4/lib/events/intel_ivb_events.h
+++ b/src/libpfm4/lib/events/intel_ivb_events.h
@@ -286,7 +286,12 @@ static const intel_x86_umask_t ivb_cpu_clk_unhalted[]={
 static const intel_x86_umask_t ivb_dsb2mite_switches[]={
    { .uname  = "COUNT",
      .udesc  = "Number of DSB to MITE switches",
-     .ucode = 0x100,
+     .ucode = 0x0100,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "PENALTY_CYCLES",
+     .udesc  = "Number of DSB to MITE switch true penalty cycles",
+     .ucode = 0x0200,
      .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
    },
 };
@@ -1652,6 +1657,20 @@ static const intel_x86_umask_t ivb_lsd[]={
    },
 };
 
+static const intel_x86_umask_t ivb_int_misc[]={
+  { .uname = "RECOVERY_CYCLES",
+    .udesc  = "Number of cycles waiting for Machine Clears  except JEClear",
+    .ucode  = 0x300,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RECOVERY_STALLS_COUNT",
+    .udesc  = "Number of occurrences waiting for Machine Clears",
+    .ucode  = 0x300 | INTEL_X86_MOD_EDGE | (1 << INTEL_X86_CMASK_BIT), /* edge=1 cnt=1 */
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_E | _INTEL_X86_ATTR_C,
+  },
+};
+
 static const intel_x86_entry_t intel_ivb_pe[]={
 { .name   = "ARITH",
   .desc   = "Counts arithmetic multiply operations",
@@ -2297,6 +2316,15 @@ static const intel_x86_entry_t intel_ivb_pe[]={
   .ngrp = 1,
   .umasks = ivb_lsd,
 },
+  { .name = "INT_MISC",
+    .desc = "Miscellaneous interruptions",
+    .code = 0xd,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V3_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(ivb_int_misc),
+    .umasks  = ivb_int_misc
+  },
 { .name   = "OFFCORE_RESPONSE_0",
   .desc   = "Offcore response event (must provide at least one request type and either any_response or any combination of supplier + snoop)",
   .modmsk = INTEL_V3_ATTRS,
diff --git a/src/libpfm4/lib/pfmlib_power_priv.h b/src/libpfm4/lib/pfmlib_power_priv.h
index 2721771..725593c 100644
--- a/src/libpfm4/lib/pfmlib_power_priv.h
+++ b/src/libpfm4/lib/pfmlib_power_priv.h
@@ -18,16 +18,16 @@
 *
 */
 typedef struct {
-   char *pme_name;
    unsigned pme_code;
-   char *pme_short_desc;
-   char *pme_long_desc;
+   const char *pme_name;
+   const char *pme_short_desc;
+   const char *pme_long_desc;
 } pme_power_entry_t;
 
 typedef struct {
-   char *pme_name;
+   const char *pme_name;
+   const char *pme_desc;
    unsigned pme_code;
-   char *pme_desc;
    uint64_t pme_modmsk;
 } pme_torrent_entry_t;
 
diff --git a/src/libpfm4/tests/validate.c b/src/libpfm4/tests/validate.c
index a63a328..522a6ab 100644
--- a/src/libpfm4/tests/validate.c
+++ b/src/libpfm4/tests/validate.c
@@ -42,7 +42,7 @@
 #define __weak_func	__attribute__((weak))
 
 #ifdef PFMLIB_WINDOWS
-int set_env_var(const char *var, char *value, int ov)
+int set_env_var(const char *var, const char *value, int ov)
 {
 	size_t len;
 	char *str;
@@ -64,7 +64,7 @@ int set_env_var(const char *var, char *value, int ov)
 }
 #else
 static inline int
-set_env_var(const char *var, char *value, int ov)
+set_env_var(const char *var, const char *value, int ov)
 {
 	return setenv(var, value, ov);
 }
-- 
2.1.0

From f58042f89f1816fdf70d258ffe991d7412a5061d Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Wed, 16 Apr 2014 12:08:12 -0400
Subject: [PATCH 14/24] Bump libpfm4

Brings us to:
-----------------------------------------------
commit 42c3455dd1a51804c854d7ce651434df7701f4c2
Author: Stephane Eranian <eranian@gmail.com>
Date:   Wed Apr 16 17:49:58 2014 +0200

    add Intel Haswell event alias for MEM_LOAD_UOPS_L3_*
-----------------------------------------------

diff --git a/src/libpfm4/lib/events/amd64_events_fam11h.h b/src/libpfm4/lib/events/amd64_events_fam11h.h
index 5760e26..b53e7f6 100644
--- a/src/libpfm4/lib/events/amd64_events_fam11h.h
+++ b/src/libpfm4/lib/events/amd64_events_fam11h.h
@@ -1033,7 +1033,7 @@ static const amd64_entry_t amd64_fam11h_pe[]={
   .umasks  = amd64_fam11h_system_read_responses,
 },
 { .name    = "QUADWORDS_WRITTEN_TO_SYSTEM",
-  .desc    = "Quawords Written to System",
+  .desc    = "Quadwords Written to System",
   .modmsk  = AMD64_FAM10H_ATTRS,
   .code    = 0x6d,
   .numasks = LIBPFM_ARRAY_SIZE(amd64_fam11h_quadwords_written_to_system),
diff --git a/src/libpfm4/lib/events/amd64_events_fam14h.h b/src/libpfm4/lib/events/amd64_events_fam14h.h
index 0cf11a9..905094a 100644
--- a/src/libpfm4/lib/events/amd64_events_fam14h.h
+++ b/src/libpfm4/lib/events/amd64_events_fam14h.h
@@ -1076,7 +1076,7 @@ static const amd64_entry_t amd64_fam14h_pe[]={
   .code    = 0x22,
 },
 { .name    = "RSQ_FULL",
-  .desc    = "Number of cycles that the RSQ holds retired stores. This buffer holds the stores waiting to retired as well as requests that missed the data cacge and waiting on a refill",
+  .desc    = "Number of cycles that the RSQ holds retired stores. This buffer holds the stores waiting to retired as well as requests that missed the data cache and waiting on a refill",
   .modmsk  = AMD64_FAM10H_ATTRS,
   .code    = 0x23,
 },
diff --git a/src/libpfm4/lib/events/intel_coreduo_events.h b/src/libpfm4/lib/events/intel_coreduo_events.h
index 9e0cb5e..33531cf 100644
--- a/src/libpfm4/lib/events/intel_coreduo_events.h
+++ b/src/libpfm4/lib/events/intel_coreduo_events.h
@@ -525,7 +525,7 @@ static const intel_x86_entry_t intel_coreduo_pe[]={
   .umasks = coreduo_l2_ads,
 },
 { .name   = "DBUS_BUSY",
-  .desc   = "Core cycle during which data buswas busy (increments by 4)",
+  .desc   = "Core cycle during which data bus was busy (increments by 4)",
   .modmsk = INTEL_X86_ATTRS,
   .cntmsk = 0x3,
   .code = 0x22,
diff --git a/src/libpfm4/lib/events/intel_hsw_events.h b/src/libpfm4/lib/events/intel_hsw_events.h
index 78b2800..8706634 100644
--- a/src/libpfm4/lib/events/intel_hsw_events.h
+++ b/src/libpfm4/lib/events/intel_hsw_events.h
@@ -410,12 +410,12 @@ static const intel_x86_umask_t hsw_idq[]={
     .uflags = INTEL_X86_NCOMBO,
   },
   { .uname = "MS_DSB_UOPS",
-    .udesc  = "Uops initiated by Decode Stream Buffer (DSB) that are being delivered to Instruction Decode Queue (IDQ) while Microcode Sequenser (MS) is busy",
+    .udesc  = "Uops initiated by Decode Stream Buffer (DSB) that are being delivered to Instruction Decode Queue (IDQ) while Microcode Sequencer (MS) is busy",
     .ucode  = 0x1000,
     .uflags = INTEL_X86_NCOMBO,
   },
   { .uname = "MS_MITE_UOPS",
-    .udesc  = "Uops initiated by MITE and delivered to Instruction Decode Queue (IDQ) while Microcode Sequenser (MS) is busy",
+    .udesc  = "Uops initiated by MITE and delivered to Instruction Decode Queue (IDQ) while Microcode Sequencer (MS) is busy",
     .ucode  = 0x2000,
     .uflags = INTEL_X86_NCOMBO,
   },
@@ -446,14 +446,14 @@ static const intel_x86_umask_t hsw_idq[]={
     .modhw  = _INTEL_X86_ATTR_C,
   },
   { .uname = "MS_DSB_UOPS_CYCLES",
-    .udesc  = "Cycles when uops initiated by Decode Stream Buffer (DSB) are being delivered to Instruction Decode Queue (IDQ) while Microcode Sequenser (MS) is busy",
+    .udesc  = "Cycles when uops initiated by Decode Stream Buffer (DSB) are being delivered to Instruction Decode Queue (IDQ) while Microcode Sequencer (MS) is busy",
     .ucode  = 0x1000 | (1 << INTEL_X86_CMASK_BIT), /* cnt=1 */
     .uequiv = "MS_DSB_UOPS:c=1",
     .uflags = INTEL_X86_NCOMBO,
     .modhw  = _INTEL_X86_ATTR_C,
   },
   { .uname = "MS_DSB_OCCUR",
-    .udesc  = "Deliveries to Instruction Decode Queue (IDQ) initiated by Decode Stream Buffer (DSB) while Microcode Sequenser (MS) is busy",
+    .udesc  = "Deliveries to Instruction Decode Queue (IDQ) initiated by Decode Stream Buffer (DSB) while Microcode Sequencer (MS) is busy",
     .ucode  = 0x1000 | INTEL_X86_MOD_EDGE | (1 << INTEL_X86_CMASK_BIT), /* edge=1 cnt=1 */
     .uequiv = "MS_DSB_UOPS:c=1:e=1",
     .uflags = INTEL_X86_NCOMBO,
@@ -2095,6 +2095,17 @@ static const intel_x86_entry_t intel_hsw_pe[]={
     .numasks = LIBPFM_ARRAY_SIZE(hsw_mem_load_uops_l3_hit_retired),
     .umasks  = hsw_mem_load_uops_l3_hit_retired
   },
+  { .name = "MEM_LOAD_UOPS_LLC_HIT_RETIRED",
+  .desc   = "L3 hit load uops retired (Precise Event)",
+    .equiv = "MEM_LOAD_UOPS_L3_HIT_RETIRED",
+    .code = 0xd2,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_mem_load_uops_l3_hit_retired),
+    .umasks  = hsw_mem_load_uops_l3_hit_retired
+  },
   { .name = "MEM_LOAD_UOPS_L3_MISS_RETIRED",
     .desc   = "Load uops retired that missed the L3 (Precise Event)",
     .code = 0xd3,
@@ -2105,6 +2116,17 @@ static const intel_x86_entry_t intel_hsw_pe[]={
     .numasks = LIBPFM_ARRAY_SIZE(hsw_mem_load_uops_l3_miss_retired),
     .umasks  = hsw_mem_load_uops_l3_miss_retired
   },
+  { .name = "MEM_LOAD_UOPS_LLC_MISS_RETIRED",
+    .desc   = "Load uops retired that missed the L3 (Precise Event)",
+    .equiv = "MEM_LOAD_UOPS_L3_MISS_RETIRED",
+    .code = 0xd3,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_mem_load_uops_l3_miss_retired),
+    .umasks  = hsw_mem_load_uops_l3_miss_retired
+  },
   { .name = "MEM_LOAD_UOPS_RETIRED",
     .desc = "Retired load uops (Precise Event)",
     .code = 0xd1,
diff --git a/src/libpfm4/lib/events/intel_ivbep_unc_cbo_events.h b/src/libpfm4/lib/events/intel_ivbep_unc_cbo_events.h
index ee8959f..318521d 100644
--- a/src/libpfm4/lib/events/intel_ivbep_unc_cbo_events.h
+++ b/src/libpfm4/lib/events/intel_ivbep_unc_cbo_events.h
@@ -228,7 +228,7 @@ static const intel_x86_umask_t ivbep_unc_c_llc_victims[]={
 
 static const intel_x86_umask_t ivbep_unc_c_ring_ad_used[]={
    { .uname  = "UP_VR0_EVEN",
-     .udesc  = "Up and Even ring polarity filter on virutal ring 0",
+     .udesc  = "Up and Even ring polarity filter on virtual ring 0",
      .ucode = 0x100,
    },
    { .uname  = "UP_VR0_ODD",
@@ -244,7 +244,7 @@ static const intel_x86_umask_t ivbep_unc_c_ring_ad_used[]={
      .ucode = 0x800,
    },
    { .uname  = "UP_VR1_EVEN",
-     .udesc  = "Up and Even ring polarity filter on virutal ring 1",
+     .udesc  = "Up and Even ring polarity filter on virtual ring 1",
      .ucode = 0x1000,
    },
    { .uname  = "UP_VR1_ODD",
@@ -786,7 +786,7 @@ static const intel_x86_umask_t ivbep_unc_c_misc[]={
     .uflags = INTEL_X86_NCOMBO,
   },
   { .uname = "RFO_HIT_S",
-    .udesc  = "Counts the number of times that an RFO hits in S state. This is usfeul for determining if it might be good for a workload to use RSPIWB instead of RSPSWB",
+    .udesc  = "Counts the number of times that an RFO hits in S state. This is useful for determining if it might be good for a workload to use RSPIWB instead of RSPSWB",
     .ucode  = 0x800,
     .uflags = INTEL_X86_NCOMBO,
   },
@@ -827,7 +827,7 @@ static const intel_x86_entry_t intel_ivbep_unc_c_pe[]={
     .umasks = ivbep_unc_c_llc_victims,
   },
   { .name   = "UNC_C_MISC",
-    .desc   = "Miscelleanous C-Box events",
+    .desc   = "Miscellaneous C-Box events",
     .modmsk = IVBEP_UNC_CBO_ATTRS,
     .cntmsk = 0x3,
     .code = 0x39,
diff --git a/src/libpfm4/lib/events/intel_ivbep_unc_ha_events.h b/src/libpfm4/lib/events/intel_ivbep_unc_ha_events.h
index 58f0e06..d92ca9e 100644
--- a/src/libpfm4/lib/events/intel_ivbep_unc_ha_events.h
+++ b/src/libpfm4/lib/events/intel_ivbep_unc_ha_events.h
@@ -568,11 +568,11 @@ static const intel_x86_umask_t ivbep_unc_h_snp_resp_recv_local[]={
 
 static const intel_x86_umask_t ivbep_unc_h_tracker_cycles_full[]={
   { .uname = "GP",
-    .udesc  = "Number of cycles when the general purpose (GP) HA trakcer pool is completely used. It will not return valid count when BT is disabled",
+    .udesc  = "Number of cycles when the general purpose (GP) HA tracker pool is completely used. It will not return valid count when BT is disabled",
     .ucode  = 0x100,
   },
   { .uname = "ALL",
-    .udesc  = "Number of cycles when the general purpose (GP) HA trakcer pool is completely used including reserved HT entries. It will not return vaid count when BT is disabled",
+    .udesc  = "Number of cycles when the general purpose (GP) HA tracker pool is completely used including reserved HT entries. It will not return vaid count when BT is disabled",
     .ucode  = 0x200,
     .uflags = INTEL_X86_DFL,
   },
diff --git a/src/libpfm4/lib/events/intel_ivbep_unc_imc_events.h b/src/libpfm4/lib/events/intel_ivbep_unc_imc_events.h
index ac8ef41..473afc4 100644
--- a/src/libpfm4/lib/events/intel_ivbep_unc_imc_events.h
+++ b/src/libpfm4/lib/events/intel_ivbep_unc_imc_events.h
@@ -80,7 +80,7 @@ static const intel_x86_umask_t ivbep_unc_m_dram_refresh[]={
 
 static const intel_x86_umask_t ivbep_unc_m_major_modes[]={
   { .uname = "ISOCH",
-    .udesc  = "Counts cycles in ISOCH Major maode",
+    .udesc  = "Counts cycles in ISOCH Major mode",
     .ucode  = 0x800,
   },
   { .uname = "PARTIAL",
diff --git a/src/libpfm4/lib/events/intel_ivbep_unc_irp_events.h b/src/libpfm4/lib/events/intel_ivbep_unc_irp_events.h
index 86b5168..19c8512 100644
--- a/src/libpfm4/lib/events/intel_ivbep_unc_irp_events.h
+++ b/src/libpfm4/lib/events/intel_ivbep_unc_irp_events.h
@@ -33,7 +33,7 @@ static const intel_x86_umask_t ivbep_unc_i_address_match[]={
     .ucode  = 0x100,
   },
   { .uname = "MERGE_COUNT",
-    .udesc  = "Number of times when two reuqests to the same address from the same source are received back to back, it is possible to merge them",
+    .udesc  = "Number of times when two requests to the same address from the same source are received back to back, it is possible to merge them",
     .ucode  = 0x200,
   },
 };
diff --git a/src/libpfm4/lib/events/intel_ivbep_unc_r2pcie_events.h b/src/libpfm4/lib/events/intel_ivbep_unc_r2pcie_events.h
index 59d96b9..081aaf2 100644
--- a/src/libpfm4/lib/events/intel_ivbep_unc_r2pcie_events.h
+++ b/src/libpfm4/lib/events/intel_ivbep_unc_r2pcie_events.h
@@ -188,7 +188,7 @@ static const intel_x86_entry_t intel_ivbep_unc_r2_pe[]={
     .umasks  = ivbep_unc_r2_rxr_ak_bounces
   },
   { .name = "UNC_R2_RXR_OCCUPANCY",
-    .desc = "Ingress occpancy accumulator",
+    .desc = "Ingress occupancy accumulator",
     .code = 0x13,
     .cntmsk = 0x1,
     .modmsk = IVBEP_UNC_R2PCIE_ATTRS,
diff --git a/src/libpfm4/lib/events/intel_p6_events.h b/src/libpfm4/lib/events/intel_p6_events.h
index f8a83a8..6964eff 100644
--- a/src/libpfm4/lib/events/intel_p6_events.h
+++ b/src/libpfm4/lib/events/intel_p6_events.h
@@ -216,7 +216,7 @@ static const intel_x86_entry_t intel_p6_pe[]={
   .code = 0x85,
 },
 { .name   = "IFU_MEM_STALL",
-  .desc   = "Number of cycles instruction fetch is stalled for any reason. Includs IFU cache misses, ITLB misses, ITLB faults, and other minor stalls",
+  .desc   = "Number of cycles instruction fetch is stalled for any reason. Includes IFU cache misses, ITLB misses, ITLB faults, and other minor stalls",
   .modmsk = INTEL_X86_ATTRS,
   .cntmsk = 0x3,
   .code = 0x86,
diff --git a/src/libpfm4/lib/events/intel_pii_events.h b/src/libpfm4/lib/events/intel_pii_events.h
index 5846c64..5c614c0 100644
--- a/src/libpfm4/lib/events/intel_pii_events.h
+++ b/src/libpfm4/lib/events/intel_pii_events.h
@@ -180,7 +180,7 @@ static const intel_x86_entry_t intel_pii_pe[]={
   .code = 0x85,
 },
 { .name   = "IFU_MEM_STALL",
-  .desc   = "Number of cycles instruction fetch is stalled for any reason. Includs IFU cache misses, ITLB misses, ITLB faults, and other minor stalls",
+  .desc   = "Number of cycles instruction fetch is stalled for any reason. Includes IFU cache misses, ITLB misses, ITLB faults, and other minor stalls",
   .modmsk = INTEL_X86_ATTRS,
   .cntmsk = 0x3,
   .code = 0x86,
diff --git a/src/libpfm4/lib/events/intel_pm_events.h b/src/libpfm4/lib/events/intel_pm_events.h
index e32a883..1bbefdb 100644
--- a/src/libpfm4/lib/events/intel_pm_events.h
+++ b/src/libpfm4/lib/events/intel_pm_events.h
@@ -283,7 +283,7 @@ static const intel_x86_entry_t intel_pm_pe[]={
   .code = 0x85,
 },
 { .name   = "IFU_MEM_STALL",
-  .desc   = "Number of cycles instruction fetch is stalled for any reason. Includs IFU cache misses, ITLB misses, ITLB faults, and other minor stalls",
+  .desc   = "Number of cycles instruction fetch is stalled for any reason. Includes IFU cache misses, ITLB misses, ITLB faults, and other minor stalls",
   .modmsk = INTEL_X86_ATTRS,
   .cntmsk = 0x3,
   .code = 0x86,
diff --git a/src/libpfm4/lib/events/intel_ppro_events.h b/src/libpfm4/lib/events/intel_ppro_events.h
index 0555652..d0b9df6 100644
--- a/src/libpfm4/lib/events/intel_ppro_events.h
+++ b/src/libpfm4/lib/events/intel_ppro_events.h
@@ -121,7 +121,7 @@ static const intel_x86_entry_t intel_ppro_pe[]={
   .code = 0x85,
 },
 { .name   = "IFU_MEM_STALL",
-  .desc   = "Number of cycles instruction fetch is stalled for any reason. Includs IFU cache misses, ITLB misses, ITLB faults, and other minor stalls",
+  .desc   = "Number of cycles instruction fetch is stalled for any reason. Includes IFU cache misses, ITLB misses, ITLB faults, and other minor stalls",
   .modmsk = INTEL_X86_ATTRS,
   .cntmsk = 0x3,
   .code = 0x86,
diff --git a/src/libpfm4/lib/events/intel_slm_events.h b/src/libpfm4/lib/events/intel_slm_events.h
index 558dbf8..c7b5ce7 100644
--- a/src/libpfm4/lib/events/intel_slm_events.h
+++ b/src/libpfm4/lib/events/intel_slm_events.h
@@ -97,7 +97,7 @@ static const intel_x86_umask_t slm_inst_retired[]={
 
 static const intel_x86_umask_t slm_l2_reject_xq[]={
    { .uname  = "ALL",
-     .udesc  = "Number of demand and prefetch transactions that the L2 XQ rejects due to a full or near full condition which likely indicates back pressure from the IDI link. The XQ may reject transactions fro mthe L2Q (non-cacheable requests), BBS (L2 misses) and WOB (L2 write-back victims)",
+     .udesc  = "Number of demand and prefetch transactions that the L2 XQ rejects due to a full or near full condition which likely indicates back pressure from the IDI link. The XQ may reject transactions from the L2Q (non-cacheable requests), BBS (L2 misses) and WOB (L2 write-back victims)",
      .ucode = 0x000,
      .uflags= INTEL_X86_DFL,
    },
diff --git a/src/libpfm4/lib/events/intel_snbep_unc_cbo_events.h b/src/libpfm4/lib/events/intel_snbep_unc_cbo_events.h
index 40d3e37..ae10b61 100644
--- a/src/libpfm4/lib/events/intel_snbep_unc_cbo_events.h
+++ b/src/libpfm4/lib/events/intel_snbep_unc_cbo_events.h
@@ -580,7 +580,7 @@ static const intel_x86_umask_t snbep_unc_c_txr_inserts[]={
     .uflags = INTEL_X86_NCOMBO,
   },
   { .uname = "IV_CACHE",
-    .udesc  = "Counts the number of ring transactions from Cachebo ton IV ring",
+    .udesc  = "Counts the number of ring transactions from Cachebo to IV ring",
     .ucode  = 0x800,
     .uflags = INTEL_X86_NCOMBO,
   },
@@ -701,7 +701,7 @@ static const intel_x86_entry_t intel_snbep_unc_c_pe[]={
     .code = 0x07,
   },
   { .name   = "UNC_C_RXR_EXT_STARVED",
-    .desc   = "Ingress arbiter blockig cycles",
+    .desc   = "Ingress arbiter blocking cycles",
     .modmsk = SNBEP_UNC_CBO_ATTRS,
     .cntmsk = 0x3,
     .code = 0x12,
diff --git a/src/libpfm4/lib/events/intel_snbep_unc_imc_events.h b/src/libpfm4/lib/events/intel_snbep_unc_imc_events.h
index e2494b2..b49487c 100644
--- a/src/libpfm4/lib/events/intel_snbep_unc_imc_events.h
+++ b/src/libpfm4/lib/events/intel_snbep_unc_imc_events.h
@@ -78,7 +78,7 @@ static const intel_x86_umask_t snbep_unc_m_dram_refresh[]={
 
 static const intel_x86_umask_t snbep_unc_m_major_modes[]={
   { .uname = "ISOCH",
-    .udesc  = "Counts cycles in ISOCH Major maode",
+    .udesc  = "Counts cycles in ISOCH Major mode",
     .ucode  = 0x800,
     .uflags = INTEL_X86_NCOMBO,
   },
-- 
2.1.0

From 319f7cd5b8ea265eb19aa7aa6486585da4e1d3ee Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Thu, 24 Apr 2014 10:45:03 -0400
Subject: [PATCH 15/24] Update libpfm4

-----------------------------------------------
commit 285a80941e04e17f66c3322a2741bb27766a0373
Author: Stephane Eranian <eranian@gmail.com>
Date:   Fri Apr 18 14:54:54 2014 +0200

    add more HSW umask aliases to match IVB

    Ths patch adds some more umask aliases
    to the following events to maintain compat
    with IvyBridge:
    - L2_RQSTS
    - BR_MISP_EXEC
    - BR_MISP_RETIRED
    - BR_INST_RETIRED
    - BR_INST_EXEC

    Signed-off-by: Stephane Eranian <eranian@gmail.com>
-----------------------------------------------

diff --git a/src/libpfm4/docs/man3/libpfm_amd64_fam15h.3 b/src/libpfm4/docs/man3/libpfm_amd64_fam15h.3
index 84ae455..ac594c2 100644
--- a/src/libpfm4/docs/man3/libpfm_amd64_fam15h.3
+++ b/src/libpfm4/docs/man3/libpfm_amd64_fam15h.3
@@ -12,7 +12,7 @@ libpfm_amd64_fam15h - support for AMD64 Family 15h processors
 .sp
 .SH DESCRIPTION
 The library supports AMD Family 15h processors core PMU in both 32 and 64-bit modes. The
-uncore PMU (Northbridge) is also supported as a separate PMU model.
+uncore (NorthBridge) PMU is also supported as a separate PMU model.
 
 .SH MODIFIERS
 The following modifiers are supported on AMD64 Family 15h core PMU:
diff --git a/src/libpfm4/docs/man3/libpfm_intel_ivb_unc.3 b/src/libpfm4/docs/man3/libpfm_intel_ivb_unc.3
index 1e9921f..5176ee7 100644
--- a/src/libpfm4/docs/man3/libpfm_intel_ivb_unc.3
+++ b/src/libpfm4/docs/man3/libpfm_intel_ivb_unc.3
@@ -13,7 +13,7 @@ The library supports the Intel Ivy Bridge client part (model 58) uncore PMU.
 The support is currently limited to the Coherency Box, so called C-Box for up
 to 4 physical cores.
 
-Each physical core has an associated C-Box which it uses to communictate with
+Each physical core has an associated C-Box which it uses to communicate with
 the L3 cache. The C-boxes all support the same set of events. However, Core 0
 C-box (snb_unc_cbo0) supports an additional uncore clock ticks event: \fBUNC_CLOCKTICKS\fR.
 
diff --git a/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_cbo.3 b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_cbo.3
index e417a46..b6023b7 100644
--- a/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_cbo.3
+++ b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_cbo.3
@@ -36,11 +36,11 @@ the threshold.  This is an integer modifier with values in the range [0:255].
 Node filter. Certain events, such as UNC_C_LLC_LOOKUP, UNC_C_LLC_VICTIMS, provide a \fBNID\fR umask.
 Sometimes the \fBNID\fR is combined with other filtering capabilities, such as opcodes.
 The node filter is an 8-bit max bitmask. A node corresponds to a processor
-socket. The legal values therefore depdend on the underlying hardware configuration. For
+socket. The legal values therefore depend on the underlying hardware configuration. For
 dual-socket systems, the bitmask has two valid bits [0:1].
 .TP
 .B cf
-Core Filter. This is a 3-bit filter which is used to filter based on phyiscal core origin
+Core Filter. This is a 3-bit filter which is used to filter based on physical core origin
 of the C-Box request. Possible values are 0-7. If the filter is not specified, then no
 filtering takes place.
 .TP
@@ -53,7 +53,7 @@ specified, then no filtering takes place.
 
 Certain events, such as UNC_C_TOR_INSERTS supports opcode matching on the C-BOX transaction
 type. To use this feature, first an opcode matching umask must be selected, e.g., MISS_OPCODE.
-Second, the opcode to match on must be selected via a second umasks amongs the OPC_* umasks.
+Second, the opcode to match on must be selected via a second umask among the OPC_* umasks.
 For instance, UNC_C_TOR_INSERTS:OPCODE:OPC_RFO, counts the number of TOR insertions for RFO
 transactions. 
 
diff --git a/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_pcu.3 b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_pcu.3
index 65ec6a3..399824c 100644
--- a/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_pcu.3
+++ b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_pcu.3
@@ -26,7 +26,7 @@ the threshold.  This is an integer modifier with values in the range [0:15].
 .B ff
 Enable frequency band filtering. This modifier applies only to the UNC_P_FREQ_BANDx_CYCLES events, where x is [0-3].
 The modifiers expects an integer in the range [0-255]. The value is interpreted as a frequency value to be
-multipled by 100Mhz. Thus if the value is 32, then all cycles where the processor is running at 3.2GHz and more are
+multiplied by 100Mhz. Thus if the value is 32, then all cycles where the processor is running at 3.2GHz and more are
 counted.
 
 .SH Frequency band filtering
diff --git a/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_ubo.3 b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_ubo.3
index 2c4a6c1..8b4024d 100644
--- a/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_ubo.3
+++ b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_ubo.3
@@ -36,7 +36,7 @@ modifier (t) with a value greater or equal to one.  This is a boolean modifier.
 .B ff
 Enable frequency band filtering. This modifier applies only to the UNC_P_FREQ_BANDx_CYCLES events, where x is [0-3].
 The modifiers expects an integer in the range [0-255]. The value is interpreted as a frequency value to be
-multipled by 100Mhz. Thus if the value is 32, then all cycles where the processor is running at 3.2GHz and more are
+multiplied by 100Mhz. Thus if the value is 32, then all cycles where the processor is running at 3.2GHz and more are
 counted.
 
 .SH Frequency band filtering
diff --git a/src/libpfm4/docs/man3/libpfm_intel_rapl.3 b/src/libpfm4/docs/man3/libpfm_intel_rapl.3
index cf7835c..d5e6227 100644
--- a/src/libpfm4/docs/man3/libpfm_intel_rapl.3
+++ b/src/libpfm4/docs/man3/libpfm_intel_rapl.3
@@ -10,7 +10,7 @@ libpfm_intel_rapl - support for Intel RAPL PMU
 .sp
 .SH DESCRIPTION
 The library supports the Intel Running Average Power Limit (RAPL)
-energy consomption counters. This is a socket-level set of counters
+energy consumption counters. This is a socket-level set of counters
 which reports energy consumption in Joules. There are up to 3 counters
 each measuring only one event. The following events are defined:
 .TP
diff --git a/src/libpfm4/docs/man3/libpfm_intel_snb_unc.3 b/src/libpfm4/docs/man3/libpfm_intel_snb_unc.3
index 9591832..c0ba38d 100644
--- a/src/libpfm4/docs/man3/libpfm_intel_snb_unc.3
+++ b/src/libpfm4/docs/man3/libpfm_intel_snb_unc.3
@@ -13,7 +13,7 @@ The library supports the Intel Sandy Bridge client part (model 42) uncore PMU.
 The support is currently limited to the Coherency Box, so called C-Box for up
 to 4 physical cores.
 
-Each physical core has an associated C-Box which it uses to communictate with
+Each physical core has an associated C-Box which it uses to communicate with
 the L3 cache. The C-boxes all support the same set of events. However, Core 0
 C-box (snb_unc_cbo0) supports an additional uncore clock ticks event: \fBUNC_CLOCKTICKS\fR.
 
diff --git a/src/libpfm4/docs/man3/libpfm_intel_snbep_unc_cbo.3 b/src/libpfm4/docs/man3/libpfm_intel_snbep_unc_cbo.3
index 24fd517..6281ed1 100644
--- a/src/libpfm4/docs/man3/libpfm_intel_snbep_unc_cbo.3
+++ b/src/libpfm4/docs/man3/libpfm_intel_snbep_unc_cbo.3
@@ -40,11 +40,11 @@ the threshold.  This is an integer modifier with values in the range [0:255].
 Node filter. Certain events, such as UNC_C_LLC_LOOKUP, UNC_C_LLC_VICTIMS, provide a \fBNID\fR umask.
 Sometimes the \fBNID\fR is combined with other filtering capabilities, such as opcodes.
 The node filter is an 8-bit max bitmask. A node corresponds to a processor
-socket. The legal values therefore depdend on the underlying hardware configuration. For
+socket. The legal values therefore depend on the underlying hardware configuration. For
 dual-socket systems, the bitmask has two valid bits [0:1].
 .TP
 .B cf
-Core Filter. This is a 3-bit filter which is used to filter based on phyiscal core origin
+Core Filter. This is a 3-bit filter which is used to filter based on physical core origin
 of the C-Box request. Possible values are 0-7. If the filter is not specified, then no
 filtering takes place.
 .TP
@@ -57,7 +57,7 @@ specified, then no filtering takes place.
 
 Certain events, such as UNC_C_TOR_INSERTS supports opcode matching on the C-BOX transaction
 type. To use this feature, first an opcode matching umask must be selected, e.g., MISS_OPCODE.
-Second, the opcode to match on must be selected via a second umasks amongs the OPC_* umasks.
+Second, the opcode to match on must be selected via a second umask among the OPC_* umasks.
 For instance, UNC_C_TOR_INSERTS:OPCODE:OPC_RFO, counts the number of TOR insertions for RFO
 transactions. 
 
diff --git a/src/libpfm4/docs/man3/libpfm_intel_snbep_unc_pcu.3 b/src/libpfm4/docs/man3/libpfm_intel_snbep_unc_pcu.3
index 47ea498..9675cd5 100644
--- a/src/libpfm4/docs/man3/libpfm_intel_snbep_unc_pcu.3
+++ b/src/libpfm4/docs/man3/libpfm_intel_snbep_unc_pcu.3
@@ -31,7 +31,7 @@ the threshold.  This is an integer modifier with values in the range [0:15].
 .B ff
 Enable frequency band filtering. This modifier applies only to the UNC_P_FREQ_BANDx_CYCLES events, where x is [0-3].
 The modifiers expects an integer in the range [0-255]. The value is interpreted as a frequency value to be
-multipled by 100Mhz. Thus if the value is 32, then all cycles where the processor is running at 3.2GHz and more are
+multiplied by 100Mhz. Thus if the value is 32, then all cycles where the processor is running at 3.2GHz and more are
 counted.
 
 .SH Frequency band filtering
diff --git a/src/libpfm4/docs/man3/libpfm_intel_snbep_unc_ubo.3 b/src/libpfm4/docs/man3/libpfm_intel_snbep_unc_ubo.3
index afd246e..97b5fa8 100644
--- a/src/libpfm4/docs/man3/libpfm_intel_snbep_unc_ubo.3
+++ b/src/libpfm4/docs/man3/libpfm_intel_snbep_unc_ubo.3
@@ -41,7 +41,7 @@ modifier (t) with a value greater or equal to one.  This is a boolean modifier.
 .B ff
 Enable frequency band filtering. This modifier applies only to the UNC_P_FREQ_BANDx_CYCLES events, where x is [0-3].
 The modifiers expects an integer in the range [0-255]. The value is interpreted as a frequency value to be
-multipled by 100Mhz. Thus if the value is 32, then all cycles where the processor is running at 3.2GHz and more are
+multiplied by 100Mhz. Thus if the value is 32, then all cycles where the processor is running at 3.2GHz and more are
 counted.
 
 .SH Frequency band filtering
diff --git a/src/libpfm4/docs/man3/libpfm_perf_event_raw.3 b/src/libpfm4/docs/man3/libpfm_perf_event_raw.3
index 2f8b535..fa1f70f 100644
--- a/src/libpfm4/docs/man3/libpfm_perf_event_raw.3
+++ b/src/libpfm4/docs/man3/libpfm_perf_event_raw.3
@@ -22,7 +22,7 @@ The syntax is very simple: rX. X is the hexadecimal 64-bit value for the event.
 It may include event filters on some PMU models. The hexadecimal number is passed
 without the 0x prefix, e.g., r01c4.
 
-The library's standard perf_events attributes are supported oby this PMU model.
+The library's standard perf_events attributes are supported by this PMU model.
 They are separated with colons as is customary with the library.
 
 .SH MODIFIERS
@@ -59,7 +59,7 @@ event should be sampled 100 times per second on average. There is no default val
 .TP
 .B excl
 The associated event is the only event measured on the PMU. This applies only to hardware
-events. This atrtribute requires admin privileges. Default is off.
+events. This attribute requires admin privileges. Default is off.
 .TP
 .B precise
 Enables precise sampling mode. This option is only valid on sampling events. This is an
diff --git a/src/libpfm4/docs/man3/pfm_find_event.3 b/src/libpfm4/docs/man3/pfm_find_event.3
index 0ac2a42..7a52c41 100644
--- a/src/libpfm4/docs/man3/pfm_find_event.3
+++ b/src/libpfm4/docs/man3/pfm_find_event.3
@@ -16,7 +16,7 @@ and try to find the matching event.
 
 The event string is a structured string and it is composed as follows:
 .TP
-.B [pmu_name::]event_name[:unit_mask][:modifer|:modifier=val]
+.B [pmu_name::]event_name[:unit_mask][:modifier|:modifier=val]
 .PP
 
 The various components are separated by \fB:\fR or \fB::\fR, they
@@ -24,7 +24,7 @@ are defined as follows:
 
 .TP
 .B pmu_name
-This is an optional prefix to designte a specific PMU model. With the
+This is an optional prefix to designate a specific PMU model. With the
 prefix the event which matches the event_name is used. In case multiple
 PMU models are activated, there may be conflict with identical event
 names to mean the same or different things. In that case, it is necessary
diff --git a/src/libpfm4/docs/man3/pfm_get_event_next.3 b/src/libpfm4/docs/man3/pfm_get_event_next.3
index 3a14af6..386ac03 100644
--- a/src/libpfm4/docs/man3/pfm_get_event_next.3
+++ b/src/libpfm4/docs/man3/pfm_get_event_next.3
@@ -25,7 +25,7 @@ when encoding events.
 
 To iterate over a list of events for a given PMU model, all that is
 needed is an initial identifier for the PMU. The first event identifier
-is usually obainted via \fBpfm_get_pmu_info()\fR.
+is usually obtained via \fBpfm_get_pmu_info()\fR.
 
 The \fBpfm_get_event_next()\fR function returns the identifier of
 next supported event after the one passed in \fBidx\fR. This iterator
diff --git a/src/libpfm4/lib/events/intel_hsw_events.h b/src/libpfm4/lib/events/intel_hsw_events.h
index 8706634..b4e7c00 100644
--- a/src/libpfm4/lib/events/intel_hsw_events.h
+++ b/src/libpfm4/lib/events/intel_hsw_events.h
@@ -38,11 +38,24 @@ static const intel_x86_umask_t hsw_br_inst_exec[]={
     .ucode  = 0x4100,
     .uflags = INTEL_X86_NCOMBO,
   },
+  { .uname = "NONTAKEN_COND",
+    .udesc  = "All macro conditional nontaken branch instructions",
+    .ucode  = 0x4100,
+    .uequiv = "NONTAKEN_CONDITIONAL",
+    .uflags = INTEL_X86_NCOMBO,
+  },
+
   { .uname = "TAKEN_CONDITIONAL",
     .udesc  = "Taken speculative and retired macro-conditional branches",
     .ucode  = 0x8100,
     .uflags = INTEL_X86_NCOMBO,
   },
+  { .uname = "TAKEN_COND",
+    .udesc  = "Taken speculative and retired macro-conditional branches",
+    .ucode  = 0x8100,
+    .uequiv = "TAKEN_CONDITIONAL",
+    .uflags = INTEL_X86_NCOMBO,
+  },
   { .uname = "TAKEN_DIRECT_JUMP",
     .udesc  = "Taken speculative and retired macro-conditional branch instructions excluding calls and indirects",
     .ucode  = 0x8200,
@@ -68,6 +81,18 @@ static const intel_x86_umask_t hsw_br_inst_exec[]={
     .ucode  = 0xc100,
     .uflags = INTEL_X86_NCOMBO,
   },
+  { .uname = "ALL_COND",
+    .udesc  = "Speculative and retired macro-conditional branches",
+    .ucode  = 0xc100,
+    .uequiv = "ALL_CONDITIONAL",
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ANY_COND",
+    .udesc  = "Speculative and retired macro-conditional branches",
+    .ucode  = 0xc100,
+    .uequiv = "ALL_CONDITIONAL",
+    .uflags = INTEL_X86_NCOMBO,
+  },
   { .uname = "ALL_DIRECT_JMP",
     .udesc  = "Speculative and retired macro-unconditional branches excluding calls and indirects",
     .ucode  = 0xc200,
@@ -106,6 +131,12 @@ static const intel_x86_umask_t hsw_br_inst_retired[]={
     .ucode  = 0x100,
     .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
   },
+  { .uname = "COND",
+    .udesc  = "Counts all taken and not taken macro conditional branch instructions",
+    .ucode  = 0x100,
+    .uequiv = "CONDITIONAL",
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
   { .uname = "NEAR_CALL",
     .udesc  = "Counts all macro direct and indirect near calls",
     .ucode  = 0x200,
@@ -144,11 +175,23 @@ static const intel_x86_umask_t hsw_br_misp_exec[]={
     .ucode  = 0x4100,
     .uflags = INTEL_X86_NCOMBO,
   },
+  { .uname = "NONTAKEN_COND",
+    .udesc  = "Not taken speculative and retired mispredicted macro conditional branches",
+    .ucode  = 0x4100,
+    .uequiv = "NONTAKEN_CONDITIONAL",
+    .uflags = INTEL_X86_NCOMBO,
+  },
   { .uname = "TAKEN_CONDITIONAL",
     .udesc  = "Taken speculative and retired mispredicted macro conditional branches",
     .ucode  = 0x8100,
     .uflags = INTEL_X86_NCOMBO,
   },
+  { .uname = "TAKEN_COND",
+    .udesc  = "Taken speculative and retired mispredicted macro conditional branches",
+    .ucode  = 0x8100,
+    .uequiv = "TAKEN_CONDITIONAL",
+    .uflags = INTEL_X86_NCOMBO,
+  },
   { .uname = "TAKEN_INDIRECT_JUMP_NON_CALL_RET",
     .udesc  = "Taken speculative and retired mispredicted indirect branches excluding calls and returns",
     .ucode  = 0x8400,
@@ -164,6 +207,12 @@ static const intel_x86_umask_t hsw_br_misp_exec[]={
     .ucode  = 0xc100,
     .uflags = INTEL_X86_NCOMBO,
   },
+  { .uname = "ANY_COND",
+    .udesc  = "Speculative and retired mispredicted macro conditional branches",
+    .ucode  = 0xc100,
+    .uequiv = "ALL_CONDITIONAL",
+    .uflags = INTEL_X86_NCOMBO,
+  },
   { .uname = "ALL_INDIRECT_JUMP_NON_CALL_RET",
     .udesc  = "All mispredicted indirect branches that are not calls nor returns",
     .ucode  = 0xc400,
@@ -187,6 +236,12 @@ static const intel_x86_umask_t hsw_br_misp_retired[]={
     .ucode  = 0x100,
     .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
   },
+  { .uname = "COND",
+    .udesc  = "All mispredicted macro conditional branch instructions",
+    .ucode  = 0x100,
+    .uequiv = "CONDITIONAL",
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
   { .uname = "ALL_BRANCHES",
     .udesc  = "All mispredicted macro branches (architectural event)",
     .ucode  = 0x0, /* architectural encoding */
@@ -578,6 +633,14 @@ static const intel_x86_umask_t hsw_l1d_pend_miss[]={
     .uflags = INTEL_X86_NCOMBO,
     .modhw  = _INTEL_X86_ATTR_E | _INTEL_X86_ATTR_C,
   },
+  { .uname = "EDGE",
+    .udesc  = "Number L1D miss outstanding",
+    .ucode  = 0x100 | INTEL_X86_MOD_EDGE | (1 << INTEL_X86_CMASK_BIT), /* edge=1 cnt=1 */
+    .uequiv = "PENDING:c=1:e=1",
+    .ucntmsk = 0x4,
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_E | _INTEL_X86_ATTR_C,
+  },
 };
 
 static const intel_x86_umask_t hsw_l2_demand_rqsts[]={
@@ -646,11 +709,23 @@ static const intel_x86_umask_t hsw_l2_rqsts[]={
     .ucode  = 0x2200,
     .uflags = INTEL_X86_NCOMBO,
   },
+  { .uname = "RFO_MISS",
+    .udesc  = "RFO requests that miss L2 cache",
+    .ucode  = 0x2200,
+    .uequiv = "DEMAND_RFO_MISS",
+    .uflags = INTEL_X86_NCOMBO,
+  },
   { .uname = "DEMAND_RFO_HIT",
     .udesc  = "RFO requests that hit L2 cache",
     .ucode  = 0x4200,
     .uflags = INTEL_X86_NCOMBO,
   },
+  { .uname = "RFO_HIT",
+    .udesc  = "RFO requests that hit L2 cache",
+    .ucode  = 0x4200,
+    .uequiv = "DEMAND_RFO_HIT",
+    .uflags = INTEL_X86_NCOMBO,
+  },
   { .uname = "CODE_RD_MISS",
     .udesc  = "L2 cache misses when fetching instructions",
     .ucode  = 0x2400,
-- 
2.1.0

From 4791b71fe7b8a6f931c3e0b56a9ed000382f0c98 Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Tue, 10 Jun 2014 15:38:00 -0400
Subject: [PATCH 16/24] Update libpfm4

Brings us inline with
---------------------
commit 58e7a3c6b29f121e9eaf0faf35304957e1d48fdf
Author: Stephane Eranian <eranian@gmail.com>
Date:   Tue Jun 10 21:31:30 2014 +0200

    remove duplicated ivbep_unc_pcu::UNC_P_DEMOTIONS_CORE14

    Remove duplicated UNC_P_DEMOTIONS_CORE14

    Reported-by: James Ralph <ralph@icl.utk.edu>
    Signed-off-by: Stephane Eranian <eranian@gmail.com>
---------------------

diff --git a/src/libpfm4/README b/src/libpfm4/README
index 334c78a..e74238f 100644
--- a/src/libpfm4/README
+++ b/src/libpfm4/README
@@ -57,6 +57,7 @@ The library supports many PMUs. The current version can handle:
 		ARMV7 Cortex A8
 		ARMV7 Cortex A9
 		ARMV7 Cortex A15
+		ARMV8 Cortex A57, A53
 		Qualcomm Krait
 
 	- For SPARC
diff --git a/src/libpfm4/config.mk b/src/libpfm4/config.mk
index 457d943..9553cbe 100644
--- a/src/libpfm4/config.mk
+++ b/src/libpfm4/config.mk
@@ -66,6 +66,15 @@ endif
 ifeq (armv7,$(findstring armv7,$(ARCH)))
 override ARCH=arm
 endif
+ifeq (armv7,$(findstring armv7,$(ARCH)))
+override ARCH=arm
+endif
+ifeq (aarch32,$(findstring aarch32,$(ARCH)))
+override ARCH=arm
+endif
+ifeq (armv8l,$(findstring armv8l,$(ARCH)))
+override ARCH=arm
+endif
 ifeq (mips64,$(findstring mips64,$(ARCH)))
 override ARCH=mips
 endif
@@ -152,6 +161,14 @@ ifeq ($(ARCH),arm)
 CONFIG_PFMLIB_ARCH_ARM=y
 endif
 
+ifeq ($(ARCH),aarch64)
+CONFIG_PFMLIB_ARCH_ARM64=y
+endif
+
+ifeq ($(ARCH),arm64)
+CONFIG_PFMLIB_ARCH_ARM64=y
+endif
+
 ifeq ($(ARCH),s390x)
 CONFIG_PFMLIB_ARCH_S390X=y
 endif
diff --git a/src/libpfm4/docs/Makefile b/src/libpfm4/docs/Makefile
index ecf6769..c7d797e 100644
--- a/src/libpfm4/docs/Makefile
+++ b/src/libpfm4/docs/Makefile
@@ -76,7 +76,17 @@ endif
 endif
 
 ifeq ($(CONFIG_PFMLIB_ARCH_ARM),y)
-ARCH_MAN += libpfm_arm_ac15.3 libpfm_arm_ac8.3 libpfm_arm_ac9.3 libpfm_arm_qcom_krait.3
+ARCH_MAN += libpfm_arm_ac57.3 \
+	    libpfm_arm_ac53.3 \
+	    libpfm_arm_ac15.3 \
+	    libpfm_arm_ac8.3 \
+	    libpfm_arm_ac9.3 \
+	    libpfm_arm_qcom_krait.3
+endif
+
+ifeq ($(CONFIG_PFMLIB_ARCH_ARM64),y)
+ARCH_MAN += libpfm_arm_ac57.3 \
+	    libpfm_arm_ac53.3
 endif
 
 ifeq ($(CONFIG_PFMLIB_ARCH_MIPS),y)
diff --git a/src/libpfm4/docs/man3/libpfm_arm_ac53.3 b/src/libpfm4/docs/man3/libpfm_arm_ac53.3
new file mode 100644
index 0000000..319accc
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_arm_ac53.3
@@ -0,0 +1,36 @@
+.TH LIBPFM 4  "May, 2014" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_arm_ac53 - support for ARM Cortex A53 PMU
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: arm_ac53
+.B PMU desc: ARM Cortex A53
+.sp
+.SH DESCRIPTION
+The library supports the ARM Cortex A53 core PMU.
+
+This PMU supports 6 counters and privilege levels filtering.
+It can operate in both 32 and 64 bit modes.
+
+.SH MODIFIERS
+The following modifiers are supported on ARM Cortex A53:
+.TP
+.B u
+Measure at the user level. This corresponds to \fBPFM_PLM3\fR.
+This is a boolean modifier.
+.TP
+.B k
+Measure at the kernel level. This corresponds to \fBPFM_PLM0\fR.
+This is a boolean modifier.
+.TP
+.B hv
+Measure at the hypervisor level. This corresponds to \fBPFM_PLMH\fR.
+This is a boolean modifier.
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.PP
diff --git a/src/libpfm4/docs/man3/libpfm_arm_ac57.3 b/src/libpfm4/docs/man3/libpfm_arm_ac57.3
new file mode 100644
index 0000000..c471ff1
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_arm_ac57.3
@@ -0,0 +1,36 @@
+.TH LIBPFM 4  "May, 2014" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_arm_ac57 - support for Arm Cortex A57 PMU
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: arm_ac57
+.B PMU desc: ARM Cortex A57
+.sp
+.SH DESCRIPTION
+The library supports the ARM Cortex A57 core PMU.
+
+This PMU supports 6 counters and privilege levels filtering.
+It can operate in both 32 and 64 bit modes.
+
+.SH MODIFIERS
+The following modifiers are supported on ARM Cortex A57:
+.TP
+.B u
+Measure at the user level. This corresponds to \fBPFM_PLM3\fR.
+This is a boolean modifier.
+.TP
+.B k
+Measure at the kernel level. This corresponds to \fBPFM_PLM0\fR.
+This is a boolean modifier.
+.TP
+.B hv
+Measure at the hypervisor level. This corresponds to \fBPFM_PLMH\fR.
+This is a boolean modifier.
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.PP
diff --git a/src/libpfm4/include/perfmon/pfmlib.h b/src/libpfm4/include/perfmon/pfmlib.h
index dfdd471..a7ec026 100644
--- a/src/libpfm4/include/perfmon/pfmlib.h
+++ b/src/libpfm4/include/perfmon/pfmlib.h
@@ -237,6 +237,9 @@ typedef enum {
 
 	PFM_PMU_S390X_CPUM_SF,		/* s390x: CPU-M sampling facility */
 
+	PFM_PMU_ARM_CORTEX_A57,		/* ARM Cortex A57 (ARMv8) */
+	PFM_PMU_ARM_CORTEX_A53,		/* ARM Cortex A53 (ARMv8) */
+
 	/* MUST ADD NEW PMU MODELS HERE */
 
 	PFM_PMU_MAX			/* end marker */
diff --git a/src/libpfm4/lib/Makefile b/src/libpfm4/lib/Makefile
index 531167e..5aaf4b3 100644
--- a/src/libpfm4/lib/Makefile
+++ b/src/libpfm4/lib/Makefile
@@ -139,10 +139,21 @@ SRCS += pfmlib_arm_perf_event.c
 endif
 
 INCARCH = $(INC_ARM)
-SRCS   += pfmlib_arm.c pfmlib_arm_armv7_pmuv1.c pfmlib_arm_armv6.c
+SRCS   += pfmlib_arm.c pfmlib_arm_armv7_pmuv1.c pfmlib_arm_armv6.c pfmlib_arm_armv8.c
 CFLAGS += -DCONFIG_PFMLIB_ARCH_ARM
 endif
 
+ifeq ($(CONFIG_PFMLIB_ARCH_ARM64),y)
+
+ifeq ($(SYS),Linux)
+SRCS += pfmlib_arm_perf_event.c
+endif
+
+INCARCH = $(INC_ARM64)
+SRCS   += pfmlib_arm.c pfmlib_arm_armv8.c
+CFLAGS += -DCONFIG_PFMLIB_ARCH_ARM64
+endif
+
 ifeq ($(CONFIG_PFMLIB_ARCH_MIPS),y)
 
 ifeq ($(SYS),Linux)
@@ -270,7 +281,12 @@ INC_ARM=events/arm_cortex_a8_events.h		\
 INC_ARM=pfmlib_arm_priv.h			\
 	events/arm_cortex_a8_events.h		\
 	events/arm_cortex_a9_events.h		\
-	events/arm_cortex_a15_events.h
+	events/arm_cortex_a15_events.h		\
+	events/arm_cortex_a57_events.h		\
+	events/arm_cortex_a53_events.h
+
+INC_ARM64=events/arm_cortex_a57_events.h	\
+	  events/arm_cortex_a53_events.h
 
 INCDEP=$(INC_COMMON) $(INCARCH)
 
diff --git a/src/libpfm4/lib/events/arm_cortex_a53_events.h b/src/libpfm4/lib/events/arm_cortex_a53_events.h
new file mode 100644
index 0000000..c0d2bb6
--- /dev/null
+++ b/src/libpfm4/lib/events/arm_cortex_a53_events.h
@@ -0,0 +1,190 @@
+/*
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Cortex A53 r0p2
+ * based on Table 12.9 from the "Cortex A53 Technical Reference Manual"
+ */
+
+static const arm_entry_t arm_cortex_a53_pe[]={
+	{.name = "SW_INCR",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x00,
+	 .desc = "Instruction architecturally executed (condition check pass) Software increment"
+	},
+	{.name = "L1I_CACHE_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x01,
+	 .desc = "Level 1 instruction cache refill"
+	},
+	{.name = "L1I_TLB_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x02,
+	 .desc = "Level 1 instruction TLB refill"
+	},
+	{.name = "L1D_CACHE_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x03,
+	 .desc = "Level 1 data cache refill"
+	},
+	{.name = "L1D_CACHE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x04,
+	 .desc = "Level 1 data cache access"
+	},
+	{.name = "L1D_TLB_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x05,
+	 .desc = "Level 1 data TLB refill"
+	},
+	{.name = "LD_RETIRED",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x06,
+	 .desc = "Load Instruction architecturally executed, condition check",
+	},
+	{.name = "ST_RETIRED",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x07,
+	 .desc = "Store Instruction architecturally executed, condition check",
+	},
+	{.name = "INST_RETIRED",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x08,
+	 .desc = "Instruction architecturally executed"
+	},
+	{.name = "EXCEPTION_TAKEN",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x09,
+	 .desc = "Exception taken"
+	},
+	{.name = "EXCEPTION_RETURN",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x0a,
+	 .desc = "Instruction architecturally executed (condition check pass) Exception return"
+	},
+	{.name = "CID_WRITE_RETIRED",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x0b,
+	 .desc = "Change to Context ID retired",
+	},
+	{.name = "PC_WRITE_RETIRED",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x0c,
+	 .desc = "Write to CONTEXTIDR, instruction architecturally executed, condition check pass"
+	},
+	{.name = "BR_IMMED_RETIRED",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x0d,
+	 .desc = "Software chnage of the PC, instruction architecturally executed, condition check pass"
+	},
+	{.name = "UNALIGNED_LDST_RETIRED",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x0f,
+	 .desc = "Procedure return, instruction architecturally executed, condition check pass"
+	},
+	{.name = "BRANCH_MISPRED",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x10,
+	 .desc = "Mispredicted or not predicted branch speculatively executed"
+	},
+	{.name = "CPU_CYCLES",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x11,
+	 .desc = "Cycles"
+	},
+	{.name = "BRANCH_PRED",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x12,
+	 .desc = "Predictable branch speculatively executed"
+	},
+	{.name = "DATA_MEM_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x13,
+	 .desc = "Data memory access"
+	},
+	{.name = "L1I_CACHE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x14,
+	 .desc = "Level 1 instruction cache access"
+	},
+	{.name = "L1D_CACHE_WB",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x15,
+	 .desc = "Level 1 data cache WriteBack"
+	},
+	{.name = "L2D_CACHE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x16,
+	 .desc = "Level 2 data cache access"
+	},
+	{.name = "L2D_CACHE_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x17,
+	 .desc = "Level 2 data cache refill"
+	},
+	{.name = "L2D_CACHE_WB",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x18,
+	 .desc = "Level 2 data cache WriteBack"
+	},
+	{.name = "BUS_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x19,
+	 .desc = "Bus access"
+	},
+	{.name = "LOCAL_MEMORY_ERROR",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x1a,
+	 .desc = "Local memory error"
+	},
+	{.name = "BUS_CYCLES",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x1d,
+	 .desc = "Bus cycle"
+	},
+
+	{.name = "BUS_READ_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x60,
+	 .desc = "Bus read access"
+	},
+	{.name = "BUS_WRITE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x61,
+	 .desc = "Bus write access"
+	},
+
+	{.name = "BRANCH_SPEC_EXEC_IND",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x7a,
+	 .desc = "Indirect branch speculatively executed"
+	},
+
+	{.name = "EXCEPTION_IRQ",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x86,
+	 .desc = "Exception taken, irq"
+	},
+	{.name = "EXCEPTION_FIQ",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x87,
+	 .desc = "Exception taken, irq"
+	},
+};
diff --git a/src/libpfm4/lib/events/arm_cortex_a57_events.h b/src/libpfm4/lib/events/arm_cortex_a57_events.h
new file mode 100644
index 0000000..9d1d407
--- /dev/null
+++ b/src/libpfm4/lib/events/arm_cortex_a57_events.h
@@ -0,0 +1,440 @@
+/*
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Cortex A57 r1p1
+ * based on Table 11-24 from the "Cortex A57 Technical Reference Manual"
+ */
+
+static const arm_entry_t arm_cortex_a57_pe[]={
+	{.name = "SW_INCR",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x00,
+	 .desc = "Instruction architecturally executed (condition check pass) Software increment"
+	},
+	{.name = "L1I_CACHE_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x01,
+	 .desc = "Level 1 instruction cache refill"
+	},
+	{.name = "L1I_TLB_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x02,
+	 .desc = "Level 1 instruction TLB refill"
+	},
+	{.name = "L1D_CACHE_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x03,
+	 .desc = "Level 1 data cache refill"
+	},
+	{.name = "L1D_CACHE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x04,
+	 .desc = "Level 1 data cache access"
+	},
+	{.name = "L1D_TLB_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x05,
+	 .desc = "Level 1 data TLB refill"
+	},
+
+	{.name = "INST_RETIRED",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x08,
+	 .desc = "Instruction architecturally executed"
+	},
+	{.name = "EXCEPTION_TAKEN",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x09,
+	 .desc = "Exception taken"
+	},
+	{.name = "EXCEPTION_RETURN",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x0a,
+	 .desc = "Instruction architecturally executed (condition check pass) Exception return"
+	},
+	{.name = "CID_WRITE_RETIRED",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x0b,
+	 .desc = "Instruction architecturally executed (condition check pass)  Write to CONTEXTIDR"
+	},
+
+	{.name = "BRANCH_MISPRED",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x10,
+	 .desc = "Mispredicted or not predicted branch speculatively executed"
+	},
+	{.name = "CPU_CYCLES",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x11,
+	 .desc = "Cycles"
+	},
+	{.name = "BRANCH_PRED",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x12,
+	 .desc = "Predictable branch speculatively executed"
+	},
+	{.name = "DATA_MEM_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x13,
+	 .desc = "Data memory access"
+	},
+	{.name = "L1I_CACHE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x14,
+	 .desc = "Level 1 instruction cache access"
+	},
+	{.name = "L1D_CACHE_WB",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x15,
+	 .desc = "Level 1 data cache WriteBack"
+	},
+	{.name = "L2D_CACHE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x16,
+	 .desc = "Level 2 data cache access"
+	},
+	{.name = "L2D_CACHE_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x17,
+	 .desc = "Level 2 data cache refill"
+	},
+	{.name = "L2D_CACHE_WB",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x18,
+	 .desc = "Level 2 data cache WriteBack"
+	},
+	{.name = "BUS_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x19,
+	 .desc = "Bus access"
+	},
+	{.name = "LOCAL_MEMORY_ERROR",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x1a,
+	 .desc = "Local memory error"
+	},
+	{.name = "INST_SPEC_EXEC",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x1b,
+	 .desc = "Instruction speculatively executed"
+	},
+	{.name = "TTBR_WRITE_RETIRED",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x1c,
+	 .desc = "Instruction architecturally executed (condition check pass)  Write to translation table base"
+	},
+	{.name = "BUS_CYCLES",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x1d,
+	 .desc = "Bus cycle"
+	},
+	{.name = "L1D_READ_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x40,
+	 .desc = "Level 1 data cache read access"
+	},
+	{.name = "L1D_WRITE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x41,
+	 .desc = "Level 1 data cache write access"
+	},
+	{.name = "L1D_READ_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x42,
+	 .desc = "Level 1 data cache read refill"
+	},
+	{.name = "L1D_WRITE_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x43,
+	 .desc = "Level 1 data cache write refill"
+	},
+	{.name = "L1D_WB_VICTIM",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x46,
+	 .desc = "Level 1 data cache writeback victim"
+	},
+	{.name = "L1D_WB_CLEAN_COHERENCY",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x47,
+	 .desc = "Level 1 data cache writeback cleaning and coherency"
+	},
+	{.name = "L1D_INVALIDATE",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x48,
+	 .desc = "Level 1 data cache invalidate"
+	},
+	{.name = "L1D_TLB_READ_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x4c,
+	 .desc = "Level 1 data TLB read refill"
+	},
+	{.name = "L1D_TLB_WRITE_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x4d,
+	 .desc = "Level 1 data TLB write refill"
+	},
+	{.name = "L2D_READ_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x50,
+	 .desc = "Level 2 data cache read access"
+	},
+	{.name = "L2D_WRITE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x51,
+	 .desc = "Level 2 data cache write access"
+	},
+	{.name = "L2D_READ_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x52,
+	 .desc = "Level 2 data cache read refill"
+	},
+	{.name = "L2D_WRITE_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x53,
+	 .desc = "Level 2 data cache write refill"
+	},
+	{.name = "L2D_WB_VICTIM",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x56,
+	 .desc = "Level 2 data cache writeback victim"
+	},
+	{.name = "L2D_WB_CLEAN_COHERENCY",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x57,
+	 .desc = "Level 2 data cache writeback cleaning and coherency"
+	},
+	{.name = "L2D_INVALIDATE",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x58,
+	 .desc = "Level 2 data cache invalidate"
+	},
+	{.name = "BUS_READ_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x60,
+	 .desc = "Bus read access"
+	},
+	{.name = "BUS_WRITE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x61,
+	 .desc = "Bus write access"
+	},
+	{.name = "BUS_NORMAL_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x62,
+	 .desc = "Bus normal access"
+	},
+	{.name = "BUS_NOT_NORMAL_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x63,
+	 .desc = "Bus not normal access"
+	},
+	{.name = "BUS_NORMAL_ACCESS_2",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x64,
+	 .desc = "Bus normal access"
+	},
+	{.name = "BUS_PERIPH_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x65,
+	 .desc = "Bus peripheral access"
+	},
+	{.name = "DATA_MEM_READ_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x66,
+	 .desc = "Data memory read access"
+	},
+	{.name = "DATA_MEM_WRITE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x67,
+	 .desc = "Data memory write access"
+	},
+	{.name = "UNALIGNED_READ_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x68,
+	 .desc = "Unaligned read access"
+	},
+	{.name = "UNALIGNED_WRITE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x69,
+	 .desc = "Unaligned read access"
+	},
+	{.name = "UNALIGNED_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x6a,
+	 .desc = "Unaligned access"
+	},
+	{.name = "INST_SPEC_EXEC_LDREX",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x6c,
+	 .desc = "LDREX exclusive instruction speculatively executed"
+	},
+	{.name = "INST_SPEC_EXEC_STREX_PASS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x6d,
+	 .desc = "STREX pass exclusive instruction speculatively executed"
+	},
+	{.name = "INST_SPEC_EXEC_STREX_FAIL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x6e,
+	 .desc = "STREX fail exclusive instruction speculatively executed"
+	},
+	{.name = "INST_SPEC_EXEC_LOAD",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x70,
+	 .desc = "Load instruction speculatively executed"
+	},
+	{.name = "INST_SPEC_EXEC_STORE",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x71,
+	 .desc = "Store instruction speculatively executed"
+	},
+	{.name = "INST_SPEC_EXEC_LOAD_STORE",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x72,
+	 .desc = "Load or store instruction speculatively executed"
+	},
+	{.name = "INST_SPEC_EXEC_INTEGER_INST",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x73,
+	 .desc = "Integer data processing instruction speculatively executed"
+	},
+	{.name = "INST_SPEC_EXEC_SIMD",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x74,
+	 .desc = "Advanced SIMD instruction speculatively executed"
+	},
+	{.name = "INST_SPEC_EXEC_VFP",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x75,
+	 .desc = "VFP instruction speculatively executed"
+	},
+	{.name = "INST_SPEC_EXEC_SOFT_PC",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x76,
+	 .desc = "Software of the PC instruction speculatively executed"
+	},
+	{.name = "BRANCH_SPEC_EXEC_IMM_BRANCH",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x78,
+	 .desc = "Immediate branch speculatively executed"
+	},
+	{.name = "BRANCH_SPEC_EXEC_RET",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x79,
+	 .desc = "Return branch speculatively executed"
+	},
+	{.name = "BRANCH_SPEC_EXEC_IND",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x7a,
+	 .desc = "Indirect branch speculatively executed"
+	},
+	{.name = "BARRIER_SPEC_EXEC_ISB",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x7c,
+	 .desc = "ISB barrier speculatively executed"
+	},
+	{.name = "BARRIER_SPEC_EXEC_DSB",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x7d,
+	 .desc = "DSB barrier speculatively executed"
+	},
+	{.name = "BARRIER_SPEC_EXEC_DMB",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x7e,
+	 .desc = "DMB barrier speculatively executed"
+	},
+	{.name = "EXCEPTION_UNDEF",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x81,
+	 .desc = "Exception taken, other synchronous"
+	},
+	{.name = "EXCEPTION_SVC",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x82,
+	 .desc = "Exception taken, supervisor call"
+	},
+	{.name = "EXCEPTION_PABORT",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x83,
+	 .desc = "Exception taken, instruction abort"
+	},
+	{.name = "EXCEPTION_DABORT",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x84,
+	 .desc = "Exception taken, data abort or SError"
+	},
+	{.name = "EXCEPTION_IRQ",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x86,
+	 .desc = "Exception taken, irq"
+	},
+	{.name = "EXCEPTION_FIQ",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x87,
+	 .desc = "Exception taken, irq"
+	},
+	{.name = "EXCEPTION_SMC",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x88,
+	 .desc = "Exception taken, secure monitor call"
+	},
+	{.name = "EXCEPTION_HVC",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x8a,
+	 .desc = "Exception taken, hypervisor call"
+	},
+	{.name = "EXCEPTION_TRAP_PABORT",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x8b,
+	 .desc = "Exception taken, instruction abort not taken locally"
+	},
+	{.name = "EXCEPTION_TRAP_DABORT",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x8c,
+	 .desc = "Exception taken, data abort or SError not taken locally"
+	},
+	{.name = "EXCEPTION_TRAP_OTHER",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x8d,
+	 .desc = "Exception taken, other traps not taken locally"
+	},
+	{.name = "EXCEPTION_TRAP_IRQ",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x8e,
+	 .desc = "Exception taken, irq not taken locally"
+	},
+	{.name = "EXCEPTION_TRAP_FIQ",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x8f,
+	 .desc = "Exception taken, fiq not taken locally"
+	},
+	{.name = "RC_LD_SPEC",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x90,
+	 .desc = "Release consistency instruction speculatively executed (load-acquire)",
+	},
+	{.name = "RC_ST_SPEC",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x91,
+	 .desc = "Release consistency instruction speculatively executed (store-release)",
+	},
+	/* END Cortex A47 specific events */
+};
diff --git a/src/libpfm4/lib/events/intel_hsw_events.h b/src/libpfm4/lib/events/intel_hsw_events.h
index b4e7c00..028f295 100644
--- a/src/libpfm4/lib/events/intel_hsw_events.h
+++ b/src/libpfm4/lib/events/intel_hsw_events.h
@@ -279,6 +279,12 @@ static const intel_x86_umask_t hsw_cpu_clk_thread_unhalted[]={
     .ucode  = 0x100,
     .uflags = INTEL_X86_NCOMBO,
   },
+  { .uname  = "REF_P",
+    .udesc  = "Cycles when the core is unhalted (count at 100 Mhz)",
+    .ucode = 0x100,
+    .uequiv = "REF_XCLK",
+    .uflags= INTEL_X86_NCOMBO,
+  },
   { .uname  = "THREAD_P",
     .udesc  = "Cycles when thread is not halted",
     .ucode = 0x000,
diff --git a/src/libpfm4/lib/events/intel_ivbep_unc_pcu_events.h b/src/libpfm4/lib/events/intel_ivbep_unc_pcu_events.h
index 14188e5..05b0118 100644
--- a/src/libpfm4/lib/events/intel_ivbep_unc_pcu_events.h
+++ b/src/libpfm4/lib/events/intel_ivbep_unc_pcu_events.h
@@ -338,12 +338,6 @@ static const intel_x86_entry_t intel_ivbep_unc_p_pe[]={
     .cntmsk = 0xf,
     .modmsk = IVBEP_UNC_PCU_ATTRS,
   },
-  { .name = "UNC_P_DEMOTIONS_CORE14",
-    .desc = "Core 14 C State Demotions",
-    .code = 0x2d,
-    .cntmsk = 0xf,
-    .modmsk = IVBEP_UNC_PCU_ATTRS,
-  },
   { .name = "UNC_P_FREQ_BAND0_CYCLES",
     .desc = "Frequency Residency",
     .code = 0xb,
diff --git a/src/libpfm4/lib/events/power8_events.h b/src/libpfm4/lib/events/power8_events.h
index 25945f3..3437602 100644
--- a/src/libpfm4/lib/events/power8_events.h
+++ b/src/libpfm4/lib/events/power8_events.h
@@ -23,481 +23,1380 @@ Author:  Carl Love
 *  http://www.power.org/documentation
 */
 
-#define POWER8_PME_PM_1PLUS_PPC_CMPL 0
-#define POWER8_PME_PM_1PLUS_PPC_DISP 1
-#define POWER8_PME_PM_ANY_THRD_RUN_CYC 2
-#define POWER8_PME_PM_BR_MPRED_CMPL 3
-#define POWER8_PME_PM_BR_TAKEN_CMPL 4
-#define POWER8_PME_PM_CYC 5
-#define POWER8_PME_PM_DATA_FROM_L2MISS 6
-#define POWER8_PME_PM_DATA_FROM_L3MISS 7
-#define POWER8_PME_PM_DATA_FROM_MEM 8
-#define POWER8_PME_PM_DTLB_MISS 9
-#define POWER8_PME_PM_EXT_INT 10
-#define POWER8_PME_PM_FLOP 11
-#define POWER8_PME_PM_FLUSH 12
-#define POWER8_PME_PM_GCT_NOSLOT_CYC 13
-#define POWER8_PME_PM_IERAT_MISS 14
-#define POWER8_PME_PM_INST_DISP 15
-#define POWER8_PME_PM_INST_FROM_L3MISS 16
-#define POWER8_PME_PM_ITLB_MISS 17
-#define POWER8_PME_PM_L1_DCACHE_RELOAD_VALID 18
-#define POWER8_PME_PM_L1_ICACHE_MISS 19
-#define POWER8_PME_PM_LD_MISS_L1 20
-#define POWER8_PME_PM_LSU_DERAT_MISS 21
-#define POWER8_PME_PM_MRK_BR_MPRED_CMPL 22
-#define POWER8_PME_PM_MRK_BR_TAKEN_CMPL 23
-#define POWER8_PME_PM_MRK_DATA_FROM_L2MISS 24
-#define POWER8_PME_PM_MRK_DATA_FROM_L3MISS 25
-#define POWER8_PME_PM_MRK_DATA_FROM_MEM 26
-#define POWER8_PME_PM_MRK_DERAT_MISS 27
-#define POWER8_PME_PM_MRK_DTLB_MISS 28
-#define POWER8_PME_PM_MRK_INST_CMPL 29
-#define POWER8_PME_PM_MRK_INST_DISP 30
-#define POWER8_PME_PM_MRK_INST_FROM_L3MISS 31
-#define POWER8_PME_PM_MRK_L1_ICACHE_MISS 32
-#define POWER8_PME_PM_MRK_L1_RELOAD_VALID 33
-#define POWER8_PME_PM_MRK_LD_MISS_L1 34
-#define POWER8_PME_PM_MRK_ST_CMPL 35
-#define POWER8_PME_PM_RUN_CYC 36
-#define POWER8_PME_PM_RUN_INST_CMPL 37
-#define POWER8_PME_PM_RUN_PURR 38
-#define POWER8_PME_PM_ST_FIN 39
-#define POWER8_PME_PM_ST_MISS_L1 40
-#define POWER8_PME_PM_TB_BIT_TRANS 41
-#define POWER8_PME_PM_THRD_CONC_RUN_INST 42
-#define POWER8_PME_PM_THRESH_EXC_1024 43
-#define POWER8_PME_PM_THRESH_EXC_128 44
-#define POWER8_PME_PM_THRESH_EXC_2048 45
-#define POWER8_PME_PM_THRESH_EXC_256 46
-#define POWER8_PME_PM_THRESH_EXC_32 47
-#define POWER8_PME_PM_THRESH_EXC_4096 48
-#define POWER8_PME_PM_THRESH_EXC_512 49
-#define POWER8_PME_PM_THRESH_EXC_64 50
-#define POWER8_PME_PM_THRESH_MET 51
-#define POWER8_PME_PM_BR_2PATH 52
-#define POWER8_PME_PM_BR_CMPL 53
-#define POWER8_PME_PM_BR_MRK_2PATH 54
-#define POWER8_PME_PM_CMPLU_STALL 55
-#define POWER8_PME_PM_CMPLU_STALL_BRU 56
-#define POWER8_PME_PM_CMPLU_STALL_BRU_CRU 57
-#define POWER8_PME_PM_CMPLU_STALL_COQ_FULL 58
-#define POWER8_PME_PM_CMPLU_STALL_DCACHE_MISS 59
-#define POWER8_PME_PM_CMPLU_STALL_DMISS_L21_L31 60
-#define POWER8_PME_PM_CMPLU_STALL_DMISS_L2L3 61
-#define POWER8_PME_PM_CMPLU_STALL_DMISS_L2L3_CONFLICT 62
-#define POWER8_PME_PM_CMPLU_STALL_DMISS_L3MISS 63
-#define POWER8_PME_PM_CMPLU_STALL_DMISS_LMEM 64
-#define POWER8_PME_PM_CMPLU_STALL_DMISS_REMOTE 65
-#define POWER8_PME_PM_CMPLU_STALL_ERAT_MISS 66
-#define POWER8_PME_PM_CMPLU_STALL_FLUSH 67
-#define POWER8_PME_PM_CMPLU_STALL_FXLONG 68
-#define POWER8_PME_PM_CMPLU_STALL_FXU 69
-#define POWER8_PME_PM_CMPLU_STALL_HWSYNC 70
-#define POWER8_PME_PM_CMPLU_STALL_LOAD_FINISH 71
-#define POWER8_PME_PM_CMPLU_STALL_LSU 72
-#define POWER8_PME_PM_CMPLU_STALL_LWSYNC 73
-#define POWER8_PME_PM_CMPLU_STALL_MEM_ECC_DELAY 74
-#define POWER8_PME_PM_CMPLU_STALL_NTCG_FLUSH 75
-#define POWER8_PME_PM_CMPLU_STALL_OTHER_CMPL 76
-#define POWER8_PME_PM_CMPLU_STALL_REJECT 77
-#define POWER8_PME_PM_CMPLU_STALL_REJECT_LHS 78
-#define POWER8_PME_PM_CMPLU_STALL_REJ_LMQ_FULL 79
-#define POWER8_PME_PM_CMPLU_STALL_SCALAR 80
-#define POWER8_PME_PM_CMPLU_STALL_SCALAR_LONG 81
-#define POWER8_PME_PM_CMPLU_STALL_STORE 82
-#define POWER8_PME_PM_CMPLU_STALL_ST_FWD 83
-#define POWER8_PME_PM_CMPLU_STALL_THRD 84
-#define POWER8_PME_PM_CMPLU_STALL_VECTOR 85
-#define POWER8_PME_PM_CMPLU_STALL_VECTOR_LONG 86
-#define POWER8_PME_PM_CMPLU_STALL_VSU 87
-#define POWER8_PME_PM_DATA_FROM_L2 88
-#define POWER8_PME_PM_DATA_FROM_L2_NO_CONFLICT 89
-#define POWER8_PME_PM_DATA_FROM_L3 90
-#define POWER8_PME_PM_DATA_FROM_L3MISS_MOD 91
-#define POWER8_PME_PM_DATA_FROM_L3_NO_CONFLICT 92
-#define POWER8_PME_PM_DATA_FROM_LMEM 93
-#define POWER8_PME_PM_DATA_FROM_MEMORY 94
-#define POWER8_PME_PM_DC_PREF_STREAM_STRIDED_CONF 95
-#define POWER8_PME_PM_GCT_NOSLOT_BR_MPRED 96
-#define POWER8_PME_PM_GCT_NOSLOT_BR_MPRED_ICMISS 97
-#define POWER8_PME_PM_GCT_NOSLOT_DISP_HELD_ISSQ 98
-#define POWER8_PME_PM_GCT_NOSLOT_DISP_HELD_OTHER 99
-#define POWER8_PME_PM_GCT_NOSLOT_DISP_HELD_SRQ 100
-#define POWER8_PME_PM_GCT_NOSLOT_IC_L3MISS 101
-#define POWER8_PME_PM_GCT_NOSLOT_IC_MISS 102
-#define POWER8_PME_PM_GRP_DISP 103
-#define POWER8_PME_PM_GRP_MRK 104
-#define POWER8_PME_PM_HV_CYC 105
-#define POWER8_PME_PM_INST_CMPL 106
-#define POWER8_PME_PM_IOPS_CMPL 107
-#define POWER8_PME_PM_LD_CMPL 108
-#define POWER8_PME_PM_LD_L3MISS_PEND_CYC 109
-#define POWER8_PME_PM_MRK_DATA_FROM_L2 110
-#define POWER8_PME_PM_MRK_DATA_FROM_L2MISS_CYC 111
-#define POWER8_PME_PM_MRK_DATA_FROM_L2_CYC 112
-#define POWER8_PME_PM_MRK_DATA_FROM_L2_NO_CONFLICT 113
-#define POWER8_PME_PM_MRK_DATA_FROM_L2_NO_CONFLICT_CYC 114
-#define POWER8_PME_PM_MRK_DATA_FROM_L3 115
-#define POWER8_PME_PM_MRK_DATA_FROM_L3MISS_CYC 116
-#define POWER8_PME_PM_MRK_DATA_FROM_L3_CYC 117
-#define POWER8_PME_PM_MRK_DATA_FROM_L3_NO_CONFLICT 118
-#define POWER8_PME_PM_MRK_DATA_FROM_L3_NO_CONFLICT_CYC 119
-#define POWER8_PME_PM_MRK_DATA_FROM_LL4 120
-#define POWER8_PME_PM_MRK_DATA_FROM_LL4_CYC 121
-#define POWER8_PME_PM_MRK_DATA_FROM_LMEM 122
-#define POWER8_PME_PM_MRK_DATA_FROM_LMEM_CYC 123
-#define POWER8_PME_PM_MRK_DATA_FROM_MEMORY 124
-#define POWER8_PME_PM_MRK_DATA_FROM_MEMORY_CYC 125
-#define POWER8_PME_PM_MRK_GRP_CMPL 126
-#define POWER8_PME_PM_MRK_INST_DECODED 127
-#define POWER8_PME_PM_MRK_L2_RC_DISP 128
-#define POWER8_PME_PM_MRK_LD_MISS_L1_CYC 129
-#define POWER8_PME_PM_MRK_STALL_CMPLU_CYC 130
-#define POWER8_PME_PM_NEST_REF_CLK 131
-#define POWER8_PME_PM_PMC1_OVERFLOW 132
-#define POWER8_PME_PM_PMC2_OVERFLOW 133
-#define POWER8_PME_PM_PMC3_OVERFLOW 134
-#define POWER8_PME_PM_PMC4_OVERFLOW 135
-#define POWER8_PME_PM_PMC6_OVERFLOW 136
-#define POWER8_PME_PM_PPC_CMPL 137
-#define POWER8_PME_PM_THRD_ALL_RUN_CYC 138
-#define POWER8_PME_PM_THRESH_NOT_MET 139
+#define POWER8_PME_PM_1LPAR_CYC 0
+#define POWER8_PME_PM_1PLUS_PPC_CMPL 1
+#define POWER8_PME_PM_1PLUS_PPC_DISP 2
+#define POWER8_PME_PM_2LPAR_CYC 3
+#define POWER8_PME_PM_4LPAR_CYC 4
+#define POWER8_PME_PM_ALL_CHIP_PUMP_CPRED 5
+#define POWER8_PME_PM_ALL_GRP_PUMP_CPRED 6
+#define POWER8_PME_PM_ALL_GRP_PUMP_MPRED 7
+#define POWER8_PME_PM_ALL_GRP_PUMP_MPRED_RTY 8
+#define POWER8_PME_PM_ALL_PUMP_CPRED 9
+#define POWER8_PME_PM_ALL_PUMP_MPRED 10
+#define POWER8_PME_PM_ALL_SYS_PUMP_CPRED 11
+#define POWER8_PME_PM_ALL_SYS_PUMP_MPRED 12
+#define POWER8_PME_PM_ALL_SYS_PUMP_MPRED_RTY 13
+#define POWER8_PME_PM_ANY_THRD_RUN_CYC 14
+#define POWER8_PME_PM_BACK_BR_CMPL 15
+#define POWER8_PME_PM_BANK_CONFLICT 16
+#define POWER8_PME_PM_BRU_FIN 17
+#define POWER8_PME_PM_BR_2PATH 18
+#define POWER8_PME_PM_BR_BC_8 19
+#define POWER8_PME_PM_BR_BC_8_CONV 20
+#define POWER8_PME_PM_BR_CMPL 21
+#define POWER8_PME_PM_BR_MPRED_CCACHE 22
+#define POWER8_PME_PM_BR_MPRED_CMPL 23
+#define POWER8_PME_PM_BR_MPRED_CR 24
+#define POWER8_PME_PM_BR_MPRED_LSTACK 25
+#define POWER8_PME_PM_BR_MPRED_TA 26
+#define POWER8_PME_PM_BR_MRK_2PATH 27
+#define POWER8_PME_PM_BR_PRED_BR0 28
+#define POWER8_PME_PM_BR_PRED_BR1 29
+#define POWER8_PME_PM_BR_PRED_BR_CMPL 30
+#define POWER8_PME_PM_BR_PRED_CCACHE_BR0 31
+#define POWER8_PME_PM_BR_PRED_CCACHE_BR1 32
+#define POWER8_PME_PM_BR_PRED_CCACHE_CMPL 33
+#define POWER8_PME_PM_BR_PRED_CR_BR0 34
+#define POWER8_PME_PM_BR_PRED_CR_BR1 35
+#define POWER8_PME_PM_BR_PRED_CR_CMPL 36
+#define POWER8_PME_PM_BR_PRED_LSTACK_BR0 37
+#define POWER8_PME_PM_BR_PRED_LSTACK_BR1 38
+#define POWER8_PME_PM_BR_PRED_LSTACK_CMPL 39
+#define POWER8_PME_PM_BR_PRED_TA_BR0 40
+#define POWER8_PME_PM_BR_PRED_TA_BR1 41
+#define POWER8_PME_PM_BR_PRED_TA_CMPL 42
+#define POWER8_PME_PM_BR_TAKEN_CMPL 43
+#define POWER8_PME_PM_BR_UNCOND_BR0 44
+#define POWER8_PME_PM_BR_UNCOND_BR1 45
+#define POWER8_PME_PM_BR_UNCOND_CMPL 46
+#define POWER8_PME_PM_CASTOUT_ISSUED 47
+#define POWER8_PME_PM_CASTOUT_ISSUED_GPR 48
+#define POWER8_PME_PM_CHIP_PUMP_CPRED 49
+#define POWER8_PME_PM_CLB_HELD 50
+#define POWER8_PME_PM_CMPLU_STALL 51
+#define POWER8_PME_PM_CMPLU_STALL_BRU 52
+#define POWER8_PME_PM_CMPLU_STALL_BRU_CRU 53
+#define POWER8_PME_PM_CMPLU_STALL_COQ_FULL 54
+#define POWER8_PME_PM_CMPLU_STALL_DCACHE_MISS 55
+#define POWER8_PME_PM_CMPLU_STALL_DMISS_L21_L31 56
+#define POWER8_PME_PM_CMPLU_STALL_DMISS_L2L3 57
+#define POWER8_PME_PM_CMPLU_STALL_DMISS_L2L3_CONFLICT 58
+#define POWER8_PME_PM_CMPLU_STALL_DMISS_L3MISS 59
+#define POWER8_PME_PM_CMPLU_STALL_DMISS_LMEM 60
+#define POWER8_PME_PM_CMPLU_STALL_DMISS_REMOTE 61
+#define POWER8_PME_PM_CMPLU_STALL_ERAT_MISS 62
+#define POWER8_PME_PM_CMPLU_STALL_FLUSH 63
+#define POWER8_PME_PM_CMPLU_STALL_FXLONG 64
+#define POWER8_PME_PM_CMPLU_STALL_FXU 65
+#define POWER8_PME_PM_CMPLU_STALL_HWSYNC 66
+#define POWER8_PME_PM_CMPLU_STALL_LOAD_FINISH 67
+#define POWER8_PME_PM_CMPLU_STALL_LSU 68
+#define POWER8_PME_PM_CMPLU_STALL_LWSYNC 69
+#define POWER8_PME_PM_CMPLU_STALL_MEM_ECC_DELAY 70
+#define POWER8_PME_PM_CMPLU_STALL_NO_NTF 71
+#define POWER8_PME_PM_CMPLU_STALL_NTCG_FLUSH 72
+#define POWER8_PME_PM_CMPLU_STALL_OTHER_CMPL 73
+#define POWER8_PME_PM_CMPLU_STALL_REJECT 74
+#define POWER8_PME_PM_CMPLU_STALL_REJECT_LHS 75
+#define POWER8_PME_PM_CMPLU_STALL_REJ_LMQ_FULL 76
+#define POWER8_PME_PM_CMPLU_STALL_SCALAR 77
+#define POWER8_PME_PM_CMPLU_STALL_SCALAR_LONG 78
+#define POWER8_PME_PM_CMPLU_STALL_STORE 79
+#define POWER8_PME_PM_CMPLU_STALL_ST_FWD 80
+#define POWER8_PME_PM_CMPLU_STALL_THRD 81
+#define POWER8_PME_PM_CMPLU_STALL_VECTOR 82
+#define POWER8_PME_PM_CMPLU_STALL_VECTOR_LONG 83
+#define POWER8_PME_PM_CMPLU_STALL_VSU 84
+#define POWER8_PME_PM_CO0_ALLOC 85
+#define POWER8_PME_PM_CO0_BUSY 86
+#define POWER8_PME_PM_CO_DISP_FAIL 87
+#define POWER8_PME_PM_CO_TM_SC_FOOTPRINT 88
+#define POWER8_PME_PM_CO_USAGE 89
+#define POWER8_PME_PM_CRU_FIN 90
+#define POWER8_PME_PM_CYC 91
+#define POWER8_PME_PM_DATA_ALL_CHIP_PUMP_CPRED 92
+#define POWER8_PME_PM_DATA_ALL_FROM_DL2L3_MOD 93
+#define POWER8_PME_PM_DATA_ALL_FROM_DL2L3_SHR 94
+#define POWER8_PME_PM_DATA_ALL_FROM_DL4 95
+#define POWER8_PME_PM_DATA_ALL_FROM_DMEM 96
+#define POWER8_PME_PM_DATA_ALL_FROM_L2 97
+#define POWER8_PME_PM_DATA_ALL_FROM_L21_MOD 98
+#define POWER8_PME_PM_DATA_ALL_FROM_L21_SHR 99
+#define POWER8_PME_PM_DATA_ALL_FROM_L2MISS_MOD 100
+#define POWER8_PME_PM_DATA_ALL_FROM_L2_DISP_CONFLICT_LDHITST 101
+#define POWER8_PME_PM_DATA_ALL_FROM_L2_DISP_CONFLICT_OTHER 102
+#define POWER8_PME_PM_DATA_ALL_FROM_L2_MEPF 103
+#define POWER8_PME_PM_DATA_ALL_FROM_L2_NO_CONFLICT 104
+#define POWER8_PME_PM_DATA_ALL_FROM_L3 105
+#define POWER8_PME_PM_DATA_ALL_FROM_L31_ECO_MOD 106
+#define POWER8_PME_PM_DATA_ALL_FROM_L31_ECO_SHR 107
+#define POWER8_PME_PM_DATA_ALL_FROM_L31_MOD 108
+#define POWER8_PME_PM_DATA_ALL_FROM_L31_SHR 109
+#define POWER8_PME_PM_DATA_ALL_FROM_L3MISS_MOD 110
+#define POWER8_PME_PM_DATA_ALL_FROM_L3_DISP_CONFLICT 111
+#define POWER8_PME_PM_DATA_ALL_FROM_L3_MEPF 112
+#define POWER8_PME_PM_DATA_ALL_FROM_L3_NO_CONFLICT 113
+#define POWER8_PME_PM_DATA_ALL_FROM_LL4 114
+#define POWER8_PME_PM_DATA_ALL_FROM_LMEM 115
+#define POWER8_PME_PM_DATA_ALL_FROM_MEMORY 116
+#define POWER8_PME_PM_DATA_ALL_FROM_OFF_CHIP_CACHE 117
+#define POWER8_PME_PM_DATA_ALL_FROM_ON_CHIP_CACHE 118
+#define POWER8_PME_PM_DATA_ALL_FROM_RL2L3_MOD 119
+#define POWER8_PME_PM_DATA_ALL_FROM_RL2L3_SHR 120
+#define POWER8_PME_PM_DATA_ALL_FROM_RL4 121
+#define POWER8_PME_PM_DATA_ALL_FROM_RMEM 122
+#define POWER8_PME_PM_DATA_ALL_GRP_PUMP_CPRED 123
+#define POWER8_PME_PM_DATA_ALL_GRP_PUMP_MPRED 124
+#define POWER8_PME_PM_DATA_ALL_GRP_PUMP_MPRED_RTY 125
+#define POWER8_PME_PM_DATA_ALL_PUMP_CPRED 126
+#define POWER8_PME_PM_DATA_ALL_PUMP_MPRED 127
+#define POWER8_PME_PM_DATA_ALL_SYS_PUMP_CPRED 128
+#define POWER8_PME_PM_DATA_ALL_SYS_PUMP_MPRED 129
+#define POWER8_PME_PM_DATA_ALL_SYS_PUMP_MPRED_RTY 130
+#define POWER8_PME_PM_DATA_CHIP_PUMP_CPRED 131
+#define POWER8_PME_PM_DATA_FROM_DL2L3_MOD 132
+#define POWER8_PME_PM_DATA_FROM_DL2L3_SHR 133
+#define POWER8_PME_PM_DATA_FROM_DL4 134
+#define POWER8_PME_PM_DATA_FROM_DMEM 135
+#define POWER8_PME_PM_DATA_FROM_L2 136
+#define POWER8_PME_PM_DATA_FROM_L21_MOD 137
+#define POWER8_PME_PM_DATA_FROM_L21_SHR 138
+#define POWER8_PME_PM_DATA_FROM_L2MISS 139
+#define POWER8_PME_PM_DATA_FROM_L2MISS_MOD 140
+#define POWER8_PME_PM_DATA_FROM_L2_DISP_CONFLICT_LDHITST 141
+#define POWER8_PME_PM_DATA_FROM_L2_DISP_CONFLICT_OTHER 142
+#define POWER8_PME_PM_DATA_FROM_L2_MEPF 143
+#define POWER8_PME_PM_DATA_FROM_L2_NO_CONFLICT 144
+#define POWER8_PME_PM_DATA_FROM_L3 145
+#define POWER8_PME_PM_DATA_FROM_L31_ECO_MOD 146
+#define POWER8_PME_PM_DATA_FROM_L31_ECO_SHR 147
+#define POWER8_PME_PM_DATA_FROM_L31_MOD 148
+#define POWER8_PME_PM_DATA_FROM_L31_SHR 149
+#define POWER8_PME_PM_DATA_FROM_L3MISS 150
+#define POWER8_PME_PM_DATA_FROM_L3MISS_MOD 151
+#define POWER8_PME_PM_DATA_FROM_L3_DISP_CONFLICT 152
+#define POWER8_PME_PM_DATA_FROM_L3_MEPF 153
+#define POWER8_PME_PM_DATA_FROM_L3_NO_CONFLICT 154
+#define POWER8_PME_PM_DATA_FROM_LL4 155
+#define POWER8_PME_PM_DATA_FROM_LMEM 156
+#define POWER8_PME_PM_DATA_FROM_MEM 157
+#define POWER8_PME_PM_DATA_FROM_MEMORY 158
+#define POWER8_PME_PM_DATA_FROM_OFF_CHIP_CACHE 159
+#define POWER8_PME_PM_DATA_FROM_ON_CHIP_CACHE 160
+#define POWER8_PME_PM_DATA_FROM_RL2L3_MOD 161
+#define POWER8_PME_PM_DATA_FROM_RL2L3_SHR 162
+#define POWER8_PME_PM_DATA_FROM_RL4 163
+#define POWER8_PME_PM_DATA_FROM_RMEM 164
+#define POWER8_PME_PM_DATA_GRP_PUMP_CPRED 165
+#define POWER8_PME_PM_DATA_GRP_PUMP_MPRED 166
+#define POWER8_PME_PM_DATA_GRP_PUMP_MPRED_RTY 167
+#define POWER8_PME_PM_DATA_PUMP_CPRED 168
+#define POWER8_PME_PM_DATA_PUMP_MPRED 169
+#define POWER8_PME_PM_DATA_SYS_PUMP_CPRED 170
+#define POWER8_PME_PM_DATA_SYS_PUMP_MPRED 171
+#define POWER8_PME_PM_DATA_SYS_PUMP_MPRED_RTY 172
+#define POWER8_PME_PM_DATA_TABLEWALK_CYC 173
+#define POWER8_PME_PM_DC_COLLISIONS 174
+#define POWER8_PME_PM_DC_PREF_STREAM_ALLOC 175
+#define POWER8_PME_PM_DC_PREF_STREAM_CONF 176
+#define POWER8_PME_PM_DC_PREF_STREAM_FUZZY_CONF 177
+#define POWER8_PME_PM_DC_PREF_STREAM_STRIDED_CONF 178
+#define POWER8_PME_PM_DERAT_MISS_16G 179
+#define POWER8_PME_PM_DERAT_MISS_16M 180
+#define POWER8_PME_PM_DERAT_MISS_4K 181
+#define POWER8_PME_PM_DERAT_MISS_64K 182
+#define POWER8_PME_PM_DFU 183
+#define POWER8_PME_PM_DFU_DCFFIX 184
+#define POWER8_PME_PM_DFU_DENBCD 185
+#define POWER8_PME_PM_DFU_MC 186
+#define POWER8_PME_PM_DISP_CLB_HELD_BAL 187
+#define POWER8_PME_PM_DISP_CLB_HELD_RES 188
+#define POWER8_PME_PM_DISP_CLB_HELD_SB 189
+#define POWER8_PME_PM_DISP_CLB_HELD_SYNC 190
+#define POWER8_PME_PM_DISP_CLB_HELD_TLBIE 191
+#define POWER8_PME_PM_DISP_HELD 192
+#define POWER8_PME_PM_DISP_HELD_IQ_FULL 193
+#define POWER8_PME_PM_DISP_HELD_MAP_FULL 194
+#define POWER8_PME_PM_DISP_HELD_SRQ_FULL 195
+#define POWER8_PME_PM_DISP_HELD_SYNC_HOLD 196
+#define POWER8_PME_PM_DISP_HOLD_GCT_FULL 197
+#define POWER8_PME_PM_DISP_WT 198
+#define POWER8_PME_PM_DPTEG_FROM_DL2L3_MOD 199
+#define POWER8_PME_PM_DPTEG_FROM_DL2L3_SHR 200
+#define POWER8_PME_PM_DPTEG_FROM_DL4 201
+#define POWER8_PME_PM_DPTEG_FROM_DMEM 202
+#define POWER8_PME_PM_DPTEG_FROM_L2 203
+#define POWER8_PME_PM_DPTEG_FROM_L21_MOD 204
+#define POWER8_PME_PM_DPTEG_FROM_L21_SHR 205
+#define POWER8_PME_PM_DPTEG_FROM_L2MISS 206
+#define POWER8_PME_PM_DPTEG_FROM_L2_DISP_CONFLICT_LDHITST 207
+#define POWER8_PME_PM_DPTEG_FROM_L2_DISP_CONFLICT_OTHER 208
+#define POWER8_PME_PM_DPTEG_FROM_L2_MEPF 209
+#define POWER8_PME_PM_DPTEG_FROM_L2_NO_CONFLICT 210
+#define POWER8_PME_PM_DPTEG_FROM_L3 211
+#define POWER8_PME_PM_DPTEG_FROM_L31_ECO_MOD 212
+#define POWER8_PME_PM_DPTEG_FROM_L31_ECO_SHR 213
+#define POWER8_PME_PM_DPTEG_FROM_L31_MOD 214
+#define POWER8_PME_PM_DPTEG_FROM_L31_SHR 215
+#define POWER8_PME_PM_DPTEG_FROM_L3MISS 216
+#define POWER8_PME_PM_DPTEG_FROM_L3_DISP_CONFLICT 217
+#define POWER8_PME_PM_DPTEG_FROM_L3_MEPF 218
+#define POWER8_PME_PM_DPTEG_FROM_L3_NO_CONFLICT 219
+#define POWER8_PME_PM_DPTEG_FROM_LL4 220
+#define POWER8_PME_PM_DPTEG_FROM_LMEM 221
+#define POWER8_PME_PM_DPTEG_FROM_MEMORY 222
+#define POWER8_PME_PM_DPTEG_FROM_OFF_CHIP_CACHE 223
+#define POWER8_PME_PM_DPTEG_FROM_ON_CHIP_CACHE 224
+#define POWER8_PME_PM_DPTEG_FROM_RL2L3_MOD 225
+#define POWER8_PME_PM_DPTEG_FROM_RL2L3_SHR 226
+#define POWER8_PME_PM_DPTEG_FROM_RL4 227
+#define POWER8_PME_PM_DPTEG_FROM_RMEM 228
+#define POWER8_PME_PM_DSLB_MISS 229
+#define POWER8_PME_PM_DTLB_MISS 230
+#define POWER8_PME_PM_DTLB_MISS_16G 231
+#define POWER8_PME_PM_DTLB_MISS_16M 232
+#define POWER8_PME_PM_DTLB_MISS_4K 233
+#define POWER8_PME_PM_DTLB_MISS_64K 234
+#define POWER8_PME_PM_EAT_FORCE_MISPRED 235
+#define POWER8_PME_PM_EAT_FULL_CYC 236
+#define POWER8_PME_PM_EE_OFF_EXT_INT 237
+#define POWER8_PME_PM_EXT_INT 238
+#define POWER8_PME_PM_FAV_TBEGIN 239
+#define POWER8_PME_PM_FLOP 240
+#define POWER8_PME_PM_FLOP_SUM_SCALAR 241
+#define POWER8_PME_PM_FLOP_SUM_VEC 242
+#define POWER8_PME_PM_FLUSH 243
+#define POWER8_PME_PM_FLUSH_BR_MPRED 244
+#define POWER8_PME_PM_FLUSH_COMPLETION 245
+#define POWER8_PME_PM_FLUSH_DISP 246
+#define POWER8_PME_PM_FLUSH_DISP_SB 247
+#define POWER8_PME_PM_FLUSH_DISP_SYNC 248
+#define POWER8_PME_PM_FLUSH_DISP_TLBIE 249
+#define POWER8_PME_PM_FLUSH_LSU 250
+#define POWER8_PME_PM_FLUSH_PARTIAL 251
+#define POWER8_PME_PM_FPU0_FCONV 252
+#define POWER8_PME_PM_FPU0_FEST 253
+#define POWER8_PME_PM_FPU0_FRSP 254
+#define POWER8_PME_PM_FPU1_FCONV 255
+#define POWER8_PME_PM_FPU1_FEST 256
+#define POWER8_PME_PM_FPU1_FRSP 257
+#define POWER8_PME_PM_FREQ_DOWN 258
+#define POWER8_PME_PM_FREQ_UP 259
+#define POWER8_PME_PM_FUSION_TOC_GRP0_1 260
+#define POWER8_PME_PM_FUSION_TOC_GRP0_2 261
+#define POWER8_PME_PM_FUSION_TOC_GRP0_3 262
+#define POWER8_PME_PM_FUSION_TOC_GRP1_1 263
+#define POWER8_PME_PM_FUSION_VSX_GRP0_1 264
+#define POWER8_PME_PM_FUSION_VSX_GRP0_2 265
+#define POWER8_PME_PM_FUSION_VSX_GRP0_3 266
+#define POWER8_PME_PM_FUSION_VSX_GRP1_1 267
+#define POWER8_PME_PM_FXU0_BUSY_FXU1_IDLE 268
+#define POWER8_PME_PM_FXU0_FIN 269
+#define POWER8_PME_PM_FXU1_BUSY_FXU0_IDLE 270
+#define POWER8_PME_PM_FXU1_FIN 271
+#define POWER8_PME_PM_FXU_BUSY 272
+#define POWER8_PME_PM_FXU_IDLE 273
+#define POWER8_PME_PM_GCT_EMPTY_CYC 274
+#define POWER8_PME_PM_GCT_MERGE 275
+#define POWER8_PME_PM_GCT_NOSLOT_BR_MPRED 276
+#define POWER8_PME_PM_GCT_NOSLOT_BR_MPRED_ICMISS 277
+#define POWER8_PME_PM_GCT_NOSLOT_CYC 278
+#define POWER8_PME_PM_GCT_NOSLOT_DISP_HELD_ISSQ 279
+#define POWER8_PME_PM_GCT_NOSLOT_DISP_HELD_MAP 280
+#define POWER8_PME_PM_GCT_NOSLOT_DISP_HELD_OTHER 281
+#define POWER8_PME_PM_GCT_NOSLOT_DISP_HELD_SRQ 282
+#define POWER8_PME_PM_GCT_NOSLOT_IC_L3MISS 283
+#define POWER8_PME_PM_GCT_NOSLOT_IC_MISS 284
+#define POWER8_PME_PM_GCT_UTIL_11_14_ENTRIES 285
+#define POWER8_PME_PM_GCT_UTIL_15_17_ENTRIES 286
+#define POWER8_PME_PM_GCT_UTIL_18_ENTRIES 287
+#define POWER8_PME_PM_GCT_UTIL_1_2_ENTRIES 288
+#define POWER8_PME_PM_GCT_UTIL_3_6_ENTRIES 289
+#define POWER8_PME_PM_GCT_UTIL_7_10_ENTRIES 290
+#define POWER8_PME_PM_GRP_BR_MPRED_NONSPEC 291
+#define POWER8_PME_PM_GRP_CMPL 292
+#define POWER8_PME_PM_GRP_DISP 293
+#define POWER8_PME_PM_GRP_IC_MISS_NONSPEC 294
+#define POWER8_PME_PM_GRP_MRK 295
+#define POWER8_PME_PM_GRP_NON_FULL_GROUP 296
+#define POWER8_PME_PM_GRP_PUMP_CPRED 297
+#define POWER8_PME_PM_GRP_PUMP_MPRED 298
+#define POWER8_PME_PM_GRP_PUMP_MPRED_RTY 299
+#define POWER8_PME_PM_GRP_TERM_2ND_BRANCH 300
+#define POWER8_PME_PM_GRP_TERM_FPU_AFTER_BR 301
+#define POWER8_PME_PM_GRP_TERM_NOINST 302
+#define POWER8_PME_PM_GRP_TERM_OTHER 303
+#define POWER8_PME_PM_GRP_TERM_SLOT_LIMIT 304
+#define POWER8_PME_PM_HV_CYC 305
+#define POWER8_PME_PM_IBUF_FULL_CYC 306
+#define POWER8_PME_PM_IC_DEMAND_CYC 307
+#define POWER8_PME_PM_IC_DEMAND_L2_BHT_REDIRECT 308
+#define POWER8_PME_PM_IC_DEMAND_L2_BR_REDIRECT 309
+#define POWER8_PME_PM_IC_DEMAND_REQ 310
+#define POWER8_PME_PM_IC_INVALIDATE 311
+#define POWER8_PME_PM_IC_PREF_CANCEL_HIT 312
+#define POWER8_PME_PM_IC_PREF_CANCEL_L2 313
+#define POWER8_PME_PM_IC_PREF_CANCEL_PAGE 314
+#define POWER8_PME_PM_IC_PREF_REQ 315
+#define POWER8_PME_PM_IC_PREF_WRITE 316
+#define POWER8_PME_PM_IC_RELOAD_PRIVATE 317
+#define POWER8_PME_PM_IERAT_RELOAD 318
+#define POWER8_PME_PM_IERAT_RELOAD_16M 319
+#define POWER8_PME_PM_IERAT_RELOAD_4K 320
+#define POWER8_PME_PM_IERAT_RELOAD_64K 321
+#define POWER8_PME_PM_IFETCH_THROTTLE 322
+#define POWER8_PME_PM_IFU_L2_TOUCH 323
+#define POWER8_PME_PM_INST_ALL_CHIP_PUMP_CPRED 324
+#define POWER8_PME_PM_INST_ALL_FROM_DL2L3_MOD 325
+#define POWER8_PME_PM_INST_ALL_FROM_DL2L3_SHR 326
+#define POWER8_PME_PM_INST_ALL_FROM_DL4 327
+#define POWER8_PME_PM_INST_ALL_FROM_DMEM 328
+#define POWER8_PME_PM_INST_ALL_FROM_L2 329
+#define POWER8_PME_PM_INST_ALL_FROM_L21_MOD 330
+#define POWER8_PME_PM_INST_ALL_FROM_L21_SHR 331
+#define POWER8_PME_PM_INST_ALL_FROM_L2MISS 332
+#define POWER8_PME_PM_INST_ALL_FROM_L2_DISP_CONFLICT_LDHITST 333
+#define POWER8_PME_PM_INST_ALL_FROM_L2_DISP_CONFLICT_OTHER 334
+#define POWER8_PME_PM_INST_ALL_FROM_L2_MEPF 335
+#define POWER8_PME_PM_INST_ALL_FROM_L2_NO_CONFLICT 336
+#define POWER8_PME_PM_INST_ALL_FROM_L3 337
+#define POWER8_PME_PM_INST_ALL_FROM_L31_ECO_MOD 338
+#define POWER8_PME_PM_INST_ALL_FROM_L31_ECO_SHR 339
+#define POWER8_PME_PM_INST_ALL_FROM_L31_MOD 340
+#define POWER8_PME_PM_INST_ALL_FROM_L31_SHR 341
+#define POWER8_PME_PM_INST_ALL_FROM_L3MISS_MOD 342
+#define POWER8_PME_PM_INST_ALL_FROM_L3_DISP_CONFLICT 343
+#define POWER8_PME_PM_INST_ALL_FROM_L3_MEPF 344
+#define POWER8_PME_PM_INST_ALL_FROM_L3_NO_CONFLICT 345
+#define POWER8_PME_PM_INST_ALL_FROM_LL4 346
+#define POWER8_PME_PM_INST_ALL_FROM_LMEM 347
+#define POWER8_PME_PM_INST_ALL_FROM_MEMORY 348
+#define POWER8_PME_PM_INST_ALL_FROM_OFF_CHIP_CACHE 349
+#define POWER8_PME_PM_INST_ALL_FROM_ON_CHIP_CACHE 350
+#define POWER8_PME_PM_INST_ALL_FROM_RL2L3_MOD 351
+#define POWER8_PME_PM_INST_ALL_FROM_RL2L3_SHR 352
+#define POWER8_PME_PM_INST_ALL_FROM_RL4 353
+#define POWER8_PME_PM_INST_ALL_FROM_RMEM 354
+#define POWER8_PME_PM_INST_ALL_GRP_PUMP_CPRED 355
+#define POWER8_PME_PM_INST_ALL_GRP_PUMP_MPRED 356
+#define POWER8_PME_PM_INST_ALL_GRP_PUMP_MPRED_RTY 357
+#define POWER8_PME_PM_INST_ALL_PUMP_CPRED 358
+#define POWER8_PME_PM_INST_ALL_PUMP_MPRED 359
+#define POWER8_PME_PM_INST_ALL_SYS_PUMP_CPRED 360
+#define POWER8_PME_PM_INST_ALL_SYS_PUMP_MPRED 361
+#define POWER8_PME_PM_INST_ALL_SYS_PUMP_MPRED_RTY 362
+#define POWER8_PME_PM_INST_CHIP_PUMP_CPRED 363
+#define POWER8_PME_PM_INST_CMPL 364
+#define POWER8_PME_PM_INST_DISP 365
+#define POWER8_PME_PM_INST_FROM_DL2L3_MOD 366
+#define POWER8_PME_PM_INST_FROM_DL2L3_SHR 367
+#define POWER8_PME_PM_INST_FROM_DL4 368
+#define POWER8_PME_PM_INST_FROM_DMEM 369
+#define POWER8_PME_PM_INST_FROM_L1 370
+#define POWER8_PME_PM_INST_FROM_L2 371
+#define POWER8_PME_PM_INST_FROM_L21_MOD 372
+#define POWER8_PME_PM_INST_FROM_L21_SHR 373
+#define POWER8_PME_PM_INST_FROM_L2MISS 374
+#define POWER8_PME_PM_INST_FROM_L2_DISP_CONFLICT_LDHITST 375
+#define POWER8_PME_PM_INST_FROM_L2_DISP_CONFLICT_OTHER 376
+#define POWER8_PME_PM_INST_FROM_L2_MEPF 377
+#define POWER8_PME_PM_INST_FROM_L2_NO_CONFLICT 378
+#define POWER8_PME_PM_INST_FROM_L3 379
+#define POWER8_PME_PM_INST_FROM_L31_ECO_MOD 380
+#define POWER8_PME_PM_INST_FROM_L31_ECO_SHR 381
+#define POWER8_PME_PM_INST_FROM_L31_MOD 382
+#define POWER8_PME_PM_INST_FROM_L31_SHR 383
+#define POWER8_PME_PM_INST_FROM_L3MISS 384
+#define POWER8_PME_PM_INST_FROM_L3MISS_MOD 385
+#define POWER8_PME_PM_INST_FROM_L3_DISP_CONFLICT 386
+#define POWER8_PME_PM_INST_FROM_L3_MEPF 387
+#define POWER8_PME_PM_INST_FROM_L3_NO_CONFLICT 388
+#define POWER8_PME_PM_INST_FROM_LL4 389
+#define POWER8_PME_PM_INST_FROM_LMEM 390
+#define POWER8_PME_PM_INST_FROM_MEMORY 391
+#define POWER8_PME_PM_INST_FROM_OFF_CHIP_CACHE 392
+#define POWER8_PME_PM_INST_FROM_ON_CHIP_CACHE 393
+#define POWER8_PME_PM_INST_FROM_RL2L3_MOD 394
+#define POWER8_PME_PM_INST_FROM_RL2L3_SHR 395
+#define POWER8_PME_PM_INST_FROM_RL4 396
+#define POWER8_PME_PM_INST_FROM_RMEM 397
+#define POWER8_PME_PM_INST_GRP_PUMP_CPRED 398
+#define POWER8_PME_PM_INST_GRP_PUMP_MPRED 399
+#define POWER8_PME_PM_INST_GRP_PUMP_MPRED_RTY 400
+#define POWER8_PME_PM_INST_IMC_MATCH_CMPL 401
+#define POWER8_PME_PM_INST_IMC_MATCH_DISP 402
+#define POWER8_PME_PM_INST_PUMP_CPRED 403
+#define POWER8_PME_PM_INST_PUMP_MPRED 404
+#define POWER8_PME_PM_INST_SYS_PUMP_CPRED 405
+#define POWER8_PME_PM_INST_SYS_PUMP_MPRED 406
+#define POWER8_PME_PM_INST_SYS_PUMP_MPRED_RTY 407
+#define POWER8_PME_PM_IOPS_CMPL 408
+#define POWER8_PME_PM_IOPS_DISP 409
+#define POWER8_PME_PM_IPTEG_FROM_DL2L3_MOD 410
+#define POWER8_PME_PM_IPTEG_FROM_DL2L3_SHR 411
+#define POWER8_PME_PM_IPTEG_FROM_DL4 412
+#define POWER8_PME_PM_IPTEG_FROM_DMEM 413
+#define POWER8_PME_PM_IPTEG_FROM_L2 414
+#define POWER8_PME_PM_IPTEG_FROM_L21_MOD 415
+#define POWER8_PME_PM_IPTEG_FROM_L21_SHR 416
+#define POWER8_PME_PM_IPTEG_FROM_L2MISS 417
+#define POWER8_PME_PM_IPTEG_FROM_L2_DISP_CONFLICT_LDHITST 418
+#define POWER8_PME_PM_IPTEG_FROM_L2_DISP_CONFLICT_OTHER 419
+#define POWER8_PME_PM_IPTEG_FROM_L2_MEPF 420
+#define POWER8_PME_PM_IPTEG_FROM_L2_NO_CONFLICT 421
+#define POWER8_PME_PM_IPTEG_FROM_L3 422
+#define POWER8_PME_PM_IPTEG_FROM_L31_ECO_MOD 423
+#define POWER8_PME_PM_IPTEG_FROM_L31_ECO_SHR 424
+#define POWER8_PME_PM_IPTEG_FROM_L31_MOD 425
+#define POWER8_PME_PM_IPTEG_FROM_L31_SHR 426
+#define POWER8_PME_PM_IPTEG_FROM_L3MISS 427
+#define POWER8_PME_PM_IPTEG_FROM_L3_DISP_CONFLICT 428
+#define POWER8_PME_PM_IPTEG_FROM_L3_MEPF 429
+#define POWER8_PME_PM_IPTEG_FROM_L3_NO_CONFLICT 430
+#define POWER8_PME_PM_IPTEG_FROM_LL4 431
+#define POWER8_PME_PM_IPTEG_FROM_LMEM 432
+#define POWER8_PME_PM_IPTEG_FROM_MEMORY 433
+#define POWER8_PME_PM_IPTEG_FROM_OFF_CHIP_CACHE 434
+#define POWER8_PME_PM_IPTEG_FROM_ON_CHIP_CACHE 435
+#define POWER8_PME_PM_IPTEG_FROM_RL2L3_MOD 436
+#define POWER8_PME_PM_IPTEG_FROM_RL2L3_SHR 437
+#define POWER8_PME_PM_IPTEG_FROM_RL4 438
+#define POWER8_PME_PM_IPTEG_FROM_RMEM 439
+#define POWER8_PME_PM_ISIDE_DISP 440
+#define POWER8_PME_PM_ISIDE_DISP_FAIL 441
+#define POWER8_PME_PM_ISIDE_DISP_FAIL_OTHER 442
+#define POWER8_PME_PM_ISIDE_L2MEMACC 443
+#define POWER8_PME_PM_ISIDE_MRU_TOUCH 444
+#define POWER8_PME_PM_ISLB_MISS 445
+#define POWER8_PME_PM_ISU_REF_FX0 446
+#define POWER8_PME_PM_ISU_REF_FX1 447
+#define POWER8_PME_PM_ISU_REF_FXU 448
+#define POWER8_PME_PM_ISU_REF_LS0 449
+#define POWER8_PME_PM_ISU_REF_LS1 450
+#define POWER8_PME_PM_ISU_REF_LS2 451
+#define POWER8_PME_PM_ISU_REF_LS3 452
+#define POWER8_PME_PM_ISU_REJECTS_ALL 453
+#define POWER8_PME_PM_ISU_REJECT_RES_NA 454
+#define POWER8_PME_PM_ISU_REJECT_SAR_BYPASS 455
+#define POWER8_PME_PM_ISU_REJECT_SRC_NA 456
+#define POWER8_PME_PM_ISU_REJ_VS0 457
+#define POWER8_PME_PM_ISU_REJ_VS1 458
+#define POWER8_PME_PM_ISU_REJ_VSU 459
+#define POWER8_PME_PM_ISYNC 460
+#define POWER8_PME_PM_ITLB_MISS 461
+#define POWER8_PME_PM_L1MISS_LAT_EXC_1024 462
+#define POWER8_PME_PM_L1MISS_LAT_EXC_2048 463
+#define POWER8_PME_PM_L1MISS_LAT_EXC_256 464
+#define POWER8_PME_PM_L1MISS_LAT_EXC_32 465
+#define POWER8_PME_PM_L1PF_L2MEMACC 466
+#define POWER8_PME_PM_L1_DCACHE_RELOADED_ALL 467
+#define POWER8_PME_PM_L1_DCACHE_RELOAD_VALID 468
+#define POWER8_PME_PM_L1_DEMAND_WRITE 469
+#define POWER8_PME_PM_L1_ICACHE_MISS 470
+#define POWER8_PME_PM_L1_ICACHE_RELOADED_ALL 471
+#define POWER8_PME_PM_L1_ICACHE_RELOADED_PREF 472
+#define POWER8_PME_PM_L2_CASTOUT_MOD 473
+#define POWER8_PME_PM_L2_CASTOUT_SHR 474
+#define POWER8_PME_PM_L2_CHIP_PUMP 475
+#define POWER8_PME_PM_L2_DC_INV 476
+#define POWER8_PME_PM_L2_DISP_ALL_L2MISS 477
+#define POWER8_PME_PM_L2_GROUP_PUMP 478
+#define POWER8_PME_PM_L2_GRP_GUESS_CORRECT 479
+#define POWER8_PME_PM_L2_GRP_GUESS_WRONG 480
+#define POWER8_PME_PM_L2_IC_INV 481
+#define POWER8_PME_PM_L2_INST 482
+#define POWER8_PME_PM_L2_INST_MISS 483
+#define POWER8_PME_PM_L2_LD 484
+#define POWER8_PME_PM_L2_LD_DISP 485
+#define POWER8_PME_PM_L2_LD_HIT 486
+#define POWER8_PME_PM_L2_LD_MISS 487
+#define POWER8_PME_PM_L2_LOC_GUESS_CORRECT 488
+#define POWER8_PME_PM_L2_LOC_GUESS_WRONG 489
+#define POWER8_PME_PM_L2_RCLD_DISP 490
+#define POWER8_PME_PM_L2_RCLD_DISP_FAIL_ADDR 491
+#define POWER8_PME_PM_L2_RCLD_DISP_FAIL_OTHER 492
+#define POWER8_PME_PM_L2_RCST_DISP 493
+#define POWER8_PME_PM_L2_RCST_DISP_FAIL_ADDR 494
+#define POWER8_PME_PM_L2_RCST_DISP_FAIL_OTHER 495
+#define POWER8_PME_PM_L2_RC_ST_DONE 496
+#define POWER8_PME_PM_L2_RTY_LD 497
+#define POWER8_PME_PM_L2_RTY_ST 498
+#define POWER8_PME_PM_L2_SN_M_RD_DONE 499
+#define POWER8_PME_PM_L2_SN_M_WR_DONE 500
+#define POWER8_PME_PM_L2_SN_SX_I_DONE 501
+#define POWER8_PME_PM_L2_ST 502
+#define POWER8_PME_PM_L2_ST_DISP 503
+#define POWER8_PME_PM_L2_ST_HIT 504
+#define POWER8_PME_PM_L2_ST_MISS 505
+#define POWER8_PME_PM_L2_SYS_GUESS_CORRECT 506
+#define POWER8_PME_PM_L2_SYS_GUESS_WRONG 507
+#define POWER8_PME_PM_L2_SYS_PUMP 508
+#define POWER8_PME_PM_L2_TM_REQ_ABORT 509
+#define POWER8_PME_PM_L2_TM_ST_ABORT_SISTER 510
+#define POWER8_PME_PM_L3_CINJ 511
+#define POWER8_PME_PM_L3_CI_HIT 512
+#define POWER8_PME_PM_L3_CI_MISS 513
+#define POWER8_PME_PM_L3_CI_USAGE 514
+#define POWER8_PME_PM_L3_CO 515
+#define POWER8_PME_PM_L3_CO0_ALLOC 516
+#define POWER8_PME_PM_L3_CO0_BUSY 517
+#define POWER8_PME_PM_L3_CO_L31 518
+#define POWER8_PME_PM_L3_CO_LCO 519
+#define POWER8_PME_PM_L3_CO_MEM 520
+#define POWER8_PME_PM_L3_CO_MEPF 521
+#define POWER8_PME_PM_L3_GRP_GUESS_CORRECT 522
+#define POWER8_PME_PM_L3_GRP_GUESS_WRONG_HIGH 523
+#define POWER8_PME_PM_L3_GRP_GUESS_WRONG_LOW 524
+#define POWER8_PME_PM_L3_HIT 525
+#define POWER8_PME_PM_L3_L2_CO_HIT 526
+#define POWER8_PME_PM_L3_L2_CO_MISS 527
+#define POWER8_PME_PM_L3_LAT_CI_HIT 528
+#define POWER8_PME_PM_L3_LAT_CI_MISS 529
+#define POWER8_PME_PM_L3_LD_HIT 530
+#define POWER8_PME_PM_L3_LD_MISS 531
+#define POWER8_PME_PM_L3_LD_PREF 532
+#define POWER8_PME_PM_L3_LOC_GUESS_CORRECT 533
+#define POWER8_PME_PM_L3_LOC_GUESS_WRONG 534
+#define POWER8_PME_PM_L3_MISS 535
+#define POWER8_PME_PM_L3_P0_CO_L31 536
+#define POWER8_PME_PM_L3_P0_CO_MEM 537
+#define POWER8_PME_PM_L3_P0_CO_RTY 538
+#define POWER8_PME_PM_L3_P0_GRP_PUMP 539
+#define POWER8_PME_PM_L3_P0_LCO_DATA 540
+#define POWER8_PME_PM_L3_P0_LCO_NO_DATA 541
+#define POWER8_PME_PM_L3_P0_LCO_RTY 542
+#define POWER8_PME_PM_L3_P0_NODE_PUMP 543
+#define POWER8_PME_PM_L3_P0_PF_RTY 544
+#define POWER8_PME_PM_L3_P0_SN_HIT 545
+#define POWER8_PME_PM_L3_P0_SN_INV 546
+#define POWER8_PME_PM_L3_P0_SN_MISS 547
+#define POWER8_PME_PM_L3_P0_SYS_PUMP 548
+#define POWER8_PME_PM_L3_P1_CO_L31 549
+#define POWER8_PME_PM_L3_P1_CO_MEM 550
+#define POWER8_PME_PM_L3_P1_CO_RTY 551
+#define POWER8_PME_PM_L3_P1_GRP_PUMP 552
+#define POWER8_PME_PM_L3_P1_LCO_DATA 553
+#define POWER8_PME_PM_L3_P1_LCO_NO_DATA 554
+#define POWER8_PME_PM_L3_P1_LCO_RTY 555
+#define POWER8_PME_PM_L3_P1_NODE_PUMP 556
+#define POWER8_PME_PM_L3_P1_PF_RTY 557
+#define POWER8_PME_PM_L3_P1_SN_HIT 558
+#define POWER8_PME_PM_L3_P1_SN_INV 559
+#define POWER8_PME_PM_L3_P1_SN_MISS 560
+#define POWER8_PME_PM_L3_P1_SYS_PUMP 561
+#define POWER8_PME_PM_L3_PF0_ALLOC 562
+#define POWER8_PME_PM_L3_PF0_BUSY 563
+#define POWER8_PME_PM_L3_PF_HIT_L3 564
+#define POWER8_PME_PM_L3_PF_MISS_L3 565
+#define POWER8_PME_PM_L3_PF_OFF_CHIP_CACHE 566
+#define POWER8_PME_PM_L3_PF_OFF_CHIP_MEM 567
+#define POWER8_PME_PM_L3_PF_ON_CHIP_CACHE 568
+#define POWER8_PME_PM_L3_PF_ON_CHIP_MEM 569
+#define POWER8_PME_PM_L3_PF_USAGE 570
+#define POWER8_PME_PM_L3_PREF_ALL 571
+#define POWER8_PME_PM_L3_RD0_ALLOC 572
+#define POWER8_PME_PM_L3_RD0_BUSY 573
+#define POWER8_PME_PM_L3_RD_USAGE 574
+#define POWER8_PME_PM_L3_SN0_ALLOC 575
+#define POWER8_PME_PM_L3_SN0_BUSY 576
+#define POWER8_PME_PM_L3_SN_USAGE 577
+#define POWER8_PME_PM_L3_ST_PREF 578
+#define POWER8_PME_PM_L3_SW_PREF 579
+#define POWER8_PME_PM_L3_SYS_GUESS_CORRECT 580
+#define POWER8_PME_PM_L3_SYS_GUESS_WRONG 581
+#define POWER8_PME_PM_L3_TRANS_PF 582
+#define POWER8_PME_PM_L3_WI0_ALLOC 583
+#define POWER8_PME_PM_L3_WI0_BUSY 584
+#define POWER8_PME_PM_L3_WI_USAGE 585
+#define POWER8_PME_PM_LARX_FIN 586
+#define POWER8_PME_PM_LD_CMPL 587
+#define POWER8_PME_PM_LD_L3MISS_PEND_CYC 588
+#define POWER8_PME_PM_LD_MISS_L1 589
+#define POWER8_PME_PM_LD_REF_L1 590
+#define POWER8_PME_PM_LD_REF_L1_LSU0 591
+#define POWER8_PME_PM_LD_REF_L1_LSU1 592
+#define POWER8_PME_PM_LD_REF_L1_LSU2 593
+#define POWER8_PME_PM_LD_REF_L1_LSU3 594
+#define POWER8_PME_PM_LINK_STACK_INVALID_PTR 595
+#define POWER8_PME_PM_LINK_STACK_WRONG_ADD_PRED 596
+#define POWER8_PME_PM_LS0_ERAT_MISS_PREF 597
+#define POWER8_PME_PM_LS0_L1_PREF 598
+#define POWER8_PME_PM_LS0_L1_SW_PREF 599
+#define POWER8_PME_PM_LS1_ERAT_MISS_PREF 600
+#define POWER8_PME_PM_LS1_L1_PREF 601
+#define POWER8_PME_PM_LS1_L1_SW_PREF 602
+#define POWER8_PME_PM_LSU0_FLUSH_LRQ 603
+#define POWER8_PME_PM_LSU0_FLUSH_SRQ 604
+#define POWER8_PME_PM_LSU0_FLUSH_ULD 605
+#define POWER8_PME_PM_LSU0_FLUSH_UST 606
+#define POWER8_PME_PM_LSU0_L1_CAM_CANCEL 607
+#define POWER8_PME_PM_LSU0_LARX_FIN 608
+#define POWER8_PME_PM_LSU0_LMQ_LHR_MERGE 609
+#define POWER8_PME_PM_LSU0_NCLD 610
+#define POWER8_PME_PM_LSU0_PRIMARY_ERAT_HIT 611
+#define POWER8_PME_PM_LSU0_REJECT 612
+#define POWER8_PME_PM_LSU0_SRQ_STFWD 613
+#define POWER8_PME_PM_LSU0_STORE_REJECT 614
+#define POWER8_PME_PM_LSU0_TMA_REQ_L2 615
+#define POWER8_PME_PM_LSU0_TM_L1_HIT 616
+#define POWER8_PME_PM_LSU0_TM_L1_MISS 617
+#define POWER8_PME_PM_LSU1_FLUSH_LRQ 618
+#define POWER8_PME_PM_LSU1_FLUSH_SRQ 619
+#define POWER8_PME_PM_LSU1_FLUSH_ULD 620
+#define POWER8_PME_PM_LSU1_FLUSH_UST 621
+#define POWER8_PME_PM_LSU1_L1_CAM_CANCEL 622
+#define POWER8_PME_PM_LSU1_LARX_FIN 623
+#define POWER8_PME_PM_LSU1_LMQ_LHR_MERGE 624
+#define POWER8_PME_PM_LSU1_NCLD 625
+#define POWER8_PME_PM_LSU1_PRIMARY_ERAT_HIT 626
+#define POWER8_PME_PM_LSU1_REJECT 627
+#define POWER8_PME_PM_LSU1_SRQ_STFWD 628
+#define POWER8_PME_PM_LSU1_STORE_REJECT 629
+#define POWER8_PME_PM_LSU1_TMA_REQ_L2 630
+#define POWER8_PME_PM_LSU1_TM_L1_HIT 631
+#define POWER8_PME_PM_LSU1_TM_L1_MISS 632
+#define POWER8_PME_PM_LSU2_FLUSH_LRQ 633
+#define POWER8_PME_PM_LSU2_FLUSH_SRQ 634
+#define POWER8_PME_PM_LSU2_FLUSH_ULD 635
+#define POWER8_PME_PM_LSU2_L1_CAM_CANCEL 636
+#define POWER8_PME_PM_LSU2_LARX_FIN 637
+#define POWER8_PME_PM_LSU2_LDF 638
+#define POWER8_PME_PM_LSU2_LDX 639
+#define POWER8_PME_PM_LSU2_LMQ_LHR_MERGE 640
+#define POWER8_PME_PM_LSU2_PRIMARY_ERAT_HIT 641
+#define POWER8_PME_PM_LSU2_REJECT 642
+#define POWER8_PME_PM_LSU2_SRQ_STFWD 643
+#define POWER8_PME_PM_LSU2_TMA_REQ_L2 644
+#define POWER8_PME_PM_LSU2_TM_L1_HIT 645
+#define POWER8_PME_PM_LSU2_TM_L1_MISS 646
+#define POWER8_PME_PM_LSU3_FLUSH_LRQ 647
+#define POWER8_PME_PM_LSU3_FLUSH_SRQ 648
+#define POWER8_PME_PM_LSU3_FLUSH_ULD 649
+#define POWER8_PME_PM_LSU3_L1_CAM_CANCEL 650
+#define POWER8_PME_PM_LSU3_LARX_FIN 651
+#define POWER8_PME_PM_LSU3_LDF 652
+#define POWER8_PME_PM_LSU3_LDX 653
+#define POWER8_PME_PM_LSU3_LMQ_LHR_MERGE 654
+#define POWER8_PME_PM_LSU3_PRIMARY_ERAT_HIT 655
+#define POWER8_PME_PM_LSU3_REJECT 656
+#define POWER8_PME_PM_LSU3_SRQ_STFWD 657
+#define POWER8_PME_PM_LSU3_TMA_REQ_L2 658
+#define POWER8_PME_PM_LSU3_TM_L1_HIT 659
+#define POWER8_PME_PM_LSU3_TM_L1_MISS 660
+#define POWER8_PME_PM_LSU_DERAT_MISS 661
+#define POWER8_PME_PM_LSU_ERAT_MISS_PREF 662
+#define POWER8_PME_PM_LSU_FIN 663
+#define POWER8_PME_PM_LSU_FLUSH_UST 664
+#define POWER8_PME_PM_LSU_FOUR_TABLEWALK_CYC 665
+#define POWER8_PME_PM_LSU_FX_FIN 666
+#define POWER8_PME_PM_LSU_L1_PREF 667
+#define POWER8_PME_PM_LSU_L1_SW_PREF 668
+#define POWER8_PME_PM_LSU_LDF 669
+#define POWER8_PME_PM_LSU_LDX 670
+#define POWER8_PME_PM_LSU_LMQ_FULL_CYC 671
+#define POWER8_PME_PM_LSU_LMQ_S0_ALLOC 672
+#define POWER8_PME_PM_LSU_LMQ_S0_VALID 673
+#define POWER8_PME_PM_LSU_LMQ_SRQ_EMPTY_ALL_CYC 674
+#define POWER8_PME_PM_LSU_LMQ_SRQ_EMPTY_CYC 675
+#define POWER8_PME_PM_LSU_LRQ_S0_ALLOC 676
+#define POWER8_PME_PM_LSU_LRQ_S0_VALID 677
+#define POWER8_PME_PM_LSU_LRQ_S43_ALLOC 678
+#define POWER8_PME_PM_LSU_LRQ_S43_VALID 679
+#define POWER8_PME_PM_LSU_MRK_DERAT_MISS 680
+#define POWER8_PME_PM_LSU_NCLD 681
+#define POWER8_PME_PM_LSU_NCST 682
+#define POWER8_PME_PM_LSU_REJECT 683
+#define POWER8_PME_PM_LSU_REJECT_ERAT_MISS 684
+#define POWER8_PME_PM_LSU_REJECT_LHS 685
+#define POWER8_PME_PM_LSU_REJECT_LMQ_FULL 686
+#define POWER8_PME_PM_LSU_SET_MPRED 687
+#define POWER8_PME_PM_LSU_SRQ_EMPTY_CYC 688
+#define POWER8_PME_PM_LSU_SRQ_FULL_CYC 689
+#define POWER8_PME_PM_LSU_SRQ_S0_ALLOC 690
+#define POWER8_PME_PM_LSU_SRQ_S0_VALID 691
+#define POWER8_PME_PM_LSU_SRQ_S39_ALLOC 692
+#define POWER8_PME_PM_LSU_SRQ_S39_VALID 693
+#define POWER8_PME_PM_LSU_SRQ_SYNC 694
+#define POWER8_PME_PM_LSU_SRQ_SYNC_CYC 695
+#define POWER8_PME_PM_LSU_STORE_REJECT 696
+#define POWER8_PME_PM_LSU_TWO_TABLEWALK_CYC 697
+#define POWER8_PME_PM_LWSYNC 698
+#define POWER8_PME_PM_LWSYNC_HELD 699
+#define POWER8_PME_PM_MEM_CO 700
+#define POWER8_PME_PM_MEM_LOC_THRESH_IFU 701
+#define POWER8_PME_PM_MEM_LOC_THRESH_LSU_HIGH 702
+#define POWER8_PME_PM_MEM_LOC_THRESH_LSU_MED 703
+#define POWER8_PME_PM_MEM_PREF 704
+#define POWER8_PME_PM_MEM_READ 705
+#define POWER8_PME_PM_MEM_RWITM 706
+#define POWER8_PME_PM_MRK_BACK_BR_CMPL 707
+#define POWER8_PME_PM_MRK_BRU_FIN 708
+#define POWER8_PME_PM_MRK_BR_CMPL 709
+#define POWER8_PME_PM_MRK_BR_MPRED_CMPL 710
+#define POWER8_PME_PM_MRK_BR_TAKEN_CMPL 711
+#define POWER8_PME_PM_MRK_CRU_FIN 712
+#define POWER8_PME_PM_MRK_DATA_FROM_DL2L3_MOD 713
+#define POWER8_PME_PM_MRK_DATA_FROM_DL2L3_MOD_CYC 714
+#define POWER8_PME_PM_MRK_DATA_FROM_DL2L3_SHR 715
+#define POWER8_PME_PM_MRK_DATA_FROM_DL2L3_SHR_CYC 716
+#define POWER8_PME_PM_MRK_DATA_FROM_DL4 717
+#define POWER8_PME_PM_MRK_DATA_FROM_DL4_CYC 718
+#define POWER8_PME_PM_MRK_DATA_FROM_DMEM 719
+#define POWER8_PME_PM_MRK_DATA_FROM_DMEM_CYC 720
+#define POWER8_PME_PM_MRK_DATA_FROM_L2 721
+#define POWER8_PME_PM_MRK_DATA_FROM_L21_MOD 722
+#define POWER8_PME_PM_MRK_DATA_FROM_L21_MOD_CYC 723
+#define POWER8_PME_PM_MRK_DATA_FROM_L21_SHR 724
+#define POWER8_PME_PM_MRK_DATA_FROM_L21_SHR_CYC 725
+#define POWER8_PME_PM_MRK_DATA_FROM_L2MISS 726
+#define POWER8_PME_PM_MRK_DATA_FROM_L2MISS_CYC 727
+#define POWER8_PME_PM_MRK_DATA_FROM_L2_CYC 728
+#define POWER8_PME_PM_MRK_DATA_FROM_L2_DISP_CONFLICT_LDHITST 729
+#define POWER8_PME_PM_MRK_DATA_FROM_L2_DISP_CONFLICT_LDHITST_CYC 730
+#define POWER8_PME_PM_MRK_DATA_FROM_L2_DISP_CONFLICT_OTHER 731
+#define POWER8_PME_PM_MRK_DATA_FROM_L2_DISP_CONFLICT_OTHER_CYC 732
+#define POWER8_PME_PM_MRK_DATA_FROM_L2_MEPF 733
+#define POWER8_PME_PM_MRK_DATA_FROM_L2_MEPF_CYC 734
+#define POWER8_PME_PM_MRK_DATA_FROM_L2_NO_CONFLICT 735
+#define POWER8_PME_PM_MRK_DATA_FROM_L2_NO_CONFLICT_CYC 736
+#define POWER8_PME_PM_MRK_DATA_FROM_L3 737
+#define POWER8_PME_PM_MRK_DATA_FROM_L31_ECO_MOD 738
+#define POWER8_PME_PM_MRK_DATA_FROM_L31_ECO_MOD_CYC 739
+#define POWER8_PME_PM_MRK_DATA_FROM_L31_ECO_SHR 740
+#define POWER8_PME_PM_MRK_DATA_FROM_L31_ECO_SHR_CYC 741
+#define POWER8_PME_PM_MRK_DATA_FROM_L31_MOD 742
+#define POWER8_PME_PM_MRK_DATA_FROM_L31_MOD_CYC 743
+#define POWER8_PME_PM_MRK_DATA_FROM_L31_SHR 744
+#define POWER8_PME_PM_MRK_DATA_FROM_L31_SHR_CYC 745
+#define POWER8_PME_PM_MRK_DATA_FROM_L3MISS 746
+#define POWER8_PME_PM_MRK_DATA_FROM_L3MISS_CYC 747
+#define POWER8_PME_PM_MRK_DATA_FROM_L3_CYC 748
+#define POWER8_PME_PM_MRK_DATA_FROM_L3_DISP_CONFLICT 749
+#define POWER8_PME_PM_MRK_DATA_FROM_L3_DISP_CONFLICT_CYC 750
+#define POWER8_PME_PM_MRK_DATA_FROM_L3_MEPF 751
+#define POWER8_PME_PM_MRK_DATA_FROM_L3_MEPF_CYC 752
+#define POWER8_PME_PM_MRK_DATA_FROM_L3_NO_CONFLICT 753
+#define POWER8_PME_PM_MRK_DATA_FROM_L3_NO_CONFLICT_CYC 754
+#define POWER8_PME_PM_MRK_DATA_FROM_LL4 755
+#define POWER8_PME_PM_MRK_DATA_FROM_LL4_CYC 756
+#define POWER8_PME_PM_MRK_DATA_FROM_LMEM 757
+#define POWER8_PME_PM_MRK_DATA_FROM_LMEM_CYC 758
+#define POWER8_PME_PM_MRK_DATA_FROM_MEM 759
+#define POWER8_PME_PM_MRK_DATA_FROM_MEMORY 760
+#define POWER8_PME_PM_MRK_DATA_FROM_MEMORY_CYC 761
+#define POWER8_PME_PM_MRK_DATA_FROM_OFF_CHIP_CACHE 762
+#define POWER8_PME_PM_MRK_DATA_FROM_OFF_CHIP_CACHE_CYC 763
+#define POWER8_PME_PM_MRK_DATA_FROM_ON_CHIP_CACHE 764
+#define POWER8_PME_PM_MRK_DATA_FROM_ON_CHIP_CACHE_CYC 765
+#define POWER8_PME_PM_MRK_DATA_FROM_RL2L3_MOD 766
+#define POWER8_PME_PM_MRK_DATA_FROM_RL2L3_MOD_CYC 767
+#define POWER8_PME_PM_MRK_DATA_FROM_RL2L3_SHR 768
+#define POWER8_PME_PM_MRK_DATA_FROM_RL2L3_SHR_CYC 769
+#define POWER8_PME_PM_MRK_DATA_FROM_RL4 770
+#define POWER8_PME_PM_MRK_DATA_FROM_RL4_CYC 771
+#define POWER8_PME_PM_MRK_DATA_FROM_RMEM 772
+#define POWER8_PME_PM_MRK_DATA_FROM_RMEM_CYC 773
+#define POWER8_PME_PM_MRK_DCACHE_RELOAD_INTV 774
+#define POWER8_PME_PM_MRK_DERAT_MISS 775
+#define POWER8_PME_PM_MRK_DERAT_MISS_16G 776
+#define POWER8_PME_PM_MRK_DERAT_MISS_16M 777
+#define POWER8_PME_PM_MRK_DERAT_MISS_4K 778
+#define POWER8_PME_PM_MRK_DERAT_MISS_64K 779
+#define POWER8_PME_PM_MRK_DFU_FIN 780
+#define POWER8_PME_PM_MRK_DPTEG_FROM_DL2L3_MOD 781
+#define POWER8_PME_PM_MRK_DPTEG_FROM_DL2L3_SHR 782
+#define POWER8_PME_PM_MRK_DPTEG_FROM_DL4 783
+#define POWER8_PME_PM_MRK_DPTEG_FROM_DMEM 784
+#define POWER8_PME_PM_MRK_DPTEG_FROM_L2 785
+#define POWER8_PME_PM_MRK_DPTEG_FROM_L21_MOD 786
+#define POWER8_PME_PM_MRK_DPTEG_FROM_L21_SHR 787
+#define POWER8_PME_PM_MRK_DPTEG_FROM_L2MISS 788
+#define POWER8_PME_PM_MRK_DPTEG_FROM_L2_DISP_CONFLICT_LDHITST 789
+#define POWER8_PME_PM_MRK_DPTEG_FROM_L2_DISP_CONFLICT_OTHER 790
+#define POWER8_PME_PM_MRK_DPTEG_FROM_L2_MEPF 791
+#define POWER8_PME_PM_MRK_DPTEG_FROM_L2_NO_CONFLICT 792
+#define POWER8_PME_PM_MRK_DPTEG_FROM_L3 793
+#define POWER8_PME_PM_MRK_DPTEG_FROM_L31_ECO_MOD 794
+#define POWER8_PME_PM_MRK_DPTEG_FROM_L31_ECO_SHR 795
+#define POWER8_PME_PM_MRK_DPTEG_FROM_L31_MOD 796
+#define POWER8_PME_PM_MRK_DPTEG_FROM_L31_SHR 797
+#define POWER8_PME_PM_MRK_DPTEG_FROM_L3MISS 798
+#define POWER8_PME_PM_MRK_DPTEG_FROM_L3_DISP_CONFLICT 799
+#define POWER8_PME_PM_MRK_DPTEG_FROM_L3_MEPF 800
+#define POWER8_PME_PM_MRK_DPTEG_FROM_L3_NO_CONFLICT 801
+#define POWER8_PME_PM_MRK_DPTEG_FROM_LL4 802
+#define POWER8_PME_PM_MRK_DPTEG_FROM_LMEM 803
+#define POWER8_PME_PM_MRK_DPTEG_FROM_MEMORY 804
+#define POWER8_PME_PM_MRK_DPTEG_FROM_OFF_CHIP_CACHE 805
+#define POWER8_PME_PM_MRK_DPTEG_FROM_ON_CHIP_CACHE 806
+#define POWER8_PME_PM_MRK_DPTEG_FROM_RL2L3_MOD 807
+#define POWER8_PME_PM_MRK_DPTEG_FROM_RL2L3_SHR 808
+#define POWER8_PME_PM_MRK_DPTEG_FROM_RL4 809
+#define POWER8_PME_PM_MRK_DPTEG_FROM_RMEM 810
+#define POWER8_PME_PM_MRK_DTLB_MISS 811
+#define POWER8_PME_PM_MRK_DTLB_MISS_16G 812
+#define POWER8_PME_PM_MRK_DTLB_MISS_16M 813
+#define POWER8_PME_PM_MRK_DTLB_MISS_4K 814
+#define POWER8_PME_PM_MRK_DTLB_MISS_64K 815
+#define POWER8_PME_PM_MRK_FAB_RSP_BKILL 816
+#define POWER8_PME_PM_MRK_FAB_RSP_BKILL_CYC 817
+#define POWER8_PME_PM_MRK_FAB_RSP_CLAIM_RTY 818
+#define POWER8_PME_PM_MRK_FAB_RSP_DCLAIM 819
+#define POWER8_PME_PM_MRK_FAB_RSP_DCLAIM_CYC 820
+#define POWER8_PME_PM_MRK_FAB_RSP_MATCH 821
+#define POWER8_PME_PM_MRK_FAB_RSP_MATCH_CYC 822
+#define POWER8_PME_PM_MRK_FAB_RSP_RD_RTY 823
+#define POWER8_PME_PM_MRK_FAB_RSP_RD_T_INTV 824
+#define POWER8_PME_PM_MRK_FAB_RSP_RWITM_CYC 825
+#define POWER8_PME_PM_MRK_FAB_RSP_RWITM_RTY 826
+#define POWER8_PME_PM_MRK_FILT_MATCH 827
+#define POWER8_PME_PM_MRK_FIN_STALL_CYC 828
+#define POWER8_PME_PM_MRK_FXU_FIN 829
+#define POWER8_PME_PM_MRK_GRP_CMPL 830
+#define POWER8_PME_PM_MRK_GRP_IC_MISS 831
+#define POWER8_PME_PM_MRK_GRP_NTC 832
+#define POWER8_PME_PM_MRK_INST_CMPL 833
+#define POWER8_PME_PM_MRK_INST_DECODED 834
+#define POWER8_PME_PM_MRK_INST_DISP 835
+#define POWER8_PME_PM_MRK_INST_FIN 836
+#define POWER8_PME_PM_MRK_INST_FROM_L3MISS 837
+#define POWER8_PME_PM_MRK_INST_ISSUED 838
+#define POWER8_PME_PM_MRK_INST_TIMEO 839
+#define POWER8_PME_PM_MRK_L1_ICACHE_MISS 840
+#define POWER8_PME_PM_MRK_L1_RELOAD_VALID 841
+#define POWER8_PME_PM_MRK_L2_RC_DISP 842
+#define POWER8_PME_PM_MRK_L2_RC_DONE 843
+#define POWER8_PME_PM_MRK_LARX_FIN 844
+#define POWER8_PME_PM_MRK_LD_MISS_EXPOSED 845
+#define POWER8_PME_PM_MRK_LD_MISS_EXPOSED_CYC 846
+#define POWER8_PME_PM_MRK_LD_MISS_L1 847
+#define POWER8_PME_PM_MRK_LD_MISS_L1_CYC 848
+#define POWER8_PME_PM_MRK_LSU_FIN 849
+#define POWER8_PME_PM_MRK_LSU_FLUSH 850
+#define POWER8_PME_PM_MRK_LSU_FLUSH_LRQ 851
+#define POWER8_PME_PM_MRK_LSU_FLUSH_SRQ 852
+#define POWER8_PME_PM_MRK_LSU_FLUSH_ULD 853
+#define POWER8_PME_PM_MRK_LSU_FLUSH_UST 854
+#define POWER8_PME_PM_MRK_LSU_REJECT 855
+#define POWER8_PME_PM_MRK_LSU_REJECT_ERAT_MISS 856
+#define POWER8_PME_PM_MRK_NTF_FIN 857
+#define POWER8_PME_PM_MRK_RUN_CYC 858
+#define POWER8_PME_PM_MRK_SRC_PREF_TRACK_EFF 859
+#define POWER8_PME_PM_MRK_SRC_PREF_TRACK_INEFF 860
+#define POWER8_PME_PM_MRK_SRC_PREF_TRACK_MOD 861
+#define POWER8_PME_PM_MRK_SRC_PREF_TRACK_MOD_L2 862
+#define POWER8_PME_PM_MRK_SRC_PREF_TRACK_MOD_L3 863
+#define POWER8_PME_PM_MRK_STALL_CMPLU_CYC 864
+#define POWER8_PME_PM_MRK_STCX_FAIL 865
+#define POWER8_PME_PM_MRK_ST_CMPL 866
+#define POWER8_PME_PM_MRK_ST_CMPL_INT 867
+#define POWER8_PME_PM_MRK_ST_DRAIN_TO_L2DISP_CYC 868
+#define POWER8_PME_PM_MRK_ST_FWD 869
+#define POWER8_PME_PM_MRK_ST_L2DISP_TO_CMPL_CYC 870
+#define POWER8_PME_PM_MRK_ST_NEST 871
+#define POWER8_PME_PM_MRK_TGT_PREF_TRACK_EFF 872
+#define POWER8_PME_PM_MRK_TGT_PREF_TRACK_INEFF 873
+#define POWER8_PME_PM_MRK_TGT_PREF_TRACK_MOD 874
+#define POWER8_PME_PM_MRK_TGT_PREF_TRACK_MOD_L2 875
+#define POWER8_PME_PM_MRK_TGT_PREF_TRACK_MOD_L3 876
+#define POWER8_PME_PM_MRK_VSU_FIN 877
+#define POWER8_PME_PM_MULT_MRK 878
+#define POWER8_PME_PM_NESTED_TEND 879
+#define POWER8_PME_PM_NEST_REF_CLK 880
+#define POWER8_PME_PM_NON_FAV_TBEGIN 881
+#define POWER8_PME_PM_NON_TM_RST_SC 882
+#define POWER8_PME_PM_NTCG_ALL_FIN 883
+#define POWER8_PME_PM_OUTER_TBEGIN 884
+#define POWER8_PME_PM_OUTER_TEND 885
+#define POWER8_PME_PM_PMC1_OVERFLOW 886
+#define POWER8_PME_PM_PMC2_OVERFLOW 887
+#define POWER8_PME_PM_PMC2_REWIND 888
+#define POWER8_PME_PM_PMC2_SAVED 889
+#define POWER8_PME_PM_PMC3_OVERFLOW 890
+#define POWER8_PME_PM_PMC4_OVERFLOW 891
+#define POWER8_PME_PM_PMC4_REWIND 892
+#define POWER8_PME_PM_PMC4_SAVED 893
+#define POWER8_PME_PM_PMC5_OVERFLOW 894
+#define POWER8_PME_PM_PMC6_OVERFLOW 895
+#define POWER8_PME_PM_PREF_TRACKED 896
+#define POWER8_PME_PM_PREF_TRACK_EFF 897
+#define POWER8_PME_PM_PREF_TRACK_INEFF 898
+#define POWER8_PME_PM_PREF_TRACK_MOD 899
+#define POWER8_PME_PM_PREF_TRACK_MOD_L2 900
+#define POWER8_PME_PM_PREF_TRACK_MOD_L3 901
+#define POWER8_PME_PM_PROBE_NOP_DISP 902
+#define POWER8_PME_PM_PTE_PREFETCH 903
+#define POWER8_PME_PM_PUMP_CPRED 904
+#define POWER8_PME_PM_PUMP_MPRED 905
+#define POWER8_PME_PM_RC0_ALLOC 906
+#define POWER8_PME_PM_RC0_BUSY 907
+#define POWER8_PME_PM_RC_LIFETIME_EXC_1024 908
+#define POWER8_PME_PM_RC_LIFETIME_EXC_2048 909
+#define POWER8_PME_PM_RC_LIFETIME_EXC_256 910
+#define POWER8_PME_PM_RC_LIFETIME_EXC_32 911
+#define POWER8_PME_PM_RC_USAGE 912
+#define POWER8_PME_PM_RD_CLEARING_SC 913
+#define POWER8_PME_PM_RD_FORMING_SC 914
+#define POWER8_PME_PM_RD_HIT_PF 915
+#define POWER8_PME_PM_REAL_SRQ_FULL 916
+#define POWER8_PME_PM_RUN_CYC 917
+#define POWER8_PME_PM_RUN_CYC_SMT2_MODE 918
+#define POWER8_PME_PM_RUN_CYC_SMT2_SHRD_MODE 919
+#define POWER8_PME_PM_RUN_CYC_SMT2_SPLIT_MODE 920
+#define POWER8_PME_PM_RUN_CYC_SMT4_MODE 921
+#define POWER8_PME_PM_RUN_CYC_SMT8_MODE 922
+#define POWER8_PME_PM_RUN_CYC_ST_MODE 923
+#define POWER8_PME_PM_RUN_INST_CMPL 924
+#define POWER8_PME_PM_RUN_PURR 925
+#define POWER8_PME_PM_RUN_SPURR 926
+#define POWER8_PME_PM_SEC_ERAT_HIT 927
+#define POWER8_PME_PM_SHL_CREATED 928
+#define POWER8_PME_PM_SHL_ST_CONVERT 929
+#define POWER8_PME_PM_SHL_ST_DISABLE 930
+#define POWER8_PME_PM_SN0_ALLOC 931
+#define POWER8_PME_PM_SN0_BUSY 932
+#define POWER8_PME_PM_SNOOP_TLBIE 933
+#define POWER8_PME_PM_SNP_TM_HIT_M 934
+#define POWER8_PME_PM_SNP_TM_HIT_T 935
+#define POWER8_PME_PM_SN_USAGE 936
+#define POWER8_PME_PM_STALL_END_GCT_EMPTY 937
+#define POWER8_PME_PM_STCX_FAIL 938
+#define POWER8_PME_PM_STCX_LSU 939
+#define POWER8_PME_PM_ST_CAUSED_FAIL 940
+#define POWER8_PME_PM_ST_CMPL 941
+#define POWER8_PME_PM_ST_FIN 942
+#define POWER8_PME_PM_ST_FWD 943
+#define POWER8_PME_PM_ST_MISS_L1 944
+#define POWER8_PME_PM_SUSPENDED 945
+#define POWER8_PME_PM_SWAP_CANCEL 946
+#define POWER8_PME_PM_SWAP_CANCEL_GPR 947
+#define POWER8_PME_PM_SWAP_COMPLETE 948
+#define POWER8_PME_PM_SWAP_COMPLETE_GPR 949
+#define POWER8_PME_PM_SYNC_MRK_BR_LINK 950
+#define POWER8_PME_PM_SYNC_MRK_BR_MPRED 951
+#define POWER8_PME_PM_SYNC_MRK_FX_DIVIDE 952
+#define POWER8_PME_PM_SYNC_MRK_L2HIT 953
+#define POWER8_PME_PM_SYNC_MRK_L2MISS 954
+#define POWER8_PME_PM_SYNC_MRK_L3MISS 955
+#define POWER8_PME_PM_SYNC_MRK_PROBE_NOP 956
+#define POWER8_PME_PM_SYS_PUMP_CPRED 957
+#define POWER8_PME_PM_SYS_PUMP_MPRED 958
+#define POWER8_PME_PM_SYS_PUMP_MPRED_RTY 959
+#define POWER8_PME_PM_TABLEWALK_CYC 960
+#define POWER8_PME_PM_TABLEWALK_CYC_PREF 961
+#define POWER8_PME_PM_TABORT_TRECLAIM 962
+#define POWER8_PME_PM_TB_BIT_TRANS 963
+#define POWER8_PME_PM_TEND_PEND_CYC 964
+#define POWER8_PME_PM_THRD_ALL_RUN_CYC 965
+#define POWER8_PME_PM_THRD_CONC_RUN_INST 966
+#define POWER8_PME_PM_THRD_GRP_CMPL_BOTH_CYC 967
+#define POWER8_PME_PM_THRD_PRIO_0_1_CYC 968
+#define POWER8_PME_PM_THRD_PRIO_2_3_CYC 969
+#define POWER8_PME_PM_THRD_PRIO_4_5_CYC 970
+#define POWER8_PME_PM_THRD_PRIO_6_7_CYC 971
+#define POWER8_PME_PM_THRD_REBAL_CYC 972
+#define POWER8_PME_PM_THRESH_EXC_1024 973
+#define POWER8_PME_PM_THRESH_EXC_128 974
+#define POWER8_PME_PM_THRESH_EXC_2048 975
+#define POWER8_PME_PM_THRESH_EXC_256 976
+#define POWER8_PME_PM_THRESH_EXC_32 977
+#define POWER8_PME_PM_THRESH_EXC_4096 978
+#define POWER8_PME_PM_THRESH_EXC_512 979
+#define POWER8_PME_PM_THRESH_EXC_64 980
+#define POWER8_PME_PM_THRESH_MET 981
+#define POWER8_PME_PM_THRESH_NOT_MET 982
+#define POWER8_PME_PM_TLBIE_FIN 983
+#define POWER8_PME_PM_TLB_MISS 984
+#define POWER8_PME_PM_TM_BEGIN_ALL 985
+#define POWER8_PME_PM_TM_CAM_OVERFLOW 986
+#define POWER8_PME_PM_TM_CAP_OVERFLOW 987
+#define POWER8_PME_PM_TM_END_ALL 988
+#define POWER8_PME_PM_TM_FAIL_CONF_NON_TM 989
+#define POWER8_PME_PM_TM_FAIL_CON_TM 990
+#define POWER8_PME_PM_TM_FAIL_DISALLOW 991
+#define POWER8_PME_PM_TM_FAIL_FOOTPRINT_OVERFLOW 992
+#define POWER8_PME_PM_TM_FAIL_NON_TX_CONFLICT 993
+#define POWER8_PME_PM_TM_FAIL_SELF 994
+#define POWER8_PME_PM_TM_FAIL_TLBIE 995
+#define POWER8_PME_PM_TM_FAIL_TX_CONFLICT 996
+#define POWER8_PME_PM_TM_FAV_CAUSED_FAIL 997
+#define POWER8_PME_PM_TM_LD_CAUSED_FAIL 998
+#define POWER8_PME_PM_TM_LD_CONF 999
+#define POWER8_PME_PM_TM_RST_SC 1000
+#define POWER8_PME_PM_TM_SC_CO 1001
+#define POWER8_PME_PM_TM_ST_CAUSED_FAIL 1002
+#define POWER8_PME_PM_TM_ST_CONF 1003
+#define POWER8_PME_PM_TM_TBEGIN 1004
+#define POWER8_PME_PM_TM_TRANS_RUN_CYC 1005
+#define POWER8_PME_PM_TM_TRANS_RUN_INST 1006
+#define POWER8_PME_PM_TM_TRESUME 1007
+#define POWER8_PME_PM_TM_TSUSPEND 1008
+#define POWER8_PME_PM_TM_TX_PASS_RUN_CYC 1009
+#define POWER8_PME_PM_TM_TX_PASS_RUN_INST 1010
+#define POWER8_PME_PM_UP_PREF_L3 1011
+#define POWER8_PME_PM_UP_PREF_POINTER 1012
+#define POWER8_PME_PM_VSU0_16FLOP 1013
+#define POWER8_PME_PM_VSU0_1FLOP 1014
+#define POWER8_PME_PM_VSU0_2FLOP 1015
+#define POWER8_PME_PM_VSU0_4FLOP 1016
+#define POWER8_PME_PM_VSU0_8FLOP 1017
+#define POWER8_PME_PM_VSU0_COMPLEX_ISSUED 1018
+#define POWER8_PME_PM_VSU0_CY_ISSUED 1019
+#define POWER8_PME_PM_VSU0_DD_ISSUED 1020
+#define POWER8_PME_PM_VSU0_DP_2FLOP 1021
+#define POWER8_PME_PM_VSU0_DP_FMA 1022
+#define POWER8_PME_PM_VSU0_DP_FSQRT_FDIV 1023
+#define POWER8_PME_PM_VSU0_DQ_ISSUED 1024
+#define POWER8_PME_PM_VSU0_EX_ISSUED 1025
+#define POWER8_PME_PM_VSU0_FIN 1026
+#define POWER8_PME_PM_VSU0_FMA 1027
+#define POWER8_PME_PM_VSU0_FPSCR 1028
+#define POWER8_PME_PM_VSU0_FSQRT_FDIV 1029
+#define POWER8_PME_PM_VSU0_PERMUTE_ISSUED 1030
+#define POWER8_PME_PM_VSU0_SCALAR_DP_ISSUED 1031
+#define POWER8_PME_PM_VSU0_SIMPLE_ISSUED 1032
+#define POWER8_PME_PM_VSU0_SINGLE 1033
+#define POWER8_PME_PM_VSU0_SQ 1034
+#define POWER8_PME_PM_VSU0_STF 1035
+#define POWER8_PME_PM_VSU0_VECTOR_DP_ISSUED 1036
+#define POWER8_PME_PM_VSU0_VECTOR_SP_ISSUED 1037
+#define POWER8_PME_PM_VSU1_16FLOP 1038
+#define POWER8_PME_PM_VSU1_1FLOP 1039
+#define POWER8_PME_PM_VSU1_2FLOP 1040
+#define POWER8_PME_PM_VSU1_4FLOP 1041
+#define POWER8_PME_PM_VSU1_8FLOP 1042
+#define POWER8_PME_PM_VSU1_COMPLEX_ISSUED 1043
+#define POWER8_PME_PM_VSU1_CY_ISSUED 1044
+#define POWER8_PME_PM_VSU1_DD_ISSUED 1045
+#define POWER8_PME_PM_VSU1_DP_2FLOP 1046
+#define POWER8_PME_PM_VSU1_DP_FMA 1047
+#define POWER8_PME_PM_VSU1_DP_FSQRT_FDIV 1048
+#define POWER8_PME_PM_VSU1_DQ_ISSUED 1049
+#define POWER8_PME_PM_VSU1_EX_ISSUED 1050
+#define POWER8_PME_PM_VSU1_FIN 1051
+#define POWER8_PME_PM_VSU1_FMA 1052
+#define POWER8_PME_PM_VSU1_FPSCR 1053
+#define POWER8_PME_PM_VSU1_FSQRT_FDIV 1054
+#define POWER8_PME_PM_VSU1_PERMUTE_ISSUED 1055
+#define POWER8_PME_PM_VSU1_SCALAR_DP_ISSUED 1056
+#define POWER8_PME_PM_VSU1_SIMPLE_ISSUED 1057
+#define POWER8_PME_PM_VSU1_SINGLE 1058
+#define POWER8_PME_PM_VSU1_SQ 1059
+#define POWER8_PME_PM_VSU1_STF 1060
+#define POWER8_PME_PM_VSU1_VECTOR_DP_ISSUED 1061
+#define POWER8_PME_PM_VSU1_VECTOR_SP_ISSUED 1062
 
 static const pme_power_entry_t power8_pe[] = {
+[ POWER8_PME_PM_1LPAR_CYC ] = {
+	.pme_name = "PM_1LPAR_CYC",
+	.pme_code = 0x1f05e,
+	.pme_short_desc = "Number of cycles in single lpar mode. All threads in the core are assigned to the same lpar",
+	.pme_long_desc = "Number of cycles in single lpar mode.",
+},
 [ POWER8_PME_PM_1PLUS_PPC_CMPL ] = {
 	.pme_name = "PM_1PLUS_PPC_CMPL",
 	.pme_code = 0x100f2,
-	.pme_short_desc = "one or more ppc instructions completed",
-	.pme_long_desc = "one or more ppc instructions finished",
+	.pme_short_desc = "1 or more ppc insts finished",
+	.pme_long_desc = "1 or more ppc insts finished (completed).",
 },
 [ POWER8_PME_PM_1PLUS_PPC_DISP ] = {
 	.pme_name = "PM_1PLUS_PPC_DISP",
 	.pme_code = 0x400f2,
 	.pme_short_desc = "Cycles at least one Instr Dispatched",
-	.pme_long_desc = "Cycles at least one Instr Dispatched",
+	.pme_long_desc = "Cycles at least one Instr Dispatched. Could be a group with only microcode. Issue HW016521",
+},
+[ POWER8_PME_PM_2LPAR_CYC ] = {
+	.pme_name = "PM_2LPAR_CYC",
+	.pme_code = 0x2006e,
+	.pme_short_desc = "Cycles in 2-lpar mode. Threads 0-3 belong to Lpar0 and threads 4-7 belong to Lpar1",
+	.pme_long_desc = "Number of cycles in 2 lpar mode.",
+},
+[ POWER8_PME_PM_4LPAR_CYC ] = {
+	.pme_name = "PM_4LPAR_CYC",
+	.pme_code = 0x4e05e,
+	.pme_short_desc = "Number of cycles in 4 LPAR mode. Threads 0-1 belong to lpar0, threads 2-3 belong to lpar1, threads 4-5 belong to lpar2, and threads 6-7 belong to lpar3",
+	.pme_long_desc = "Number of cycles in 4 LPAR mode.",
+},
+[ POWER8_PME_PM_ALL_CHIP_PUMP_CPRED ] = {
+	.pme_name = "PM_ALL_CHIP_PUMP_CPRED",
+	.pme_code = 0x610050,
+	.pme_short_desc = "Initial and Final Pump Scope was chip pump (prediction=correct) for all data types (demand load,data prefetch,inst prefetch,inst fetch,xlate)",
+	.pme_long_desc = "Initial and Final Pump Scope and data sourced across this scope was chip pump (prediction=correct) for all data types ( demand load,data,inst prefetch,inst fetch,xlate (I or d)",
+},
+[ POWER8_PME_PM_ALL_GRP_PUMP_CPRED ] = {
+	.pme_name = "PM_ALL_GRP_PUMP_CPRED",
+	.pme_code = 0x520050,
+	.pme_short_desc = "Initial and Final Pump Scope and data sourced across this scope was group pump for all data types (demand load,data prefetch,inst prefetch,inst fetch,xlate)",
+	.pme_long_desc = "Initial and Final Pump Scope and data sourced across this scope was group pump for all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate)",
+},
+[ POWER8_PME_PM_ALL_GRP_PUMP_MPRED ] = {
+	.pme_name = "PM_ALL_GRP_PUMP_MPRED",
+	.pme_code = 0x620052,
+	.pme_short_desc = "Final Pump Scope (Group) ended up either larger or smaller than Initial Pump Scope for all data types (demand load,data prefetch,inst prefetch,inst fetch,xlate)",
+	.pme_long_desc = "Final Pump Scope(Group) to get data sourced, ended up larger than Initial Pump Scope OR Final Pump Scope(Group) got data from source that was at smaller scope(Chip) Final pump was group pump and initial pump was chip or final and initial pump was gro",
+},
+[ POWER8_PME_PM_ALL_GRP_PUMP_MPRED_RTY ] = {
+	.pme_name = "PM_ALL_GRP_PUMP_MPRED_RTY",
+	.pme_code = 0x610052,
+	.pme_short_desc = "Final Pump Scope (Group) ended up larger than Initial Pump Scope (Chip) for all data types (demand load,data prefetch,inst prefetch,inst fetch,xlate)",
+	.pme_long_desc = "Final Pump Scope(Group) to get data sourced, ended up larger than Initial Pump Scope (Chip) Final pump was group pump and initial pump was chip pumpfor all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate)",
+},
+[ POWER8_PME_PM_ALL_PUMP_CPRED ] = {
+	.pme_name = "PM_ALL_PUMP_CPRED",
+	.pme_code = 0x610054,
+	.pme_short_desc = "Pump prediction correct. Counts across all types of pumps for all data types (demand load,data prefetch,inst prefetch,inst fetch,xlate)",
+	.pme_long_desc = "Pump prediction correct. Counts across all types of pumpsfor all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate)",
+},
+[ POWER8_PME_PM_ALL_PUMP_MPRED ] = {
+	.pme_name = "PM_ALL_PUMP_MPRED",
+	.pme_code = 0x640052,
+	.pme_short_desc = "Pump misprediction. Counts across all types of pumps for all data types (demand load,data prefetch,inst prefetch,inst fetch,xlate)",
+	.pme_long_desc = "Pump Mis prediction Counts across all types of pumpsfor all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate)",
+},
+[ POWER8_PME_PM_ALL_SYS_PUMP_CPRED ] = {
+	.pme_name = "PM_ALL_SYS_PUMP_CPRED",
+	.pme_code = 0x630050,
+	.pme_short_desc = "Initial and Final Pump Scope was system pump for all data types (demand load,data prefetch,inst prefetch,inst fetch,xlate)",
+	.pme_long_desc = "Initial and Final Pump Scope and data sourced across this scope was system pump for all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate)",
+},
+[ POWER8_PME_PM_ALL_SYS_PUMP_MPRED ] = {
+	.pme_name = "PM_ALL_SYS_PUMP_MPRED",
+	.pme_code = 0x630052,
+	.pme_short_desc = "Final Pump Scope (system) mispredicted. Either the original scope was too small (Chip/Group) or the original scope was System and it should have been smaller. Counts for all data types (demand load,data prefetch,inst prefetch,inst fetch,xlate)",
+	.pme_long_desc = "Final Pump Scope(system) to get data sourced, ended up larger than Initial Pump Scope(Chip/Group) OR Final Pump Scope(system) got data from source that was at smaller scope(Chip/group) Final pump was system pump and initial pump was chip or group or",
+},
+[ POWER8_PME_PM_ALL_SYS_PUMP_MPRED_RTY ] = {
+	.pme_name = "PM_ALL_SYS_PUMP_MPRED_RTY",
+	.pme_code = 0x640050,
+	.pme_short_desc = "Final Pump Scope (system) ended up larger than Initial Pump Scope (Chip/Group) for all data types (demand load,data prefetch,inst prefetch,inst fetch,xlate)",
+	.pme_long_desc = "Final Pump Scope(system) to get data sourced, ended up larger than Initial Pump Scope (Chip or Group) for all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate)",
 },
 [ POWER8_PME_PM_ANY_THRD_RUN_CYC ] = {
 	.pme_name = "PM_ANY_THRD_RUN_CYC",
 	.pme_code = 0x100fa,
-	.pme_short_desc = "Any thread in run_cycles (was one thread in run_cycles)",
-	.pme_long_desc = "One of threads in run_cycles",
-},
-[ POWER8_PME_PM_BR_MPRED_CMPL ] = {
-	.pme_name = "PM_BR_MPRED_CMPL",
-	.pme_code = 0x400f6,
-	.pme_short_desc = "Number of Branch Mispredicts",
-	.pme_long_desc = "Number of Branch Mispredicts",
-},
-[ POWER8_PME_PM_BR_TAKEN_CMPL ] = {
-	.pme_name = "PM_BR_TAKEN_CMPL",
-	.pme_code = 0x200fa,
-	.pme_short_desc = "Branch Taken",
-	.pme_long_desc = "New event for Branch Taken",
-},
-[ POWER8_PME_PM_CYC ] = {
-	.pme_name = "PM_CYC",
-	.pme_code = 0x100f0,
-	.pme_short_desc = "Cycles",
-	.pme_long_desc = "Cycles",
-},
-[ POWER8_PME_PM_DATA_FROM_L2MISS ] = {
-	.pme_name = "PM_DATA_FROM_L2MISS",
-	.pme_code = 0x200fe,
-	.pme_short_desc = "Demand LD - L2 Miss (not L2 hit)",
-	.pme_long_desc = "Demand LD - L2 Miss (not L2 hit)",
-},
-[ POWER8_PME_PM_DATA_FROM_L3MISS ] = {
-	.pme_name = "PM_DATA_FROM_L3MISS",
-	.pme_code = 0x300fe,
-	.pme_short_desc = "Demand LD - L3 Miss (not L2 hit and not L3 hit)",
-	.pme_long_desc = "Demand LD - L3 Miss (not L2 hit and not L3 hit)",
-},
-[ POWER8_PME_PM_DATA_FROM_MEM ] = {
-	.pme_name = "PM_DATA_FROM_MEM",
-	.pme_code = 0x400fe,
-	.pme_short_desc = "Data cache reload from memory (including L4)",
-	.pme_long_desc = "data from Memory",
-},
-[ POWER8_PME_PM_DTLB_MISS ] = {
-	.pme_name = "PM_DTLB_MISS",
-	.pme_code = 0x300fc,
-	.pme_short_desc = "Data PTEG Reloaded (DTLB Miss)",
-	.pme_long_desc = "Data PTEG reload",
-},
-[ POWER8_PME_PM_EXT_INT ] = {
-	.pme_name = "PM_EXT_INT",
-	.pme_code = 0x200f8,
-	.pme_short_desc = "external interrupt",
-	.pme_long_desc = "external interrupt",
-},
-[ POWER8_PME_PM_FLOP ] = {
-	.pme_name = "PM_FLOP",
-	.pme_code = 0x100f4,
-	.pme_short_desc = "Floating Point Operations Finished",
-	.pme_long_desc = "Floating Point Operations Finished",
-},
-[ POWER8_PME_PM_FLUSH ] = {
-	.pme_name = "PM_FLUSH",
-	.pme_code = 0x400f8,
-	.pme_short_desc = "Flush (any type)",
-	.pme_long_desc = "Flush (any type)",
-},
-[ POWER8_PME_PM_GCT_NOSLOT_CYC ] = {
-	.pme_name = "PM_GCT_NOSLOT_CYC",
-	.pme_code = 0x100f8,
-	.pme_short_desc = "Pipeline empty (No itags assigned , no GCT slots used)",
-	.pme_long_desc = "No itags assigned",
-},
-[ POWER8_PME_PM_IERAT_MISS ] = {
-	.pme_name = "PM_IERAT_MISS",
-	.pme_code = 0x100f6,
-	.pme_short_desc = "IERAT Reloaded (Miss)",
-	.pme_long_desc = "Cycles Instruction ERAT was reloaded",
-},
-[ POWER8_PME_PM_INST_DISP ] = {
-	.pme_name = "PM_INST_DISP",
-	.pme_code = 0x200f2,
-	.pme_short_desc = "Number of PPC Dispatched",
-	.pme_long_desc = "Number of PPC Dispatched",
-},
-[ POWER8_PME_PM_INST_FROM_L3MISS ] = {
-	.pme_name = "PM_INST_FROM_L3MISS",
-	.pme_code = 0x300fa,
-	.pme_short_desc = "Inst from L3 miss",
-	.pme_long_desc = "A Instruction cacheline request resolved from a location that was beyond the local L3 cache",
-},
-[ POWER8_PME_PM_ITLB_MISS ] = {
-	.pme_name = "PM_ITLB_MISS",
-	.pme_code = 0x400fc,
-	.pme_short_desc = "ITLB Reloaded",
-	.pme_long_desc = "ITLB Reloaded (always zero on POWER6)",
-},
-[ POWER8_PME_PM_L1_DCACHE_RELOAD_VALID ] = {
-	.pme_name = "PM_L1_DCACHE_RELOAD_VALID",
-	.pme_code = 0x300f6,
-	.pme_short_desc = "DL1 reloaded due to Demand Load",
-	.pme_long_desc = "DL1 reloaded due to Demand Load",
-},
-[ POWER8_PME_PM_L1_ICACHE_MISS ] = {
-	.pme_name = "PM_L1_ICACHE_MISS",
-	.pme_code = 0x200fc,
-	.pme_short_desc = "Demand iCache Miss",
-	.pme_long_desc = "Demand iCache Miss",
-},
-[ POWER8_PME_PM_LD_MISS_L1 ] = {
-	.pme_name = "PM_LD_MISS_L1",
-	.pme_code = 0x400f0,
-	.pme_short_desc = "Load Missed L1",
-	.pme_long_desc = "Load Missed L1",
-},
-[ POWER8_PME_PM_LSU_DERAT_MISS ] = {
-	.pme_name = "PM_LSU_DERAT_MISS",
-	.pme_code = 0x200f6,
-	.pme_short_desc = "DERAT Reloaded (Miss)",
-	.pme_long_desc = "DERAT Reloaded due to a DERAT miss",
-},
-[ POWER8_PME_PM_MRK_BR_MPRED_CMPL ] = {
-	.pme_name = "PM_MRK_BR_MPRED_CMPL",
-	.pme_code = 0x300e4,
-	.pme_short_desc = "Marked Branch Mispredicted",
-	.pme_long_desc = "Marked Branch Mispredicted",
-},
-[ POWER8_PME_PM_MRK_BR_TAKEN_CMPL ] = {
-	.pme_name = "PM_MRK_BR_TAKEN_CMPL",
-	.pme_code = 0x100e2,
-	.pme_short_desc = "Marked Branch Taken",
-	.pme_long_desc = "Marked Branch Taken completed",
-},
-[ POWER8_PME_PM_MRK_DATA_FROM_L2MISS ] = {
-	.pme_name = "PM_MRK_DATA_FROM_L2MISS",
-	.pme_code = 0x400e8,
-	.pme_short_desc = "Data cache reload L2 miss",
-	.pme_long_desc = "sampled load resolved beyond L2",
-},
-[ POWER8_PME_PM_MRK_DATA_FROM_L3MISS ] = {
-	.pme_name = "PM_MRK_DATA_FROM_L3MISS",
-	.pme_code = 0x200e4,
-	.pme_short_desc = "The processor's data cache was reloaded from a location other than the local core's L3 due to a marked load",
-	.pme_long_desc = "sampled load resolved beyond L3",
-},
-[ POWER8_PME_PM_MRK_DATA_FROM_MEM ] = {
-	.pme_name = "PM_MRK_DATA_FROM_MEM",
-	.pme_code = 0x200e0,
-	.pme_short_desc = "The processor's data cache was reloaded from a memory location including L4 from local remote or distant due to a marked load",
-	.pme_long_desc = "sampled load resolved from memory",
-},
-[ POWER8_PME_PM_MRK_DERAT_MISS ] = {
-	.pme_name = "PM_MRK_DERAT_MISS",
-	.pme_code = 0x300e6,
-	.pme_short_desc = "Erat Miss (TLB Access) All page sizes",
-	.pme_long_desc = "Erat Miss (TLB Access) All page sizes",
-},
-[ POWER8_PME_PM_MRK_DTLB_MISS ] = {
-	.pme_name = "PM_MRK_DTLB_MISS",
-	.pme_code = 0x400e4,
-	.pme_short_desc = "Marked dtlb miss",
-	.pme_long_desc = "sampled Instruction dtlb miss",
-},
-[ POWER8_PME_PM_MRK_INST_CMPL ] = {
-	.pme_name = "PM_MRK_INST_CMPL",
-	.pme_code = 0x400e0,
-	.pme_short_desc = "marked instruction completed",
-	.pme_long_desc = "Marked group complete",
-},
-[ POWER8_PME_PM_MRK_INST_DISP ] = {
-	.pme_name = "PM_MRK_INST_DISP",
-	.pme_code = 0x100e0,
-	.pme_short_desc = "Marked Instruction dispatched",
-	.pme_long_desc = "The thread has dispatched a randomly sampled marked instruction",
-},
-[ POWER8_PME_PM_MRK_INST_FROM_L3MISS ] = {
-	.pme_name = "PM_MRK_INST_FROM_L3MISS",
-	.pme_code = 0x400e6,
-	.pme_short_desc = "sampled instruction missed icache and came from beyond L3 A Instruction cacheline request for a marked/sampled instruction resolved from a location that was beyond the local L3 cache",
-	.pme_long_desc = "sampled instruction missed icache and came from beyond L3 A Instruction cacheline request for a marked/sampled instruction resolved from a location that was beyond the local L3 cache",
-},
-[ POWER8_PME_PM_MRK_L1_ICACHE_MISS ] = {
-	.pme_name = "PM_MRK_L1_ICACHE_MISS",
-	.pme_code = 0x100e4,
-	.pme_short_desc = "Marked L1 Icache Miss",
-	.pme_long_desc = "sampled Instruction suffered an icache Miss",
-},
-[ POWER8_PME_PM_MRK_L1_RELOAD_VALID ] = {
-	.pme_name = "PM_MRK_L1_RELOAD_VALID",
-	.pme_code = 0x100ea,
-	.pme_short_desc = "Marked demand reload",
-	.pme_long_desc = "Sampled Instruction had a data reload",
-},
-[ POWER8_PME_PM_MRK_LD_MISS_L1 ] = {
-	.pme_name = "PM_MRK_LD_MISS_L1",
-	.pme_code = 0x200e2,
-	.pme_short_desc = "Marked DL1 Demand Miss counted at exec time",
-	.pme_long_desc = "Marked DL1 Demand Miss",
-},
-[ POWER8_PME_PM_MRK_ST_CMPL ] = {
-	.pme_name = "PM_MRK_ST_CMPL",
-	.pme_code = 0x300e2,
-	.pme_short_desc = "Marked store completed",
-	.pme_long_desc = "marked store completed and sent to nest",
-},
-[ POWER8_PME_PM_RUN_CYC ] = {
-	.pme_name = "PM_RUN_CYC",
-	.pme_code = 0x600f4,
-	.pme_short_desc = "Run_cycles",
-	.pme_long_desc = "Run_cycles",
-},
-[ POWER8_PME_PM_RUN_INST_CMPL ] = {
-	.pme_name = "PM_RUN_INST_CMPL",
-	.pme_code = 0x500fa,
-	.pme_short_desc = "Run_Instructions",
-	.pme_long_desc = "Run_Instructions",
-},
-[ POWER8_PME_PM_RUN_PURR ] = {
-	.pme_name = "PM_RUN_PURR",
-	.pme_code = 0x400f4,
-	.pme_short_desc = "Run_PURR",
-	.pme_long_desc = "Run_PURR",
-},
-[ POWER8_PME_PM_ST_FIN ] = {
-	.pme_name = "PM_ST_FIN",
-	.pme_code = 0x200f0,
-	.pme_short_desc = "Store Instructions Finished (store sent to nest)",
-	.pme_long_desc = "Store Instructions Finished",
-},
-[ POWER8_PME_PM_ST_MISS_L1 ] = {
-	.pme_name = "PM_ST_MISS_L1",
-	.pme_code = 0x300f0,
-	.pme_short_desc = "Store Missed L1",
-	.pme_long_desc = "Store Missed L1",
-},
-[ POWER8_PME_PM_TB_BIT_TRANS ] = {
-	.pme_name = "PM_TB_BIT_TRANS",
-	.pme_code = 0x300f8,
-	.pme_short_desc = "timebase event",
-	.pme_long_desc = "timebase event",
-},
-[ POWER8_PME_PM_THRD_CONC_RUN_INST ] = {
-	.pme_name = "PM_THRD_CONC_RUN_INST",
-	.pme_code = 0x300f4,
-	.pme_short_desc = "Concurrent Run Instructions",
-	.pme_long_desc = "PPC Instructions Finished when both threads in run_cycles",
-},
-[ POWER8_PME_PM_THRESH_EXC_1024 ] = {
-	.pme_name = "PM_THRESH_EXC_1024",
-	.pme_code = 0x300ea,
-	.pme_short_desc = "Threshold counter exceeded a value of 1024 Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 1024",
-	.pme_long_desc = "Threshold counter exceeded a value of 1024 Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 1024",
-},
-[ POWER8_PME_PM_THRESH_EXC_128 ] = {
-	.pme_name = "PM_THRESH_EXC_128",
-	.pme_code = 0x400ea,
-	.pme_short_desc = "Threshold counter exceeded a value of 128",
-	.pme_long_desc = "Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 128",
-},
-[ POWER8_PME_PM_THRESH_EXC_2048 ] = {
-	.pme_name = "PM_THRESH_EXC_2048",
-	.pme_code = 0x400ec,
-	.pme_short_desc = "Threshold counter exceeded a value of 2048",
-	.pme_long_desc = "Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 2048",
-},
-[ POWER8_PME_PM_THRESH_EXC_256 ] = {
-	.pme_name = "PM_THRESH_EXC_256",
-	.pme_code = 0x100e8,
-	.pme_short_desc = "Threshold counter exceed a count of 256",
-	.pme_long_desc = "Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 256",
-},
-[ POWER8_PME_PM_THRESH_EXC_32 ] = {
-	.pme_name = "PM_THRESH_EXC_32",
-	.pme_code = 0x200e6,
-	.pme_short_desc = "Threshold counter exceeded a value of 32",
-	.pme_long_desc = "Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 32",
-},
-[ POWER8_PME_PM_THRESH_EXC_4096 ] = {
-	.pme_name = "PM_THRESH_EXC_4096",
-	.pme_code = 0x100e6,
-	.pme_short_desc = "Threshold counter exceed a count of 4096",
-	.pme_long_desc = "Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 4096",
-},
-[ POWER8_PME_PM_THRESH_EXC_512 ] = {
-	.pme_name = "PM_THRESH_EXC_512",
-	.pme_code = 0x200e8,
-	.pme_short_desc = "Threshold counter exceeded a value of 512 Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 512",
-	.pme_long_desc = "Threshold counter exceeded a value of 512 Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 512",
-},
-[ POWER8_PME_PM_THRESH_EXC_64 ] = {
-	.pme_name = "PM_THRESH_EXC_64",
-	.pme_code = 0x300e8,
-	.pme_short_desc = "Threshold counter exceeded a value of 64 Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 64",
-	.pme_long_desc = "Threshold counter exceeded a value of 64 Architecture provides a thresholding counter in MMCRA, it has a start and stop events to configure and a programmable threshold, this event increments when the threshold exceeded a count of 64",
-},
-[ POWER8_PME_PM_THRESH_MET ] = {
-	.pme_name = "PM_THRESH_MET",
-	.pme_code = 0x100ec,
-	.pme_short_desc = "threshold exceeded",
-	.pme_long_desc = "Threshold exceeded",
+	.pme_short_desc = "One of threads in run_cycles",
+	.pme_long_desc = "Any thread in run_cycles (was one thread in run_cycles).",
+},
+[ POWER8_PME_PM_BACK_BR_CMPL ] = {
+	.pme_name = "PM_BACK_BR_CMPL",
+	.pme_code = 0x2505e,
+	.pme_short_desc = "Branch instruction completed with a target address less than current instruction address",
+	.pme_long_desc = "Branch instruction completed with a target address less than current instruction address.",
+},
+[ POWER8_PME_PM_BANK_CONFLICT ] = {
+	.pme_name = "PM_BANK_CONFLICT",
+	.pme_code = 0x4082,
+	.pme_short_desc = "Read blocked due to interleave conflict. The ifar logic will detect an interleave conflict and kill the data that was read that cycle.",
+	.pme_long_desc = "Read blocked due to interleave conflict. The ifar logic will detect an interleave conflict and kill the data that was read that cycle.",
+},
+[ POWER8_PME_PM_BRU_FIN ] = {
+	.pme_name = "PM_BRU_FIN",
+	.pme_code = 0x10068,
+	.pme_short_desc = "Branch Instruction Finished",
+	.pme_long_desc = "Branch Instruction Finished .",
 },
 [ POWER8_PME_PM_BR_2PATH ] = {
 	.pme_name = "PM_BR_2PATH",
-	.pme_code = 0x40036,
+	.pme_code = 0x20036,
 	.pme_short_desc = "two path branch",
 	.pme_long_desc = "two path branch.",
 },
+[ POWER8_PME_PM_BR_BC_8 ] = {
+	.pme_name = "PM_BR_BC_8",
+	.pme_code = 0x5086,
+	.pme_short_desc = "Pairable BC+8 branch that has not been converted to a Resolve Finished in the BRU pipeline",
+	.pme_long_desc = "Pairable BC+8 branch that has not been converted to a Resolve Finished in the BRU pipeline",
+},
+[ POWER8_PME_PM_BR_BC_8_CONV ] = {
+	.pme_name = "PM_BR_BC_8_CONV",
+	.pme_code = 0x5084,
+	.pme_short_desc = "Pairable BC+8 branch that was converted to a Resolve Finished in the BRU pipeline.",
+	.pme_long_desc = "Pairable BC+8 branch that was converted to a Resolve Finished in the BRU pipeline.",
+},
 [ POWER8_PME_PM_BR_CMPL ] = {
 	.pme_name = "PM_BR_CMPL",
 	.pme_code = 0x40060,
 	.pme_short_desc = "Branch Instruction completed",
 	.pme_long_desc = "Branch Instruction completed.",
 },
+[ POWER8_PME_PM_BR_MPRED_CCACHE ] = {
+	.pme_name = "PM_BR_MPRED_CCACHE",
+	.pme_code = 0x40ac,
+	.pme_short_desc = "Conditional Branch Completed that was Mispredicted due to the Count Cache Target Prediction",
+	.pme_long_desc = "Conditional Branch Completed that was Mispredicted due to the Count Cache Target Prediction",
+},
+[ POWER8_PME_PM_BR_MPRED_CMPL ] = {
+	.pme_name = "PM_BR_MPRED_CMPL",
+	.pme_code = 0x400f6,
+	.pme_short_desc = "Number of Branch Mispredicts",
+	.pme_long_desc = "Number of Branch Mispredicts.",
+},
+[ POWER8_PME_PM_BR_MPRED_CR ] = {
+	.pme_name = "PM_BR_MPRED_CR",
+	.pme_code = 0x40b8,
+	.pme_short_desc = "Conditional Branch Completed that was Mispredicted due to the BHT Direction Prediction (taken/not taken).",
+	.pme_long_desc = "Conditional Branch Completed that was Mispredicted due to the BHT Direction Prediction (taken/not taken).",
+},
+[ POWER8_PME_PM_BR_MPRED_LSTACK ] = {
+	.pme_name = "PM_BR_MPRED_LSTACK",
+	.pme_code = 0x40ae,
+	.pme_short_desc = "Conditional Branch Completed that was Mispredicted due to the Link Stack Target Prediction",
+	.pme_long_desc = "Conditional Branch Completed that was Mispredicted due to the Link Stack Target Prediction",
+},
+[ POWER8_PME_PM_BR_MPRED_TA ] = {
+	.pme_name = "PM_BR_MPRED_TA",
+	.pme_code = 0x40ba,
+	.pme_short_desc = "Conditional Branch Completed that was Mispredicted due to the Target Address Prediction from the Count Cache or Link Stack. Only XL-form branches that resolved Taken set this event.",
+	.pme_long_desc = "Conditional Branch Completed that was Mispredicted due to the Target Address Prediction from the Count Cache or Link Stack. Only XL-form branches that resolved Taken set this event.",
+},
 [ POWER8_PME_PM_BR_MRK_2PATH ] = {
 	.pme_name = "PM_BR_MRK_2PATH",
-	.pme_code = 0x40138,
+	.pme_code = 0x10138,
 	.pme_short_desc = "marked two path branch",
 	.pme_long_desc = "marked two path branch.",
 },
+[ POWER8_PME_PM_BR_PRED_BR0 ] = {
+	.pme_name = "PM_BR_PRED_BR0",
+	.pme_code = 0x409c,
+	.pme_short_desc = "Conditional Branch Completed on BR0 (1st branch in group) in which the HW predicted the Direction or Target",
+	.pme_long_desc = "Conditional Branch Completed on BR0 (1st branch in group) in which the HW predicted the Direction or Target",
+},
+[ POWER8_PME_PM_BR_PRED_BR1 ] = {
+	.pme_name = "PM_BR_PRED_BR1",
+	.pme_code = 0x409e,
+	.pme_short_desc = "Conditional Branch Completed on BR1 (2nd branch in group) in which the HW predicted the Direction or Target. Note: BR1 can only be used in Single Thread Mode. In all of the SMT modes, only one branch can complete, thus BR1 is unused.",
+	.pme_long_desc = "Conditional Branch Completed on BR1 (2nd branch in group) in which the HW predicted the Direction or Target. Note: BR1 can only be used in Single Thread Mode. In all of the SMT modes, only one branch can complete, thus BR1 is unused.",
+},
+[ POWER8_PME_PM_BR_PRED_BR_CMPL ] = {
+	.pme_name = "PM_BR_PRED_BR_CMPL",
+	.pme_code = 0x489c,
+	.pme_short_desc = "Completion Time Event. This event can also be calculated from the direct bus as follows: if_pc_br0_br_pred(0) OR if_pc_br0_br_pred(1).",
+	.pme_long_desc = "IFU",
+},
+[ POWER8_PME_PM_BR_PRED_CCACHE_BR0 ] = {
+	.pme_name = "PM_BR_PRED_CCACHE_BR0",
+	.pme_code = 0x40a4,
+	.pme_short_desc = "Conditional Branch Completed on BR0 that used the Count Cache for Target Prediction",
+	.pme_long_desc = "Conditional Branch Completed on BR0 that used the Count Cache for Target Prediction",
+},
+[ POWER8_PME_PM_BR_PRED_CCACHE_BR1 ] = {
+	.pme_name = "PM_BR_PRED_CCACHE_BR1",
+	.pme_code = 0x40a6,
+	.pme_short_desc = "Conditional Branch Completed on BR1 that used the Count Cache for Target Prediction",
+	.pme_long_desc = "Conditional Branch Completed on BR1 that used the Count Cache for Target Prediction",
+},
+[ POWER8_PME_PM_BR_PRED_CCACHE_CMPL ] = {
+	.pme_name = "PM_BR_PRED_CCACHE_CMPL",
+	.pme_code = 0x48a4,
+	.pme_short_desc = "Completion Time Event. This event can also be calculated from the direct bus as follows: if_pc_br0_br_pred(0) AND if_pc_br0_pred_type.",
+	.pme_long_desc = "IFU",
+},
+[ POWER8_PME_PM_BR_PRED_CR_BR0 ] = {
+	.pme_name = "PM_BR_PRED_CR_BR0",
+	.pme_code = 0x40b0,
+	.pme_short_desc = "Conditional Branch Completed on BR0 that had its direction predicted. I-form branches do not set this event. In addition, B-form branches which do not use the BHT do not set this event - these are branches with BO-field set to 'always taken' and branches",
+	.pme_long_desc = "Conditional Branch Completed on BR0 that had its direction predicted. I-form branches do not set this event. In addition, B-form branches which do not use the BHT do not set this event - these are branches with BO-field set to 'always taken' and bra",
+},
+[ POWER8_PME_PM_BR_PRED_CR_BR1 ] = {
+	.pme_name = "PM_BR_PRED_CR_BR1",
+	.pme_code = 0x40b2,
+	.pme_short_desc = "Conditional Branch Completed on BR1 that had its direction predicted. I-form branches do not set this event. In addition, B-form branches which do not use the BHT do not set this event - these are branches with BO-field set to 'always taken' and branches",
+	.pme_long_desc = "Conditional Branch Completed on BR1 that had its direction predicted. I-form branches do not set this event. In addition, B-form branches which do not use the BHT do not set this event - these are branches with BO-field set to 'always taken' and bra",
+},
+[ POWER8_PME_PM_BR_PRED_CR_CMPL ] = {
+	.pme_name = "PM_BR_PRED_CR_CMPL",
+	.pme_code = 0x48b0,
+	.pme_short_desc = "Completion Time Event. This event can also be calculated from the direct bus as follows: if_pc_br0_br_pred(1)='1'.",
+	.pme_long_desc = "IFU",
+},
+[ POWER8_PME_PM_BR_PRED_LSTACK_BR0 ] = {
+	.pme_name = "PM_BR_PRED_LSTACK_BR0",
+	.pme_code = 0x40a8,
+	.pme_short_desc = "Conditional Branch Completed on BR0 that used the Link Stack for Target Prediction",
+	.pme_long_desc = "Conditional Branch Completed on BR0 that used the Link Stack for Target Prediction",
+},
+[ POWER8_PME_PM_BR_PRED_LSTACK_BR1 ] = {
+	.pme_name = "PM_BR_PRED_LSTACK_BR1",
+	.pme_code = 0x40aa,
+	.pme_short_desc = "Conditional Branch Completed on BR1 that used the Link Stack for Target Prediction",
+	.pme_long_desc = "Conditional Branch Completed on BR1 that used the Link Stack for Target Prediction",
+},
+[ POWER8_PME_PM_BR_PRED_LSTACK_CMPL ] = {
+	.pme_name = "PM_BR_PRED_LSTACK_CMPL",
+	.pme_code = 0x48a8,
+	.pme_short_desc = "Completion Time Event. This event can also be calculated from the direct bus as follows: if_pc_br0_br_pred(0) AND (not if_pc_br0_pred_type).",
+	.pme_long_desc = "IFU",
+},
+[ POWER8_PME_PM_BR_PRED_TA_BR0 ] = {
+	.pme_name = "PM_BR_PRED_TA_BR0",
+	.pme_code = 0x40b4,
+	.pme_short_desc = "Conditional Branch Completed on BR0 that had its target address predicted. Only XL-form branches set this event.",
+	.pme_long_desc = "Conditional Branch Completed on BR0 that had its target address predicted. Only XL-form branches set this event.",
+},
+[ POWER8_PME_PM_BR_PRED_TA_BR1 ] = {
+	.pme_name = "PM_BR_PRED_TA_BR1",
+	.pme_code = 0x40b6,
+	.pme_short_desc = "Conditional Branch Completed on BR1 that had its target address predicted. Only XL-form branches set this event.",
+	.pme_long_desc = "Conditional Branch Completed on BR1 that had its target address predicted. Only XL-form branches set this event.",
+},
+[ POWER8_PME_PM_BR_PRED_TA_CMPL ] = {
+	.pme_name = "PM_BR_PRED_TA_CMPL",
+	.pme_code = 0x48b4,
+	.pme_short_desc = "Completion Time Event. This event can also be calculated from the direct bus as follows: if_pc_br0_br_pred(0)='1'.",
+	.pme_long_desc = "IFU",
+},
+[ POWER8_PME_PM_BR_TAKEN_CMPL ] = {
+	.pme_name = "PM_BR_TAKEN_CMPL",
+	.pme_code = 0x200fa,
+	.pme_short_desc = "New event for Branch Taken",
+	.pme_long_desc = "Branch Taken.",
+},
+[ POWER8_PME_PM_BR_UNCOND_BR0 ] = {
+	.pme_name = "PM_BR_UNCOND_BR0",
+	.pme_code = 0x40a0,
+	.pme_short_desc = "Unconditional Branch Completed on BR0. HW branch prediction was not used for this branch. This can be an I-form branch, a B-form branch with BO-field set to branch always, or a B-form branch which was coverted to a Resolve.",
+	.pme_long_desc = "Unconditional Branch Completed on BR0. HW branch prediction was not used for this branch. This can be an I-form branch, a B-form branch with BO-field set to branch always, or a B-form branch which was coverted to a Resolve.",
+},
+[ POWER8_PME_PM_BR_UNCOND_BR1 ] = {
+	.pme_name = "PM_BR_UNCOND_BR1",
+	.pme_code = 0x40a2,
+	.pme_short_desc = "Unconditional Branch Completed on BR1. HW branch prediction was not used for this branch. This can be an I-form branch, a B-form branch with BO-field set to branch always, or a B-form branch which was coverted to a Resolve.",
+	.pme_long_desc = "Unconditional Branch Completed on BR1. HW branch prediction was not used for this branch. This can be an I-form branch, a B-form branch with BO-field set to branch always, or a B-form branch which was coverted to a Resolve.",
+},
+[ POWER8_PME_PM_BR_UNCOND_CMPL ] = {
+	.pme_name = "PM_BR_UNCOND_CMPL",
+	.pme_code = 0x48a0,
+	.pme_short_desc = "Completion Time Event. This event can also be calculated from the direct bus as follows: if_pc_br0_br_pred=00 AND if_pc_br0_completed.",
+	.pme_long_desc = "IFU",
+},
+[ POWER8_PME_PM_CASTOUT_ISSUED ] = {
+	.pme_name = "PM_CASTOUT_ISSUED",
+	.pme_code = 0x3094,
+	.pme_short_desc = "Castouts issued",
+	.pme_long_desc = "Castouts issued",
+},
+[ POWER8_PME_PM_CASTOUT_ISSUED_GPR ] = {
+	.pme_name = "PM_CASTOUT_ISSUED_GPR",
+	.pme_code = 0x3096,
+	.pme_short_desc = "Castouts issued GPR",
+	.pme_long_desc = "Castouts issued GPR",
+},
+[ POWER8_PME_PM_CHIP_PUMP_CPRED ] = {
+	.pme_name = "PM_CHIP_PUMP_CPRED",
+	.pme_code = 0x10050,
+	.pme_short_desc = "Initial and Final Pump Scope was chip pump (prediction=correct) for all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate)",
+	.pme_long_desc = "Initial and Final Pump Scope and data sourced across this scope was chip pump (prediction=correct) for all data types ( demand load,data,inst prefetch,inst fetch,xlate (I or d).",
+},
+[ POWER8_PME_PM_CLB_HELD ] = {
+	.pme_name = "PM_CLB_HELD",
+	.pme_code = 0x2090,
+	.pme_short_desc = "CLB Hold: Any Reason",
+	.pme_long_desc = "CLB Hold: Any Reason",
+},
 [ POWER8_PME_PM_CMPLU_STALL ] = {
 	.pme_name = "PM_CMPLU_STALL",
-	.pme_code = 0x1e054,
+	.pme_code = 0x4000a,
 	.pme_short_desc = "Completion stall",
 	.pme_long_desc = "Completion stall.",
 },
@@ -540,7 +1439,7 @@ static const pme_power_entry_t power8_pe[] = {
 [ POWER8_PME_PM_CMPLU_STALL_DMISS_L2L3_CONFLICT ] = {
 	.pme_name = "PM_CMPLU_STALL_DMISS_L2L3_CONFLICT",
 	.pme_code = 0x4c016,
-	.pme_short_desc = "Completion stall due to cache miss due to L2 l3 conflict",
+	.pme_short_desc = "Completion stall due to cache miss that resolves in the L2 or L3 with a conflict",
 	.pme_long_desc = "Completion stall due to cache miss resolving in core's L2/L3 with a conflict.",
 },
 [ POWER8_PME_PM_CMPLU_STALL_DMISS_L3MISS ] = {
@@ -552,7 +1451,7 @@ static const pme_power_entry_t power8_pe[] = {
 [ POWER8_PME_PM_CMPLU_STALL_DMISS_LMEM ] = {
 	.pme_name = "PM_CMPLU_STALL_DMISS_LMEM",
 	.pme_code = 0x4c018,
-	.pme_short_desc = "GCT empty by branch mispredict + IC miss",
+	.pme_short_desc = "Completion stall due to cache miss that resolves in local memory",
 	.pme_long_desc = "Completion stall due to cache miss resolving in core's Local Memory.",
 },
 [ POWER8_PME_PM_CMPLU_STALL_DMISS_REMOTE ] = {
@@ -615,6 +1514,12 @@ static const pme_power_entry_t power8_pe[] = {
 	.pme_short_desc = "Completion stall due to mem ECC delay",
 	.pme_long_desc = "Completion stall due to mem ECC delay.",
 },
+[ POWER8_PME_PM_CMPLU_STALL_NO_NTF ] = {
+	.pme_name = "PM_CMPLU_STALL_NO_NTF",
+	.pme_code = 0x2e01c,
+	.pme_short_desc = "Completion stall due to nop",
+	.pme_long_desc = "Completion stall due to nop.",
+},
 [ POWER8_PME_PM_CMPLU_STALL_NTCG_FLUSH ] = {
 	.pme_name = "PM_CMPLU_STALL_NTCG_FLUSH",
 	.pme_code = 0x2e01e,
@@ -624,7 +1529,7 @@ static const pme_power_entry_t power8_pe[] = {
 [ POWER8_PME_PM_CMPLU_STALL_OTHER_CMPL ] = {
 	.pme_name = "PM_CMPLU_STALL_OTHER_CMPL",
 	.pme_code = 0x30006,
-	.pme_short_desc = "Instructions core completed while this thread was stalled.",
+	.pme_short_desc = "Instructions core completed while this tread was stalled",
 	.pme_long_desc = "Instructions core completed while this thread was stalled.",
 },
 [ POWER8_PME_PM_CMPLU_STALL_REJECT ] = {
@@ -660,7 +1565,7 @@ static const pme_power_entry_t power8_pe[] = {
 [ POWER8_PME_PM_CMPLU_STALL_STORE ] = {
 	.pme_name = "PM_CMPLU_STALL_STORE",
 	.pme_code = 0x2c014,
-	.pme_short_desc = "Completion stall by stores this includes store agent finishes in pipe LS0/LS1 and store data finishes in LS2/LS3",
+	.pme_short_desc = "Completion stall by stores this includes store agen finishes in pipe LS0/LS1 and store data finishes in LS2/LS3",
 	.pme_long_desc = "Completion stall by stores.",
 },
 [ POWER8_PME_PM_CMPLU_STALL_ST_FWD ] = {
@@ -693,47 +1598,563 @@ static const pme_power_entry_t power8_pe[] = {
 	.pme_short_desc = "Completion stall due to VSU instruction",
 	.pme_long_desc = "Completion stall due to VSU instruction.",
 },
+[ POWER8_PME_PM_CO0_ALLOC ] = {
+	.pme_name = "PM_CO0_ALLOC",
+	.pme_code = 0x16083,
+	.pme_short_desc = "CO mach 0 Busy. Used by PMU to sample ave RC livetime(mach0 used as sample point)",
+	.pme_long_desc = "0.0",
+},
+[ POWER8_PME_PM_CO0_BUSY ] = {
+	.pme_name = "PM_CO0_BUSY",
+	.pme_code = 0x16082,
+	.pme_short_desc = "CO mach 0 Busy. Used by PMU to sample ave RC livetime(mach0 used as sample point)",
+	.pme_long_desc = "CO mach 0 Busy. Used by PMU to sample ave RC livetime(mach0 used as sample point)",
+},
+[ POWER8_PME_PM_CO_DISP_FAIL ] = {
+	.pme_name = "PM_CO_DISP_FAIL",
+	.pme_code = 0x517082,
+	.pme_short_desc = "CO dispatch failed due to all CO machines being busy",
+	.pme_long_desc = "CO dispatch failed due to all CO machines being busy",
+},
+[ POWER8_PME_PM_CO_TM_SC_FOOTPRINT ] = {
+	.pme_name = "PM_CO_TM_SC_FOOTPRINT",
+	.pme_code = 0x527084,
+	.pme_short_desc = "L2 did a cleanifdirty CO to the L3 (ie created an SC line in the L3)",
+	.pme_long_desc = "L2 did a cleanifdirty CO to the L3 (ie created an SC line in the L3)",
+},
+[ POWER8_PME_PM_CO_USAGE ] = {
+	.pme_name = "PM_CO_USAGE",
+	.pme_code = 0x3608a,
+	.pme_short_desc = "Continuous 16 cycle(2to1) window where this signals rotates thru sampling each L2 CO machine busy. PMU uses this wave to then do 16 cyc count to sample total number of machs running",
+	.pme_long_desc = "Continuous 16 cycle(2to1) window where this signals rotates thru sampling each L2 CO machine busy. PMU uses this wave to then do 16 cyc count to sample total number of machs running",
+},
+[ POWER8_PME_PM_CRU_FIN ] = {
+	.pme_name = "PM_CRU_FIN",
+	.pme_code = 0x40066,
+	.pme_short_desc = "IFU Finished a (non-branch) instruction",
+	.pme_long_desc = "IFU Finished a (non-branch) instruction.",
+},
+[ POWER8_PME_PM_CYC ] = {
+	.pme_name = "PM_CYC",
+	.pme_code = 0x1e,
+	.pme_short_desc = "Cycles",
+	.pme_long_desc = "Cycles .",
+},
+[ POWER8_PME_PM_DATA_ALL_CHIP_PUMP_CPRED ] = {
+	.pme_name = "PM_DATA_ALL_CHIP_PUMP_CPRED",
+	.pme_code = 0x61c050,
+	.pme_short_desc = "Initial and Final Pump Scope was chip pump (prediction=correct) for either demand loads or data prefetch",
+	.pme_long_desc = "Initial and Final Pump Scope and data sourced across this scope was chip pump (prediction=correct) for a demand load",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_DL2L3_MOD ] = {
+	.pme_name = "PM_DATA_ALL_FROM_DL2L3_MOD",
+	.pme_code = 0x64c048,
+	.pme_short_desc = "The processor's data cache was reloaded with Modified (M) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded with Modified (M) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_DL2L3_SHR ] = {
+	.pme_name = "PM_DATA_ALL_FROM_DL2L3_SHR",
+	.pme_code = 0x63c048,
+	.pme_short_desc = "The processor's data cache was reloaded with Shared (S) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded with Shared (S) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_DL4 ] = {
+	.pme_name = "PM_DATA_ALL_FROM_DL4",
+	.pme_code = 0x63c04c,
+	.pme_short_desc = "The processor's data cache was reloaded from another chip's L4 on a different Node or Group (Distant) due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded from another chip's L4 on a different Node or Group (Distant) due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_DMEM ] = {
+	.pme_name = "PM_DATA_ALL_FROM_DMEM",
+	.pme_code = 0x64c04c,
+	.pme_short_desc = "The processor's data cache was reloaded from another chip's memory on the same Node or Group (Distant) due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded from another chip's memory on the same Node or Group (Distant) due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_L2 ] = {
+	.pme_name = "PM_DATA_ALL_FROM_L2",
+	.pme_code = 0x61c042,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_L21_MOD ] = {
+	.pme_name = "PM_DATA_ALL_FROM_L21_MOD",
+	.pme_code = 0x64c046,
+	.pme_short_desc = "The processor's data cache was reloaded with Modified (M) data from another core's L2 on the same chip due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded with Modified (M) data from another core's L2 on the same chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_L21_SHR ] = {
+	.pme_name = "PM_DATA_ALL_FROM_L21_SHR",
+	.pme_code = 0x63c046,
+	.pme_short_desc = "The processor's data cache was reloaded with Shared (S) data from another core's L2 on the same chip due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded with Shared (S) data from another core's L2 on the same chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_L2MISS_MOD ] = {
+	.pme_name = "PM_DATA_ALL_FROM_L2MISS_MOD",
+	.pme_code = 0x61c04e,
+	.pme_short_desc = "The processor's data cache was reloaded from a localtion other than the local core's L2 due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded from a localtion other than the local core's L2 due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_L2_DISP_CONFLICT_LDHITST ] = {
+	.pme_name = "PM_DATA_ALL_FROM_L2_DISP_CONFLICT_LDHITST",
+	.pme_code = 0x63c040,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 with load hit store conflict due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 with load hit store conflict due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_L2_DISP_CONFLICT_OTHER ] = {
+	.pme_name = "PM_DATA_ALL_FROM_L2_DISP_CONFLICT_OTHER",
+	.pme_code = 0x64c040,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 with dispatch conflict due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 with dispatch conflict due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_L2_MEPF ] = {
+	.pme_name = "PM_DATA_ALL_FROM_L2_MEPF",
+	.pme_code = 0x62c040,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 hit without dispatch conflicts on Mepf state due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 hit without dispatch conflicts on Mepf state due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_L2_NO_CONFLICT ] = {
+	.pme_name = "PM_DATA_ALL_FROM_L2_NO_CONFLICT",
+	.pme_code = 0x61c040,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 without conflict due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 without conflict due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_L3 ] = {
+	.pme_name = "PM_DATA_ALL_FROM_L3",
+	.pme_code = 0x64c042,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L3 due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L3 due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_L31_ECO_MOD ] = {
+	.pme_name = "PM_DATA_ALL_FROM_L31_ECO_MOD",
+	.pme_code = 0x64c044,
+	.pme_short_desc = "The processor's data cache was reloaded with Modified (M) data from another core's ECO L3 on the same chip due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded with Modified (M) data from another core's ECO L3 on the same chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_L31_ECO_SHR ] = {
+	.pme_name = "PM_DATA_ALL_FROM_L31_ECO_SHR",
+	.pme_code = 0x63c044,
+	.pme_short_desc = "The processor's data cache was reloaded with Shared (S) data from another core's ECO L3 on the same chip due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded with Shared (S) data from another core's ECO L3 on the same chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_L31_MOD ] = {
+	.pme_name = "PM_DATA_ALL_FROM_L31_MOD",
+	.pme_code = 0x62c044,
+	.pme_short_desc = "The processor's data cache was reloaded with Modified (M) data from another core's L3 on the same chip due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded with Modified (M) data from another core's L3 on the same chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_L31_SHR ] = {
+	.pme_name = "PM_DATA_ALL_FROM_L31_SHR",
+	.pme_code = 0x61c046,
+	.pme_short_desc = "The processor's data cache was reloaded with Shared (S) data from another core's L3 on the same chip due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded with Shared (S) data from another core's L3 on the same chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_L3MISS_MOD ] = {
+	.pme_name = "PM_DATA_ALL_FROM_L3MISS_MOD",
+	.pme_code = 0x64c04e,
+	.pme_short_desc = "The processor's data cache was reloaded from a localtion other than the local core's L3 due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded from a localtion other than the local core's L3 due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_L3_DISP_CONFLICT ] = {
+	.pme_name = "PM_DATA_ALL_FROM_L3_DISP_CONFLICT",
+	.pme_code = 0x63c042,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L3 with dispatch conflict due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L3 with dispatch conflict due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_L3_MEPF ] = {
+	.pme_name = "PM_DATA_ALL_FROM_L3_MEPF",
+	.pme_code = 0x62c042,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L3 without dispatch conflicts hit on Mepf state due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L3 without dispatch conflicts hit on Mepf state due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_L3_NO_CONFLICT ] = {
+	.pme_name = "PM_DATA_ALL_FROM_L3_NO_CONFLICT",
+	.pme_code = 0x61c044,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L3 without conflict due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L3 without conflict due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_LL4 ] = {
+	.pme_name = "PM_DATA_ALL_FROM_LL4",
+	.pme_code = 0x61c04c,
+	.pme_short_desc = "The processor's data cache was reloaded from the local chip's L4 cache due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded from the local chip's L4 cache due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_LMEM ] = {
+	.pme_name = "PM_DATA_ALL_FROM_LMEM",
+	.pme_code = 0x62c048,
+	.pme_short_desc = "The processor's data cache was reloaded from the local chip's Memory due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded from the local chip's Memory due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_MEMORY ] = {
+	.pme_name = "PM_DATA_ALL_FROM_MEMORY",
+	.pme_code = 0x62c04c,
+	.pme_short_desc = "The processor's data cache was reloaded from a memory location including L4 from local remote or distant due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded from a memory location including L4 from local remote or distant due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_OFF_CHIP_CACHE ] = {
+	.pme_name = "PM_DATA_ALL_FROM_OFF_CHIP_CACHE",
+	.pme_code = 0x64c04a,
+	.pme_short_desc = "The processor's data cache was reloaded either shared or modified data from another core's L2/L3 on a different chip (remote or distant) due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded either shared or modified data from another core's L2/L3 on a different chip (remote or distant) due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_ON_CHIP_CACHE ] = {
+	.pme_name = "PM_DATA_ALL_FROM_ON_CHIP_CACHE",
+	.pme_code = 0x61c048,
+	.pme_short_desc = "The processor's data cache was reloaded either shared or modified data from another core's L2/L3 on the same chip due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded either shared or modified data from another core's L2/L3 on the same chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_RL2L3_MOD ] = {
+	.pme_name = "PM_DATA_ALL_FROM_RL2L3_MOD",
+	.pme_code = 0x62c046,
+	.pme_short_desc = "The processor's data cache was reloaded with Modified (M) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded with Modified (M) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_RL2L3_SHR ] = {
+	.pme_name = "PM_DATA_ALL_FROM_RL2L3_SHR",
+	.pme_code = 0x61c04a,
+	.pme_short_desc = "The processor's data cache was reloaded with Shared (S) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded with Shared (S) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_RL4 ] = {
+	.pme_name = "PM_DATA_ALL_FROM_RL4",
+	.pme_code = 0x62c04a,
+	.pme_short_desc = "The processor's data cache was reloaded from another chip's L4 on the same Node or Group ( Remote) due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded from another chip's L4 on the same Node or Group ( Remote) due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_FROM_RMEM ] = {
+	.pme_name = "PM_DATA_ALL_FROM_RMEM",
+	.pme_code = 0x63c04a,
+	.pme_short_desc = "The processor's data cache was reloaded from another chip's memory on the same Node or Group ( Remote) due to either demand loads or data prefetch",
+	.pme_long_desc = "The processor's data cache was reloaded from another chip's memory on the same Node or Group ( Remote) due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1",
+},
+[ POWER8_PME_PM_DATA_ALL_GRP_PUMP_CPRED ] = {
+	.pme_name = "PM_DATA_ALL_GRP_PUMP_CPRED",
+	.pme_code = 0x62c050,
+	.pme_short_desc = "Initial and Final Pump Scope was group pump (prediction=correct) for either demand loads or data prefetch",
+	.pme_long_desc = "Initial and Final Pump Scope and data sourced across this scope was group pump for a demand load",
+},
+[ POWER8_PME_PM_DATA_ALL_GRP_PUMP_MPRED ] = {
+	.pme_name = "PM_DATA_ALL_GRP_PUMP_MPRED",
+	.pme_code = 0x62c052,
+	.pme_short_desc = "Final Pump Scope (Group) ended up either larger or smaller than Initial Pump Scope for either demand loads or data prefetch",
+	.pme_long_desc = "Final Pump Scope(Group) to get data sourced, ended up larger than Initial Pump Scope OR Final Pump Scope(Group) got data from source that was at smaller scope(Chip) Final pump was group pump and initial pump was chip or final and initial pump was gro",
+},
+[ POWER8_PME_PM_DATA_ALL_GRP_PUMP_MPRED_RTY ] = {
+	.pme_name = "PM_DATA_ALL_GRP_PUMP_MPRED_RTY",
+	.pme_code = 0x61c052,
+	.pme_short_desc = "Final Pump Scope (Group) ended up larger than Initial Pump Scope (Chip) for either demand loads or data prefetch",
+	.pme_long_desc = "Final Pump Scope(Group) to get data sourced, ended up larger than Initial Pump Scope (Chip) Final pump was group pump and initial pump was chip pumpfor a demand load",
+},
+[ POWER8_PME_PM_DATA_ALL_PUMP_CPRED ] = {
+	.pme_name = "PM_DATA_ALL_PUMP_CPRED",
+	.pme_code = 0x61c054,
+	.pme_short_desc = "Pump prediction correct. Counts across all types of pumps for either demand loads or data prefetch",
+	.pme_long_desc = "Pump prediction correct. Counts across all types of pumps for a demand load",
+},
+[ POWER8_PME_PM_DATA_ALL_PUMP_MPRED ] = {
+	.pme_name = "PM_DATA_ALL_PUMP_MPRED",
+	.pme_code = 0x64c052,
+	.pme_short_desc = "Pump misprediction. Counts across all types of pumps for either demand loads or data prefetch",
+	.pme_long_desc = "Pump Mis prediction Counts across all types of pumpsfor a demand load",
+},
+[ POWER8_PME_PM_DATA_ALL_SYS_PUMP_CPRED ] = {
+	.pme_name = "PM_DATA_ALL_SYS_PUMP_CPRED",
+	.pme_code = 0x63c050,
+	.pme_short_desc = "Initial and Final Pump Scope was system pump (prediction=correct) for either demand loads or data prefetch",
+	.pme_long_desc = "Initial and Final Pump Scope and data sourced across this scope was system pump for a demand load",
+},
+[ POWER8_PME_PM_DATA_ALL_SYS_PUMP_MPRED ] = {
+	.pme_name = "PM_DATA_ALL_SYS_PUMP_MPRED",
+	.pme_code = 0x63c052,
+	.pme_short_desc = "Final Pump Scope (system) mispredicted. Either the original scope was too small (Chip/Group) or the original scope was System and it should have been smaller. Counts for either demand loads or data prefetch",
+	.pme_long_desc = "Final Pump Scope(system) to get data sourced, ended up larger than Initial Pump Scope(Chip/Group) OR Final Pump Scope(system) got data from source that was at smaller scope(Chip/group) Final pump was system pump and initial pump was chip or group or",
+},
+[ POWER8_PME_PM_DATA_ALL_SYS_PUMP_MPRED_RTY ] = {
+	.pme_name = "PM_DATA_ALL_SYS_PUMP_MPRED_RTY",
+	.pme_code = 0x64c050,
+	.pme_short_desc = "Final Pump Scope (system) ended up larger than Initial Pump Scope (Chip/Group) for either demand loads or data prefetch",
+	.pme_long_desc = "Final Pump Scope(system) to get data sourced, ended up larger than Initial Pump Scope (Chip or Group) for a demand load",
+},
+[ POWER8_PME_PM_DATA_CHIP_PUMP_CPRED ] = {
+	.pme_name = "PM_DATA_CHIP_PUMP_CPRED",
+	.pme_code = 0x1c050,
+	.pme_short_desc = "Initial and Final Pump Scope was chip pump (prediction=correct) for a demand load",
+	.pme_long_desc = "Initial and Final Pump Scope and data sourced across this scope was chip pump (prediction=correct) for a demand load.",
+},
+[ POWER8_PME_PM_DATA_FROM_DL2L3_MOD ] = {
+	.pme_name = "PM_DATA_FROM_DL2L3_MOD",
+	.pme_code = 0x4c048,
+	.pme_short_desc = "The processor's data cache was reloaded with Modified (M) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded with Modified (M) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_DL2L3_SHR ] = {
+	.pme_name = "PM_DATA_FROM_DL2L3_SHR",
+	.pme_code = 0x3c048,
+	.pme_short_desc = "The processor's data cache was reloaded with Shared (S) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded with Shared (S) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_DL4 ] = {
+	.pme_name = "PM_DATA_FROM_DL4",
+	.pme_code = 0x3c04c,
+	.pme_short_desc = "The processor's data cache was reloaded from another chip's L4 on a different Node or Group (Distant) due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded from another chip's L4 on a different Node or Group (Distant) due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_DMEM ] = {
+	.pme_name = "PM_DATA_FROM_DMEM",
+	.pme_code = 0x4c04c,
+	.pme_short_desc = "The processor's data cache was reloaded from another chip's memory on the same Node or Group (Distant) due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded from another chip's memory on the same Node or Group (Distant) due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
 [ POWER8_PME_PM_DATA_FROM_L2 ] = {
 	.pme_name = "PM_DATA_FROM_L2",
 	.pme_code = 0x1c042,
-	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 due to a demand load or demand load plus prefetch controlled by MMCR1[16]",
-	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 due to a demand load or demand load plus prefetch controlled by MMCR1[20].",
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_L21_MOD ] = {
+	.pme_name = "PM_DATA_FROM_L21_MOD",
+	.pme_code = 0x4c046,
+	.pme_short_desc = "The processor's data cache was reloaded with Modified (M) data from another core's L2 on the same chip due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded with Modified (M) data from another core's L2 on the same chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_L21_SHR ] = {
+	.pme_name = "PM_DATA_FROM_L21_SHR",
+	.pme_code = 0x3c046,
+	.pme_short_desc = "The processor's data cache was reloaded with Shared (S) data from another core's L2 on the same chip due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded with Shared (S) data from another core's L2 on the same chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_L2MISS ] = {
+	.pme_name = "PM_DATA_FROM_L2MISS",
+	.pme_code = 0x200fe,
+	.pme_short_desc = "Demand LD - L2 Miss (not L2 hit)",
+	.pme_long_desc = "Demand LD - L2 Miss (not L2 hit).",
+},
+[ POWER8_PME_PM_DATA_FROM_L2MISS_MOD ] = {
+	.pme_name = "PM_DATA_FROM_L2MISS_MOD",
+	.pme_code = 0x1c04e,
+	.pme_short_desc = "The processor's data cache was reloaded from a localtion other than the local core's L2 due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded from a localtion other than the local core's L2 due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_L2_DISP_CONFLICT_LDHITST ] = {
+	.pme_name = "PM_DATA_FROM_L2_DISP_CONFLICT_LDHITST",
+	.pme_code = 0x3c040,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 with load hit store conflict due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 with load hit store conflict due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_L2_DISP_CONFLICT_OTHER ] = {
+	.pme_name = "PM_DATA_FROM_L2_DISP_CONFLICT_OTHER",
+	.pme_code = 0x4c040,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 with dispatch conflict due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 with dispatch conflict due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_L2_MEPF ] = {
+	.pme_name = "PM_DATA_FROM_L2_MEPF",
+	.pme_code = 0x2c040,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 hit without dispatch conflicts on Mepf state due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 hit without dispatch conflicts on Mepf state due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
 },
 [ POWER8_PME_PM_DATA_FROM_L2_NO_CONFLICT ] = {
 	.pme_name = "PM_DATA_FROM_L2_NO_CONFLICT",
 	.pme_code = 0x1c040,
-	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 without conflict due to a demand load or demand load plus prefetch controlled by MMCR1[16]",
-	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 without conflict due to a demand load or demand load plus prefetch controlled by MMCR1[20] .",
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 without conflict due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 without conflict due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1 .",
 },
 [ POWER8_PME_PM_DATA_FROM_L3 ] = {
 	.pme_name = "PM_DATA_FROM_L3",
 	.pme_code = 0x4c042,
 	.pme_short_desc = "The processor's data cache was reloaded from local core's L3 due to a demand load",
-	.pme_long_desc = "The processor's data cache was reloaded from local core's L3 due to a demand load.",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L3 due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_L31_ECO_MOD ] = {
+	.pme_name = "PM_DATA_FROM_L31_ECO_MOD",
+	.pme_code = 0x4c044,
+	.pme_short_desc = "The processor's data cache was reloaded with Modified (M) data from another core's ECO L3 on the same chip due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded with Modified (M) data from another core's ECO L3 on the same chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_L31_ECO_SHR ] = {
+	.pme_name = "PM_DATA_FROM_L31_ECO_SHR",
+	.pme_code = 0x3c044,
+	.pme_short_desc = "The processor's data cache was reloaded with Shared (S) data from another core's ECO L3 on the same chip due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded with Shared (S) data from another core's ECO L3 on the same chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_L31_MOD ] = {
+	.pme_name = "PM_DATA_FROM_L31_MOD",
+	.pme_code = 0x2c044,
+	.pme_short_desc = "The processor's data cache was reloaded with Modified (M) data from another core's L3 on the same chip due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded with Modified (M) data from another core's L3 on the same chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_L31_SHR ] = {
+	.pme_name = "PM_DATA_FROM_L31_SHR",
+	.pme_code = 0x1c046,
+	.pme_short_desc = "The processor's data cache was reloaded with Shared (S) data from another core's L3 on the same chip due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded with Shared (S) data from another core's L3 on the same chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_L3MISS ] = {
+	.pme_name = "PM_DATA_FROM_L3MISS",
+	.pme_code = 0x300fe,
+	.pme_short_desc = "Demand LD - L3 Miss (not L2 hit and not L3 hit)",
+	.pme_long_desc = "Demand LD - L3 Miss (not L2 hit and not L3 hit).",
 },
 [ POWER8_PME_PM_DATA_FROM_L3MISS_MOD ] = {
 	.pme_name = "PM_DATA_FROM_L3MISS_MOD",
 	.pme_code = 0x4c04e,
-	.pme_short_desc = "The processor's data cache was reloaded from a location other than the local core's L3 due to a demand load",
-	.pme_long_desc = "The processor's data cache was reloaded from a location other than the local core's L3 due to a demand load.",
+	.pme_short_desc = "The processor's data cache was reloaded from a localtion other than the local core's L3 due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded from a localtion other than the local core's L3 due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_L3_DISP_CONFLICT ] = {
+	.pme_name = "PM_DATA_FROM_L3_DISP_CONFLICT",
+	.pme_code = 0x3c042,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L3 with dispatch conflict due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L3 with dispatch conflict due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_L3_MEPF ] = {
+	.pme_name = "PM_DATA_FROM_L3_MEPF",
+	.pme_code = 0x2c042,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L3 without dispatch conflicts hit on Mepf state due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L3 without dispatch conflicts hit on Mepf state due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
 },
 [ POWER8_PME_PM_DATA_FROM_L3_NO_CONFLICT ] = {
 	.pme_name = "PM_DATA_FROM_L3_NO_CONFLICT",
 	.pme_code = 0x1c044,
-	.pme_short_desc = "The processor's data cache was reloaded from local core's L3 without conflict due to a demand load or demand load plus prefetch controlled by MMCR1[16]",
-	.pme_long_desc = "The processor's data cache was reloaded from local core's L3 without conflict due to a demand load or demand load plus prefetch controlled by MMCR1[20].",
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L3 without conflict due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L3 without conflict due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_LL4 ] = {
+	.pme_name = "PM_DATA_FROM_LL4",
+	.pme_code = 0x1c04c,
+	.pme_short_desc = "The processor's data cache was reloaded from the local chip's L4 cache due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded from the local chip's L4 cache due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
 },
 [ POWER8_PME_PM_DATA_FROM_LMEM ] = {
 	.pme_name = "PM_DATA_FROM_LMEM",
 	.pme_code = 0x2c048,
 	.pme_short_desc = "The processor's data cache was reloaded from the local chip's Memory due to a demand load",
-	.pme_long_desc = "The processor's data cache was reloaded from the local chip's Memory due to a demand load.",
+	.pme_long_desc = "The processor's data cache was reloaded from the local chip's Memory due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_MEM ] = {
+	.pme_name = "PM_DATA_FROM_MEM",
+	.pme_code = 0x400fe,
+	.pme_short_desc = "The processor's data cache was reloaded from a memory location including L4 from local remote or distant due to a demand load",
+	.pme_long_desc = "Data cache reload from memory (including L4).",
 },
 [ POWER8_PME_PM_DATA_FROM_MEMORY ] = {
 	.pme_name = "PM_DATA_FROM_MEMORY",
 	.pme_code = 0x2c04c,
 	.pme_short_desc = "The processor's data cache was reloaded from a memory location including L4 from local remote or distant due to a demand load",
-	.pme_long_desc = "The processor's data cache was reloaded from a memory location including L4 from local remote or distant due to a demand load.",
+	.pme_long_desc = "The processor's data cache was reloaded from a memory location including L4 from local remote or distant due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_OFF_CHIP_CACHE ] = {
+	.pme_name = "PM_DATA_FROM_OFF_CHIP_CACHE",
+	.pme_code = 0x4c04a,
+	.pme_short_desc = "The processor's data cache was reloaded either shared or modified data from another core's L2/L3 on a different chip (remote or distant) due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded either shared or modified data from another core's L2/L3 on a different chip (remote or distant) due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_ON_CHIP_CACHE ] = {
+	.pme_name = "PM_DATA_FROM_ON_CHIP_CACHE",
+	.pme_code = 0x1c048,
+	.pme_short_desc = "The processor's data cache was reloaded either shared or modified data from another core's L2/L3 on the same chip due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded either shared or modified data from another core's L2/L3 on the same chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_RL2L3_MOD ] = {
+	.pme_name = "PM_DATA_FROM_RL2L3_MOD",
+	.pme_code = 0x2c046,
+	.pme_short_desc = "The processor's data cache was reloaded with Modified (M) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded with Modified (M) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_RL2L3_SHR ] = {
+	.pme_name = "PM_DATA_FROM_RL2L3_SHR",
+	.pme_code = 0x1c04a,
+	.pme_short_desc = "The processor's data cache was reloaded with Shared (S) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded with Shared (S) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_RL4 ] = {
+	.pme_name = "PM_DATA_FROM_RL4",
+	.pme_code = 0x2c04a,
+	.pme_short_desc = "The processor's data cache was reloaded from another chip's L4 on the same Node or Group ( Remote) due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded from another chip's L4 on the same Node or Group ( Remote) due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_FROM_RMEM ] = {
+	.pme_name = "PM_DATA_FROM_RMEM",
+	.pme_code = 0x3c04a,
+	.pme_short_desc = "The processor's data cache was reloaded from another chip's memory on the same Node or Group ( Remote) due to a demand load",
+	.pme_long_desc = "The processor's data cache was reloaded from another chip's memory on the same Node or Group ( Remote) due to either only demand loads or demand loads plus prefetches if MMCR1[16] is 1.",
+},
+[ POWER8_PME_PM_DATA_GRP_PUMP_CPRED ] = {
+	.pme_name = "PM_DATA_GRP_PUMP_CPRED",
+	.pme_code = 0x2c050,
+	.pme_short_desc = "Initial and Final Pump Scope was group pump (prediction=correct) for a demand load",
+	.pme_long_desc = "Initial and Final Pump Scope and data sourced across this scope was group pump for a demand load.",
+},
+[ POWER8_PME_PM_DATA_GRP_PUMP_MPRED ] = {
+	.pme_name = "PM_DATA_GRP_PUMP_MPRED",
+	.pme_code = 0x2c052,
+	.pme_short_desc = "Final Pump Scope (Group) ended up either larger or smaller than Initial Pump Scope for a demand load",
+	.pme_long_desc = "Final Pump Scope(Group) to get data sourced, ended up larger than Initial Pump Scope OR Final Pump Scope(Group) got data from source that was at smaller scope(Chip) Final pump was group pump and initial pump was chip or final and initial pump was gro",
+},
+[ POWER8_PME_PM_DATA_GRP_PUMP_MPRED_RTY ] = {
+	.pme_name = "PM_DATA_GRP_PUMP_MPRED_RTY",
+	.pme_code = 0x1c052,
+	.pme_short_desc = "Final Pump Scope (Group) ended up larger than Initial Pump Scope (Chip) for a demand load",
+	.pme_long_desc = "Final Pump Scope(Group) to get data sourced, ended up larger than Initial Pump Scope (Chip) Final pump was group pump and initial pump was chip pumpfor a demand load.",
+},
+[ POWER8_PME_PM_DATA_PUMP_CPRED ] = {
+	.pme_name = "PM_DATA_PUMP_CPRED",
+	.pme_code = 0x1c054,
+	.pme_short_desc = "Pump prediction correct. Counts across all types of pumps for a demand load",
+	.pme_long_desc = "Pump prediction correct. Counts across all types of pumps for a demand load.",
+},
+[ POWER8_PME_PM_DATA_PUMP_MPRED ] = {
+	.pme_name = "PM_DATA_PUMP_MPRED",
+	.pme_code = 0x4c052,
+	.pme_short_desc = "Pump misprediction. Counts across all types of pumps for a demand load",
+	.pme_long_desc = "Pump Mis prediction Counts across all types of pumpsfor a demand load.",
+},
+[ POWER8_PME_PM_DATA_SYS_PUMP_CPRED ] = {
+	.pme_name = "PM_DATA_SYS_PUMP_CPRED",
+	.pme_code = 0x3c050,
+	.pme_short_desc = "Initial and Final Pump Scope was system pump (prediction=correct) for a demand load",
+	.pme_long_desc = "Initial and Final Pump Scope and data sourced across this scope was system pump for a demand load.",
+},
+[ POWER8_PME_PM_DATA_SYS_PUMP_MPRED ] = {
+	.pme_name = "PM_DATA_SYS_PUMP_MPRED",
+	.pme_code = 0x3c052,
+	.pme_short_desc = "Final Pump Scope (system) mispredicted. Either the original scope was too small (Chip/Group) or the original scope was System and it should have been smaller. Counts for a demand load",
+	.pme_long_desc = "Final Pump Scope(system) to get data sourced, ended up larger than Initial Pump Scope(Chip/Group) OR Final Pump Scope(system) got data from source that was at smaller scope(Chip/group) Final pump was system pump and initial pump was chip or group or",
+},
+[ POWER8_PME_PM_DATA_SYS_PUMP_MPRED_RTY ] = {
+	.pme_name = "PM_DATA_SYS_PUMP_MPRED_RTY",
+	.pme_code = 0x4c050,
+	.pme_short_desc = "Final Pump Scope (system) ended up larger than Initial Pump Scope (Chip/Group) for a demand load",
+	.pme_long_desc = "Final Pump Scope(system) to get data sourced, ended up larger than Initial Pump Scope (Chip or Group) for a demand load.",
+},
+[ POWER8_PME_PM_DATA_TABLEWALK_CYC ] = {
+	.pme_name = "PM_DATA_TABLEWALK_CYC",
+	.pme_code = 0x3001a,
+	.pme_short_desc = "Tablwalk Cycles (could be 1 or 2 active)",
+	.pme_long_desc = "Data Tablewalk Active.",
+},
+[ POWER8_PME_PM_DC_COLLISIONS ] = {
+	.pme_name = "PM_DC_COLLISIONS",
+	.pme_code = 0xe0bc,
+	.pme_short_desc = "DATA Cache collisions",
+	.pme_long_desc = "DATA Cache collisions42",
+},
+[ POWER8_PME_PM_DC_PREF_STREAM_ALLOC ] = {
+	.pme_name = "PM_DC_PREF_STREAM_ALLOC",
+	.pme_code = 0x1e050,
+	.pme_short_desc = "Stream marked valid. The stream could have been allocated through the hardware prefetch mechanism or through software. This is combined ls0 and ls1",
+	.pme_long_desc = "Stream marked valid. The stream could have been allocated through the hardware prefetch mechanism or through software. This is combined ls0 and ls1.",
+},
+[ POWER8_PME_PM_DC_PREF_STREAM_CONF ] = {
+	.pme_name = "PM_DC_PREF_STREAM_CONF",
+	.pme_code = 0x2e050,
+	.pme_short_desc = "A demand load referenced a line in an active prefetch stream. The stream could have been allocated through the hardware prefetch mechanism or through software. Combine up + down",
+	.pme_long_desc = "A demand load referenced a line in an active prefetch stream. The stream could have been allocated through the hardware prefetch mechanism or through software. Combine up + down.",
+},
+[ POWER8_PME_PM_DC_PREF_STREAM_FUZZY_CONF ] = {
+	.pme_name = "PM_DC_PREF_STREAM_FUZZY_CONF",
+	.pme_code = 0x4e050,
+	.pme_short_desc = "A demand load referenced a line in an active fuzzy prefetch stream. The stream could have been allocated through the hardware prefetch mechanism or through software.Fuzzy stream confirm (out of order effects, or pf cant keep up)",
+	.pme_long_desc = "A demand load referenced a line in an active fuzzy prefetch stream. The stream could have been allocated through the hardware prefetch mechanism or through software.Fuzzy stream confirm (out of order effects, or pf cant keep up).",
 },
 [ POWER8_PME_PM_DC_PREF_STREAM_STRIDED_CONF ] = {
 	.pme_name = "PM_DC_PREF_STREAM_STRIDED_CONF",
@@ -741,11 +2162,593 @@ static const pme_power_entry_t power8_pe[] = {
 	.pme_short_desc = "A demand load referenced a line in an active strided prefetch stream. The stream could have been allocated through the hardware prefetch mechanism or through software.",
 	.pme_long_desc = "A demand load referenced a line in an active strided prefetch stream. The stream could have been allocated through the hardware prefetch mechanism or through software..",
 },
+[ POWER8_PME_PM_DERAT_MISS_16G ] = {
+	.pme_name = "PM_DERAT_MISS_16G",
+	.pme_code = 0x4c054,
+	.pme_short_desc = "Data ERAT Miss (Data TLB Access) page size 16G",
+	.pme_long_desc = "Data ERAT Miss (Data TLB Access) page size 16G.",
+},
+[ POWER8_PME_PM_DERAT_MISS_16M ] = {
+	.pme_name = "PM_DERAT_MISS_16M",
+	.pme_code = 0x3c054,
+	.pme_short_desc = "Data ERAT Miss (Data TLB Access) page size 16M",
+	.pme_long_desc = "Data ERAT Miss (Data TLB Access) page size 16M.",
+},
+[ POWER8_PME_PM_DERAT_MISS_4K ] = {
+	.pme_name = "PM_DERAT_MISS_4K",
+	.pme_code = 0x1c056,
+	.pme_short_desc = "Data ERAT Miss (Data TLB Access) page size 4K",
+	.pme_long_desc = "Data ERAT Miss (Data TLB Access) page size 4K.",
+},
+[ POWER8_PME_PM_DERAT_MISS_64K ] = {
+	.pme_name = "PM_DERAT_MISS_64K",
+	.pme_code = 0x2c054,
+	.pme_short_desc = "Data ERAT Miss (Data TLB Access) page size 64K",
+	.pme_long_desc = "Data ERAT Miss (Data TLB Access) page size 64K.",
+},
+[ POWER8_PME_PM_DFU ] = {
+	.pme_name = "PM_DFU",
+	.pme_code = 0xb0ba,
+	.pme_short_desc = "Finish DFU (all finish)",
+	.pme_long_desc = "Finish DFU (all finish)",
+},
+[ POWER8_PME_PM_DFU_DCFFIX ] = {
+	.pme_name = "PM_DFU_DCFFIX",
+	.pme_code = 0xb0be,
+	.pme_short_desc = "Convert from fixed opcode finish (dcffix,dcffixq)",
+	.pme_long_desc = "Convert from fixed opcode finish (dcffix,dcffixq)",
+},
+[ POWER8_PME_PM_DFU_DENBCD ] = {
+	.pme_name = "PM_DFU_DENBCD",
+	.pme_code = 0xb0bc,
+	.pme_short_desc = "BCD->DPD opcode finish (denbcd, denbcdq)",
+	.pme_long_desc = "BCD->DPD opcode finish (denbcd, denbcdq)",
+},
+[ POWER8_PME_PM_DFU_MC ] = {
+	.pme_name = "PM_DFU_MC",
+	.pme_code = 0xb0b8,
+	.pme_short_desc = "Finish DFU multicycle",
+	.pme_long_desc = "Finish DFU multicycle",
+},
+[ POWER8_PME_PM_DISP_CLB_HELD_BAL ] = {
+	.pme_name = "PM_DISP_CLB_HELD_BAL",
+	.pme_code = 0x2092,
+	.pme_short_desc = "Dispatch/CLB Hold: Balance",
+	.pme_long_desc = "Dispatch/CLB Hold: Balance",
+},
+[ POWER8_PME_PM_DISP_CLB_HELD_RES ] = {
+	.pme_name = "PM_DISP_CLB_HELD_RES",
+	.pme_code = 0x2094,
+	.pme_short_desc = "Dispatch/CLB Hold: Resource",
+	.pme_long_desc = "Dispatch/CLB Hold: Resource",
+},
+[ POWER8_PME_PM_DISP_CLB_HELD_SB ] = {
+	.pme_name = "PM_DISP_CLB_HELD_SB",
+	.pme_code = 0x20a8,
+	.pme_short_desc = "Dispatch/CLB Hold: Scoreboard",
+	.pme_long_desc = "Dispatch/CLB Hold: Scoreboard",
+},
+[ POWER8_PME_PM_DISP_CLB_HELD_SYNC ] = {
+	.pme_name = "PM_DISP_CLB_HELD_SYNC",
+	.pme_code = 0x2098,
+	.pme_short_desc = "Dispatch/CLB Hold: Sync type instruction",
+	.pme_long_desc = "Dispatch/CLB Hold: Sync type instruction",
+},
+[ POWER8_PME_PM_DISP_CLB_HELD_TLBIE ] = {
+	.pme_name = "PM_DISP_CLB_HELD_TLBIE",
+	.pme_code = 0x2096,
+	.pme_short_desc = "Dispatch Hold: Due to TLBIE",
+	.pme_long_desc = "Dispatch Hold: Due to TLBIE",
+},
+[ POWER8_PME_PM_DISP_HELD ] = {
+	.pme_name = "PM_DISP_HELD",
+	.pme_code = 0x10006,
+	.pme_short_desc = "Dispatch Held",
+	.pme_long_desc = "Dispatch Held.",
+},
+[ POWER8_PME_PM_DISP_HELD_IQ_FULL ] = {
+	.pme_name = "PM_DISP_HELD_IQ_FULL",
+	.pme_code = 0x20006,
+	.pme_short_desc = "Dispatch held due to Issue q full",
+	.pme_long_desc = "Dispatch held due to Issue q full.",
+},
+[ POWER8_PME_PM_DISP_HELD_MAP_FULL ] = {
+	.pme_name = "PM_DISP_HELD_MAP_FULL",
+	.pme_code = 0x1002a,
+	.pme_short_desc = "Dispatch for this thread was held because the Mappers were full",
+	.pme_long_desc = "Dispatch held due to Mapper full.",
+},
+[ POWER8_PME_PM_DISP_HELD_SRQ_FULL ] = {
+	.pme_name = "PM_DISP_HELD_SRQ_FULL",
+	.pme_code = 0x30018,
+	.pme_short_desc = "Dispatch held due SRQ no room",
+	.pme_long_desc = "Dispatch held due SRQ no room.",
+},
+[ POWER8_PME_PM_DISP_HELD_SYNC_HOLD ] = {
+	.pme_name = "PM_DISP_HELD_SYNC_HOLD",
+	.pme_code = 0x4003c,
+	.pme_short_desc = "Dispatch held due to SYNC hold",
+	.pme_long_desc = "Dispatch held due to SYNC hold.",
+},
+[ POWER8_PME_PM_DISP_HOLD_GCT_FULL ] = {
+	.pme_name = "PM_DISP_HOLD_GCT_FULL",
+	.pme_code = 0x30a6,
+	.pme_short_desc = "Dispatch Hold Due to no space in the GCT",
+	.pme_long_desc = "Dispatch Hold Due to no space in the GCT",
+},
+[ POWER8_PME_PM_DISP_WT ] = {
+	.pme_name = "PM_DISP_WT",
+	.pme_code = 0x30008,
+	.pme_short_desc = "Dispatched Starved",
+	.pme_long_desc = "Dispatched Starved (not held, nothing to dispatch).",
+},
+[ POWER8_PME_PM_DPTEG_FROM_DL2L3_MOD ] = {
+	.pme_name = "PM_DPTEG_FROM_DL2L3_MOD",
+	.pme_code = 0x4e048,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_DL2L3_SHR ] = {
+	.pme_name = "PM_DPTEG_FROM_DL2L3_SHR",
+	.pme_code = 0x3e048,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_DL4 ] = {
+	.pme_name = "PM_DPTEG_FROM_DL4",
+	.pme_code = 0x3e04c,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from another chip's L4 on a different Node or Group (Distant) due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from another chip's L4 on a different Node or Group (Distant) due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_DMEM ] = {
+	.pme_name = "PM_DPTEG_FROM_DMEM",
+	.pme_code = 0x4e04c,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from another chip's memory on the same Node or Group (Distant) due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from another chip's memory on the same Node or Group (Distant) due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_L2 ] = {
+	.pme_name = "PM_DPTEG_FROM_L2",
+	.pme_code = 0x1e042,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L2 due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L2 due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_L21_MOD ] = {
+	.pme_name = "PM_DPTEG_FROM_L21_MOD",
+	.pme_code = 0x4e046,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another core's L2 on the same chip due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another core's L2 on the same chip due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_L21_SHR ] = {
+	.pme_name = "PM_DPTEG_FROM_L21_SHR",
+	.pme_code = 0x3e046,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another core's L2 on the same chip due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another core's L2 on the same chip due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_L2MISS ] = {
+	.pme_name = "PM_DPTEG_FROM_L2MISS",
+	.pme_code = 0x1e04e,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from a localtion other than the local core's L2 due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from a localtion other than the local core's L2 due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_L2_DISP_CONFLICT_LDHITST ] = {
+	.pme_name = "PM_DPTEG_FROM_L2_DISP_CONFLICT_LDHITST",
+	.pme_code = 0x3e040,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L2 with load hit store conflict due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L2 with load hit store conflict due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_L2_DISP_CONFLICT_OTHER ] = {
+	.pme_name = "PM_DPTEG_FROM_L2_DISP_CONFLICT_OTHER",
+	.pme_code = 0x4e040,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L2 with dispatch conflict due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L2 with dispatch conflict due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_L2_MEPF ] = {
+	.pme_name = "PM_DPTEG_FROM_L2_MEPF",
+	.pme_code = 0x2e040,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L2 hit without dispatch conflicts on Mepf state. due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L2 hit without dispatch conflicts on Mepf state. due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_L2_NO_CONFLICT ] = {
+	.pme_name = "PM_DPTEG_FROM_L2_NO_CONFLICT",
+	.pme_code = 0x1e040,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L2 without conflict due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L2 without conflict due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_L3 ] = {
+	.pme_name = "PM_DPTEG_FROM_L3",
+	.pme_code = 0x4e042,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L3 due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L3 due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_L31_ECO_MOD ] = {
+	.pme_name = "PM_DPTEG_FROM_L31_ECO_MOD",
+	.pme_code = 0x4e044,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another core's ECO L3 on the same chip due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another core's ECO L3 on the same chip due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_L31_ECO_SHR ] = {
+	.pme_name = "PM_DPTEG_FROM_L31_ECO_SHR",
+	.pme_code = 0x3e044,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another core's ECO L3 on the same chip due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another core's ECO L3 on the same chip due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_L31_MOD ] = {
+	.pme_name = "PM_DPTEG_FROM_L31_MOD",
+	.pme_code = 0x2e044,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another core's L3 on the same chip due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another core's L3 on the same chip due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_L31_SHR ] = {
+	.pme_name = "PM_DPTEG_FROM_L31_SHR",
+	.pme_code = 0x1e046,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another core's L3 on the same chip due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another core's L3 on the same chip due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_L3MISS ] = {
+	.pme_name = "PM_DPTEG_FROM_L3MISS",
+	.pme_code = 0x4e04e,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from a localtion other than the local core's L3 due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from a localtion other than the local core's L3 due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_L3_DISP_CONFLICT ] = {
+	.pme_name = "PM_DPTEG_FROM_L3_DISP_CONFLICT",
+	.pme_code = 0x3e042,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L3 with dispatch conflict due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L3 with dispatch conflict due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_L3_MEPF ] = {
+	.pme_name = "PM_DPTEG_FROM_L3_MEPF",
+	.pme_code = 0x2e042,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L3 without dispatch conflicts hit on Mepf state. due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L3 without dispatch conflicts hit on Mepf state. due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_L3_NO_CONFLICT ] = {
+	.pme_name = "PM_DPTEG_FROM_L3_NO_CONFLICT",
+	.pme_code = 0x1e044,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L3 without conflict due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L3 without conflict due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_LL4 ] = {
+	.pme_name = "PM_DPTEG_FROM_LL4",
+	.pme_code = 0x1e04c,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from the local chip's L4 cache due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from the local chip's L4 cache due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_LMEM ] = {
+	.pme_name = "PM_DPTEG_FROM_LMEM",
+	.pme_code = 0x2e048,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from the local chip's Memory due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from the local chip's Memory due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_MEMORY ] = {
+	.pme_name = "PM_DPTEG_FROM_MEMORY",
+	.pme_code = 0x2e04c,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from a memory location including L4 from local remote or distant due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from a memory location including L4 from local remote or distant due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_OFF_CHIP_CACHE ] = {
+	.pme_name = "PM_DPTEG_FROM_OFF_CHIP_CACHE",
+	.pme_code = 0x4e04a,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB either shared or modified data from another core's L2/L3 on a different chip (remote or distant) due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB either shared or modified data from another core's L2/L3 on a different chip (remote or distant) due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_ON_CHIP_CACHE ] = {
+	.pme_name = "PM_DPTEG_FROM_ON_CHIP_CACHE",
+	.pme_code = 0x1e048,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB either shared or modified data from another core's L2/L3 on the same chip due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB either shared or modified data from another core's L2/L3 on the same chip due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_RL2L3_MOD ] = {
+	.pme_name = "PM_DPTEG_FROM_RL2L3_MOD",
+	.pme_code = 0x2e046,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_RL2L3_SHR ] = {
+	.pme_name = "PM_DPTEG_FROM_RL2L3_SHR",
+	.pme_code = 0x1e04a,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_RL4 ] = {
+	.pme_name = "PM_DPTEG_FROM_RL4",
+	.pme_code = 0x2e04a,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from another chip's L4 on the same Node or Group ( Remote) due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from another chip's L4 on the same Node or Group ( Remote) due to a data side request.",
+},
+[ POWER8_PME_PM_DPTEG_FROM_RMEM ] = {
+	.pme_name = "PM_DPTEG_FROM_RMEM",
+	.pme_code = 0x3e04a,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from another chip's memory on the same Node or Group ( Remote) due to a data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from another chip's memory on the same Node or Group ( Remote) due to a data side request.",
+},
+[ POWER8_PME_PM_DSLB_MISS ] = {
+	.pme_name = "PM_DSLB_MISS",
+	.pme_code = 0xd094,
+	.pme_short_desc = "Data SLB Miss - Total of all segment sizes",
+	.pme_long_desc = "Data SLB Miss - Total of all segment sizesData SLB misses",
+},
+[ POWER8_PME_PM_DTLB_MISS ] = {
+	.pme_name = "PM_DTLB_MISS",
+	.pme_code = 0x300fc,
+	.pme_short_desc = "Data PTEG reload",
+	.pme_long_desc = "Data PTEG Reloaded (DTLB Miss).",
+},
+[ POWER8_PME_PM_DTLB_MISS_16G ] = {
+	.pme_name = "PM_DTLB_MISS_16G",
+	.pme_code = 0x1c058,
+	.pme_short_desc = "Data TLB Miss page size 16G",
+	.pme_long_desc = "Data TLB Miss page size 16G.",
+},
+[ POWER8_PME_PM_DTLB_MISS_16M ] = {
+	.pme_name = "PM_DTLB_MISS_16M",
+	.pme_code = 0x4c056,
+	.pme_short_desc = "Data TLB Miss page size 16M",
+	.pme_long_desc = "Data TLB Miss page size 16M.",
+},
+[ POWER8_PME_PM_DTLB_MISS_4K ] = {
+	.pme_name = "PM_DTLB_MISS_4K",
+	.pme_code = 0x2c056,
+	.pme_short_desc = "Data TLB Miss page size 4k",
+	.pme_long_desc = "Data TLB Miss page size 4k.",
+},
+[ POWER8_PME_PM_DTLB_MISS_64K ] = {
+	.pme_name = "PM_DTLB_MISS_64K",
+	.pme_code = 0x3c056,
+	.pme_short_desc = "Data TLB Miss page size 64K",
+	.pme_long_desc = "Data TLB Miss page size 64K.",
+},
+[ POWER8_PME_PM_EAT_FORCE_MISPRED ] = {
+	.pme_name = "PM_EAT_FORCE_MISPRED",
+	.pme_code = 0x50a8,
+	.pme_short_desc = "XL-form branch was mispredicted due to the predicted target address missing from EAT. The EAT forces a mispredict in this case since there is no predicated target to validate. This is a rare case that may occur when the EAT is full and a branch is issue",
+	.pme_long_desc = "XL-form branch was mispredicted due to the predicted target address missing from EAT. The EAT forces a mispredict in this case since there is no predicated target to validate. This is a rare case that may occur when the EAT is full and a branch is",
+},
+[ POWER8_PME_PM_EAT_FULL_CYC ] = {
+	.pme_name = "PM_EAT_FULL_CYC",
+	.pme_code = 0x4084,
+	.pme_short_desc = "Cycles No room in EAT",
+	.pme_long_desc = "Cycles No room in EATSet on bank conflict and case where no ibuffers available.",
+},
+[ POWER8_PME_PM_EE_OFF_EXT_INT ] = {
+	.pme_name = "PM_EE_OFF_EXT_INT",
+	.pme_code = 0x2080,
+	.pme_short_desc = "Ee off and external interrupt",
+	.pme_long_desc = "Ee off and external interrupt",
+},
+[ POWER8_PME_PM_EXT_INT ] = {
+	.pme_name = "PM_EXT_INT",
+	.pme_code = 0x200f8,
+	.pme_short_desc = "external interrupt",
+	.pme_long_desc = "external interrupt.",
+},
+[ POWER8_PME_PM_FAV_TBEGIN ] = {
+	.pme_name = "PM_FAV_TBEGIN",
+	.pme_code = 0x20b4,
+	.pme_short_desc = "Dispatch time Favored tbegin",
+	.pme_long_desc = "Dispatch time Favored tbegin",
+},
+[ POWER8_PME_PM_FLOP ] = {
+	.pme_name = "PM_FLOP",
+	.pme_code = 0x100f4,
+	.pme_short_desc = "Floating Point Operation Finished",
+	.pme_long_desc = "Floating Point Operations Finished.",
+},
+[ POWER8_PME_PM_FLOP_SUM_SCALAR ] = {
+	.pme_name = "PM_FLOP_SUM_SCALAR",
+	.pme_code = 0xa0ae,
+	.pme_short_desc = "flops summary scalar instructions",
+	.pme_long_desc = "flops summary scalar instructions",
+},
+[ POWER8_PME_PM_FLOP_SUM_VEC ] = {
+	.pme_name = "PM_FLOP_SUM_VEC",
+	.pme_code = 0xa0ac,
+	.pme_short_desc = "flops summary vector instructions",
+	.pme_long_desc = "flops summary vector instructions",
+},
+[ POWER8_PME_PM_FLUSH ] = {
+	.pme_name = "PM_FLUSH",
+	.pme_code = 0x400f8,
+	.pme_short_desc = "Flush (any type)",
+	.pme_long_desc = "Flush (any type).",
+},
+[ POWER8_PME_PM_FLUSH_BR_MPRED ] = {
+	.pme_name = "PM_FLUSH_BR_MPRED",
+	.pme_code = 0x2084,
+	.pme_short_desc = "Flush caused by branch mispredict",
+	.pme_long_desc = "Flush caused by branch mispredict",
+},
+[ POWER8_PME_PM_FLUSH_COMPLETION ] = {
+	.pme_name = "PM_FLUSH_COMPLETION",
+	.pme_code = 0x30012,
+	.pme_short_desc = "Completion Flush",
+	.pme_long_desc = "Completion Flush.",
+},
+[ POWER8_PME_PM_FLUSH_DISP ] = {
+	.pme_name = "PM_FLUSH_DISP",
+	.pme_code = 0x2082,
+	.pme_short_desc = "Dispatch flush",
+	.pme_long_desc = "Dispatch flush",
+},
+[ POWER8_PME_PM_FLUSH_DISP_SB ] = {
+	.pme_name = "PM_FLUSH_DISP_SB",
+	.pme_code = 0x208c,
+	.pme_short_desc = "Dispatch Flush: Scoreboard",
+	.pme_long_desc = "Dispatch Flush: Scoreboard",
+},
+[ POWER8_PME_PM_FLUSH_DISP_SYNC ] = {
+	.pme_name = "PM_FLUSH_DISP_SYNC",
+	.pme_code = 0x2088,
+	.pme_short_desc = "Dispatch Flush: Sync",
+	.pme_long_desc = "Dispatch Flush: Sync",
+},
+[ POWER8_PME_PM_FLUSH_DISP_TLBIE ] = {
+	.pme_name = "PM_FLUSH_DISP_TLBIE",
+	.pme_code = 0x208a,
+	.pme_short_desc = "Dispatch Flush: TLBIE",
+	.pme_long_desc = "Dispatch Flush: TLBIE",
+},
+[ POWER8_PME_PM_FLUSH_LSU ] = {
+	.pme_name = "PM_FLUSH_LSU",
+	.pme_code = 0x208e,
+	.pme_short_desc = "Flush initiated by LSU",
+	.pme_long_desc = "Flush initiated by LSU",
+},
+[ POWER8_PME_PM_FLUSH_PARTIAL ] = {
+	.pme_name = "PM_FLUSH_PARTIAL",
+	.pme_code = 0x2086,
+	.pme_short_desc = "Partial flush",
+	.pme_long_desc = "Partial flush",
+},
+[ POWER8_PME_PM_FPU0_FCONV ] = {
+	.pme_name = "PM_FPU0_FCONV",
+	.pme_code = 0xa0b0,
+	.pme_short_desc = "Convert instruction executed",
+	.pme_long_desc = "Convert instruction executed",
+},
+[ POWER8_PME_PM_FPU0_FEST ] = {
+	.pme_name = "PM_FPU0_FEST",
+	.pme_code = 0xa0b8,
+	.pme_short_desc = "Estimate instruction executed",
+	.pme_long_desc = "Estimate instruction executed",
+},
+[ POWER8_PME_PM_FPU0_FRSP ] = {
+	.pme_name = "PM_FPU0_FRSP",
+	.pme_code = 0xa0b4,
+	.pme_short_desc = "Round to single precision instruction executed",
+	.pme_long_desc = "Round to single precision instruction executed",
+},
+[ POWER8_PME_PM_FPU1_FCONV ] = {
+	.pme_name = "PM_FPU1_FCONV",
+	.pme_code = 0xa0b2,
+	.pme_short_desc = "Convert instruction executed",
+	.pme_long_desc = "Convert instruction executed",
+},
+[ POWER8_PME_PM_FPU1_FEST ] = {
+	.pme_name = "PM_FPU1_FEST",
+	.pme_code = 0xa0ba,
+	.pme_short_desc = "Estimate instruction executed",
+	.pme_long_desc = "Estimate instruction executed",
+},
+[ POWER8_PME_PM_FPU1_FRSP ] = {
+	.pme_name = "PM_FPU1_FRSP",
+	.pme_code = 0xa0b6,
+	.pme_short_desc = "Round to single precision instruction executed",
+	.pme_long_desc = "Round to single precision instruction executed",
+},
+[ POWER8_PME_PM_FREQ_DOWN ] = {
+	.pme_name = "PM_FREQ_DOWN",
+	.pme_code = 0x3000c,
+	.pme_short_desc = "Power Management: Below Threshold B",
+	.pme_long_desc = "Frequency is being slewed down due to Power Management.",
+},
+[ POWER8_PME_PM_FREQ_UP ] = {
+	.pme_name = "PM_FREQ_UP",
+	.pme_code = 0x4000c,
+	.pme_short_desc = "Power Management: Above Threshold A",
+	.pme_long_desc = "Frequency is being slewed up due to Power Management.",
+},
+[ POWER8_PME_PM_FUSION_TOC_GRP0_1 ] = {
+	.pme_name = "PM_FUSION_TOC_GRP0_1",
+	.pme_code = 0x50b0,
+	.pme_short_desc = "One pair of instructions fused with TOC in Group0",
+	.pme_long_desc = "One pair of instructions fused with TOC in Group0",
+},
+[ POWER8_PME_PM_FUSION_TOC_GRP0_2 ] = {
+	.pme_name = "PM_FUSION_TOC_GRP0_2",
+	.pme_code = 0x50ae,
+	.pme_short_desc = "Two pairs of instructions fused with TOCin Group0",
+	.pme_long_desc = "Two pairs of instructions fused with TOCin Group0",
+},
+[ POWER8_PME_PM_FUSION_TOC_GRP0_3 ] = {
+	.pme_name = "PM_FUSION_TOC_GRP0_3",
+	.pme_code = 0x50ac,
+	.pme_short_desc = "Three pairs of instructions fused with TOC in Group0",
+	.pme_long_desc = "Three pairs of instructions fused with TOC in Group0",
+},
+[ POWER8_PME_PM_FUSION_TOC_GRP1_1 ] = {
+	.pme_name = "PM_FUSION_TOC_GRP1_1",
+	.pme_code = 0x50b2,
+	.pme_short_desc = "One pair of instructions fused with TOX in Group1",
+	.pme_long_desc = "One pair of instructions fused with TOX in Group1",
+},
+[ POWER8_PME_PM_FUSION_VSX_GRP0_1 ] = {
+	.pme_name = "PM_FUSION_VSX_GRP0_1",
+	.pme_code = 0x50b8,
+	.pme_short_desc = "One pair of instructions fused with VSX in Group0",
+	.pme_long_desc = "One pair of instructions fused with VSX in Group0",
+},
+[ POWER8_PME_PM_FUSION_VSX_GRP0_2 ] = {
+	.pme_name = "PM_FUSION_VSX_GRP0_2",
+	.pme_code = 0x50b6,
+	.pme_short_desc = "Two pairs of instructions fused with VSX in Group0",
+	.pme_long_desc = "Two pairs of instructions fused with VSX in Group0",
+},
+[ POWER8_PME_PM_FUSION_VSX_GRP0_3 ] = {
+	.pme_name = "PM_FUSION_VSX_GRP0_3",
+	.pme_code = 0x50b4,
+	.pme_short_desc = "Three pairs of instructions fused with VSX in Group0",
+	.pme_long_desc = "Three pairs of instructions fused with VSX in Group0",
+},
+[ POWER8_PME_PM_FUSION_VSX_GRP1_1 ] = {
+	.pme_name = "PM_FUSION_VSX_GRP1_1",
+	.pme_code = 0x50ba,
+	.pme_short_desc = "One pair of instructions fused with VSX in Group1",
+	.pme_long_desc = "One pair of instructions fused with VSX in Group1",
+},
+[ POWER8_PME_PM_FXU0_BUSY_FXU1_IDLE ] = {
+	.pme_name = "PM_FXU0_BUSY_FXU1_IDLE",
+	.pme_code = 0x3000e,
+	.pme_short_desc = "fxu0 busy and fxu1 idle",
+	.pme_long_desc = "fxu0 busy and fxu1 idle.",
+},
+[ POWER8_PME_PM_FXU0_FIN ] = {
+	.pme_name = "PM_FXU0_FIN",
+	.pme_code = 0x10004,
+	.pme_short_desc = "The fixed point unit Unit 0 finished an instruction. Instructions that finish may not necessary complete.",
+	.pme_long_desc = "FXU0 Finished.",
+},
+[ POWER8_PME_PM_FXU1_BUSY_FXU0_IDLE ] = {
+	.pme_name = "PM_FXU1_BUSY_FXU0_IDLE",
+	.pme_code = 0x4000e,
+	.pme_short_desc = "fxu0 idle and fxu1 busy.",
+	.pme_long_desc = "fxu0 idle and fxu1 busy. .",
+},
+[ POWER8_PME_PM_FXU1_FIN ] = {
+	.pme_name = "PM_FXU1_FIN",
+	.pme_code = 0x40004,
+	.pme_short_desc = "FXU1 Finished",
+	.pme_long_desc = "FXU1 Finished.",
+},
+[ POWER8_PME_PM_FXU_BUSY ] = {
+	.pme_name = "PM_FXU_BUSY",
+	.pme_code = 0x2000e,
+	.pme_short_desc = "fxu0 busy and fxu1 busy.",
+	.pme_long_desc = "fxu0 busy and fxu1 busy..",
+},
+[ POWER8_PME_PM_FXU_IDLE ] = {
+	.pme_name = "PM_FXU_IDLE",
+	.pme_code = 0x1000e,
+	.pme_short_desc = "fxu0 idle and fxu1 idle",
+	.pme_long_desc = "fxu0 idle and fxu1 idle.",
+},
+[ POWER8_PME_PM_GCT_EMPTY_CYC ] = {
+	.pme_name = "PM_GCT_EMPTY_CYC",
+	.pme_code = 0x20008,
+	.pme_short_desc = "No itags assigned either thread (GCT Empty)",
+	.pme_long_desc = "No itags assigned either thread (GCT Empty).",
+},
+[ POWER8_PME_PM_GCT_MERGE ] = {
+	.pme_name = "PM_GCT_MERGE",
+	.pme_code = 0x30a4,
+	.pme_short_desc = "Group dispatched on a merged GCT empty. GCT entries can be merged only within the same thread",
+	.pme_long_desc = "Group dispatched on a merged GCT empty. GCT entries can be merged only within the same thread",
+},
 [ POWER8_PME_PM_GCT_NOSLOT_BR_MPRED ] = {
 	.pme_name = "PM_GCT_NOSLOT_BR_MPRED",
 	.pme_code = 0x4d01e,
-	.pme_short_desc = "Gct empty fo this thread due to branch misprediction",
-	.pme_long_desc = "Gct empty for this thread due to branch misprediction.",
+	.pme_short_desc = "Gct empty for this thread due to branch mispred",
+	.pme_long_desc = "Gct empty for this thread due to branch mispred.",
 },
 [ POWER8_PME_PM_GCT_NOSLOT_BR_MPRED_ICMISS ] = {
 	.pme_name = "PM_GCT_NOSLOT_BR_MPRED_ICMISS",
@@ -753,12 +2756,24 @@ static const pme_power_entry_t power8_pe[] = {
 	.pme_short_desc = "Gct empty for this thread due to Icache Miss and branch mispred",
 	.pme_long_desc = "Gct empty for this thread due to Icache Miss and branch mispred.",
 },
+[ POWER8_PME_PM_GCT_NOSLOT_CYC ] = {
+	.pme_name = "PM_GCT_NOSLOT_CYC",
+	.pme_code = 0x100f8,
+	.pme_short_desc = "No itags assigned",
+	.pme_long_desc = "Pipeline empty (No itags assigned , no GCT slots used).",
+},
 [ POWER8_PME_PM_GCT_NOSLOT_DISP_HELD_ISSQ ] = {
 	.pme_name = "PM_GCT_NOSLOT_DISP_HELD_ISSQ",
 	.pme_code = 0x2d01e,
 	.pme_short_desc = "Gct empty for this thread due to dispatch hold on this thread due to Issue q full",
 	.pme_long_desc = "Gct empty for this thread due to dispatch hold on this thread due to Issue q full.",
 },
+[ POWER8_PME_PM_GCT_NOSLOT_DISP_HELD_MAP ] = {
+	.pme_name = "PM_GCT_NOSLOT_DISP_HELD_MAP",
+	.pme_code = 0x4d01c,
+	.pme_short_desc = "Gct empty for this thread due to dispatch hold on this thread due to Mapper full",
+	.pme_long_desc = "Gct empty for this thread due to dispatch hold on this thread due to Mapper full.",
+},
 [ POWER8_PME_PM_GCT_NOSLOT_DISP_HELD_OTHER ] = {
 	.pme_name = "PM_GCT_NOSLOT_DISP_HELD_OTHER",
 	.pme_code = 0x2e010,
@@ -783,36 +2798,1818 @@ static const pme_power_entry_t power8_pe[] = {
 	.pme_short_desc = "Gct empty for this thread due to Icache Miss",
 	.pme_long_desc = "Gct empty for this thread due to Icache Miss.",
 },
+[ POWER8_PME_PM_GCT_UTIL_11_14_ENTRIES ] = {
+	.pme_name = "PM_GCT_UTIL_11_14_ENTRIES",
+	.pme_code = 0x20a2,
+	.pme_short_desc = "GCT Utilization 11-14 entries",
+	.pme_long_desc = "GCT Utilization 11-14 entries",
+},
+[ POWER8_PME_PM_GCT_UTIL_15_17_ENTRIES ] = {
+	.pme_name = "PM_GCT_UTIL_15_17_ENTRIES",
+	.pme_code = 0x20a4,
+	.pme_short_desc = "GCT Utilization 15-17 entries",
+	.pme_long_desc = "GCT Utilization 15-17 entries",
+},
+[ POWER8_PME_PM_GCT_UTIL_18_ENTRIES ] = {
+	.pme_name = "PM_GCT_UTIL_18_ENTRIES",
+	.pme_code = 0x20a6,
+	.pme_short_desc = "GCT Utilization 18+ entries",
+	.pme_long_desc = "GCT Utilization 18+ entries",
+},
+[ POWER8_PME_PM_GCT_UTIL_1_2_ENTRIES ] = {
+	.pme_name = "PM_GCT_UTIL_1_2_ENTRIES",
+	.pme_code = 0x209c,
+	.pme_short_desc = "GCT Utilization 1-2 entries",
+	.pme_long_desc = "GCT Utilization 1-2 entries",
+},
+[ POWER8_PME_PM_GCT_UTIL_3_6_ENTRIES ] = {
+	.pme_name = "PM_GCT_UTIL_3_6_ENTRIES",
+	.pme_code = 0x209e,
+	.pme_short_desc = "GCT Utilization 3-6 entries",
+	.pme_long_desc = "GCT Utilization 3-6 entries",
+},
+[ POWER8_PME_PM_GCT_UTIL_7_10_ENTRIES ] = {
+	.pme_name = "PM_GCT_UTIL_7_10_ENTRIES",
+	.pme_code = 0x20a0,
+	.pme_short_desc = "GCT Utilization 7-10 entries",
+	.pme_long_desc = "GCT Utilization 7-10 entries",
+},
+[ POWER8_PME_PM_GRP_BR_MPRED_NONSPEC ] = {
+	.pme_name = "PM_GRP_BR_MPRED_NONSPEC",
+	.pme_code = 0x1000a,
+	.pme_short_desc = "Group experienced non-speculative branch redirect",
+	.pme_long_desc = "Group experienced Non-speculative br mispredicct.",
+},
+[ POWER8_PME_PM_GRP_CMPL ] = {
+	.pme_name = "PM_GRP_CMPL",
+	.pme_code = 0x30004,
+	.pme_short_desc = "group completed",
+	.pme_long_desc = "group completed.",
+},
 [ POWER8_PME_PM_GRP_DISP ] = {
 	.pme_name = "PM_GRP_DISP",
 	.pme_code = 0x3000a,
 	.pme_short_desc = "group dispatch",
 	.pme_long_desc = "dispatch_success (Group Dispatched).",
 },
+[ POWER8_PME_PM_GRP_IC_MISS_NONSPEC ] = {
+	.pme_name = "PM_GRP_IC_MISS_NONSPEC",
+	.pme_code = 0x1000c,
+	.pme_short_desc = "Group experienced non-speculative I cache miss",
+	.pme_long_desc = "Group experi enced Non-specu lative I cache miss.",
+},
 [ POWER8_PME_PM_GRP_MRK ] = {
 	.pme_name = "PM_GRP_MRK",
 	.pme_code = 0x10130,
 	.pme_short_desc = "Instruction Marked",
 	.pme_long_desc = "Instruction marked in idu.",
 },
+[ POWER8_PME_PM_GRP_NON_FULL_GROUP ] = {
+	.pme_name = "PM_GRP_NON_FULL_GROUP",
+	.pme_code = 0x509c,
+	.pme_short_desc = "GROUPs where we did not have 6 non branch instructions in the group(ST mode), in SMT mode 3 non branches",
+	.pme_long_desc = "GROUPs where we did not have 6 non branch instructions in the group(ST mode), in SMT mode 3 non branches",
+},
+[ POWER8_PME_PM_GRP_PUMP_CPRED ] = {
+	.pme_name = "PM_GRP_PUMP_CPRED",
+	.pme_code = 0x20050,
+	.pme_short_desc = "Initial and Final Pump Scope and data sourced across this scope was group pump for all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate)",
+	.pme_long_desc = "Initial and Final Pump Scope and data sourced across this scope was group pump for all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate).",
+},
+[ POWER8_PME_PM_GRP_PUMP_MPRED ] = {
+	.pme_name = "PM_GRP_PUMP_MPRED",
+	.pme_code = 0x20052,
+	.pme_short_desc = "Final Pump Scope (Group) ended up either larger or smaller than Initial Pump Scope for all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate)",
+	.pme_long_desc = "Final Pump Scope(Group) to get data sourced, ended up larger than Initial Pump Scope OR Final Pump Scope(Group) got data from source that was at smaller scope(Chip) Final pump was group pump and initial pump was chip or final and initial pump was gro",
+},
+[ POWER8_PME_PM_GRP_PUMP_MPRED_RTY ] = {
+	.pme_name = "PM_GRP_PUMP_MPRED_RTY",
+	.pme_code = 0x10052,
+	.pme_short_desc = "Final Pump Scope (Group) ended up larger than Initial Pump Scope (Chip) for all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate)",
+	.pme_long_desc = "Final Pump Scope(Group) to get data sourced, ended up larger than Initial Pump Scope (Chip) Final pump was group pump and initial pump was chip pumpfor all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate).",
+},
+[ POWER8_PME_PM_GRP_TERM_2ND_BRANCH ] = {
+	.pme_name = "PM_GRP_TERM_2ND_BRANCH",
+	.pme_code = 0x50a4,
+	.pme_short_desc = "There were enough instructions in the Ibuffer, but 2nd branch ends group",
+	.pme_long_desc = "There were enough instructions in the Ibuffer, but 2nd branch ends group",
+},
+[ POWER8_PME_PM_GRP_TERM_FPU_AFTER_BR ] = {
+	.pme_name = "PM_GRP_TERM_FPU_AFTER_BR",
+	.pme_code = 0x50a6,
+	.pme_short_desc = "There were enough instructions in the Ibuffer, but FPU OP IN same group after a branch terminates a group, cant do partial flushes",
+	.pme_long_desc = "There were enough instructions in the Ibuffer, but FPU OP IN same group after a branch terminates a group, cant do partial flushes",
+},
+[ POWER8_PME_PM_GRP_TERM_NOINST ] = {
+	.pme_name = "PM_GRP_TERM_NOINST",
+	.pme_code = 0x509e,
+	.pme_short_desc = "Do not fill every slot in the group, Not enough instructions in the Ibuffer. This includes cases where the group started with enough instructions, but some got knocked out by a cache miss or branch redirect (which would also empty the Ibuffer).",
+	.pme_long_desc = "Do not fill every slot in the group, Not enough instructions in the Ibuffer. This includes cases where the group started with enough instructions, but some got knocked out by a cache miss or branch redirect (which would also empty the Ibuffer).",
+},
+[ POWER8_PME_PM_GRP_TERM_OTHER ] = {
+	.pme_name = "PM_GRP_TERM_OTHER",
+	.pme_code = 0x50a0,
+	.pme_short_desc = "There were enough instructions in the Ibuffer, but the group terminated early for some other reason, most likely due to a First or Last.",
+	.pme_long_desc = "There were enough instructions in the Ibuffer, but the group terminated early for some other reason, most likely due to a First or Last.",
+},
+[ POWER8_PME_PM_GRP_TERM_SLOT_LIMIT ] = {
+	.pme_name = "PM_GRP_TERM_SLOT_LIMIT",
+	.pme_code = 0x50a2,
+	.pme_short_desc = "There were enough instructions in the Ibuffer, but 3 src RA/RB/RC , 2 way crack caused a group termination",
+	.pme_long_desc = "There were enough instructions in the Ibuffer, but 3 src RA/RB/RC , 2 way crack caused a group termination",
+},
 [ POWER8_PME_PM_HV_CYC ] = {
 	.pme_name = "PM_HV_CYC",
 	.pme_code = 0x2000a,
-	.pme_short_desc = "cycles in hypervisor mode",
+	.pme_short_desc = "Cycles in which msr_hv is high. Note that this event does not take msr_pr into consideration",
 	.pme_long_desc = "cycles in hypervisor mode .",
 },
+[ POWER8_PME_PM_IBUF_FULL_CYC ] = {
+	.pme_name = "PM_IBUF_FULL_CYC",
+	.pme_code = 0x4086,
+	.pme_short_desc = "Cycles No room in ibuff",
+	.pme_long_desc = "Cycles No room in ibufffully qualified tranfer (if5 valid).",
+},
+[ POWER8_PME_PM_IC_DEMAND_CYC ] = {
+	.pme_name = "PM_IC_DEMAND_CYC",
+	.pme_code = 0x10018,
+	.pme_short_desc = "Cycles when a demand ifetch was pending",
+	.pme_long_desc = "Demand ifetch pending.",
+},
+[ POWER8_PME_PM_IC_DEMAND_L2_BHT_REDIRECT ] = {
+	.pme_name = "PM_IC_DEMAND_L2_BHT_REDIRECT",
+	.pme_code = 0x4098,
+	.pme_short_desc = "L2 I cache demand request due to BHT redirect, branch redirect ( 2 bubbles 3 cycles)",
+	.pme_long_desc = "L2 I cache demand request due to BHT redirect, branch redirect ( 2 bubbles 3 cycles)",
+},
+[ POWER8_PME_PM_IC_DEMAND_L2_BR_REDIRECT ] = {
+	.pme_name = "PM_IC_DEMAND_L2_BR_REDIRECT",
+	.pme_code = 0x409a,
+	.pme_short_desc = "L2 I cache demand request due to branch Mispredict ( 15 cycle path)",
+	.pme_long_desc = "L2 I cache demand request due to branch Mispredict ( 15 cycle path)",
+},
+[ POWER8_PME_PM_IC_DEMAND_REQ ] = {
+	.pme_name = "PM_IC_DEMAND_REQ",
+	.pme_code = 0x4088,
+	.pme_short_desc = "Demand Instruction fetch request",
+	.pme_long_desc = "Demand Instruction fetch request",
+},
+[ POWER8_PME_PM_IC_INVALIDATE ] = {
+	.pme_name = "PM_IC_INVALIDATE",
+	.pme_code = 0x508a,
+	.pme_short_desc = "Ic line invalidated",
+	.pme_long_desc = "Ic line invalidated",
+},
+[ POWER8_PME_PM_IC_PREF_CANCEL_HIT ] = {
+	.pme_name = "PM_IC_PREF_CANCEL_HIT",
+	.pme_code = 0x4092,
+	.pme_short_desc = "Prefetch Canceled due to icache hit",
+	.pme_long_desc = "Prefetch Canceled due to icache hit",
+},
+[ POWER8_PME_PM_IC_PREF_CANCEL_L2 ] = {
+	.pme_name = "PM_IC_PREF_CANCEL_L2",
+	.pme_code = 0x4094,
+	.pme_short_desc = "L2 Squashed request",
+	.pme_long_desc = "L2 Squashed request",
+},
+[ POWER8_PME_PM_IC_PREF_CANCEL_PAGE ] = {
+	.pme_name = "PM_IC_PREF_CANCEL_PAGE",
+	.pme_code = 0x4090,
+	.pme_short_desc = "Prefetch Canceled due to page boundary",
+	.pme_long_desc = "Prefetch Canceled due to page boundary",
+},
+[ POWER8_PME_PM_IC_PREF_REQ ] = {
+	.pme_name = "PM_IC_PREF_REQ",
+	.pme_code = 0x408a,
+	.pme_short_desc = "Instruction prefetch requests",
+	.pme_long_desc = "Instruction prefetch requests",
+},
+[ POWER8_PME_PM_IC_PREF_WRITE ] = {
+	.pme_name = "PM_IC_PREF_WRITE",
+	.pme_code = 0x408e,
+	.pme_short_desc = "Instruction prefetch written into IL1",
+	.pme_long_desc = "Instruction prefetch written into IL1",
+},
+[ POWER8_PME_PM_IC_RELOAD_PRIVATE ] = {
+	.pme_name = "PM_IC_RELOAD_PRIVATE",
+	.pme_code = 0x4096,
+	.pme_short_desc = "Reloading line was brought in private for a specific thread. Most lines are brought in shared for all eight thrreads. If RA does not match then invalidates and then brings it shared to other thread. In P7 line brought in private , then line was invalidat",
+	.pme_long_desc = "Reloading line was brought in private for a specific thread. Most lines are brought in shared for all eight thrreads. If RA does not match then invalidates and then brings it shared to other thread. In P7 line brought in private , then line was inv",
+},
+[ POWER8_PME_PM_IERAT_RELOAD ] = {
+	.pme_name = "PM_IERAT_RELOAD",
+	.pme_code = 0x100f6,
+	.pme_short_desc = "Number of I-ERAT reloads",
+	.pme_long_desc = "IERAT Reloaded (Miss).",
+},
+[ POWER8_PME_PM_IERAT_RELOAD_16M ] = {
+	.pme_name = "PM_IERAT_RELOAD_16M",
+	.pme_code = 0x4006a,
+	.pme_short_desc = "IERAT Reloaded (Miss) for a 16M page",
+	.pme_long_desc = "IERAT Reloaded (Miss) for a 16M page.",
+},
+[ POWER8_PME_PM_IERAT_RELOAD_4K ] = {
+	.pme_name = "PM_IERAT_RELOAD_4K",
+	.pme_code = 0x20064,
+	.pme_short_desc = "IERAT Miss (Not implemented as DI on POWER6)",
+	.pme_long_desc = "IERAT Reloaded (Miss) for a 4k page.",
+},
+[ POWER8_PME_PM_IERAT_RELOAD_64K ] = {
+	.pme_name = "PM_IERAT_RELOAD_64K",
+	.pme_code = 0x3006a,
+	.pme_short_desc = "IERAT Reloaded (Miss) for a 64k page",
+	.pme_long_desc = "IERAT Reloaded (Miss) for a 64k page.",
+},
+[ POWER8_PME_PM_IFETCH_THROTTLE ] = {
+	.pme_name = "PM_IFETCH_THROTTLE",
+	.pme_code = 0x3405e,
+	.pme_short_desc = "Cycles in which Instruction fetch throttle was active",
+	.pme_long_desc = "Cycles instruction fecth was throttled in IFU.",
+},
+[ POWER8_PME_PM_IFU_L2_TOUCH ] = {
+	.pme_name = "PM_IFU_L2_TOUCH",
+	.pme_code = 0x5088,
+	.pme_short_desc = "L2 touch to update MRU on a line",
+	.pme_long_desc = "L2 touch to update MRU on a line",
+},
+[ POWER8_PME_PM_INST_ALL_CHIP_PUMP_CPRED ] = {
+	.pme_name = "PM_INST_ALL_CHIP_PUMP_CPRED",
+	.pme_code = 0x514050,
+	.pme_short_desc = "Initial and Final Pump Scope was chip pump (prediction=correct) for instruction fetches and prefetches",
+	.pme_long_desc = "Initial and Final Pump Scope and data sourced across this scope was chip pump (prediction=correct) for an instruction fetch",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_DL2L3_MOD ] = {
+	.pme_name = "PM_INST_ALL_FROM_DL2L3_MOD",
+	.pme_code = 0x544048,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_DL2L3_SHR ] = {
+	.pme_name = "PM_INST_ALL_FROM_DL2L3_SHR",
+	.pme_code = 0x534048,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_DL4 ] = {
+	.pme_name = "PM_INST_ALL_FROM_DL4",
+	.pme_code = 0x53404c,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from another chip's L4 on a different Node or Group (Distant) due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from another chip's L4 on a different Node or Group (Distant) due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_DMEM ] = {
+	.pme_name = "PM_INST_ALL_FROM_DMEM",
+	.pme_code = 0x54404c,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from another chip's memory on the same Node or Group (Distant) due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from another chip's memory on the same Node or Group (Distant) due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_L2 ] = {
+	.pme_name = "PM_INST_ALL_FROM_L2",
+	.pme_code = 0x514042,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from local core's L2 due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from local core's L2 due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_L21_MOD ] = {
+	.pme_name = "PM_INST_ALL_FROM_L21_MOD",
+	.pme_code = 0x544046,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another core's L2 on the same chip due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another core's L2 on the same chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_L21_SHR ] = {
+	.pme_name = "PM_INST_ALL_FROM_L21_SHR",
+	.pme_code = 0x534046,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another core's L2 on the same chip due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another core's L2 on the same chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_L2MISS ] = {
+	.pme_name = "PM_INST_ALL_FROM_L2MISS",
+	.pme_code = 0x51404e,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from a localtion other than the local core's L2 due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from a localtion other than the local core's L2 due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_L2_DISP_CONFLICT_LDHITST ] = {
+	.pme_name = "PM_INST_ALL_FROM_L2_DISP_CONFLICT_LDHITST",
+	.pme_code = 0x534040,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from local core's L2 with load hit store conflict due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from local core's L2 with load hit store conflict due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_L2_DISP_CONFLICT_OTHER ] = {
+	.pme_name = "PM_INST_ALL_FROM_L2_DISP_CONFLICT_OTHER",
+	.pme_code = 0x544040,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from local core's L2 with dispatch conflict due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from local core's L2 with dispatch conflict due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_L2_MEPF ] = {
+	.pme_name = "PM_INST_ALL_FROM_L2_MEPF",
+	.pme_code = 0x524040,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from local core's L2 hit without dispatch conflicts on Mepf state. due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from local core's L2 hit without dispatch conflicts on Mepf state. due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_L2_NO_CONFLICT ] = {
+	.pme_name = "PM_INST_ALL_FROM_L2_NO_CONFLICT",
+	.pme_code = 0x514040,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from local core's L2 without conflict due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from local core's L2 without conflict due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_L3 ] = {
+	.pme_name = "PM_INST_ALL_FROM_L3",
+	.pme_code = 0x544042,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from local core's L3 due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from local core's L3 due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_L31_ECO_MOD ] = {
+	.pme_name = "PM_INST_ALL_FROM_L31_ECO_MOD",
+	.pme_code = 0x544044,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another core's ECO L3 on the same chip due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another core's ECO L3 on the same chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_L31_ECO_SHR ] = {
+	.pme_name = "PM_INST_ALL_FROM_L31_ECO_SHR",
+	.pme_code = 0x534044,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another core's ECO L3 on the same chip due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another core's ECO L3 on the same chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_L31_MOD ] = {
+	.pme_name = "PM_INST_ALL_FROM_L31_MOD",
+	.pme_code = 0x524044,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another core's L3 on the same chip due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another core's L3 on the same chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_L31_SHR ] = {
+	.pme_name = "PM_INST_ALL_FROM_L31_SHR",
+	.pme_code = 0x514046,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another core's L3 on the same chip due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another core's L3 on the same chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_L3MISS_MOD ] = {
+	.pme_name = "PM_INST_ALL_FROM_L3MISS_MOD",
+	.pme_code = 0x54404e,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from a localtion other than the local core's L3 due to a instruction fetch",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from a localtion other than the local core's L3 due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_L3_DISP_CONFLICT ] = {
+	.pme_name = "PM_INST_ALL_FROM_L3_DISP_CONFLICT",
+	.pme_code = 0x534042,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from local core's L3 with dispatch conflict due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from local core's L3 with dispatch conflict due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_L3_MEPF ] = {
+	.pme_name = "PM_INST_ALL_FROM_L3_MEPF",
+	.pme_code = 0x524042,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from local core's L3 without dispatch conflicts hit on Mepf state. due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from local core's L3 without dispatch conflicts hit on Mepf state. due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_L3_NO_CONFLICT ] = {
+	.pme_name = "PM_INST_ALL_FROM_L3_NO_CONFLICT",
+	.pme_code = 0x514044,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from local core's L3 without conflict due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from local core's L3 without conflict due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_LL4 ] = {
+	.pme_name = "PM_INST_ALL_FROM_LL4",
+	.pme_code = 0x51404c,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from the local chip's L4 cache due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from the local chip's L4 cache due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_LMEM ] = {
+	.pme_name = "PM_INST_ALL_FROM_LMEM",
+	.pme_code = 0x524048,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from the local chip's Memory due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from the local chip's Memory due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_MEMORY ] = {
+	.pme_name = "PM_INST_ALL_FROM_MEMORY",
+	.pme_code = 0x52404c,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from a memory location including L4 from local remote or distant due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from a memory location including L4 from local remote or distant due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_OFF_CHIP_CACHE ] = {
+	.pme_name = "PM_INST_ALL_FROM_OFF_CHIP_CACHE",
+	.pme_code = 0x54404a,
+	.pme_short_desc = "The processor's Instruction cache was reloaded either shared or modified data from another core's L2/L3 on a different chip (remote or distant) due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded either shared or modified data from another core's L2/L3 on a different chip (remote or distant) due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_ON_CHIP_CACHE ] = {
+	.pme_name = "PM_INST_ALL_FROM_ON_CHIP_CACHE",
+	.pme_code = 0x514048,
+	.pme_short_desc = "The processor's Instruction cache was reloaded either shared or modified data from another core's L2/L3 on the same chip due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded either shared or modified data from another core's L2/L3 on the same chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_RL2L3_MOD ] = {
+	.pme_name = "PM_INST_ALL_FROM_RL2L3_MOD",
+	.pme_code = 0x524046,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_RL2L3_SHR ] = {
+	.pme_name = "PM_INST_ALL_FROM_RL2L3_SHR",
+	.pme_code = 0x51404a,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_RL4 ] = {
+	.pme_name = "PM_INST_ALL_FROM_RL4",
+	.pme_code = 0x52404a,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from another chip's L4 on the same Node or Group ( Remote) due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from another chip's L4 on the same Node or Group ( Remote) due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_FROM_RMEM ] = {
+	.pme_name = "PM_INST_ALL_FROM_RMEM",
+	.pme_code = 0x53404a,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from another chip's memory on the same Node or Group ( Remote) due to instruction fetches and prefetches",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from another chip's memory on the same Node or Group ( Remote) due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1",
+},
+[ POWER8_PME_PM_INST_ALL_GRP_PUMP_CPRED ] = {
+	.pme_name = "PM_INST_ALL_GRP_PUMP_CPRED",
+	.pme_code = 0x524050,
+	.pme_short_desc = "Initial and Final Pump Scope was group pump (prediction=correct) for instruction fetches and prefetches",
+	.pme_long_desc = "Initial and Final Pump Scope and data sourced across this scope was group pump for an instruction fetch",
+},
+[ POWER8_PME_PM_INST_ALL_GRP_PUMP_MPRED ] = {
+	.pme_name = "PM_INST_ALL_GRP_PUMP_MPRED",
+	.pme_code = 0x524052,
+	.pme_short_desc = "Final Pump Scope (Group) ended up either larger or smaller than Initial Pump Scope for instruction fetches and prefetches",
+	.pme_long_desc = "Final Pump Scope(Group) to get data sourced, ended up larger than Initial Pump Scope OR Final Pump Scope(Group) got data from source that was at smaller scope(Chip) Final pump was group pump and initial pump was chip or final and initial pump was gro",
+},
+[ POWER8_PME_PM_INST_ALL_GRP_PUMP_MPRED_RTY ] = {
+	.pme_name = "PM_INST_ALL_GRP_PUMP_MPRED_RTY",
+	.pme_code = 0x514052,
+	.pme_short_desc = "Final Pump Scope (Group) ended up larger than Initial Pump Scope (Chip) for instruction fetches and prefetches",
+	.pme_long_desc = "Final Pump Scope(Group) to get data sourced, ended up larger than Initial Pump Scope (Chip) Final pump was group pump and initial pump was chip pumpfor an instruction fetch",
+},
+[ POWER8_PME_PM_INST_ALL_PUMP_CPRED ] = {
+	.pme_name = "PM_INST_ALL_PUMP_CPRED",
+	.pme_code = 0x514054,
+	.pme_short_desc = "Pump prediction correct. Counts across all types of pumps for instruction fetches and prefetches",
+	.pme_long_desc = "Pump prediction correct. Counts across all types of pumpsfor an instruction fetch",
+},
+[ POWER8_PME_PM_INST_ALL_PUMP_MPRED ] = {
+	.pme_name = "PM_INST_ALL_PUMP_MPRED",
+	.pme_code = 0x544052,
+	.pme_short_desc = "Pump misprediction. Counts across all types of pumps for instruction fetches and prefetches",
+	.pme_long_desc = "Pump Mis prediction Counts across all types of pumpsfor an instruction fetch",
+},
+[ POWER8_PME_PM_INST_ALL_SYS_PUMP_CPRED ] = {
+	.pme_name = "PM_INST_ALL_SYS_PUMP_CPRED",
+	.pme_code = 0x534050,
+	.pme_short_desc = "Initial and Final Pump Scope was system pump (prediction=correct) for instruction fetches and prefetches",
+	.pme_long_desc = "Initial and Final Pump Scope and data sourced across this scope was system pump for an instruction fetch",
+},
+[ POWER8_PME_PM_INST_ALL_SYS_PUMP_MPRED ] = {
+	.pme_name = "PM_INST_ALL_SYS_PUMP_MPRED",
+	.pme_code = 0x534052,
+	.pme_short_desc = "Final Pump Scope (system) mispredicted. Either the original scope was too small (Chip/Group) or the original scope was System and it should have been smaller. Counts for instruction fetches and prefetches",
+	.pme_long_desc = "Final Pump Scope(system) to get data sourced, ended up larger than Initial Pump Scope(Chip/Group) OR Final Pump Scope(system) got data from source that was at smaller scope(Chip/group) Final pump was system pump and initial pump was chip or group or",
+},
+[ POWER8_PME_PM_INST_ALL_SYS_PUMP_MPRED_RTY ] = {
+	.pme_name = "PM_INST_ALL_SYS_PUMP_MPRED_RTY",
+	.pme_code = 0x544050,
+	.pme_short_desc = "Final Pump Scope (system) ended up larger than Initial Pump Scope (Chip/Group) for instruction fetches and prefetches",
+	.pme_long_desc = "Final Pump Scope(system) to get data sourced, ended up larger than Initial Pump Scope (Chip or Group) for an instruction fetch",
+},
+[ POWER8_PME_PM_INST_CHIP_PUMP_CPRED ] = {
+	.pme_name = "PM_INST_CHIP_PUMP_CPRED",
+	.pme_code = 0x14050,
+	.pme_short_desc = "Initial and Final Pump Scope was chip pump (prediction=correct) for an instruction fetch",
+	.pme_long_desc = "Initial and Final Pump Scope and data sourced across this scope was chip pump (prediction=correct) for an instruction fetch.",
+},
 [ POWER8_PME_PM_INST_CMPL ] = {
 	.pme_name = "PM_INST_CMPL",
-	.pme_code = 0x10002,
+	.pme_code = 0x2,
 	.pme_short_desc = "Number of PowerPC Instructions that completed.",
 	.pme_long_desc = "PPC Instructions Finished (completed).",
 },
+[ POWER8_PME_PM_INST_DISP ] = {
+	.pme_name = "PM_INST_DISP",
+	.pme_code = 0x200f2,
+	.pme_short_desc = "PPC Dispatched",
+	.pme_long_desc = "PPC Dispatched.",
+},
+[ POWER8_PME_PM_INST_FROM_DL2L3_MOD ] = {
+	.pme_name = "PM_INST_FROM_DL2L3_MOD",
+	.pme_code = 0x44048,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_DL2L3_SHR ] = {
+	.pme_name = "PM_INST_FROM_DL2L3_SHR",
+	.pme_code = 0x34048,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_DL4 ] = {
+	.pme_name = "PM_INST_FROM_DL4",
+	.pme_code = 0x3404c,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from another chip's L4 on a different Node or Group (Distant) due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from another chip's L4 on a different Node or Group (Distant) due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_DMEM ] = {
+	.pme_name = "PM_INST_FROM_DMEM",
+	.pme_code = 0x4404c,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from another chip's memory on the same Node or Group (Distant) due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from another chip's memory on the same Node or Group (Distant) due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_L1 ] = {
+	.pme_name = "PM_INST_FROM_L1",
+	.pme_code = 0x4080,
+	.pme_short_desc = "Instruction fetches from L1",
+	.pme_long_desc = "Instruction fetches from L1",
+},
+[ POWER8_PME_PM_INST_FROM_L2 ] = {
+	.pme_name = "PM_INST_FROM_L2",
+	.pme_code = 0x14042,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from local core's L2 due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from local core's L2 due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_L21_MOD ] = {
+	.pme_name = "PM_INST_FROM_L21_MOD",
+	.pme_code = 0x44046,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another core's L2 on the same chip due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another core's L2 on the same chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_L21_SHR ] = {
+	.pme_name = "PM_INST_FROM_L21_SHR",
+	.pme_code = 0x34046,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another core's L2 on the same chip due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another core's L2 on the same chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_L2MISS ] = {
+	.pme_name = "PM_INST_FROM_L2MISS",
+	.pme_code = 0x1404e,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from a localtion other than the local core's L2 due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from a localtion other than the local core's L2 due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_L2_DISP_CONFLICT_LDHITST ] = {
+	.pme_name = "PM_INST_FROM_L2_DISP_CONFLICT_LDHITST",
+	.pme_code = 0x34040,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from local core's L2 with load hit store conflict due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from local core's L2 with load hit store conflict due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_L2_DISP_CONFLICT_OTHER ] = {
+	.pme_name = "PM_INST_FROM_L2_DISP_CONFLICT_OTHER",
+	.pme_code = 0x44040,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from local core's L2 with dispatch conflict due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from local core's L2 with dispatch conflict due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_L2_MEPF ] = {
+	.pme_name = "PM_INST_FROM_L2_MEPF",
+	.pme_code = 0x24040,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from local core's L2 hit without dispatch conflicts on Mepf state. due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from local core's L2 hit without dispatch conflicts on Mepf state. due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_L2_NO_CONFLICT ] = {
+	.pme_name = "PM_INST_FROM_L2_NO_CONFLICT",
+	.pme_code = 0x14040,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from local core's L2 without conflict due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from local core's L2 without conflict due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_L3 ] = {
+	.pme_name = "PM_INST_FROM_L3",
+	.pme_code = 0x44042,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from local core's L3 due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from local core's L3 due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_L31_ECO_MOD ] = {
+	.pme_name = "PM_INST_FROM_L31_ECO_MOD",
+	.pme_code = 0x44044,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another core's ECO L3 on the same chip due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another core's ECO L3 on the same chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_L31_ECO_SHR ] = {
+	.pme_name = "PM_INST_FROM_L31_ECO_SHR",
+	.pme_code = 0x34044,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another core's ECO L3 on the same chip due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another core's ECO L3 on the same chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_L31_MOD ] = {
+	.pme_name = "PM_INST_FROM_L31_MOD",
+	.pme_code = 0x24044,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another core's L3 on the same chip due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another core's L3 on the same chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_L31_SHR ] = {
+	.pme_name = "PM_INST_FROM_L31_SHR",
+	.pme_code = 0x14046,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another core's L3 on the same chip due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another core's L3 on the same chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_L3MISS ] = {
+	.pme_name = "PM_INST_FROM_L3MISS",
+	.pme_code = 0x300fa,
+	.pme_short_desc = "Marked instruction was reloaded from a location beyond the local chiplet",
+	.pme_long_desc = "Inst from L3 miss.",
+},
+[ POWER8_PME_PM_INST_FROM_L3MISS_MOD ] = {
+	.pme_name = "PM_INST_FROM_L3MISS_MOD",
+	.pme_code = 0x4404e,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from a localtion other than the local core's L3 due to a instruction fetch",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from a localtion other than the local core's L3 due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_L3_DISP_CONFLICT ] = {
+	.pme_name = "PM_INST_FROM_L3_DISP_CONFLICT",
+	.pme_code = 0x34042,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from local core's L3 with dispatch conflict due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from local core's L3 with dispatch conflict due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_L3_MEPF ] = {
+	.pme_name = "PM_INST_FROM_L3_MEPF",
+	.pme_code = 0x24042,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from local core's L3 without dispatch conflicts hit on Mepf state. due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from local core's L3 without dispatch conflicts hit on Mepf state. due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_L3_NO_CONFLICT ] = {
+	.pme_name = "PM_INST_FROM_L3_NO_CONFLICT",
+	.pme_code = 0x14044,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from local core's L3 without conflict due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from local core's L3 without conflict due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_LL4 ] = {
+	.pme_name = "PM_INST_FROM_LL4",
+	.pme_code = 0x1404c,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from the local chip's L4 cache due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from the local chip's L4 cache due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_LMEM ] = {
+	.pme_name = "PM_INST_FROM_LMEM",
+	.pme_code = 0x24048,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from the local chip's Memory due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from the local chip's Memory due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_MEMORY ] = {
+	.pme_name = "PM_INST_FROM_MEMORY",
+	.pme_code = 0x2404c,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from a memory location including L4 from local remote or distant due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from a memory location including L4 from local remote or distant due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_OFF_CHIP_CACHE ] = {
+	.pme_name = "PM_INST_FROM_OFF_CHIP_CACHE",
+	.pme_code = 0x4404a,
+	.pme_short_desc = "The processor's Instruction cache was reloaded either shared or modified data from another core's L2/L3 on a different chip (remote or distant) due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded either shared or modified data from another core's L2/L3 on a different chip (remote or distant) due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_ON_CHIP_CACHE ] = {
+	.pme_name = "PM_INST_FROM_ON_CHIP_CACHE",
+	.pme_code = 0x14048,
+	.pme_short_desc = "The processor's Instruction cache was reloaded either shared or modified data from another core's L2/L3 on the same chip due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded either shared or modified data from another core's L2/L3 on the same chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_RL2L3_MOD ] = {
+	.pme_name = "PM_INST_FROM_RL2L3_MOD",
+	.pme_code = 0x24046,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Modified (M) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_RL2L3_SHR ] = {
+	.pme_name = "PM_INST_FROM_RL2L3_SHR",
+	.pme_code = 0x1404a,
+	.pme_short_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded with Shared (S) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_RL4 ] = {
+	.pme_name = "PM_INST_FROM_RL4",
+	.pme_code = 0x2404a,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from another chip's L4 on the same Node or Group ( Remote) due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from another chip's L4 on the same Node or Group ( Remote) due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_FROM_RMEM ] = {
+	.pme_name = "PM_INST_FROM_RMEM",
+	.pme_code = 0x3404a,
+	.pme_short_desc = "The processor's Instruction cache was reloaded from another chip's memory on the same Node or Group ( Remote) due to an instruction fetch (not prefetch)",
+	.pme_long_desc = "The processor's Instruction cache was reloaded from another chip's memory on the same Node or Group ( Remote) due to either an instruction fetch or instruction fetch plus prefetch if MMCR1[17] is 1 .",
+},
+[ POWER8_PME_PM_INST_GRP_PUMP_CPRED ] = {
+	.pme_name = "PM_INST_GRP_PUMP_CPRED",
+	.pme_code = 0x24050,
+	.pme_short_desc = "Initial and Final Pump Scope was group pump (prediction=correct) for an instruction fetch",
+	.pme_long_desc = "Initial and Final Pump Scope and data sourced across this scope was group pump for an instruction fetch.",
+},
+[ POWER8_PME_PM_INST_GRP_PUMP_MPRED ] = {
+	.pme_name = "PM_INST_GRP_PUMP_MPRED",
+	.pme_code = 0x24052,
+	.pme_short_desc = "Final Pump Scope (Group) ended up either larger or smaller than Initial Pump Scope for an instruction fetch",
+	.pme_long_desc = "Final Pump Scope(Group) to get data sourced, ended up larger than Initial Pump Scope OR Final Pump Scope(Group) got data from source that was at smaller scope(Chip) Final pump was group pump and initial pump was chip or final and initial pump was gro",
+},
+[ POWER8_PME_PM_INST_GRP_PUMP_MPRED_RTY ] = {
+	.pme_name = "PM_INST_GRP_PUMP_MPRED_RTY",
+	.pme_code = 0x14052,
+	.pme_short_desc = "Final Pump Scope (Group) ended up larger than Initial Pump Scope (Chip) for an instruction fetch",
+	.pme_long_desc = "Final Pump Scope(Group) to get data sourced, ended up larger than Initial Pump Scope (Chip) Final pump was group pump and initial pump was chip pumpfor an instruction fetch.",
+},
+[ POWER8_PME_PM_INST_IMC_MATCH_CMPL ] = {
+	.pme_name = "PM_INST_IMC_MATCH_CMPL",
+	.pme_code = 0x1003a,
+	.pme_short_desc = "IMC Match Count ( Not architected in P8)",
+	.pme_long_desc = "IMC Match Count.",
+},
+[ POWER8_PME_PM_INST_IMC_MATCH_DISP ] = {
+	.pme_name = "PM_INST_IMC_MATCH_DISP",
+	.pme_code = 0x30016,
+	.pme_short_desc = "Matched Instructions Dispatched",
+	.pme_long_desc = "IMC Matches dispatched.",
+},
+[ POWER8_PME_PM_INST_PUMP_CPRED ] = {
+	.pme_name = "PM_INST_PUMP_CPRED",
+	.pme_code = 0x14054,
+	.pme_short_desc = "Pump prediction correct. Counts across all types of pumps for an instruction fetch",
+	.pme_long_desc = "Pump prediction correct. Counts across all types of pumpsfor an instruction fetch.",
+},
+[ POWER8_PME_PM_INST_PUMP_MPRED ] = {
+	.pme_name = "PM_INST_PUMP_MPRED",
+	.pme_code = 0x44052,
+	.pme_short_desc = "Pump misprediction. Counts across all types of pumps for an instruction fetch",
+	.pme_long_desc = "Pump Mis prediction Counts across all types of pumpsfor an instruction fetch.",
+},
+[ POWER8_PME_PM_INST_SYS_PUMP_CPRED ] = {
+	.pme_name = "PM_INST_SYS_PUMP_CPRED",
+	.pme_code = 0x34050,
+	.pme_short_desc = "Initial and Final Pump Scope was system pump (prediction=correct) for an instruction fetch",
+	.pme_long_desc = "Initial and Final Pump Scope and data sourced across this scope was system pump for an instruction fetch.",
+},
+[ POWER8_PME_PM_INST_SYS_PUMP_MPRED ] = {
+	.pme_name = "PM_INST_SYS_PUMP_MPRED",
+	.pme_code = 0x34052,
+	.pme_short_desc = "Final Pump Scope (system) mispredicted. Either the original scope was too small (Chip/Group) or the original scope was System and it should have been smaller. Counts for an instruction fetch",
+	.pme_long_desc = "Final Pump Scope(system) to get data sourced, ended up larger than Initial Pump Scope(Chip/Group) OR Final Pump Scope(system) got data from source that was at smaller scope(Chip/group) Final pump was system pump and initial pump was chip or group or",
+},
+[ POWER8_PME_PM_INST_SYS_PUMP_MPRED_RTY ] = {
+	.pme_name = "PM_INST_SYS_PUMP_MPRED_RTY",
+	.pme_code = 0x44050,
+	.pme_short_desc = "Final Pump Scope (system) ended up larger than Initial Pump Scope (Chip/Group) for an instruction fetch",
+	.pme_long_desc = "Final Pump Scope(system) to get data sourced, ended up larger than Initial Pump Scope (Chip or Group) for an instruction fetch.",
+},
 [ POWER8_PME_PM_IOPS_CMPL ] = {
 	.pme_name = "PM_IOPS_CMPL",
 	.pme_code = 0x10014,
 	.pme_short_desc = "Internal Operations completed",
 	.pme_long_desc = "IOPS Completed.",
 },
+[ POWER8_PME_PM_IOPS_DISP ] = {
+	.pme_name = "PM_IOPS_DISP",
+	.pme_code = 0x30014,
+	.pme_short_desc = "Internal Operations dispatched",
+	.pme_long_desc = "IOPS dispatched.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_DL2L3_MOD ] = {
+	.pme_name = "PM_IPTEG_FROM_DL2L3_MOD",
+	.pme_code = 0x45048,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_DL2L3_SHR ] = {
+	.pme_name = "PM_IPTEG_FROM_DL2L3_SHR",
+	.pme_code = 0x35048,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_DL4 ] = {
+	.pme_name = "PM_IPTEG_FROM_DL4",
+	.pme_code = 0x3504c,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from another chip's L4 on a different Node or Group (Distant) due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from another chip's L4 on a different Node or Group (Distant) due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_DMEM ] = {
+	.pme_name = "PM_IPTEG_FROM_DMEM",
+	.pme_code = 0x4504c,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from another chip's memory on the same Node or Group (Distant) due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from another chip's memory on the same Node or Group (Distant) due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_L2 ] = {
+	.pme_name = "PM_IPTEG_FROM_L2",
+	.pme_code = 0x15042,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L2 due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L2 due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_L21_MOD ] = {
+	.pme_name = "PM_IPTEG_FROM_L21_MOD",
+	.pme_code = 0x45046,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another core's L2 on the same chip due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another core's L2 on the same chip due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_L21_SHR ] = {
+	.pme_name = "PM_IPTEG_FROM_L21_SHR",
+	.pme_code = 0x35046,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another core's L2 on the same chip due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another core's L2 on the same chip due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_L2MISS ] = {
+	.pme_name = "PM_IPTEG_FROM_L2MISS",
+	.pme_code = 0x1504e,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from a localtion other than the local core's L2 due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from a localtion other than the local core's L2 due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_L2_DISP_CONFLICT_LDHITST ] = {
+	.pme_name = "PM_IPTEG_FROM_L2_DISP_CONFLICT_LDHITST",
+	.pme_code = 0x35040,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L2 with load hit store conflict due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L2 with load hit store conflict due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_L2_DISP_CONFLICT_OTHER ] = {
+	.pme_name = "PM_IPTEG_FROM_L2_DISP_CONFLICT_OTHER",
+	.pme_code = 0x45040,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L2 with dispatch conflict due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L2 with dispatch conflict due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_L2_MEPF ] = {
+	.pme_name = "PM_IPTEG_FROM_L2_MEPF",
+	.pme_code = 0x25040,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L2 hit without dispatch conflicts on Mepf state. due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L2 hit without dispatch conflicts on Mepf state. due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_L2_NO_CONFLICT ] = {
+	.pme_name = "PM_IPTEG_FROM_L2_NO_CONFLICT",
+	.pme_code = 0x15040,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L2 without conflict due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L2 without conflict due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_L3 ] = {
+	.pme_name = "PM_IPTEG_FROM_L3",
+	.pme_code = 0x45042,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L3 due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L3 due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_L31_ECO_MOD ] = {
+	.pme_name = "PM_IPTEG_FROM_L31_ECO_MOD",
+	.pme_code = 0x45044,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another core's ECO L3 on the same chip due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another core's ECO L3 on the same chip due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_L31_ECO_SHR ] = {
+	.pme_name = "PM_IPTEG_FROM_L31_ECO_SHR",
+	.pme_code = 0x35044,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another core's ECO L3 on the same chip due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another core's ECO L3 on the same chip due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_L31_MOD ] = {
+	.pme_name = "PM_IPTEG_FROM_L31_MOD",
+	.pme_code = 0x25044,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another core's L3 on the same chip due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another core's L3 on the same chip due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_L31_SHR ] = {
+	.pme_name = "PM_IPTEG_FROM_L31_SHR",
+	.pme_code = 0x15046,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another core's L3 on the same chip due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another core's L3 on the same chip due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_L3MISS ] = {
+	.pme_name = "PM_IPTEG_FROM_L3MISS",
+	.pme_code = 0x4504e,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from a localtion other than the local core's L3 due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from a localtion other than the local core's L3 due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_L3_DISP_CONFLICT ] = {
+	.pme_name = "PM_IPTEG_FROM_L3_DISP_CONFLICT",
+	.pme_code = 0x35042,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L3 with dispatch conflict due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L3 with dispatch conflict due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_L3_MEPF ] = {
+	.pme_name = "PM_IPTEG_FROM_L3_MEPF",
+	.pme_code = 0x25042,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L3 without dispatch conflicts hit on Mepf state. due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L3 without dispatch conflicts hit on Mepf state. due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_L3_NO_CONFLICT ] = {
+	.pme_name = "PM_IPTEG_FROM_L3_NO_CONFLICT",
+	.pme_code = 0x15044,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L3 without conflict due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L3 without conflict due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_LL4 ] = {
+	.pme_name = "PM_IPTEG_FROM_LL4",
+	.pme_code = 0x1504c,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from the local chip's L4 cache due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from the local chip's L4 cache due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_LMEM ] = {
+	.pme_name = "PM_IPTEG_FROM_LMEM",
+	.pme_code = 0x25048,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from the local chip's Memory due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from the local chip's Memory due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_MEMORY ] = {
+	.pme_name = "PM_IPTEG_FROM_MEMORY",
+	.pme_code = 0x2504c,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from a memory location including L4 from local remote or distant due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from a memory location including L4 from local remote or distant due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_OFF_CHIP_CACHE ] = {
+	.pme_name = "PM_IPTEG_FROM_OFF_CHIP_CACHE",
+	.pme_code = 0x4504a,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB either shared or modified data from another core's L2/L3 on a different chip (remote or distant) due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB either shared or modified data from another core's L2/L3 on a different chip (remote or distant) due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_ON_CHIP_CACHE ] = {
+	.pme_name = "PM_IPTEG_FROM_ON_CHIP_CACHE",
+	.pme_code = 0x15048,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB either shared or modified data from another core's L2/L3 on the same chip due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB either shared or modified data from another core's L2/L3 on the same chip due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_RL2L3_MOD ] = {
+	.pme_name = "PM_IPTEG_FROM_RL2L3_MOD",
+	.pme_code = 0x25046,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_RL2L3_SHR ] = {
+	.pme_name = "PM_IPTEG_FROM_RL2L3_SHR",
+	.pme_code = 0x1504a,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_RL4 ] = {
+	.pme_name = "PM_IPTEG_FROM_RL4",
+	.pme_code = 0x2504a,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from another chip's L4 on the same Node or Group ( Remote) due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from another chip's L4 on the same Node or Group ( Remote) due to a instruction side request.",
+},
+[ POWER8_PME_PM_IPTEG_FROM_RMEM ] = {
+	.pme_name = "PM_IPTEG_FROM_RMEM",
+	.pme_code = 0x3504a,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from another chip's memory on the same Node or Group ( Remote) due to a instruction side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from another chip's memory on the same Node or Group ( Remote) due to a instruction side request.",
+},
+[ POWER8_PME_PM_ISIDE_DISP ] = {
+	.pme_name = "PM_ISIDE_DISP",
+	.pme_code = 0x617082,
+	.pme_short_desc = "All i-side dispatch attempts",
+	.pme_long_desc = "All i-side dispatch attempts",
+},
+[ POWER8_PME_PM_ISIDE_DISP_FAIL ] = {
+	.pme_name = "PM_ISIDE_DISP_FAIL",
+	.pme_code = 0x627084,
+	.pme_short_desc = "All i-side dispatch attempts that failed due to a addr collision with another machine",
+	.pme_long_desc = "All i-side dispatch attempts that failed due to a addr collision with another machine",
+},
+[ POWER8_PME_PM_ISIDE_DISP_FAIL_OTHER ] = {
+	.pme_name = "PM_ISIDE_DISP_FAIL_OTHER",
+	.pme_code = 0x627086,
+	.pme_short_desc = "All i-side dispatch attempts that failed due to a reason other than addrs collision",
+	.pme_long_desc = "All i-side dispatch attempts that failed due to a reason other than addrs collision",
+},
+[ POWER8_PME_PM_ISIDE_L2MEMACC ] = {
+	.pme_name = "PM_ISIDE_L2MEMACC",
+	.pme_code = 0x4608e,
+	.pme_short_desc = "valid when first beat of data comes in for an i-side fetch where data came from mem(or L4)",
+	.pme_long_desc = "valid when first beat of data comes in for an i-side fetch where data came from mem(or L4)",
+},
+[ POWER8_PME_PM_ISIDE_MRU_TOUCH ] = {
+	.pme_name = "PM_ISIDE_MRU_TOUCH",
+	.pme_code = 0x44608e,
+	.pme_short_desc = "Iside L2 MRU touch",
+	.pme_long_desc = "Iside L2 MRU touch",
+},
+[ POWER8_PME_PM_ISLB_MISS ] = {
+	.pme_name = "PM_ISLB_MISS",
+	.pme_code = 0xd096,
+	.pme_short_desc = "I SLB Miss.",
+	.pme_long_desc = "I SLB Miss.",
+},
+[ POWER8_PME_PM_ISU_REF_FX0 ] = {
+	.pme_name = "PM_ISU_REF_FX0",
+	.pme_code = 0x30ac,
+	.pme_short_desc = "FX0 ISU reject",
+	.pme_long_desc = "FX0 ISU reject",
+},
+[ POWER8_PME_PM_ISU_REF_FX1 ] = {
+	.pme_name = "PM_ISU_REF_FX1",
+	.pme_code = 0x30ae,
+	.pme_short_desc = "FX1 ISU reject",
+	.pme_long_desc = "FX1 ISU reject",
+},
+[ POWER8_PME_PM_ISU_REF_FXU ] = {
+	.pme_name = "PM_ISU_REF_FXU",
+	.pme_code = 0x38ac,
+	.pme_short_desc = "FXU ISU reject from either pipe",
+	.pme_long_desc = "ISU",
+},
+[ POWER8_PME_PM_ISU_REF_LS0 ] = {
+	.pme_name = "PM_ISU_REF_LS0",
+	.pme_code = 0x30b0,
+	.pme_short_desc = "LS0 ISU reject",
+	.pme_long_desc = "LS0 ISU reject",
+},
+[ POWER8_PME_PM_ISU_REF_LS1 ] = {
+	.pme_name = "PM_ISU_REF_LS1",
+	.pme_code = 0x30b2,
+	.pme_short_desc = "LS1 ISU reject",
+	.pme_long_desc = "LS1 ISU reject",
+},
+[ POWER8_PME_PM_ISU_REF_LS2 ] = {
+	.pme_name = "PM_ISU_REF_LS2",
+	.pme_code = 0x30b4,
+	.pme_short_desc = "LS2 ISU reject",
+	.pme_long_desc = "LS2 ISU reject",
+},
+[ POWER8_PME_PM_ISU_REF_LS3 ] = {
+	.pme_name = "PM_ISU_REF_LS3",
+	.pme_code = 0x30b6,
+	.pme_short_desc = "LS3 ISU reject",
+	.pme_long_desc = "LS3 ISU reject",
+},
+[ POWER8_PME_PM_ISU_REJECTS_ALL ] = {
+	.pme_name = "PM_ISU_REJECTS_ALL",
+	.pme_code = 0x309c,
+	.pme_short_desc = "All isu rejects could be more than 1 per cycle",
+	.pme_long_desc = "All isu rejects could be more than 1 per cycle",
+},
+[ POWER8_PME_PM_ISU_REJECT_RES_NA ] = {
+	.pme_name = "PM_ISU_REJECT_RES_NA",
+	.pme_code = 0x30a2,
+	.pme_short_desc = "ISU reject due to resource not available",
+	.pme_long_desc = "ISU reject due to resource not available",
+},
+[ POWER8_PME_PM_ISU_REJECT_SAR_BYPASS ] = {
+	.pme_name = "PM_ISU_REJECT_SAR_BYPASS",
+	.pme_code = 0x309e,
+	.pme_short_desc = "Reject because of SAR bypass",
+	.pme_long_desc = "Reject because of SAR bypass",
+},
+[ POWER8_PME_PM_ISU_REJECT_SRC_NA ] = {
+	.pme_name = "PM_ISU_REJECT_SRC_NA",
+	.pme_code = 0x30a0,
+	.pme_short_desc = "ISU reject due to source not available",
+	.pme_long_desc = "ISU reject due to source not available",
+},
+[ POWER8_PME_PM_ISU_REJ_VS0 ] = {
+	.pme_name = "PM_ISU_REJ_VS0",
+	.pme_code = 0x30a8,
+	.pme_short_desc = "VS0 ISU reject",
+	.pme_long_desc = "VS0 ISU reject",
+},
+[ POWER8_PME_PM_ISU_REJ_VS1 ] = {
+	.pme_name = "PM_ISU_REJ_VS1",
+	.pme_code = 0x30aa,
+	.pme_short_desc = "VS1 ISU reject",
+	.pme_long_desc = "VS1 ISU reject",
+},
+[ POWER8_PME_PM_ISU_REJ_VSU ] = {
+	.pme_name = "PM_ISU_REJ_VSU",
+	.pme_code = 0x38a8,
+	.pme_short_desc = "VSU ISU reject from either pipe",
+	.pme_long_desc = "ISU",
+},
+[ POWER8_PME_PM_ISYNC ] = {
+	.pme_name = "PM_ISYNC",
+	.pme_code = 0x30b8,
+	.pme_short_desc = "Isync count per thread",
+	.pme_long_desc = "Isync count per thread",
+},
+[ POWER8_PME_PM_ITLB_MISS ] = {
+	.pme_name = "PM_ITLB_MISS",
+	.pme_code = 0x400fc,
+	.pme_short_desc = "ITLB Reloaded (always zero on POWER6)",
+	.pme_long_desc = "ITLB Reloaded.",
+},
+[ POWER8_PME_PM_L1MISS_LAT_EXC_1024 ] = {
+	.pme_name = "PM_L1MISS_LAT_EXC_1024",
+	.pme_code = 0x200301ea,
+	.pme_short_desc = "L1 misses that took longer than 1024 cyles to resolve (miss to reload)",
+	.pme_long_desc = "Reload latency exceeded 1024 cyc",
+},
+[ POWER8_PME_PM_L1MISS_LAT_EXC_2048 ] = {
+	.pme_name = "PM_L1MISS_LAT_EXC_2048",
+	.pme_code = 0x200401ec,
+	.pme_short_desc = "L1 misses that took longer than 2048 cyles to resolve (miss to reload)",
+	.pme_long_desc = "Reload latency exceeded 2048 cyc",
+},
+[ POWER8_PME_PM_L1MISS_LAT_EXC_256 ] = {
+	.pme_name = "PM_L1MISS_LAT_EXC_256",
+	.pme_code = 0x200101e8,
+	.pme_short_desc = "L1 misses that took longer than 256 cyles to resolve (miss to reload)",
+	.pme_long_desc = "Reload latency exceeded 256 cyc",
+},
+[ POWER8_PME_PM_L1MISS_LAT_EXC_32 ] = {
+	.pme_name = "PM_L1MISS_LAT_EXC_32",
+	.pme_code = 0x200201e6,
+	.pme_short_desc = "L1 misses that took longer than 32 cyles to resolve (miss to reload)",
+	.pme_long_desc = "Reload latency exceeded 32 cyc",
+},
+[ POWER8_PME_PM_L1PF_L2MEMACC ] = {
+	.pme_name = "PM_L1PF_L2MEMACC",
+	.pme_code = 0x26086,
+	.pme_short_desc = "valid when first beat of data comes in for an L1pref where data came from mem(or L4)",
+	.pme_long_desc = "valid when first beat of data comes in for an L1pref where data came from mem(or L4)",
+},
+[ POWER8_PME_PM_L1_DCACHE_RELOADED_ALL ] = {
+	.pme_name = "PM_L1_DCACHE_RELOADED_ALL",
+	.pme_code = 0x1002c,
+	.pme_short_desc = "L1 data cache reloaded for demand or prefetch",
+	.pme_long_desc = "L1 data cache reloaded for demand or prefetch .",
+},
+[ POWER8_PME_PM_L1_DCACHE_RELOAD_VALID ] = {
+	.pme_name = "PM_L1_DCACHE_RELOAD_VALID",
+	.pme_code = 0x300f6,
+	.pme_short_desc = "DL1 reloaded due to Demand Load",
+	.pme_long_desc = "DL1 reloaded due to Demand Load .",
+},
+[ POWER8_PME_PM_L1_DEMAND_WRITE ] = {
+	.pme_name = "PM_L1_DEMAND_WRITE",
+	.pme_code = 0x408c,
+	.pme_short_desc = "Instruction Demand sectors wriittent into IL1",
+	.pme_long_desc = "Instruction Demand sectors wriittent into IL1",
+},
+[ POWER8_PME_PM_L1_ICACHE_MISS ] = {
+	.pme_name = "PM_L1_ICACHE_MISS",
+	.pme_code = 0x200fd,
+	.pme_short_desc = "Demand iCache Miss",
+	.pme_long_desc = "Demand iCache Miss.",
+},
+[ POWER8_PME_PM_L1_ICACHE_RELOADED_ALL ] = {
+	.pme_name = "PM_L1_ICACHE_RELOADED_ALL",
+	.pme_code = 0x40012,
+	.pme_short_desc = "Counts all Icache reloads includes demand, prefetchm prefetch turned into demand and demand turned into prefetch",
+	.pme_long_desc = "Counts all Icache reloads includes demand, prefetchm prefetch turned into demand and demand turned into prefetch.",
+},
+[ POWER8_PME_PM_L1_ICACHE_RELOADED_PREF ] = {
+	.pme_name = "PM_L1_ICACHE_RELOADED_PREF",
+	.pme_code = 0x30068,
+	.pme_short_desc = "Counts all Icache prefetch reloads ( includes demand turned into prefetch)",
+	.pme_long_desc = "Counts all Icache prefetch reloads ( includes demand turned into prefetch).",
+},
+[ POWER8_PME_PM_L2_CASTOUT_MOD ] = {
+	.pme_name = "PM_L2_CASTOUT_MOD",
+	.pme_code = 0x417080,
+	.pme_short_desc = "L2 Castouts - Modified (M, Mu, Me)",
+	.pme_long_desc = "L2 Castouts - Modified (M, Mu, Me)",
+},
+[ POWER8_PME_PM_L2_CASTOUT_SHR ] = {
+	.pme_name = "PM_L2_CASTOUT_SHR",
+	.pme_code = 0x417082,
+	.pme_short_desc = "L2 Castouts - Shared (T, Te, Si, S)",
+	.pme_long_desc = "L2 Castouts - Shared (T, Te, Si, S)",
+},
+[ POWER8_PME_PM_L2_CHIP_PUMP ] = {
+	.pme_name = "PM_L2_CHIP_PUMP",
+	.pme_code = 0x27084,
+	.pme_short_desc = "RC requests that were local on chip pump attempts",
+	.pme_long_desc = "RC requests that were local on chip pump attempts",
+},
+[ POWER8_PME_PM_L2_DC_INV ] = {
+	.pme_name = "PM_L2_DC_INV",
+	.pme_code = 0x427086,
+	.pme_short_desc = "Dcache invalidates from L2",
+	.pme_long_desc = "Dcache invalidates from L2",
+},
+[ POWER8_PME_PM_L2_DISP_ALL_L2MISS ] = {
+	.pme_name = "PM_L2_DISP_ALL_L2MISS",
+	.pme_code = 0x44608c,
+	.pme_short_desc = "All successful Ld/St dispatches for this thread that were an L2miss.",
+	.pme_long_desc = "All successful Ld/St dispatches for this thread that were an L2miss.",
+},
+[ POWER8_PME_PM_L2_GROUP_PUMP ] = {
+	.pme_name = "PM_L2_GROUP_PUMP",
+	.pme_code = 0x27086,
+	.pme_short_desc = "RC requests that were on Node Pump attempts",
+	.pme_long_desc = "RC requests that were on Node Pump attempts",
+},
+[ POWER8_PME_PM_L2_GRP_GUESS_CORRECT ] = {
+	.pme_name = "PM_L2_GRP_GUESS_CORRECT",
+	.pme_code = 0x626084,
+	.pme_short_desc = "L2 guess grp and guess was correct (data intra-6chip AND ^on-chip)",
+	.pme_long_desc = "L2 guess grp and guess was correct (data intra-6chip AND ^on-chip)",
+},
+[ POWER8_PME_PM_L2_GRP_GUESS_WRONG ] = {
+	.pme_name = "PM_L2_GRP_GUESS_WRONG",
+	.pme_code = 0x626086,
+	.pme_short_desc = "L2 guess grp and guess was not correct (ie data on-chip OR beyond-6chip)",
+	.pme_long_desc = "L2 guess grp and guess was not correct (ie data on-chip OR beyond-6chip)",
+},
+[ POWER8_PME_PM_L2_IC_INV ] = {
+	.pme_name = "PM_L2_IC_INV",
+	.pme_code = 0x427084,
+	.pme_short_desc = "Icache Invalidates from L2",
+	.pme_long_desc = "Icache Invalidates from L2",
+},
+[ POWER8_PME_PM_L2_INST ] = {
+	.pme_name = "PM_L2_INST",
+	.pme_code = 0x436088,
+	.pme_short_desc = "All successful I-side dispatches for this thread (excludes i_l2mru_tch reqs)",
+	.pme_long_desc = "All successful I-side dispatches for this thread (excludes i_l2mru_tch reqs)",
+},
+[ POWER8_PME_PM_L2_INST_MISS ] = {
+	.pme_name = "PM_L2_INST_MISS",
+	.pme_code = 0x43608a,
+	.pme_short_desc = "All successful i-side dispatches that were an L2miss for this thread (excludes i_l2mru_tch reqs)",
+	.pme_long_desc = "All successful i-side dispatches that were an L2miss for this thread (excludes i_l2mru_tch reqs)",
+},
+[ POWER8_PME_PM_L2_LD ] = {
+	.pme_name = "PM_L2_LD",
+	.pme_code = 0x416080,
+	.pme_short_desc = "All successful D-side Load dispatches for this thread",
+	.pme_long_desc = "All successful D-side Load dispatches for this thread",
+},
+[ POWER8_PME_PM_L2_LD_DISP ] = {
+	.pme_name = "PM_L2_LD_DISP",
+	.pme_code = 0x437088,
+	.pme_short_desc = "All successful load dispatches",
+	.pme_long_desc = "All successful load dispatches",
+},
+[ POWER8_PME_PM_L2_LD_HIT ] = {
+	.pme_name = "PM_L2_LD_HIT",
+	.pme_code = 0x43708a,
+	.pme_short_desc = "All successful load dispatches that were L2 hits",
+	.pme_long_desc = "All successful load dispatches that were L2 hits",
+},
+[ POWER8_PME_PM_L2_LD_MISS ] = {
+	.pme_name = "PM_L2_LD_MISS",
+	.pme_code = 0x426084,
+	.pme_short_desc = "All successful D-Side Load dispatches that were an L2miss for this thread",
+	.pme_long_desc = "All successful D-Side Load dispatches that were an L2miss for this thread",
+},
+[ POWER8_PME_PM_L2_LOC_GUESS_CORRECT ] = {
+	.pme_name = "PM_L2_LOC_GUESS_CORRECT",
+	.pme_code = 0x616080,
+	.pme_short_desc = "L2 guess loc and guess was correct (ie data local)",
+	.pme_long_desc = "L2 guess loc and guess was correct (ie data local)",
+},
+[ POWER8_PME_PM_L2_LOC_GUESS_WRONG ] = {
+	.pme_name = "PM_L2_LOC_GUESS_WRONG",
+	.pme_code = 0x616082,
+	.pme_short_desc = "L2 guess loc and guess was not correct (ie data not on chip)",
+	.pme_long_desc = "L2 guess loc and guess was not correct (ie data not on chip)",
+},
+[ POWER8_PME_PM_L2_RCLD_DISP ] = {
+	.pme_name = "PM_L2_RCLD_DISP",
+	.pme_code = 0x516080,
+	.pme_short_desc = "L2 RC load dispatch attempt",
+	.pme_long_desc = "L2 RC load dispatch attempt",
+},
+[ POWER8_PME_PM_L2_RCLD_DISP_FAIL_ADDR ] = {
+	.pme_name = "PM_L2_RCLD_DISP_FAIL_ADDR",
+	.pme_code = 0x516082,
+	.pme_short_desc = "L2 RC load dispatch attempt failed due to address collision with RC/CO/SN/SQ",
+	.pme_long_desc = "L2 RC load dispatch attempt failed due to address collision with RC/CO/SN/SQ",
+},
+[ POWER8_PME_PM_L2_RCLD_DISP_FAIL_OTHER ] = {
+	.pme_name = "PM_L2_RCLD_DISP_FAIL_OTHER",
+	.pme_code = 0x526084,
+	.pme_short_desc = "L2 RC load dispatch attempt failed due to other reasons",
+	.pme_long_desc = "L2 RC load dispatch attempt failed due to other reasons",
+},
+[ POWER8_PME_PM_L2_RCST_DISP ] = {
+	.pme_name = "PM_L2_RCST_DISP",
+	.pme_code = 0x536088,
+	.pme_short_desc = "L2 RC store dispatch attempt",
+	.pme_long_desc = "L2 RC store dispatch attempt",
+},
+[ POWER8_PME_PM_L2_RCST_DISP_FAIL_ADDR ] = {
+	.pme_name = "PM_L2_RCST_DISP_FAIL_ADDR",
+	.pme_code = 0x53608a,
+	.pme_short_desc = "L2 RC store dispatch attempt failed due to address collision with RC/CO/SN/SQ",
+	.pme_long_desc = "L2 RC store dispatch attempt failed due to address collision with RC/CO/SN/SQ",
+},
+[ POWER8_PME_PM_L2_RCST_DISP_FAIL_OTHER ] = {
+	.pme_name = "PM_L2_RCST_DISP_FAIL_OTHER",
+	.pme_code = 0x54608c,
+	.pme_short_desc = "L2 RC store dispatch attempt failed due to other reasons",
+	.pme_long_desc = "L2 RC store dispatch attempt failed due to other reasons",
+},
+[ POWER8_PME_PM_L2_RC_ST_DONE ] = {
+	.pme_name = "PM_L2_RC_ST_DONE",
+	.pme_code = 0x537088,
+	.pme_short_desc = "RC did st to line that was Tx or Sx",
+	.pme_long_desc = "RC did st to line that was Tx or Sx",
+},
+[ POWER8_PME_PM_L2_RTY_LD ] = {
+	.pme_name = "PM_L2_RTY_LD",
+	.pme_code = 0x63708a,
+	.pme_short_desc = "RC retries on PB for any load from core",
+	.pme_long_desc = "RC retries on PB for any load from core",
+},
+[ POWER8_PME_PM_L2_RTY_ST ] = {
+	.pme_name = "PM_L2_RTY_ST",
+	.pme_code = 0x3708a,
+	.pme_short_desc = "RC retries on PB for any store from core",
+	.pme_long_desc = "RC retries on PB for any store from core",
+},
+[ POWER8_PME_PM_L2_SN_M_RD_DONE ] = {
+	.pme_name = "PM_L2_SN_M_RD_DONE",
+	.pme_code = 0x54708c,
+	.pme_short_desc = "SNP dispatched for a read and was M",
+	.pme_long_desc = "SNP dispatched for a read and was M",
+},
+[ POWER8_PME_PM_L2_SN_M_WR_DONE ] = {
+	.pme_name = "PM_L2_SN_M_WR_DONE",
+	.pme_code = 0x54708e,
+	.pme_short_desc = "SNP dispatched for a write and was M",
+	.pme_long_desc = "SNP dispatched for a write and was M",
+},
+[ POWER8_PME_PM_L2_SN_SX_I_DONE ] = {
+	.pme_name = "PM_L2_SN_SX_I_DONE",
+	.pme_code = 0x53708a,
+	.pme_short_desc = "SNP dispatched and went from Sx or Tx to Ix",
+	.pme_long_desc = "SNP dispatched and went from Sx or Tx to Ix",
+},
+[ POWER8_PME_PM_L2_ST ] = {
+	.pme_name = "PM_L2_ST",
+	.pme_code = 0x17080,
+	.pme_short_desc = "All successful D-side store dispatches for this thread",
+	.pme_long_desc = "All successful D-side store dispatches for this thread",
+},
+[ POWER8_PME_PM_L2_ST_DISP ] = {
+	.pme_name = "PM_L2_ST_DISP",
+	.pme_code = 0x44708c,
+	.pme_short_desc = "All successful store dispatches",
+	.pme_long_desc = "All successful store dispatches",
+},
+[ POWER8_PME_PM_L2_ST_HIT ] = {
+	.pme_name = "PM_L2_ST_HIT",
+	.pme_code = 0x44708e,
+	.pme_short_desc = "All successful store dispatches that were L2Hits",
+	.pme_long_desc = "All successful store dispatches that were L2Hits",
+},
+[ POWER8_PME_PM_L2_ST_MISS ] = {
+	.pme_name = "PM_L2_ST_MISS",
+	.pme_code = 0x17082,
+	.pme_short_desc = "All successful D-side store dispatches for this thread that were L2 Miss",
+	.pme_long_desc = "All successful D-side store dispatches for this thread that were L2 Miss",
+},
+[ POWER8_PME_PM_L2_SYS_GUESS_CORRECT ] = {
+	.pme_name = "PM_L2_SYS_GUESS_CORRECT",
+	.pme_code = 0x636088,
+	.pme_short_desc = "L2 guess sys and guess was correct (ie data beyond-6chip)",
+	.pme_long_desc = "L2 guess sys and guess was correct (ie data beyond-6chip)",
+},
+[ POWER8_PME_PM_L2_SYS_GUESS_WRONG ] = {
+	.pme_name = "PM_L2_SYS_GUESS_WRONG",
+	.pme_code = 0x63608a,
+	.pme_short_desc = "L2 guess sys and guess was not correct (ie data ^beyond-6chip)",
+	.pme_long_desc = "L2 guess sys and guess was not correct (ie data ^beyond-6chip)",
+},
+[ POWER8_PME_PM_L2_SYS_PUMP ] = {
+	.pme_name = "PM_L2_SYS_PUMP",
+	.pme_code = 0x617080,
+	.pme_short_desc = "RC requests that were system pump attempts",
+	.pme_long_desc = "RC requests that were system pump attempts",
+},
+[ POWER8_PME_PM_L2_TM_REQ_ABORT ] = {
+	.pme_name = "PM_L2_TM_REQ_ABORT",
+	.pme_code = 0x1e05e,
+	.pme_short_desc = "TM abort",
+	.pme_long_desc = "TM abort.",
+},
+[ POWER8_PME_PM_L2_TM_ST_ABORT_SISTER ] = {
+	.pme_name = "PM_L2_TM_ST_ABORT_SISTER",
+	.pme_code = 0x3e05c,
+	.pme_short_desc = "TM marked store abort",
+	.pme_long_desc = "TM marked store abort.",
+},
+[ POWER8_PME_PM_L3_CINJ ] = {
+	.pme_name = "PM_L3_CINJ",
+	.pme_code = 0x23808a,
+	.pme_short_desc = "l3 ci of cache inject",
+	.pme_long_desc = "l3 ci of cache inject",
+},
+[ POWER8_PME_PM_L3_CI_HIT ] = {
+	.pme_name = "PM_L3_CI_HIT",
+	.pme_code = 0x128084,
+	.pme_short_desc = "L3 Castins Hit (total count",
+	.pme_long_desc = "L3 Castins Hit (total count",
+},
+[ POWER8_PME_PM_L3_CI_MISS ] = {
+	.pme_name = "PM_L3_CI_MISS",
+	.pme_code = 0x128086,
+	.pme_short_desc = "L3 castins miss (total count",
+	.pme_long_desc = "L3 castins miss (total count",
+},
+[ POWER8_PME_PM_L3_CI_USAGE ] = {
+	.pme_name = "PM_L3_CI_USAGE",
+	.pme_code = 0x819082,
+	.pme_short_desc = "rotating sample of 16 CI or CO actives",
+	.pme_long_desc = "rotating sample of 16 CI or CO actives",
+},
+[ POWER8_PME_PM_L3_CO ] = {
+	.pme_name = "PM_L3_CO",
+	.pme_code = 0x438088,
+	.pme_short_desc = "l3 castout occuring ( does not include casthrough or log writes (cinj/dmaw)",
+	.pme_long_desc = "l3 castout occuring ( does not include casthrough or log writes (cinj/dmaw)",
+},
+[ POWER8_PME_PM_L3_CO0_ALLOC ] = {
+	.pme_name = "PM_L3_CO0_ALLOC",
+	.pme_code = 0x83908b,
+	.pme_short_desc = "lifetime, sample of CO machine 0 valid",
+	.pme_long_desc = "0.0",
+},
+[ POWER8_PME_PM_L3_CO0_BUSY ] = {
+	.pme_name = "PM_L3_CO0_BUSY",
+	.pme_code = 0x83908a,
+	.pme_short_desc = "lifetime, sample of CO machine 0 valid",
+	.pme_long_desc = "lifetime, sample of CO machine 0 valid",
+},
+[ POWER8_PME_PM_L3_CO_L31 ] = {
+	.pme_name = "PM_L3_CO_L31",
+	.pme_code = 0x28086,
+	.pme_short_desc = "L3 CO to L3.1 OR of port 0 and 1 ( lossy)",
+	.pme_long_desc = "L3 CO to L3.1 OR of port 0 and 1 ( lossy)",
+},
+[ POWER8_PME_PM_L3_CO_LCO ] = {
+	.pme_name = "PM_L3_CO_LCO",
+	.pme_code = 0x238088,
+	.pme_short_desc = "Total L3 castouts occurred on LCO",
+	.pme_long_desc = "Total L3 castouts occurred on LCO",
+},
+[ POWER8_PME_PM_L3_CO_MEM ] = {
+	.pme_name = "PM_L3_CO_MEM",
+	.pme_code = 0x28084,
+	.pme_short_desc = "L3 CO to memory OR of port 0 and 1 ( lossy)",
+	.pme_long_desc = "L3 CO to memory OR of port 0 and 1 ( lossy)",
+},
+[ POWER8_PME_PM_L3_CO_MEPF ] = {
+	.pme_name = "PM_L3_CO_MEPF",
+	.pme_code = 0x18082,
+	.pme_short_desc = "L3 CO of line in Mep state ( includes casthrough",
+	.pme_long_desc = "L3 CO of line in Mep state ( includes casthrough",
+},
+[ POWER8_PME_PM_L3_GRP_GUESS_CORRECT ] = {
+	.pme_name = "PM_L3_GRP_GUESS_CORRECT",
+	.pme_code = 0xb19082,
+	.pme_short_desc = "Initial scope=group and data from same group (near) (pred successful)",
+	.pme_long_desc = "Initial scope=group and data from same group (near) (pred successful)",
+},
+[ POWER8_PME_PM_L3_GRP_GUESS_WRONG_HIGH ] = {
+	.pme_name = "PM_L3_GRP_GUESS_WRONG_HIGH",
+	.pme_code = 0xb3908a,
+	.pme_short_desc = "Initial scope=group but data from local node. Predition too high",
+	.pme_long_desc = "Initial scope=group but data from local node. Predition too high",
+},
+[ POWER8_PME_PM_L3_GRP_GUESS_WRONG_LOW ] = {
+	.pme_name = "PM_L3_GRP_GUESS_WRONG_LOW",
+	.pme_code = 0xb39088,
+	.pme_short_desc = "Initial scope=group but data from outside group (far or rem). Prediction too Low",
+	.pme_long_desc = "Initial scope=group but data from outside group (far or rem). Prediction too Low",
+},
+[ POWER8_PME_PM_L3_HIT ] = {
+	.pme_name = "PM_L3_HIT",
+	.pme_code = 0x218080,
+	.pme_short_desc = "L3 Hits",
+	.pme_long_desc = "L3 Hits",
+},
+[ POWER8_PME_PM_L3_L2_CO_HIT ] = {
+	.pme_name = "PM_L3_L2_CO_HIT",
+	.pme_code = 0x138088,
+	.pme_short_desc = "L2 castout hits",
+	.pme_long_desc = "L2 castout hits",
+},
+[ POWER8_PME_PM_L3_L2_CO_MISS ] = {
+	.pme_name = "PM_L3_L2_CO_MISS",
+	.pme_code = 0x13808a,
+	.pme_short_desc = "L2 castout miss",
+	.pme_long_desc = "L2 castout miss",
+},
+[ POWER8_PME_PM_L3_LAT_CI_HIT ] = {
+	.pme_name = "PM_L3_LAT_CI_HIT",
+	.pme_code = 0x14808c,
+	.pme_short_desc = "L3 Lateral Castins Hit",
+	.pme_long_desc = "L3 Lateral Castins Hit",
+},
+[ POWER8_PME_PM_L3_LAT_CI_MISS ] = {
+	.pme_name = "PM_L3_LAT_CI_MISS",
+	.pme_code = 0x14808e,
+	.pme_short_desc = "L3 Lateral Castins Miss",
+	.pme_long_desc = "L3 Lateral Castins Miss",
+},
+[ POWER8_PME_PM_L3_LD_HIT ] = {
+	.pme_name = "PM_L3_LD_HIT",
+	.pme_code = 0x228084,
+	.pme_short_desc = "L3 demand LD Hits",
+	.pme_long_desc = "L3 demand LD Hits",
+},
+[ POWER8_PME_PM_L3_LD_MISS ] = {
+	.pme_name = "PM_L3_LD_MISS",
+	.pme_code = 0x228086,
+	.pme_short_desc = "L3 demand LD Miss",
+	.pme_long_desc = "L3 demand LD Miss",
+},
+[ POWER8_PME_PM_L3_LD_PREF ] = {
+	.pme_name = "PM_L3_LD_PREF",
+	.pme_code = 0x1e052,
+	.pme_short_desc = "L3 Load Prefetches",
+	.pme_long_desc = "L3 Load Prefetches.",
+},
+[ POWER8_PME_PM_L3_LOC_GUESS_CORRECT ] = {
+	.pme_name = "PM_L3_LOC_GUESS_CORRECT",
+	.pme_code = 0xb19080,
+	.pme_short_desc = "initial scope=node/chip and data from local node (local) (pred successful)",
+	.pme_long_desc = "initial scope=node/chip and data from local node (local) (pred successful)",
+},
+[ POWER8_PME_PM_L3_LOC_GUESS_WRONG ] = {
+	.pme_name = "PM_L3_LOC_GUESS_WRONG",
+	.pme_code = 0xb29086,
+	.pme_short_desc = "Initial scope=node but data from out side local node (near or far or rem). Prediction too Low",
+	.pme_long_desc = "Initial scope=node but data from out side local node (near or far or rem). Prediction too Low",
+},
+[ POWER8_PME_PM_L3_MISS ] = {
+	.pme_name = "PM_L3_MISS",
+	.pme_code = 0x218082,
+	.pme_short_desc = "L3 Misses",
+	.pme_long_desc = "L3 Misses",
+},
+[ POWER8_PME_PM_L3_P0_CO_L31 ] = {
+	.pme_name = "PM_L3_P0_CO_L31",
+	.pme_code = 0x54808c,
+	.pme_short_desc = "l3 CO to L3.1 (lco) port 0",
+	.pme_long_desc = "l3 CO to L3.1 (lco) port 0",
+},
+[ POWER8_PME_PM_L3_P0_CO_MEM ] = {
+	.pme_name = "PM_L3_P0_CO_MEM",
+	.pme_code = 0x538088,
+	.pme_short_desc = "l3 CO to memory port 0",
+	.pme_long_desc = "l3 CO to memory port 0",
+},
+[ POWER8_PME_PM_L3_P0_CO_RTY ] = {
+	.pme_name = "PM_L3_P0_CO_RTY",
+	.pme_code = 0x929084,
+	.pme_short_desc = "L3 CO received retry port 0",
+	.pme_long_desc = "L3 CO received retry port 0",
+},
+[ POWER8_PME_PM_L3_P0_GRP_PUMP ] = {
+	.pme_name = "PM_L3_P0_GRP_PUMP",
+	.pme_code = 0xa29084,
+	.pme_short_desc = "L3 pf sent with grp scope port 0",
+	.pme_long_desc = "L3 pf sent with grp scope port 0",
+},
+[ POWER8_PME_PM_L3_P0_LCO_DATA ] = {
+	.pme_name = "PM_L3_P0_LCO_DATA",
+	.pme_code = 0x528084,
+	.pme_short_desc = "lco sent with data port 0",
+	.pme_long_desc = "lco sent with data port 0",
+},
+[ POWER8_PME_PM_L3_P0_LCO_NO_DATA ] = {
+	.pme_name = "PM_L3_P0_LCO_NO_DATA",
+	.pme_code = 0x518080,
+	.pme_short_desc = "dataless l3 lco sent port 0",
+	.pme_long_desc = "dataless l3 lco sent port 0",
+},
+[ POWER8_PME_PM_L3_P0_LCO_RTY ] = {
+	.pme_name = "PM_L3_P0_LCO_RTY",
+	.pme_code = 0xa4908c,
+	.pme_short_desc = "L3 LCO received retry port 0",
+	.pme_long_desc = "L3 LCO received retry port 0",
+},
+[ POWER8_PME_PM_L3_P0_NODE_PUMP ] = {
+	.pme_name = "PM_L3_P0_NODE_PUMP",
+	.pme_code = 0xa19080,
+	.pme_short_desc = "L3 pf sent with nodal scope port 0",
+	.pme_long_desc = "L3 pf sent with nodal scope port 0",
+},
+[ POWER8_PME_PM_L3_P0_PF_RTY ] = {
+	.pme_name = "PM_L3_P0_PF_RTY",
+	.pme_code = 0x919080,
+	.pme_short_desc = "L3 PF received retry port 0",
+	.pme_long_desc = "L3 PF received retry port 0",
+},
+[ POWER8_PME_PM_L3_P0_SN_HIT ] = {
+	.pme_name = "PM_L3_P0_SN_HIT",
+	.pme_code = 0x939088,
+	.pme_short_desc = "L3 snoop hit port 0",
+	.pme_long_desc = "L3 snoop hit port 0",
+},
+[ POWER8_PME_PM_L3_P0_SN_INV ] = {
+	.pme_name = "PM_L3_P0_SN_INV",
+	.pme_code = 0x118080,
+	.pme_short_desc = "Port0 snooper detects someone doing a store to a line thats Sx",
+	.pme_long_desc = "Port0 snooper detects someone doing a store to a line thats Sx",
+},
+[ POWER8_PME_PM_L3_P0_SN_MISS ] = {
+	.pme_name = "PM_L3_P0_SN_MISS",
+	.pme_code = 0x94908c,
+	.pme_short_desc = "L3 snoop miss port 0",
+	.pme_long_desc = "L3 snoop miss port 0",
+},
+[ POWER8_PME_PM_L3_P0_SYS_PUMP ] = {
+	.pme_name = "PM_L3_P0_SYS_PUMP",
+	.pme_code = 0xa39088,
+	.pme_short_desc = "L3 pf sent with sys scope port 0",
+	.pme_long_desc = "L3 pf sent with sys scope port 0",
+},
+[ POWER8_PME_PM_L3_P1_CO_L31 ] = {
+	.pme_name = "PM_L3_P1_CO_L31",
+	.pme_code = 0x54808e,
+	.pme_short_desc = "l3 CO to L3.1 (lco) port 1",
+	.pme_long_desc = "l3 CO to L3.1 (lco) port 1",
+},
+[ POWER8_PME_PM_L3_P1_CO_MEM ] = {
+	.pme_name = "PM_L3_P1_CO_MEM",
+	.pme_code = 0x53808a,
+	.pme_short_desc = "l3 CO to memory port 1",
+	.pme_long_desc = "l3 CO to memory port 1",
+},
+[ POWER8_PME_PM_L3_P1_CO_RTY ] = {
+	.pme_name = "PM_L3_P1_CO_RTY",
+	.pme_code = 0x929086,
+	.pme_short_desc = "L3 CO received retry port 1",
+	.pme_long_desc = "L3 CO received retry port 1",
+},
+[ POWER8_PME_PM_L3_P1_GRP_PUMP ] = {
+	.pme_name = "PM_L3_P1_GRP_PUMP",
+	.pme_code = 0xa29086,
+	.pme_short_desc = "L3 pf sent with grp scope port 1",
+	.pme_long_desc = "L3 pf sent with grp scope port 1",
+},
+[ POWER8_PME_PM_L3_P1_LCO_DATA ] = {
+	.pme_name = "PM_L3_P1_LCO_DATA",
+	.pme_code = 0x528086,
+	.pme_short_desc = "lco sent with data port 1",
+	.pme_long_desc = "lco sent with data port 1",
+},
+[ POWER8_PME_PM_L3_P1_LCO_NO_DATA ] = {
+	.pme_name = "PM_L3_P1_LCO_NO_DATA",
+	.pme_code = 0x518082,
+	.pme_short_desc = "dataless l3 lco sent port 1",
+	.pme_long_desc = "dataless l3 lco sent port 1",
+},
+[ POWER8_PME_PM_L3_P1_LCO_RTY ] = {
+	.pme_name = "PM_L3_P1_LCO_RTY",
+	.pme_code = 0xa4908e,
+	.pme_short_desc = "L3 LCO received retry port 1",
+	.pme_long_desc = "L3 LCO received retry port 1",
+},
+[ POWER8_PME_PM_L3_P1_NODE_PUMP ] = {
+	.pme_name = "PM_L3_P1_NODE_PUMP",
+	.pme_code = 0xa19082,
+	.pme_short_desc = "L3 pf sent with nodal scope port 1",
+	.pme_long_desc = "L3 pf sent with nodal scope port 1",
+},
+[ POWER8_PME_PM_L3_P1_PF_RTY ] = {
+	.pme_name = "PM_L3_P1_PF_RTY",
+	.pme_code = 0x919082,
+	.pme_short_desc = "L3 PF received retry port 1",
+	.pme_long_desc = "L3 PF received retry port 1",
+},
+[ POWER8_PME_PM_L3_P1_SN_HIT ] = {
+	.pme_name = "PM_L3_P1_SN_HIT",
+	.pme_code = 0x93908a,
+	.pme_short_desc = "L3 snoop hit port 1",
+	.pme_long_desc = "L3 snoop hit port 1",
+},
+[ POWER8_PME_PM_L3_P1_SN_INV ] = {
+	.pme_name = "PM_L3_P1_SN_INV",
+	.pme_code = 0x118082,
+	.pme_short_desc = "Port1 snooper detects someone doing a store to a line thats Sx",
+	.pme_long_desc = "Port1 snooper detects someone doing a store to a line thats Sx",
+},
+[ POWER8_PME_PM_L3_P1_SN_MISS ] = {
+	.pme_name = "PM_L3_P1_SN_MISS",
+	.pme_code = 0x94908e,
+	.pme_short_desc = "L3 snoop miss port 1",
+	.pme_long_desc = "L3 snoop miss port 1",
+},
+[ POWER8_PME_PM_L3_P1_SYS_PUMP ] = {
+	.pme_name = "PM_L3_P1_SYS_PUMP",
+	.pme_code = 0xa3908a,
+	.pme_short_desc = "L3 pf sent with sys scope port 1",
+	.pme_long_desc = "L3 pf sent with sys scope port 1",
+},
+[ POWER8_PME_PM_L3_PF0_ALLOC ] = {
+	.pme_name = "PM_L3_PF0_ALLOC",
+	.pme_code = 0x84908d,
+	.pme_short_desc = "lifetime, sample of PF machine 0 valid",
+	.pme_long_desc = "0.0",
+},
+[ POWER8_PME_PM_L3_PF0_BUSY ] = {
+	.pme_name = "PM_L3_PF0_BUSY",
+	.pme_code = 0x84908c,
+	.pme_short_desc = "lifetime, sample of PF machine 0 valid",
+	.pme_long_desc = "lifetime, sample of PF machine 0 valid",
+},
+[ POWER8_PME_PM_L3_PF_HIT_L3 ] = {
+	.pme_name = "PM_L3_PF_HIT_L3",
+	.pme_code = 0x428084,
+	.pme_short_desc = "l3 pf hit in l3",
+	.pme_long_desc = "l3 pf hit in l3",
+},
+[ POWER8_PME_PM_L3_PF_MISS_L3 ] = {
+	.pme_name = "PM_L3_PF_MISS_L3",
+	.pme_code = 0x18080,
+	.pme_short_desc = "L3 Prefetch missed in L3",
+	.pme_long_desc = "L3 Prefetch missed in L3",
+},
+[ POWER8_PME_PM_L3_PF_OFF_CHIP_CACHE ] = {
+	.pme_name = "PM_L3_PF_OFF_CHIP_CACHE",
+	.pme_code = 0x3808a,
+	.pme_short_desc = "L3 Prefetch from Off chip cache",
+	.pme_long_desc = "L3 Prefetch from Off chip cache",
+},
+[ POWER8_PME_PM_L3_PF_OFF_CHIP_MEM ] = {
+	.pme_name = "PM_L3_PF_OFF_CHIP_MEM",
+	.pme_code = 0x4808e,
+	.pme_short_desc = "L3 Prefetch from Off chip memory",
+	.pme_long_desc = "L3 Prefetch from Off chip memory",
+},
+[ POWER8_PME_PM_L3_PF_ON_CHIP_CACHE ] = {
+	.pme_name = "PM_L3_PF_ON_CHIP_CACHE",
+	.pme_code = 0x38088,
+	.pme_short_desc = "L3 Prefetch from On chip cache",
+	.pme_long_desc = "L3 Prefetch from On chip cache",
+},
+[ POWER8_PME_PM_L3_PF_ON_CHIP_MEM ] = {
+	.pme_name = "PM_L3_PF_ON_CHIP_MEM",
+	.pme_code = 0x4808c,
+	.pme_short_desc = "L3 Prefetch from On chip memory",
+	.pme_long_desc = "L3 Prefetch from On chip memory",
+},
+[ POWER8_PME_PM_L3_PF_USAGE ] = {
+	.pme_name = "PM_L3_PF_USAGE",
+	.pme_code = 0x829084,
+	.pme_short_desc = "rotating sample of 32 PF actives",
+	.pme_long_desc = "rotating sample of 32 PF actives",
+},
+[ POWER8_PME_PM_L3_PREF_ALL ] = {
+	.pme_name = "PM_L3_PREF_ALL",
+	.pme_code = 0x4e052,
+	.pme_short_desc = "Total HW L3 prefetches(Load+store)",
+	.pme_long_desc = "Total HW L3 prefetches(Load+store).",
+},
+[ POWER8_PME_PM_L3_RD0_ALLOC ] = {
+	.pme_name = "PM_L3_RD0_ALLOC",
+	.pme_code = 0x84908f,
+	.pme_short_desc = "lifetime, sample of RD machine 0 valid",
+	.pme_long_desc = "0.0",
+},
+[ POWER8_PME_PM_L3_RD0_BUSY ] = {
+	.pme_name = "PM_L3_RD0_BUSY",
+	.pme_code = 0x84908e,
+	.pme_short_desc = "lifetime, sample of RD machine 0 valid",
+	.pme_long_desc = "lifetime, sample of RD machine 0 valid",
+},
+[ POWER8_PME_PM_L3_RD_USAGE ] = {
+	.pme_name = "PM_L3_RD_USAGE",
+	.pme_code = 0x829086,
+	.pme_short_desc = "rotating sample of 16 RD actives",
+	.pme_long_desc = "rotating sample of 16 RD actives",
+},
+[ POWER8_PME_PM_L3_SN0_ALLOC ] = {
+	.pme_name = "PM_L3_SN0_ALLOC",
+	.pme_code = 0x839089,
+	.pme_short_desc = "lifetime, sample of snooper machine 0 valid",
+	.pme_long_desc = "0.0",
+},
+[ POWER8_PME_PM_L3_SN0_BUSY ] = {
+	.pme_name = "PM_L3_SN0_BUSY",
+	.pme_code = 0x839088,
+	.pme_short_desc = "lifetime, sample of snooper machine 0 valid",
+	.pme_long_desc = "lifetime, sample of snooper machine 0 valid",
+},
+[ POWER8_PME_PM_L3_SN_USAGE ] = {
+	.pme_name = "PM_L3_SN_USAGE",
+	.pme_code = 0x819080,
+	.pme_short_desc = "rotating sample of 8 snoop valids",
+	.pme_long_desc = "rotating sample of 8 snoop valids",
+},
+[ POWER8_PME_PM_L3_ST_PREF ] = {
+	.pme_name = "PM_L3_ST_PREF",
+	.pme_code = 0x2e052,
+	.pme_short_desc = "L3 store Prefetches",
+	.pme_long_desc = "L3 store Prefetches.",
+},
+[ POWER8_PME_PM_L3_SW_PREF ] = {
+	.pme_name = "PM_L3_SW_PREF",
+	.pme_code = 0x3e052,
+	.pme_short_desc = "Data stream touchto L3",
+	.pme_long_desc = "Data stream touchto L3.",
+},
+[ POWER8_PME_PM_L3_SYS_GUESS_CORRECT ] = {
+	.pme_name = "PM_L3_SYS_GUESS_CORRECT",
+	.pme_code = 0xb29084,
+	.pme_short_desc = "Initial scope=system and data from outside group (far or rem)(pred successful)",
+	.pme_long_desc = "Initial scope=system and data from outside group (far or rem)(pred successful)",
+},
+[ POWER8_PME_PM_L3_SYS_GUESS_WRONG ] = {
+	.pme_name = "PM_L3_SYS_GUESS_WRONG",
+	.pme_code = 0xb4908c,
+	.pme_short_desc = "Initial scope=system but data from local or near. Predction too high",
+	.pme_long_desc = "Initial scope=system but data from local or near. Predction too high",
+},
+[ POWER8_PME_PM_L3_TRANS_PF ] = {
+	.pme_name = "PM_L3_TRANS_PF",
+	.pme_code = 0x24808e,
+	.pme_short_desc = "L3 Transient prefetch",
+	.pme_long_desc = "L3 Transient prefetch",
+},
+[ POWER8_PME_PM_L3_WI0_ALLOC ] = {
+	.pme_name = "PM_L3_WI0_ALLOC",
+	.pme_code = 0x18081,
+	.pme_short_desc = "lifetime, sample of Write Inject machine 0 valid",
+	.pme_long_desc = "0.0",
+},
+[ POWER8_PME_PM_L3_WI0_BUSY ] = {
+	.pme_name = "PM_L3_WI0_BUSY",
+	.pme_code = 0x418080,
+	.pme_short_desc = "lifetime, sample of Write Inject machine 0 valid",
+	.pme_long_desc = "lifetime, sample of Write Inject machine 0 valid",
+},
+[ POWER8_PME_PM_L3_WI_USAGE ] = {
+	.pme_name = "PM_L3_WI_USAGE",
+	.pme_code = 0x418082,
+	.pme_short_desc = "rotating sample of 8 WI actives",
+	.pme_long_desc = "rotating sample of 8 WI actives",
+},
+[ POWER8_PME_PM_LARX_FIN ] = {
+	.pme_name = "PM_LARX_FIN",
+	.pme_code = 0x3c058,
+	.pme_short_desc = "Larx finished",
+	.pme_long_desc = "Larx finished .",
+},
 [ POWER8_PME_PM_LD_CMPL ] = {
 	.pme_name = "PM_LD_CMPL",
 	.pme_code = 0x1002e,
@@ -825,17 +4622,839 @@ static const pme_power_entry_t power8_pe[] = {
 	.pme_short_desc = "Cycles L3 miss was pending for this thread",
 	.pme_long_desc = "Cycles L3 miss was pending for this thread.",
 },
+[ POWER8_PME_PM_LD_MISS_L1 ] = {
+	.pme_name = "PM_LD_MISS_L1",
+	.pme_code = 0x3e054,
+	.pme_short_desc = "Load Missed L1",
+	.pme_long_desc = "Load Missed L1.",
+},
+[ POWER8_PME_PM_LD_REF_L1 ] = {
+	.pme_name = "PM_LD_REF_L1",
+	.pme_code = 0x100ee,
+	.pme_short_desc = "All L1 D cache load references counted at finish, gated by reject",
+	.pme_long_desc = "Load Ref count combined for all units.",
+},
+[ POWER8_PME_PM_LD_REF_L1_LSU0 ] = {
+	.pme_name = "PM_LD_REF_L1_LSU0",
+	.pme_code = 0xc080,
+	.pme_short_desc = "LS0 L1 D cache load references counted at finish, gated by reject",
+	.pme_long_desc = "LS0 L1 D cache load references counted at finish, gated by rejectLSU0 L1 D cache load references",
+},
+[ POWER8_PME_PM_LD_REF_L1_LSU1 ] = {
+	.pme_name = "PM_LD_REF_L1_LSU1",
+	.pme_code = 0xc082,
+	.pme_short_desc = "LS1 L1 D cache load references counted at finish, gated by reject",
+	.pme_long_desc = "LS1 L1 D cache load references counted at finish, gated by rejectLSU1 L1 D cache load references",
+},
+[ POWER8_PME_PM_LD_REF_L1_LSU2 ] = {
+	.pme_name = "PM_LD_REF_L1_LSU2",
+	.pme_code = 0xc094,
+	.pme_short_desc = "LS2 L1 D cache load references counted at finish, gated by reject",
+	.pme_long_desc = "LS2 L1 D cache load references counted at finish, gated by reject42",
+},
+[ POWER8_PME_PM_LD_REF_L1_LSU3 ] = {
+	.pme_name = "PM_LD_REF_L1_LSU3",
+	.pme_code = 0xc096,
+	.pme_short_desc = "LS3 L1 D cache load references counted at finish, gated by reject",
+	.pme_long_desc = "LS3 L1 D cache load references counted at finish, gated by reject42",
+},
+[ POWER8_PME_PM_LINK_STACK_INVALID_PTR ] = {
+	.pme_name = "PM_LINK_STACK_INVALID_PTR",
+	.pme_code = 0x509a,
+	.pme_short_desc = "A flush were LS ptr is invalid, results in a pop , A lot of interrupts between push and pops",
+	.pme_long_desc = "A flush were LS ptr is invalid, results in a pop , A lot of interrupts between push and pops",
+},
+[ POWER8_PME_PM_LINK_STACK_WRONG_ADD_PRED ] = {
+	.pme_name = "PM_LINK_STACK_WRONG_ADD_PRED",
+	.pme_code = 0x5098,
+	.pme_short_desc = "Link stack predicts wrong address, because of link stack design limitation.",
+	.pme_long_desc = "Link stack predicts wrong address, because of link stack design limitation.",
+},
+[ POWER8_PME_PM_LS0_ERAT_MISS_PREF ] = {
+	.pme_name = "PM_LS0_ERAT_MISS_PREF",
+	.pme_code = 0xe080,
+	.pme_short_desc = "LS0 Erat miss due to prefetch",
+	.pme_long_desc = "LS0 Erat miss due to prefetch42",
+},
+[ POWER8_PME_PM_LS0_L1_PREF ] = {
+	.pme_name = "PM_LS0_L1_PREF",
+	.pme_code = 0xd0b8,
+	.pme_short_desc = "LS0 L1 cache data prefetches",
+	.pme_long_desc = "LS0 L1 cache data prefetches42",
+},
+[ POWER8_PME_PM_LS0_L1_SW_PREF ] = {
+	.pme_name = "PM_LS0_L1_SW_PREF",
+	.pme_code = 0xc098,
+	.pme_short_desc = "Software L1 Prefetches, including SW Transient Prefetches",
+	.pme_long_desc = "Software L1 Prefetches, including SW Transient Prefetches42",
+},
+[ POWER8_PME_PM_LS1_ERAT_MISS_PREF ] = {
+	.pme_name = "PM_LS1_ERAT_MISS_PREF",
+	.pme_code = 0xe082,
+	.pme_short_desc = "LS1 Erat miss due to prefetch",
+	.pme_long_desc = "LS1 Erat miss due to prefetch42",
+},
+[ POWER8_PME_PM_LS1_L1_PREF ] = {
+	.pme_name = "PM_LS1_L1_PREF",
+	.pme_code = 0xd0ba,
+	.pme_short_desc = "LS1 L1 cache data prefetches",
+	.pme_long_desc = "LS1 L1 cache data prefetches42",
+},
+[ POWER8_PME_PM_LS1_L1_SW_PREF ] = {
+	.pme_name = "PM_LS1_L1_SW_PREF",
+	.pme_code = 0xc09a,
+	.pme_short_desc = "Software L1 Prefetches, including SW Transient Prefetches",
+	.pme_long_desc = "Software L1 Prefetches, including SW Transient Prefetches42",
+},
+[ POWER8_PME_PM_LSU0_FLUSH_LRQ ] = {
+	.pme_name = "PM_LSU0_FLUSH_LRQ",
+	.pme_code = 0xc0b0,
+	.pme_short_desc = "LS0 Flush: LRQ",
+	.pme_long_desc = "LS0 Flush: LRQLSU0 LRQ flushes",
+},
+[ POWER8_PME_PM_LSU0_FLUSH_SRQ ] = {
+	.pme_name = "PM_LSU0_FLUSH_SRQ",
+	.pme_code = 0xc0b8,
+	.pme_short_desc = "LS0 Flush: SRQ",
+	.pme_long_desc = "LS0 Flush: SRQLSU0 SRQ lhs flushes",
+},
+[ POWER8_PME_PM_LSU0_FLUSH_ULD ] = {
+	.pme_name = "PM_LSU0_FLUSH_ULD",
+	.pme_code = 0xc0a4,
+	.pme_short_desc = "LS0 Flush: Unaligned Load",
+	.pme_long_desc = "LS0 Flush: Unaligned LoadLSU0 unaligned load flushes",
+},
+[ POWER8_PME_PM_LSU0_FLUSH_UST ] = {
+	.pme_name = "PM_LSU0_FLUSH_UST",
+	.pme_code = 0xc0ac,
+	.pme_short_desc = "LS0 Flush: Unaligned Store",
+	.pme_long_desc = "LS0 Flush: Unaligned StoreLSU0 unaligned store flushes",
+},
+[ POWER8_PME_PM_LSU0_L1_CAM_CANCEL ] = {
+	.pme_name = "PM_LSU0_L1_CAM_CANCEL",
+	.pme_code = 0xf088,
+	.pme_short_desc = "ls0 l1 tm cam cancel",
+	.pme_long_desc = "ls0 l1 tm cam cancel42",
+},
+[ POWER8_PME_PM_LSU0_LARX_FIN ] = {
+	.pme_name = "PM_LSU0_LARX_FIN",
+	.pme_code = 0x1e056,
+	.pme_short_desc = "Larx finished in LSU pipe0",
+	.pme_long_desc = ".",
+},
+[ POWER8_PME_PM_LSU0_LMQ_LHR_MERGE ] = {
+	.pme_name = "PM_LSU0_LMQ_LHR_MERGE",
+	.pme_code = 0xd08c,
+	.pme_short_desc = "LS0 Load Merged with another cacheline request",
+	.pme_long_desc = "LS0 Load Merged with another cacheline request42",
+},
+[ POWER8_PME_PM_LSU0_NCLD ] = {
+	.pme_name = "PM_LSU0_NCLD",
+	.pme_code = 0xc08c,
+	.pme_short_desc = "LS0 Non-cachable Loads counted at finish",
+	.pme_long_desc = "LS0 Non-cachable Loads counted at finishLSU0 non-cacheable loads",
+},
+[ POWER8_PME_PM_LSU0_PRIMARY_ERAT_HIT ] = {
+	.pme_name = "PM_LSU0_PRIMARY_ERAT_HIT",
+	.pme_code = 0xe090,
+	.pme_short_desc = "Primary ERAT hit",
+	.pme_long_desc = "Primary ERAT hit42",
+},
+[ POWER8_PME_PM_LSU0_REJECT ] = {
+	.pme_name = "PM_LSU0_REJECT",
+	.pme_code = 0x1e05a,
+	.pme_short_desc = "LSU0 reject",
+	.pme_long_desc = "LSU0 reject .",
+},
+[ POWER8_PME_PM_LSU0_SRQ_STFWD ] = {
+	.pme_name = "PM_LSU0_SRQ_STFWD",
+	.pme_code = 0xc09c,
+	.pme_short_desc = "LS0 SRQ forwarded data to a load",
+	.pme_long_desc = "LS0 SRQ forwarded data to a loadLSU0 SRQ store forwarded",
+},
+[ POWER8_PME_PM_LSU0_STORE_REJECT ] = {
+	.pme_name = "PM_LSU0_STORE_REJECT",
+	.pme_code = 0xf084,
+	.pme_short_desc = "ls0 store reject",
+	.pme_long_desc = "ls0 store reject42",
+},
+[ POWER8_PME_PM_LSU0_TMA_REQ_L2 ] = {
+	.pme_name = "PM_LSU0_TMA_REQ_L2",
+	.pme_code = 0xe0a8,
+	.pme_short_desc = "addrs only req to L2 only on the first one,Indication that Load footprint is not expanding",
+	.pme_long_desc = "addrs only req to L2 only on the first one,Indication that Load footprint is not expanding42",
+},
+[ POWER8_PME_PM_LSU0_TM_L1_HIT ] = {
+	.pme_name = "PM_LSU0_TM_L1_HIT",
+	.pme_code = 0xe098,
+	.pme_short_desc = "Load tm hit in L1",
+	.pme_long_desc = "Load tm hit in L142",
+},
+[ POWER8_PME_PM_LSU0_TM_L1_MISS ] = {
+	.pme_name = "PM_LSU0_TM_L1_MISS",
+	.pme_code = 0xe0a0,
+	.pme_short_desc = "Load tm L1 miss",
+	.pme_long_desc = "Load tm L1 miss42",
+},
+[ POWER8_PME_PM_LSU1_FLUSH_LRQ ] = {
+	.pme_name = "PM_LSU1_FLUSH_LRQ",
+	.pme_code = 0xc0b2,
+	.pme_short_desc = "LS1 Flush: LRQ",
+	.pme_long_desc = "LS1 Flush: LRQLSU1 LRQ flushes",
+},
+[ POWER8_PME_PM_LSU1_FLUSH_SRQ ] = {
+	.pme_name = "PM_LSU1_FLUSH_SRQ",
+	.pme_code = 0xc0ba,
+	.pme_short_desc = "LS1 Flush: SRQ",
+	.pme_long_desc = "LS1 Flush: SRQLSU1 SRQ lhs flushes",
+},
+[ POWER8_PME_PM_LSU1_FLUSH_ULD ] = {
+	.pme_name = "PM_LSU1_FLUSH_ULD",
+	.pme_code = 0xc0a6,
+	.pme_short_desc = "LS 1 Flush: Unaligned Load",
+	.pme_long_desc = "LS 1 Flush: Unaligned LoadLSU1 unaligned load flushes",
+},
+[ POWER8_PME_PM_LSU1_FLUSH_UST ] = {
+	.pme_name = "PM_LSU1_FLUSH_UST",
+	.pme_code = 0xc0ae,
+	.pme_short_desc = "LS1 Flush: Unaligned Store",
+	.pme_long_desc = "LS1 Flush: Unaligned StoreLSU1 unaligned store flushes",
+},
+[ POWER8_PME_PM_LSU1_L1_CAM_CANCEL ] = {
+	.pme_name = "PM_LSU1_L1_CAM_CANCEL",
+	.pme_code = 0xf08a,
+	.pme_short_desc = "ls1 l1 tm cam cancel",
+	.pme_long_desc = "ls1 l1 tm cam cancel42",
+},
+[ POWER8_PME_PM_LSU1_LARX_FIN ] = {
+	.pme_name = "PM_LSU1_LARX_FIN",
+	.pme_code = 0x2e056,
+	.pme_short_desc = "Larx finished in LSU pipe1",
+	.pme_long_desc = "Larx finished in LSU pipe1.",
+},
+[ POWER8_PME_PM_LSU1_LMQ_LHR_MERGE ] = {
+	.pme_name = "PM_LSU1_LMQ_LHR_MERGE",
+	.pme_code = 0xd08e,
+	.pme_short_desc = "LS1 Load Merge with another cacheline request",
+	.pme_long_desc = "LS1 Load Merge with another cacheline request42",
+},
+[ POWER8_PME_PM_LSU1_NCLD ] = {
+	.pme_name = "PM_LSU1_NCLD",
+	.pme_code = 0xc08e,
+	.pme_short_desc = "LS1 Non-cachable Loads counted at finish",
+	.pme_long_desc = "LS1 Non-cachable Loads counted at finishLSU1 non-cacheable loads",
+},
+[ POWER8_PME_PM_LSU1_PRIMARY_ERAT_HIT ] = {
+	.pme_name = "PM_LSU1_PRIMARY_ERAT_HIT",
+	.pme_code = 0xe092,
+	.pme_short_desc = "Primary ERAT hit",
+	.pme_long_desc = "Primary ERAT hit42",
+},
+[ POWER8_PME_PM_LSU1_REJECT ] = {
+	.pme_name = "PM_LSU1_REJECT",
+	.pme_code = 0x2e05a,
+	.pme_short_desc = "LSU1 reject",
+	.pme_long_desc = "LSU1 reject .",
+},
+[ POWER8_PME_PM_LSU1_SRQ_STFWD ] = {
+	.pme_name = "PM_LSU1_SRQ_STFWD",
+	.pme_code = 0xc09e,
+	.pme_short_desc = "LS1 SRQ forwarded data to a load",
+	.pme_long_desc = "LS1 SRQ forwarded data to a loadLSU1 SRQ store forwarded",
+},
+[ POWER8_PME_PM_LSU1_STORE_REJECT ] = {
+	.pme_name = "PM_LSU1_STORE_REJECT",
+	.pme_code = 0xf086,
+	.pme_short_desc = "ls1 store reject",
+	.pme_long_desc = "ls1 store reject42",
+},
+[ POWER8_PME_PM_LSU1_TMA_REQ_L2 ] = {
+	.pme_name = "PM_LSU1_TMA_REQ_L2",
+	.pme_code = 0xe0aa,
+	.pme_short_desc = "addrs only req to L2 only on the first one,Indication that Load footprint is not expanding",
+	.pme_long_desc = "addrs only req to L2 only on the first one,Indication that Load footprint is not expanding42",
+},
+[ POWER8_PME_PM_LSU1_TM_L1_HIT ] = {
+	.pme_name = "PM_LSU1_TM_L1_HIT",
+	.pme_code = 0xe09a,
+	.pme_short_desc = "Load tm hit in L1",
+	.pme_long_desc = "Load tm hit in L142",
+},
+[ POWER8_PME_PM_LSU1_TM_L1_MISS ] = {
+	.pme_name = "PM_LSU1_TM_L1_MISS",
+	.pme_code = 0xe0a2,
+	.pme_short_desc = "Load tm L1 miss",
+	.pme_long_desc = "Load tm L1 miss42",
+},
+[ POWER8_PME_PM_LSU2_FLUSH_LRQ ] = {
+	.pme_name = "PM_LSU2_FLUSH_LRQ",
+	.pme_code = 0xc0b4,
+	.pme_short_desc = "LS02Flush: LRQ",
+	.pme_long_desc = "LS02Flush: LRQ42",
+},
+[ POWER8_PME_PM_LSU2_FLUSH_SRQ ] = {
+	.pme_name = "PM_LSU2_FLUSH_SRQ",
+	.pme_code = 0xc0bc,
+	.pme_short_desc = "LS2 Flush: SRQ",
+	.pme_long_desc = "LS2 Flush: SRQ42",
+},
+[ POWER8_PME_PM_LSU2_FLUSH_ULD ] = {
+	.pme_name = "PM_LSU2_FLUSH_ULD",
+	.pme_code = 0xc0a8,
+	.pme_short_desc = "LS3 Flush: Unaligned Load",
+	.pme_long_desc = "LS3 Flush: Unaligned Load42",
+},
+[ POWER8_PME_PM_LSU2_L1_CAM_CANCEL ] = {
+	.pme_name = "PM_LSU2_L1_CAM_CANCEL",
+	.pme_code = 0xf08c,
+	.pme_short_desc = "ls2 l1 tm cam cancel",
+	.pme_long_desc = "ls2 l1 tm cam cancel42",
+},
+[ POWER8_PME_PM_LSU2_LARX_FIN ] = {
+	.pme_name = "PM_LSU2_LARX_FIN",
+	.pme_code = 0x3e056,
+	.pme_short_desc = "Larx finished in LSU pipe2",
+	.pme_long_desc = "Larx finished in LSU pipe2.",
+},
+[ POWER8_PME_PM_LSU2_LDF ] = {
+	.pme_name = "PM_LSU2_LDF",
+	.pme_code = 0xc084,
+	.pme_short_desc = "LS2 Scalar Loads",
+	.pme_long_desc = "LS2 Scalar Loads42",
+},
+[ POWER8_PME_PM_LSU2_LDX ] = {
+	.pme_name = "PM_LSU2_LDX",
+	.pme_code = 0xc088,
+	.pme_short_desc = "LS0 Vector Loads",
+	.pme_long_desc = "LS0 Vector Loads42",
+},
+[ POWER8_PME_PM_LSU2_LMQ_LHR_MERGE ] = {
+	.pme_name = "PM_LSU2_LMQ_LHR_MERGE",
+	.pme_code = 0xd090,
+	.pme_short_desc = "LS0 Load Merged with another cacheline request",
+	.pme_long_desc = "LS0 Load Merged with another cacheline request42",
+},
+[ POWER8_PME_PM_LSU2_PRIMARY_ERAT_HIT ] = {
+	.pme_name = "PM_LSU2_PRIMARY_ERAT_HIT",
+	.pme_code = 0xe094,
+	.pme_short_desc = "Primary ERAT hit",
+	.pme_long_desc = "Primary ERAT hit42",
+},
+[ POWER8_PME_PM_LSU2_REJECT ] = {
+	.pme_name = "PM_LSU2_REJECT",
+	.pme_code = 0x3e05a,
+	.pme_short_desc = "LSU2 reject",
+	.pme_long_desc = "LSU2 reject .",
+},
+[ POWER8_PME_PM_LSU2_SRQ_STFWD ] = {
+	.pme_name = "PM_LSU2_SRQ_STFWD",
+	.pme_code = 0xc0a0,
+	.pme_short_desc = "LS2 SRQ forwarded data to a load",
+	.pme_long_desc = "LS2 SRQ forwarded data to a load42",
+},
+[ POWER8_PME_PM_LSU2_TMA_REQ_L2 ] = {
+	.pme_name = "PM_LSU2_TMA_REQ_L2",
+	.pme_code = 0xe0ac,
+	.pme_short_desc = "addrs only req to L2 only on the first one,Indication that Load footprint is not expanding",
+	.pme_long_desc = "addrs only req to L2 only on the first one,Indication that Load footprint is not expanding42",
+},
+[ POWER8_PME_PM_LSU2_TM_L1_HIT ] = {
+	.pme_name = "PM_LSU2_TM_L1_HIT",
+	.pme_code = 0xe09c,
+	.pme_short_desc = "Load tm hit in L1",
+	.pme_long_desc = "Load tm hit in L142",
+},
+[ POWER8_PME_PM_LSU2_TM_L1_MISS ] = {
+	.pme_name = "PM_LSU2_TM_L1_MISS",
+	.pme_code = 0xe0a4,
+	.pme_short_desc = "Load tm L1 miss",
+	.pme_long_desc = "Load tm L1 miss42",
+},
+[ POWER8_PME_PM_LSU3_FLUSH_LRQ ] = {
+	.pme_name = "PM_LSU3_FLUSH_LRQ",
+	.pme_code = 0xc0b6,
+	.pme_short_desc = "LS3 Flush: LRQ",
+	.pme_long_desc = "LS3 Flush: LRQ42",
+},
+[ POWER8_PME_PM_LSU3_FLUSH_SRQ ] = {
+	.pme_name = "PM_LSU3_FLUSH_SRQ",
+	.pme_code = 0xc0be,
+	.pme_short_desc = "LS13 Flush: SRQ",
+	.pme_long_desc = "LS13 Flush: SRQ42",
+},
+[ POWER8_PME_PM_LSU3_FLUSH_ULD ] = {
+	.pme_name = "PM_LSU3_FLUSH_ULD",
+	.pme_code = 0xc0aa,
+	.pme_short_desc = "LS 14Flush: Unaligned Load",
+	.pme_long_desc = "LS 14Flush: Unaligned Load42",
+},
+[ POWER8_PME_PM_LSU3_L1_CAM_CANCEL ] = {
+	.pme_name = "PM_LSU3_L1_CAM_CANCEL",
+	.pme_code = 0xf08e,
+	.pme_short_desc = "ls3 l1 tm cam cancel",
+	.pme_long_desc = "ls3 l1 tm cam cancel42",
+},
+[ POWER8_PME_PM_LSU3_LARX_FIN ] = {
+	.pme_name = "PM_LSU3_LARX_FIN",
+	.pme_code = 0x4e056,
+	.pme_short_desc = "Larx finished in LSU pipe3",
+	.pme_long_desc = "Larx finished in LSU pipe3.",
+},
+[ POWER8_PME_PM_LSU3_LDF ] = {
+	.pme_name = "PM_LSU3_LDF",
+	.pme_code = 0xc086,
+	.pme_short_desc = "LS3 Scalar Loads",
+	.pme_long_desc = "LS3 Scalar Loads 42",
+},
+[ POWER8_PME_PM_LSU3_LDX ] = {
+	.pme_name = "PM_LSU3_LDX",
+	.pme_code = 0xc08a,
+	.pme_short_desc = "LS1 Vector Loads",
+	.pme_long_desc = "LS1 Vector Loads42",
+},
+[ POWER8_PME_PM_LSU3_LMQ_LHR_MERGE ] = {
+	.pme_name = "PM_LSU3_LMQ_LHR_MERGE",
+	.pme_code = 0xd092,
+	.pme_short_desc = "LS1 Load Merge with another cacheline request",
+	.pme_long_desc = "LS1 Load Merge with another cacheline request42",
+},
+[ POWER8_PME_PM_LSU3_PRIMARY_ERAT_HIT ] = {
+	.pme_name = "PM_LSU3_PRIMARY_ERAT_HIT",
+	.pme_code = 0xe096,
+	.pme_short_desc = "Primary ERAT hit",
+	.pme_long_desc = "Primary ERAT hit42",
+},
+[ POWER8_PME_PM_LSU3_REJECT ] = {
+	.pme_name = "PM_LSU3_REJECT",
+	.pme_code = 0x4e05a,
+	.pme_short_desc = "LSU3 reject",
+	.pme_long_desc = "LSU3 reject .",
+},
+[ POWER8_PME_PM_LSU3_SRQ_STFWD ] = {
+	.pme_name = "PM_LSU3_SRQ_STFWD",
+	.pme_code = 0xc0a2,
+	.pme_short_desc = "LS3 SRQ forwarded data to a load",
+	.pme_long_desc = "LS3 SRQ forwarded data to a load42",
+},
+[ POWER8_PME_PM_LSU3_TMA_REQ_L2 ] = {
+	.pme_name = "PM_LSU3_TMA_REQ_L2",
+	.pme_code = 0xe0ae,
+	.pme_short_desc = "addrs only req to L2 only on the first one,Indication that Load footprint is not expanding",
+	.pme_long_desc = "addrs only req to L2 only on the first one,Indication that Load footprint is not expanding42",
+},
+[ POWER8_PME_PM_LSU3_TM_L1_HIT ] = {
+	.pme_name = "PM_LSU3_TM_L1_HIT",
+	.pme_code = 0xe09e,
+	.pme_short_desc = "Load tm hit in L1",
+	.pme_long_desc = "Load tm hit in L142",
+},
+[ POWER8_PME_PM_LSU3_TM_L1_MISS ] = {
+	.pme_name = "PM_LSU3_TM_L1_MISS",
+	.pme_code = 0xe0a6,
+	.pme_short_desc = "Load tm L1 miss",
+	.pme_long_desc = "Load tm L1 miss42",
+},
+[ POWER8_PME_PM_LSU_DERAT_MISS ] = {
+	.pme_name = "PM_LSU_DERAT_MISS",
+	.pme_code = 0x200f6,
+	.pme_short_desc = "DERAT Reloaded due to a DERAT miss",
+	.pme_long_desc = "DERAT Reloaded (Miss).",
+},
+[ POWER8_PME_PM_LSU_ERAT_MISS_PREF ] = {
+	.pme_name = "PM_LSU_ERAT_MISS_PREF",
+	.pme_code = 0xe880,
+	.pme_short_desc = "Erat miss due to prefetch, on either pipe",
+	.pme_long_desc = "LSU",
+},
+[ POWER8_PME_PM_LSU_FIN ] = {
+	.pme_name = "PM_LSU_FIN",
+	.pme_code = 0x30066,
+	.pme_short_desc = "LSU Finished an instruction (up to 2 per cycle)",
+	.pme_long_desc = "LSU Finished an instruction (up to 2 per cycle).",
+},
+[ POWER8_PME_PM_LSU_FLUSH_UST ] = {
+	.pme_name = "PM_LSU_FLUSH_UST",
+	.pme_code = 0xc8ac,
+	.pme_short_desc = "Unaligned Store Flush on either pipe",
+	.pme_long_desc = "LSU",
+},
+[ POWER8_PME_PM_LSU_FOUR_TABLEWALK_CYC ] = {
+	.pme_name = "PM_LSU_FOUR_TABLEWALK_CYC",
+	.pme_code = 0xd0a4,
+	.pme_short_desc = "Cycles when four tablewalks pending on this thread",
+	.pme_long_desc = "Cycles when four tablewalks pending on this thread42",
+},
+[ POWER8_PME_PM_LSU_FX_FIN ] = {
+	.pme_name = "PM_LSU_FX_FIN",
+	.pme_code = 0x10066,
+	.pme_short_desc = "LSU Finished a FX operation (up to 2 per cycle",
+	.pme_long_desc = "LSU Finished a FX operation (up to 2 per cycle.",
+},
+[ POWER8_PME_PM_LSU_L1_PREF ] = {
+	.pme_name = "PM_LSU_L1_PREF",
+	.pme_code = 0xd8b8,
+	.pme_short_desc = "hw initiated , include sw streaming forms as well , include sw streams as a separate event",
+	.pme_long_desc = "LSU",
+},
+[ POWER8_PME_PM_LSU_L1_SW_PREF ] = {
+	.pme_name = "PM_LSU_L1_SW_PREF",
+	.pme_code = 0xc898,
+	.pme_short_desc = "Software L1 Prefetches, including SW Transient Prefetches, on both pipes",
+	.pme_long_desc = "LSU",
+},
+[ POWER8_PME_PM_LSU_LDF ] = {
+	.pme_name = "PM_LSU_LDF",
+	.pme_code = 0xc884,
+	.pme_short_desc = "FPU loads only on LS2/LS3 ie LU0/LU1",
+	.pme_long_desc = "LSU",
+},
+[ POWER8_PME_PM_LSU_LDX ] = {
+	.pme_name = "PM_LSU_LDX",
+	.pme_code = 0xc888,
+	.pme_short_desc = "Vector loads can issue only on LS2/LS3",
+	.pme_long_desc = "LSU",
+},
+[ POWER8_PME_PM_LSU_LMQ_FULL_CYC ] = {
+	.pme_name = "PM_LSU_LMQ_FULL_CYC",
+	.pme_code = 0xd0a2,
+	.pme_short_desc = "LMQ full",
+	.pme_long_desc = "LMQ fullCycles LMQ full,",
+},
+[ POWER8_PME_PM_LSU_LMQ_S0_ALLOC ] = {
+	.pme_name = "PM_LSU_LMQ_S0_ALLOC",
+	.pme_code = 0xd0a1,
+	.pme_short_desc = "Per thread - use edge detect to count allocates On a per thread basis, level signal indicating Slot 0 is valid. By instrumenting a single slot we can calculate service time for that slot. Previous machines required a separate signal indicating the slot was allocated. Because any signal can be routed to any counter in P8, we can count level in one PMC and edge detect in another PMC using the same signal",
+	.pme_long_desc = "0.0",
+},
+[ POWER8_PME_PM_LSU_LMQ_S0_VALID ] = {
+	.pme_name = "PM_LSU_LMQ_S0_VALID",
+	.pme_code = 0xd0a0,
+	.pme_short_desc = "Slot 0 of LMQ valid",
+	.pme_long_desc = "Slot 0 of LMQ validLMQ slot 0 valid",
+},
+[ POWER8_PME_PM_LSU_LMQ_SRQ_EMPTY_ALL_CYC ] = {
+	.pme_name = "PM_LSU_LMQ_SRQ_EMPTY_ALL_CYC",
+	.pme_code = 0x3001c,
+	.pme_short_desc = "ALL threads lsu empty (lmq and srq empty)",
+	.pme_long_desc = "ALL threads lsu empty (lmq and srq empty). Issue HW016541",
+},
+[ POWER8_PME_PM_LSU_LMQ_SRQ_EMPTY_CYC ] = {
+	.pme_name = "PM_LSU_LMQ_SRQ_EMPTY_CYC",
+	.pme_code = 0x2003e,
+	.pme_short_desc = "LSU empty (lmq and srq empty)",
+	.pme_long_desc = "LSU empty (lmq and srq empty).",
+},
+[ POWER8_PME_PM_LSU_LRQ_S0_ALLOC ] = {
+	.pme_name = "PM_LSU_LRQ_S0_ALLOC",
+	.pme_code = 0xd09f,
+	.pme_short_desc = "Per thread - use edge detect to count allocates On a per thread basis, level signal indicating Slot 0 is valid. By instrumenting a single slot we can calculate service time for that slot. Previous machines required a separate signal indicating the slot was allocated. Because any signal can be routed to any counter in P8, we can count level in one PMC and edge detect in another PMC using the same signal",
+	.pme_long_desc = "0.0",
+},
+[ POWER8_PME_PM_LSU_LRQ_S0_VALID ] = {
+	.pme_name = "PM_LSU_LRQ_S0_VALID",
+	.pme_code = 0xd09e,
+	.pme_short_desc = "Slot 0 of LRQ valid",
+	.pme_long_desc = "Slot 0 of LRQ validLRQ slot 0 valid",
+},
+[ POWER8_PME_PM_LSU_LRQ_S43_ALLOC ] = {
+	.pme_name = "PM_LSU_LRQ_S43_ALLOC",
+	.pme_code = 0xf091,
+	.pme_short_desc = "LRQ slot 43 was released",
+	.pme_long_desc = "0.0",
+},
+[ POWER8_PME_PM_LSU_LRQ_S43_VALID ] = {
+	.pme_name = "PM_LSU_LRQ_S43_VALID",
+	.pme_code = 0xf090,
+	.pme_short_desc = "LRQ slot 43 was busy",
+	.pme_long_desc = "LRQ slot 43 was busy42",
+},
+[ POWER8_PME_PM_LSU_MRK_DERAT_MISS ] = {
+	.pme_name = "PM_LSU_MRK_DERAT_MISS",
+	.pme_code = 0x30162,
+	.pme_short_desc = "DERAT Reloaded (Miss)",
+	.pme_long_desc = "DERAT Reloaded (Miss).",
+},
+[ POWER8_PME_PM_LSU_NCLD ] = {
+	.pme_name = "PM_LSU_NCLD",
+	.pme_code = 0xc88c,
+	.pme_short_desc = "count at finish so can return only on ls0 or ls1",
+	.pme_long_desc = "LSU",
+},
+[ POWER8_PME_PM_LSU_NCST ] = {
+	.pme_name = "PM_LSU_NCST",
+	.pme_code = 0xc092,
+	.pme_short_desc = "Non-cachable Stores sent to nest",
+	.pme_long_desc = "Non-cachable Stores sent to nest42",
+},
+[ POWER8_PME_PM_LSU_REJECT ] = {
+	.pme_name = "PM_LSU_REJECT",
+	.pme_code = 0x10064,
+	.pme_short_desc = "LSU Reject (up to 4 per cycle)",
+	.pme_long_desc = "LSU Reject (up to 4 per cycle).",
+},
+[ POWER8_PME_PM_LSU_REJECT_ERAT_MISS ] = {
+	.pme_name = "PM_LSU_REJECT_ERAT_MISS",
+	.pme_code = 0x2e05c,
+	.pme_short_desc = "LSU Reject due to ERAT (up to 4 per cycles)",
+	.pme_long_desc = "LSU Reject due to ERAT (up to 4 per cycles).",
+},
+[ POWER8_PME_PM_LSU_REJECT_LHS ] = {
+	.pme_name = "PM_LSU_REJECT_LHS",
+	.pme_code = 0x4e05c,
+	.pme_short_desc = "LSU Reject due to LHS (up to 4 per cycle)",
+	.pme_long_desc = "LSU Reject due to LHS (up to 4 per cycle).",
+},
+[ POWER8_PME_PM_LSU_REJECT_LMQ_FULL ] = {
+	.pme_name = "PM_LSU_REJECT_LMQ_FULL",
+	.pme_code = 0x1e05c,
+	.pme_short_desc = "LSU reject due to LMQ full ( 4 per cycle)",
+	.pme_long_desc = "LSU reject due to LMQ full ( 4 per cycle).",
+},
+[ POWER8_PME_PM_LSU_SET_MPRED ] = {
+	.pme_name = "PM_LSU_SET_MPRED",
+	.pme_code = 0xd082,
+	.pme_short_desc = "Line already in cache at reload time",
+	.pme_long_desc = "Line already in cache at reload time42",
+},
+[ POWER8_PME_PM_LSU_SRQ_EMPTY_CYC ] = {
+	.pme_name = "PM_LSU_SRQ_EMPTY_CYC",
+	.pme_code = 0x40008,
+	.pme_short_desc = "ALL threads srq empty",
+	.pme_long_desc = "All threads srq empty.",
+},
+[ POWER8_PME_PM_LSU_SRQ_FULL_CYC ] = {
+	.pme_name = "PM_LSU_SRQ_FULL_CYC",
+	.pme_code = 0x1001a,
+	.pme_short_desc = "Storage Queue is full and is blocking dispatch",
+	.pme_long_desc = "SRQ is Full.",
+},
+[ POWER8_PME_PM_LSU_SRQ_S0_ALLOC ] = {
+	.pme_name = "PM_LSU_SRQ_S0_ALLOC",
+	.pme_code = 0xd09d,
+	.pme_short_desc = "Per thread - use edge detect to count allocates On a per thread basis, level signal indicating Slot 0 is valid. By instrumenting a single slot we can calculate service time for that slot. Previous machines required a separate signal indicating the slot was allocated. Because any signal can be routed to any counter in P8, we can count level in one PMC and edge detect in another PMC using the same signal",
+	.pme_long_desc = "0.0",
+},
+[ POWER8_PME_PM_LSU_SRQ_S0_VALID ] = {
+	.pme_name = "PM_LSU_SRQ_S0_VALID",
+	.pme_code = 0xd09c,
+	.pme_short_desc = "Slot 0 of SRQ valid",
+	.pme_long_desc = "Slot 0 of SRQ validSRQ slot 0 valid",
+},
+[ POWER8_PME_PM_LSU_SRQ_S39_ALLOC ] = {
+	.pme_name = "PM_LSU_SRQ_S39_ALLOC",
+	.pme_code = 0xf093,
+	.pme_short_desc = "SRQ slot 39 was released",
+	.pme_long_desc = "0.0",
+},
+[ POWER8_PME_PM_LSU_SRQ_S39_VALID ] = {
+	.pme_name = "PM_LSU_SRQ_S39_VALID",
+	.pme_code = 0xf092,
+	.pme_short_desc = "SRQ slot 39 was busy",
+	.pme_long_desc = "SRQ slot 39 was busy42",
+},
+[ POWER8_PME_PM_LSU_SRQ_SYNC ] = {
+	.pme_name = "PM_LSU_SRQ_SYNC",
+	.pme_code = 0xd09b,
+	.pme_short_desc = "A sync in the SRQ ended",
+	.pme_long_desc = "0.0",
+},
+[ POWER8_PME_PM_LSU_SRQ_SYNC_CYC ] = {
+	.pme_name = "PM_LSU_SRQ_SYNC_CYC",
+	.pme_code = 0xd09a,
+	.pme_short_desc = "A sync is in the SRQ (edge detect to count)",
+	.pme_long_desc = "A sync is in the SRQ (edge detect to count)SRQ sync duration",
+},
+[ POWER8_PME_PM_LSU_STORE_REJECT ] = {
+	.pme_name = "PM_LSU_STORE_REJECT",
+	.pme_code = 0xf084,
+	.pme_short_desc = "Store reject on either pipe",
+	.pme_long_desc = "LSU",
+},
+[ POWER8_PME_PM_LSU_TWO_TABLEWALK_CYC ] = {
+	.pme_name = "PM_LSU_TWO_TABLEWALK_CYC",
+	.pme_code = 0xd0a6,
+	.pme_short_desc = "Cycles when two tablewalks pending on this thread",
+	.pme_long_desc = "Cycles when two tablewalks pending on this thread42",
+},
+[ POWER8_PME_PM_LWSYNC ] = {
+	.pme_name = "PM_LWSYNC",
+	.pme_code = 0x5094,
+	.pme_short_desc = "threaded version, IC Misses where we got EA dir hit but no sector valids were on. ICBI took line out",
+	.pme_long_desc = "threaded version, IC Misses where we got EA dir hit but no sector valids were on. ICBI took line out",
+},
+[ POWER8_PME_PM_LWSYNC_HELD ] = {
+	.pme_name = "PM_LWSYNC_HELD",
+	.pme_code = 0x209a,
+	.pme_short_desc = "LWSYNC held at dispatch",
+	.pme_long_desc = "LWSYNC held at dispatch",
+},
+[ POWER8_PME_PM_MEM_CO ] = {
+	.pme_name = "PM_MEM_CO",
+	.pme_code = 0x4c058,
+	.pme_short_desc = "Memory castouts from this lpar",
+	.pme_long_desc = "Memory castouts from this lpar.",
+},
+[ POWER8_PME_PM_MEM_LOC_THRESH_IFU ] = {
+	.pme_name = "PM_MEM_LOC_THRESH_IFU",
+	.pme_code = 0x10058,
+	.pme_short_desc = "Local Memory above threshold for IFU speculation control",
+	.pme_long_desc = "Local Memory above threshold for IFU speculation control.",
+},
+[ POWER8_PME_PM_MEM_LOC_THRESH_LSU_HIGH ] = {
+	.pme_name = "PM_MEM_LOC_THRESH_LSU_HIGH",
+	.pme_code = 0x40056,
+	.pme_short_desc = "Local memory above threshold for LSU medium",
+	.pme_long_desc = "Local memory above threshold for LSU medium.",
+},
+[ POWER8_PME_PM_MEM_LOC_THRESH_LSU_MED ] = {
+	.pme_name = "PM_MEM_LOC_THRESH_LSU_MED",
+	.pme_code = 0x1c05e,
+	.pme_short_desc = "Local memory above theshold for data prefetch",
+	.pme_long_desc = "Local memory above theshold for data prefetch.",
+},
+[ POWER8_PME_PM_MEM_PREF ] = {
+	.pme_name = "PM_MEM_PREF",
+	.pme_code = 0x2c058,
+	.pme_short_desc = "Memory prefetch for this lpar. Includes L4",
+	.pme_long_desc = "Memory prefetch for this lpar.",
+},
+[ POWER8_PME_PM_MEM_READ ] = {
+	.pme_name = "PM_MEM_READ",
+	.pme_code = 0x10056,
+	.pme_short_desc = "Reads from Memory from this lpar (includes data/inst/xlate/l1prefetch/inst prefetch). Includes L4",
+	.pme_long_desc = "Reads from Memory from this lpar (includes data/inst/xlate/l1prefetch/inst prefetch).",
+},
+[ POWER8_PME_PM_MEM_RWITM ] = {
+	.pme_name = "PM_MEM_RWITM",
+	.pme_code = 0x3c05e,
+	.pme_short_desc = "Memory rwitm for this lpar",
+	.pme_long_desc = "Memory rwitm for this lpar.",
+},
+[ POWER8_PME_PM_MRK_BACK_BR_CMPL ] = {
+	.pme_name = "PM_MRK_BACK_BR_CMPL",
+	.pme_code = 0x3515e,
+	.pme_short_desc = "Marked branch instruction completed with a target address less than current instruction address",
+	.pme_long_desc = "Marked branch instruction completed with a target address less than current instruction address.",
+},
+[ POWER8_PME_PM_MRK_BRU_FIN ] = {
+	.pme_name = "PM_MRK_BRU_FIN",
+	.pme_code = 0x2013a,
+	.pme_short_desc = "bru marked instr finish",
+	.pme_long_desc = "bru marked instr finish.",
+},
+[ POWER8_PME_PM_MRK_BR_CMPL ] = {
+	.pme_name = "PM_MRK_BR_CMPL",
+	.pme_code = 0x1016e,
+	.pme_short_desc = "Branch Instruction completed",
+	.pme_long_desc = "Branch Instruction completed.",
+},
+[ POWER8_PME_PM_MRK_BR_MPRED_CMPL ] = {
+	.pme_name = "PM_MRK_BR_MPRED_CMPL",
+	.pme_code = 0x301e4,
+	.pme_short_desc = "Marked Branch Mispredicted",
+	.pme_long_desc = "Marked Branch Mispredicted.",
+},
+[ POWER8_PME_PM_MRK_BR_TAKEN_CMPL ] = {
+	.pme_name = "PM_MRK_BR_TAKEN_CMPL",
+	.pme_code = 0x101e2,
+	.pme_short_desc = "Marked Branch Taken completed",
+	.pme_long_desc = "Marked Branch Taken.",
+},
+[ POWER8_PME_PM_MRK_CRU_FIN ] = {
+	.pme_name = "PM_MRK_CRU_FIN",
+	.pme_code = 0x3013a,
+	.pme_short_desc = "IFU non-branch finished",
+	.pme_long_desc = "IFU non-branch marked instruction finished.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_DL2L3_MOD ] = {
+	.pme_name = "PM_MRK_DATA_FROM_DL2L3_MOD",
+	.pme_code = 0x4d148,
+	.pme_short_desc = "The processor's data cache was reloaded with Modified (M) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded with Modified (M) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_DL2L3_MOD_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_DL2L3_MOD_CYC",
+	.pme_code = 0x2d128,
+	.pme_short_desc = "Duration in cycles to reload with Modified (M) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload with Modified (M) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_DL2L3_SHR ] = {
+	.pme_name = "PM_MRK_DATA_FROM_DL2L3_SHR",
+	.pme_code = 0x3d148,
+	.pme_short_desc = "The processor's data cache was reloaded with Shared (S) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded with Shared (S) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_DL2L3_SHR_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_DL2L3_SHR_CYC",
+	.pme_code = 0x2c128,
+	.pme_short_desc = "Duration in cycles to reload with Shared (S) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload with Shared (S) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_DL4 ] = {
+	.pme_name = "PM_MRK_DATA_FROM_DL4",
+	.pme_code = 0x3d14c,
+	.pme_short_desc = "The processor's data cache was reloaded from another chip's L4 on a different Node or Group (Distant) due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded from another chip's L4 on a different Node or Group (Distant) due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_DL4_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_DL4_CYC",
+	.pme_code = 0x2c12c,
+	.pme_short_desc = "Duration in cycles to reload from another chip's L4 on a different Node or Group (Distant) due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from another chip's L4 on a different Node or Group (Distant) due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_DMEM ] = {
+	.pme_name = "PM_MRK_DATA_FROM_DMEM",
+	.pme_code = 0x4d14c,
+	.pme_short_desc = "The processor's data cache was reloaded from another chip's memory on the same Node or Group (Distant) due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded from another chip's memory on the same Node or Group (Distant) due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_DMEM_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_DMEM_CYC",
+	.pme_code = 0x2d12c,
+	.pme_short_desc = "Duration in cycles to reload from another chip's memory on the same Node or Group (Distant) due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from another chip's memory on the same Node or Group (Distant) due to a marked load.",
+},
 [ POWER8_PME_PM_MRK_DATA_FROM_L2 ] = {
 	.pme_name = "PM_MRK_DATA_FROM_L2",
 	.pme_code = 0x1d142,
 	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 due to a marked load",
 	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 due to a marked load.",
 },
+[ POWER8_PME_PM_MRK_DATA_FROM_L21_MOD ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L21_MOD",
+	.pme_code = 0x4d146,
+	.pme_short_desc = "The processor's data cache was reloaded with Modified (M) data from another core's L2 on the same chip due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded with Modified (M) data from another core's L2 on the same chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L21_MOD_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L21_MOD_CYC",
+	.pme_code = 0x2d126,
+	.pme_short_desc = "Duration in cycles to reload with Modified (M) data from another core's L2 on the same chip due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload with Modified (M) data from another core's L2 on the same chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L21_SHR ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L21_SHR",
+	.pme_code = 0x3d146,
+	.pme_short_desc = "The processor's data cache was reloaded with Shared (S) data from another core's L2 on the same chip due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded with Shared (S) data from another core's L2 on the same chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L21_SHR_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L21_SHR_CYC",
+	.pme_code = 0x2c126,
+	.pme_short_desc = "Duration in cycles to reload with Shared (S) data from another core's L2 on the same chip due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload with Shared (S) data from another core's L2 on the same chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L2MISS ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L2MISS",
+	.pme_code = 0x1d14e,
+	.pme_short_desc = "Data cache reload L2 miss",
+	.pme_long_desc = "Data cache reload L2 miss.",
+},
 [ POWER8_PME_PM_MRK_DATA_FROM_L2MISS_CYC ] = {
 	.pme_name = "PM_MRK_DATA_FROM_L2MISS_CYC",
 	.pme_code = 0x4c12e,
-	.pme_short_desc = "Duration in cycles to reload from a location other than the local core's L2 due to a marked load",
-	.pme_long_desc = "Duration in cycles to reload from a location other than the local core's L2 due to a marked load.",
+	.pme_short_desc = "Duration in cycles to reload from a localtion other than the local core's L2 due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from a localtion other than the local core's L2 due to a marked load.",
 },
 [ POWER8_PME_PM_MRK_DATA_FROM_L2_CYC ] = {
 	.pme_name = "PM_MRK_DATA_FROM_L2_CYC",
@@ -843,6 +5462,42 @@ static const pme_power_entry_t power8_pe[] = {
 	.pme_short_desc = "Duration in cycles to reload from local core's L2 due to a marked load",
 	.pme_long_desc = "Duration in cycles to reload from local core's L2 due to a marked load.",
 },
+[ POWER8_PME_PM_MRK_DATA_FROM_L2_DISP_CONFLICT_LDHITST ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L2_DISP_CONFLICT_LDHITST",
+	.pme_code = 0x3d140,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 with load hit store conflict due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 with load hit store conflict due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L2_DISP_CONFLICT_LDHITST_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L2_DISP_CONFLICT_LDHITST_CYC",
+	.pme_code = 0x2c120,
+	.pme_short_desc = "Duration in cycles to reload from local core's L2 with load hit store conflict due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from local core's L2 with load hit store conflict due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L2_DISP_CONFLICT_OTHER ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L2_DISP_CONFLICT_OTHER",
+	.pme_code = 0x4d140,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 with dispatch conflict due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 with dispatch conflict due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L2_DISP_CONFLICT_OTHER_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L2_DISP_CONFLICT_OTHER_CYC",
+	.pme_code = 0x2d120,
+	.pme_short_desc = "Duration in cycles to reload from local core's L2 with dispatch conflict due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from local core's L2 with dispatch conflict due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L2_MEPF ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L2_MEPF",
+	.pme_code = 0x2d140,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L2 hit without dispatch conflicts on Mepf state. due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L2 hit without dispatch conflicts on Mepf state. due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L2_MEPF_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L2_MEPF_CYC",
+	.pme_code = 0x4d120,
+	.pme_short_desc = "Duration in cycles to reload from local core's L2 hit without dispatch conflicts on Mepf state. due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from local core's L2 hit without dispatch conflicts on Mepf state. due to a marked load.",
+},
 [ POWER8_PME_PM_MRK_DATA_FROM_L2_NO_CONFLICT ] = {
 	.pme_name = "PM_MRK_DATA_FROM_L2_NO_CONFLICT",
 	.pme_code = 0x1d140,
@@ -861,11 +5516,65 @@ static const pme_power_entry_t power8_pe[] = {
 	.pme_short_desc = "The processor's data cache was reloaded from local core's L3 due to a marked load",
 	.pme_long_desc = "The processor's data cache was reloaded from local core's L3 due to a marked load.",
 },
+[ POWER8_PME_PM_MRK_DATA_FROM_L31_ECO_MOD ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L31_ECO_MOD",
+	.pme_code = 0x4d144,
+	.pme_short_desc = "The processor's data cache was reloaded with Modified (M) data from another core's ECO L3 on the same chip due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded with Modified (M) data from another core's ECO L3 on the same chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L31_ECO_MOD_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L31_ECO_MOD_CYC",
+	.pme_code = 0x2d124,
+	.pme_short_desc = "Duration in cycles to reload with Modified (M) data from another core's ECO L3 on the same chip due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload with Modified (M) data from another core's ECO L3 on the same chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L31_ECO_SHR ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L31_ECO_SHR",
+	.pme_code = 0x3d144,
+	.pme_short_desc = "The processor's data cache was reloaded with Shared (S) data from another core's ECO L3 on the same chip due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded with Shared (S) data from another core's ECO L3 on the same chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L31_ECO_SHR_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L31_ECO_SHR_CYC",
+	.pme_code = 0x2c124,
+	.pme_short_desc = "Duration in cycles to reload with Shared (S) data from another core's ECO L3 on the same chip due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload with Shared (S) data from another core's ECO L3 on the same chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L31_MOD ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L31_MOD",
+	.pme_code = 0x2d144,
+	.pme_short_desc = "The processor's data cache was reloaded with Modified (M) data from another core's L3 on the same chip due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded with Modified (M) data from another core's L3 on the same chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L31_MOD_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L31_MOD_CYC",
+	.pme_code = 0x4d124,
+	.pme_short_desc = "Duration in cycles to reload with Modified (M) data from another core's L3 on the same chip due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload with Modified (M) data from another core's L3 on the same chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L31_SHR ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L31_SHR",
+	.pme_code = 0x1d146,
+	.pme_short_desc = "The processor's data cache was reloaded with Shared (S) data from another core's L3 on the same chip due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded with Shared (S) data from another core's L3 on the same chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L31_SHR_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L31_SHR_CYC",
+	.pme_code = 0x4c126,
+	.pme_short_desc = "Duration in cycles to reload with Shared (S) data from another core's L3 on the same chip due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload with Shared (S) data from another core's L3 on the same chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L3MISS ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L3MISS",
+	.pme_code = 0x201e4,
+	.pme_short_desc = "The processor's data cache was reloaded from a localtion other than the local core's L3 due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded from a localtion other than the local core's L3 due to a marked load.",
+},
 [ POWER8_PME_PM_MRK_DATA_FROM_L3MISS_CYC ] = {
 	.pme_name = "PM_MRK_DATA_FROM_L3MISS_CYC",
 	.pme_code = 0x2d12e,
-	.pme_short_desc = "Duration in cycles to reload from a location other than the local core's L3 due to a marked load",
-	.pme_long_desc = "Duration in cycles to reload from a location other than the local core's L3 due to a marked load.",
+	.pme_short_desc = "Duration in cycles to reload from a localtion other than the local core's L3 due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from a localtion other than the local core's L3 due to a marked load.",
 },
 [ POWER8_PME_PM_MRK_DATA_FROM_L3_CYC ] = {
 	.pme_name = "PM_MRK_DATA_FROM_L3_CYC",
@@ -873,6 +5582,30 @@ static const pme_power_entry_t power8_pe[] = {
 	.pme_short_desc = "Duration in cycles to reload from local core's L3 due to a marked load",
 	.pme_long_desc = "Duration in cycles to reload from local core's L3 due to a marked load.",
 },
+[ POWER8_PME_PM_MRK_DATA_FROM_L3_DISP_CONFLICT ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L3_DISP_CONFLICT",
+	.pme_code = 0x3d142,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L3 with dispatch conflict due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L3 with dispatch conflict due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L3_DISP_CONFLICT_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L3_DISP_CONFLICT_CYC",
+	.pme_code = 0x2c122,
+	.pme_short_desc = "Duration in cycles to reload from local core's L3 with dispatch conflict due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from local core's L3 with dispatch conflict due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L3_MEPF ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L3_MEPF",
+	.pme_code = 0x2d142,
+	.pme_short_desc = "The processor's data cache was reloaded from local core's L3 without dispatch conflicts hit on Mepf state. due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded from local core's L3 without dispatch conflicts hit on Mepf state. due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_L3_MEPF_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_L3_MEPF_CYC",
+	.pme_code = 0x4d122,
+	.pme_short_desc = "Duration in cycles to reload from local core's L3 without dispatch conflicts hit on Mepf state. due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from local core's L3 without dispatch conflicts hit on Mepf state. due to a marked load.",
+},
 [ POWER8_PME_PM_MRK_DATA_FROM_L3_NO_CONFLICT ] = {
 	.pme_name = "PM_MRK_DATA_FROM_L3_NO_CONFLICT",
 	.pme_code = 0x1d144,
@@ -909,6 +5642,12 @@ static const pme_power_entry_t power8_pe[] = {
 	.pme_short_desc = "Duration in cycles to reload from the local chip's Memory due to a marked load",
 	.pme_long_desc = "Duration in cycles to reload from the local chip's Memory due to a marked load.",
 },
+[ POWER8_PME_PM_MRK_DATA_FROM_MEM ] = {
+	.pme_name = "PM_MRK_DATA_FROM_MEM",
+	.pme_code = 0x201e0,
+	.pme_short_desc = "The processor's data cache was reloaded from a memory location including L4 from local remote or distant due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded from a memory location including L4 from local remote or distant due to a marked load.",
+},
 [ POWER8_PME_PM_MRK_DATA_FROM_MEMORY ] = {
 	.pme_name = "PM_MRK_DATA_FROM_MEMORY",
 	.pme_code = 0x2d14c,
@@ -921,42 +5660,750 @@ static const pme_power_entry_t power8_pe[] = {
 	.pme_short_desc = "Duration in cycles to reload from a memory location including L4 from local remote or distant due to a marked load",
 	.pme_long_desc = "Duration in cycles to reload from a memory location including L4 from local remote or distant due to a marked load.",
 },
+[ POWER8_PME_PM_MRK_DATA_FROM_OFF_CHIP_CACHE ] = {
+	.pme_name = "PM_MRK_DATA_FROM_OFF_CHIP_CACHE",
+	.pme_code = 0x4d14a,
+	.pme_short_desc = "The processor's data cache was reloaded either shared or modified data from another core's L2/L3 on a different chip (remote or distant) due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded either shared or modified data from another core's L2/L3 on a different chip (remote or distant) due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_OFF_CHIP_CACHE_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_OFF_CHIP_CACHE_CYC",
+	.pme_code = 0x2d12a,
+	.pme_short_desc = "Duration in cycles to reload either shared or modified data from another core's L2/L3 on a different chip (remote or distant) due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload either shared or modified data from another core's L2/L3 on a different chip (remote or distant) due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_ON_CHIP_CACHE ] = {
+	.pme_name = "PM_MRK_DATA_FROM_ON_CHIP_CACHE",
+	.pme_code = 0x1d148,
+	.pme_short_desc = "The processor's data cache was reloaded either shared or modified data from another core's L2/L3 on the same chip due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded either shared or modified data from another core's L2/L3 on the same chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_ON_CHIP_CACHE_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_ON_CHIP_CACHE_CYC",
+	.pme_code = 0x4c128,
+	.pme_short_desc = "Duration in cycles to reload either shared or modified data from another core's L2/L3 on the same chip due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload either shared or modified data from another core's L2/L3 on the same chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_RL2L3_MOD ] = {
+	.pme_name = "PM_MRK_DATA_FROM_RL2L3_MOD",
+	.pme_code = 0x2d146,
+	.pme_short_desc = "The processor's data cache was reloaded with Modified (M) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded with Modified (M) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_RL2L3_MOD_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_RL2L3_MOD_CYC",
+	.pme_code = 0x4d126,
+	.pme_short_desc = "Duration in cycles to reload with Modified (M) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload with Modified (M) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_RL2L3_SHR ] = {
+	.pme_name = "PM_MRK_DATA_FROM_RL2L3_SHR",
+	.pme_code = 0x1d14a,
+	.pme_short_desc = "The processor's data cache was reloaded with Shared (S) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded with Shared (S) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_RL2L3_SHR_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_RL2L3_SHR_CYC",
+	.pme_code = 0x4c12a,
+	.pme_short_desc = "Duration in cycles to reload with Shared (S) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload with Shared (S) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_RL4 ] = {
+	.pme_name = "PM_MRK_DATA_FROM_RL4",
+	.pme_code = 0x2d14a,
+	.pme_short_desc = "The processor's data cache was reloaded from another chip's L4 on the same Node or Group ( Remote) due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded from another chip's L4 on the same Node or Group ( Remote) due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_RL4_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_RL4_CYC",
+	.pme_code = 0x4d12a,
+	.pme_short_desc = "Duration in cycles to reload from another chip's L4 on the same Node or Group ( Remote) due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from another chip's L4 on the same Node or Group ( Remote) due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_RMEM ] = {
+	.pme_name = "PM_MRK_DATA_FROM_RMEM",
+	.pme_code = 0x3d14a,
+	.pme_short_desc = "The processor's data cache was reloaded from another chip's memory on the same Node or Group ( Remote) due to a marked load",
+	.pme_long_desc = "The processor's data cache was reloaded from another chip's memory on the same Node or Group ( Remote) due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DATA_FROM_RMEM_CYC ] = {
+	.pme_name = "PM_MRK_DATA_FROM_RMEM_CYC",
+	.pme_code = 0x2c12a,
+	.pme_short_desc = "Duration in cycles to reload from another chip's memory on the same Node or Group ( Remote) due to a marked load",
+	.pme_long_desc = "Duration in cycles to reload from another chip's memory on the same Node or Group ( Remote) due to a marked load.",
+},
+[ POWER8_PME_PM_MRK_DCACHE_RELOAD_INTV ] = {
+	.pme_name = "PM_MRK_DCACHE_RELOAD_INTV",
+	.pme_code = 0x40118,
+	.pme_short_desc = "Combined Intervention event",
+	.pme_long_desc = "Combined Intervention event.",
+},
+[ POWER8_PME_PM_MRK_DERAT_MISS ] = {
+	.pme_name = "PM_MRK_DERAT_MISS",
+	.pme_code = 0x301e6,
+	.pme_short_desc = "Erat Miss (TLB Access) All page sizes",
+	.pme_long_desc = "Erat Miss (TLB Access) All page sizes.",
+},
+[ POWER8_PME_PM_MRK_DERAT_MISS_16G ] = {
+	.pme_name = "PM_MRK_DERAT_MISS_16G",
+	.pme_code = 0x4d154,
+	.pme_short_desc = "Marked Data ERAT Miss (Data TLB Access) page size 16G",
+	.pme_long_desc = "Marked Data ERAT Miss (Data TLB Access) page size 16G.",
+},
+[ POWER8_PME_PM_MRK_DERAT_MISS_16M ] = {
+	.pme_name = "PM_MRK_DERAT_MISS_16M",
+	.pme_code = 0x3d154,
+	.pme_short_desc = "Marked Data ERAT Miss (Data TLB Access) page size 16M",
+	.pme_long_desc = "Marked Data ERAT Miss (Data TLB Access) page size 16M.",
+},
+[ POWER8_PME_PM_MRK_DERAT_MISS_4K ] = {
+	.pme_name = "PM_MRK_DERAT_MISS_4K",
+	.pme_code = 0x1d156,
+	.pme_short_desc = "Marked Data ERAT Miss (Data TLB Access) page size 4K",
+	.pme_long_desc = "Marked Data ERAT Miss (Data TLB Access) page size 4K.",
+},
+[ POWER8_PME_PM_MRK_DERAT_MISS_64K ] = {
+	.pme_name = "PM_MRK_DERAT_MISS_64K",
+	.pme_code = 0x2d154,
+	.pme_short_desc = "Marked Data ERAT Miss (Data TLB Access) page size 64K",
+	.pme_long_desc = "Marked Data ERAT Miss (Data TLB Access) page size 64K.",
+},
+[ POWER8_PME_PM_MRK_DFU_FIN ] = {
+	.pme_name = "PM_MRK_DFU_FIN",
+	.pme_code = 0x20132,
+	.pme_short_desc = "Decimal Unit marked Instruction Finish",
+	.pme_long_desc = "Decimal Unit marked Instruction Finish.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_DL2L3_MOD ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_DL2L3_MOD",
+	.pme_code = 0x4f148,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_DL2L3_SHR ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_DL2L3_SHR",
+	.pme_code = 0x3f148,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another chip's L2 or L3 on a different Node or Group (Distant), as this chip due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_DL4 ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_DL4",
+	.pme_code = 0x3f14c,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from another chip's L4 on a different Node or Group (Distant) due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from another chip's L4 on a different Node or Group (Distant) due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_DMEM ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_DMEM",
+	.pme_code = 0x4f14c,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from another chip's memory on the same Node or Group (Distant) due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from another chip's memory on the same Node or Group (Distant) due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_L2 ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_L2",
+	.pme_code = 0x1f142,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L2 due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L2 due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_L21_MOD ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_L21_MOD",
+	.pme_code = 0x4f146,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another core's L2 on the same chip due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another core's L2 on the same chip due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_L21_SHR ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_L21_SHR",
+	.pme_code = 0x3f146,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another core's L2 on the same chip due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another core's L2 on the same chip due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_L2MISS ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_L2MISS",
+	.pme_code = 0x1f14e,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from a localtion other than the local core's L2 due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from a localtion other than the local core's L2 due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_L2_DISP_CONFLICT_LDHITST ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_L2_DISP_CONFLICT_LDHITST",
+	.pme_code = 0x3f140,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L2 with load hit store conflict due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L2 with load hit store conflict due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_L2_DISP_CONFLICT_OTHER ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_L2_DISP_CONFLICT_OTHER",
+	.pme_code = 0x4f140,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L2 with dispatch conflict due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L2 with dispatch conflict due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_L2_MEPF ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_L2_MEPF",
+	.pme_code = 0x2f140,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L2 hit without dispatch conflicts on Mepf state. due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L2 hit without dispatch conflicts on Mepf state. due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_L2_NO_CONFLICT ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_L2_NO_CONFLICT",
+	.pme_code = 0x1f140,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L2 without conflict due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L2 without conflict due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_L3 ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_L3",
+	.pme_code = 0x4f142,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L3 due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L3 due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_L31_ECO_MOD ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_L31_ECO_MOD",
+	.pme_code = 0x4f144,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another core's ECO L3 on the same chip due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another core's ECO L3 on the same chip due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_L31_ECO_SHR ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_L31_ECO_SHR",
+	.pme_code = 0x3f144,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another core's ECO L3 on the same chip due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another core's ECO L3 on the same chip due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_L31_MOD ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_L31_MOD",
+	.pme_code = 0x2f144,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another core's L3 on the same chip due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another core's L3 on the same chip due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_L31_SHR ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_L31_SHR",
+	.pme_code = 0x1f146,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another core's L3 on the same chip due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another core's L3 on the same chip due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_L3MISS ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_L3MISS",
+	.pme_code = 0x4f14e,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from a localtion other than the local core's L3 due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from a localtion other than the local core's L3 due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_L3_DISP_CONFLICT ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_L3_DISP_CONFLICT",
+	.pme_code = 0x3f142,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L3 with dispatch conflict due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L3 with dispatch conflict due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_L3_MEPF ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_L3_MEPF",
+	.pme_code = 0x2f142,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L3 without dispatch conflicts hit on Mepf state. due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L3 without dispatch conflicts hit on Mepf state. due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_L3_NO_CONFLICT ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_L3_NO_CONFLICT",
+	.pme_code = 0x1f144,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from local core's L3 without conflict due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from local core's L3 without conflict due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_LL4 ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_LL4",
+	.pme_code = 0x1f14c,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from the local chip's L4 cache due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from the local chip's L4 cache due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_LMEM ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_LMEM",
+	.pme_code = 0x2f148,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from the local chip's Memory due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from the local chip's Memory due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_MEMORY ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_MEMORY",
+	.pme_code = 0x2f14c,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from a memory location including L4 from local remote or distant due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from a memory location including L4 from local remote or distant due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_OFF_CHIP_CACHE ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_OFF_CHIP_CACHE",
+	.pme_code = 0x4f14a,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB either shared or modified data from another core's L2/L3 on a different chip (remote or distant) due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB either shared or modified data from another core's L2/L3 on a different chip (remote or distant) due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_ON_CHIP_CACHE ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_ON_CHIP_CACHE",
+	.pme_code = 0x1f148,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB either shared or modified data from another core's L2/L3 on the same chip due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB either shared or modified data from another core's L2/L3 on the same chip due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_RL2L3_MOD ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_RL2L3_MOD",
+	.pme_code = 0x2f146,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Modified (M) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_RL2L3_SHR ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_RL2L3_SHR",
+	.pme_code = 0x1f14a,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB with Shared (S) data from another chip's L2 or L3 on the same Node or Group (Remote), as this chip due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_RL4 ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_RL4",
+	.pme_code = 0x2f14a,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from another chip's L4 on the same Node or Group ( Remote) due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from another chip's L4 on the same Node or Group ( Remote) due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DPTEG_FROM_RMEM ] = {
+	.pme_name = "PM_MRK_DPTEG_FROM_RMEM",
+	.pme_code = 0x3f14a,
+	.pme_short_desc = "A Page Table Entry was loaded into the TLB from another chip's memory on the same Node or Group ( Remote) due to a marked data side request",
+	.pme_long_desc = "A Page Table Entry was loaded into the TLB from another chip's memory on the same Node or Group ( Remote) due to a marked data side request.",
+},
+[ POWER8_PME_PM_MRK_DTLB_MISS ] = {
+	.pme_name = "PM_MRK_DTLB_MISS",
+	.pme_code = 0x401e4,
+	.pme_short_desc = "Marked dtlb miss",
+	.pme_long_desc = "Marked dtlb miss.",
+},
+[ POWER8_PME_PM_MRK_DTLB_MISS_16G ] = {
+	.pme_name = "PM_MRK_DTLB_MISS_16G",
+	.pme_code = 0x1d158,
+	.pme_short_desc = "Marked Data TLB Miss page size 16G",
+	.pme_long_desc = "Marked Data TLB Miss page size 16G.",
+},
+[ POWER8_PME_PM_MRK_DTLB_MISS_16M ] = {
+	.pme_name = "PM_MRK_DTLB_MISS_16M",
+	.pme_code = 0x4d156,
+	.pme_short_desc = "Marked Data TLB Miss page size 16M",
+	.pme_long_desc = "Marked Data TLB Miss page size 16M.",
+},
+[ POWER8_PME_PM_MRK_DTLB_MISS_4K ] = {
+	.pme_name = "PM_MRK_DTLB_MISS_4K",
+	.pme_code = 0x2d156,
+	.pme_short_desc = "Marked Data TLB Miss page size 4k",
+	.pme_long_desc = "Marked Data TLB Miss page size 4k.",
+},
+[ POWER8_PME_PM_MRK_DTLB_MISS_64K ] = {
+	.pme_name = "PM_MRK_DTLB_MISS_64K",
+	.pme_code = 0x3d156,
+	.pme_short_desc = "Marked Data TLB Miss page size 64K",
+	.pme_long_desc = "Marked Data TLB Miss page size 64K.",
+},
+[ POWER8_PME_PM_MRK_FAB_RSP_BKILL ] = {
+	.pme_name = "PM_MRK_FAB_RSP_BKILL",
+	.pme_code = 0x40154,
+	.pme_short_desc = "Marked store had to do a bkill",
+	.pme_long_desc = "Marked store had to do a bkill.",
+},
+[ POWER8_PME_PM_MRK_FAB_RSP_BKILL_CYC ] = {
+	.pme_name = "PM_MRK_FAB_RSP_BKILL_CYC",
+	.pme_code = 0x2f150,
+	.pme_short_desc = "cycles L2 RC took for a bkill",
+	.pme_long_desc = "cycles L2 RC took for a bkill.",
+},
+[ POWER8_PME_PM_MRK_FAB_RSP_CLAIM_RTY ] = {
+	.pme_name = "PM_MRK_FAB_RSP_CLAIM_RTY",
+	.pme_code = 0x3015e,
+	.pme_short_desc = "Sampled store did a rwitm and got a rty",
+	.pme_long_desc = "Sampled store did a rwitm and got a rty.",
+},
+[ POWER8_PME_PM_MRK_FAB_RSP_DCLAIM ] = {
+	.pme_name = "PM_MRK_FAB_RSP_DCLAIM",
+	.pme_code = 0x30154,
+	.pme_short_desc = "Marked store had to do a dclaim",
+	.pme_long_desc = "Marked store had to do a dclaim.",
+},
+[ POWER8_PME_PM_MRK_FAB_RSP_DCLAIM_CYC ] = {
+	.pme_name = "PM_MRK_FAB_RSP_DCLAIM_CYC",
+	.pme_code = 0x2f152,
+	.pme_short_desc = "cycles L2 RC took for a dclaim",
+	.pme_long_desc = "cycles L2 RC took for a dclaim.",
+},
+[ POWER8_PME_PM_MRK_FAB_RSP_MATCH ] = {
+	.pme_name = "PM_MRK_FAB_RSP_MATCH",
+	.pme_code = 0x30156,
+	.pme_short_desc = "ttype and cresp matched as specified in MMCR1",
+	.pme_long_desc = "ttype and cresp matched as specified in MMCR1.",
+},
+[ POWER8_PME_PM_MRK_FAB_RSP_MATCH_CYC ] = {
+	.pme_name = "PM_MRK_FAB_RSP_MATCH_CYC",
+	.pme_code = 0x4f152,
+	.pme_short_desc = "cresp/ttype match cycles",
+	.pme_long_desc = "cresp/ttype match cycles.",
+},
+[ POWER8_PME_PM_MRK_FAB_RSP_RD_RTY ] = {
+	.pme_name = "PM_MRK_FAB_RSP_RD_RTY",
+	.pme_code = 0x4015e,
+	.pme_short_desc = "Sampled L2 reads retry count",
+	.pme_long_desc = "Sampled L2 reads retry count.",
+},
+[ POWER8_PME_PM_MRK_FAB_RSP_RD_T_INTV ] = {
+	.pme_name = "PM_MRK_FAB_RSP_RD_T_INTV",
+	.pme_code = 0x1015e,
+	.pme_short_desc = "Sampled Read got a T intervention",
+	.pme_long_desc = "Sampled Read got a T intervention.",
+},
+[ POWER8_PME_PM_MRK_FAB_RSP_RWITM_CYC ] = {
+	.pme_name = "PM_MRK_FAB_RSP_RWITM_CYC",
+	.pme_code = 0x4f150,
+	.pme_short_desc = "cycles L2 RC took for a rwitm",
+	.pme_long_desc = "cycles L2 RC took for a rwitm.",
+},
+[ POWER8_PME_PM_MRK_FAB_RSP_RWITM_RTY ] = {
+	.pme_name = "PM_MRK_FAB_RSP_RWITM_RTY",
+	.pme_code = 0x2015e,
+	.pme_short_desc = "Sampled store did a rwitm and got a rty",
+	.pme_long_desc = "Sampled store did a rwitm and got a rty.",
+},
+[ POWER8_PME_PM_MRK_FILT_MATCH ] = {
+	.pme_name = "PM_MRK_FILT_MATCH",
+	.pme_code = 0x2013c,
+	.pme_short_desc = "Marked filter Match",
+	.pme_long_desc = "Marked filter Match.",
+},
+[ POWER8_PME_PM_MRK_FIN_STALL_CYC ] = {
+	.pme_name = "PM_MRK_FIN_STALL_CYC",
+	.pme_code = 0x1013c,
+	.pme_short_desc = "Marked instruction Finish Stall cycles (marked finish after NTC) (use edge detect to count )",
+	.pme_long_desc = "Marked instruction Finish Stall cycles (marked finish after NTC) (use edge detect to count #).",
+},
+[ POWER8_PME_PM_MRK_FXU_FIN ] = {
+	.pme_name = "PM_MRK_FXU_FIN",
+	.pme_code = 0x20134,
+	.pme_short_desc = "fxu marked instr finish",
+	.pme_long_desc = "fxu marked instr finish.",
+},
 [ POWER8_PME_PM_MRK_GRP_CMPL ] = {
 	.pme_name = "PM_MRK_GRP_CMPL",
 	.pme_code = 0x40130,
 	.pme_short_desc = "marked instruction finished (completed)",
 	.pme_long_desc = "marked instruction finished (completed).",
 },
+[ POWER8_PME_PM_MRK_GRP_IC_MISS ] = {
+	.pme_name = "PM_MRK_GRP_IC_MISS",
+	.pme_code = 0x4013a,
+	.pme_short_desc = "Marked Group experienced I cache miss",
+	.pme_long_desc = "Marked Group experienced I cache miss.",
+},
+[ POWER8_PME_PM_MRK_GRP_NTC ] = {
+	.pme_name = "PM_MRK_GRP_NTC",
+	.pme_code = 0x3013c,
+	.pme_short_desc = "Marked group ntc cycles.",
+	.pme_long_desc = "Marked group ntc cycles.",
+},
+[ POWER8_PME_PM_MRK_INST_CMPL ] = {
+	.pme_name = "PM_MRK_INST_CMPL",
+	.pme_code = 0x401e0,
+	.pme_short_desc = "marked instruction completed",
+	.pme_long_desc = "marked instruction completed.",
+},
 [ POWER8_PME_PM_MRK_INST_DECODED ] = {
 	.pme_name = "PM_MRK_INST_DECODED",
 	.pme_code = 0x20130,
 	.pme_short_desc = "marked instruction decoded",
 	.pme_long_desc = "marked instruction decoded. Name from ISU?",
 },
+[ POWER8_PME_PM_MRK_INST_DISP ] = {
+	.pme_name = "PM_MRK_INST_DISP",
+	.pme_code = 0x101e0,
+	.pme_short_desc = "The thread has dispatched a randomly sampled marked instruction",
+	.pme_long_desc = "Marked Instruction dispatched.",
+},
+[ POWER8_PME_PM_MRK_INST_FIN ] = {
+	.pme_name = "PM_MRK_INST_FIN",
+	.pme_code = 0x30130,
+	.pme_short_desc = "marked instruction finished",
+	.pme_long_desc = "marked instr finish any unit .",
+},
+[ POWER8_PME_PM_MRK_INST_FROM_L3MISS ] = {
+	.pme_name = "PM_MRK_INST_FROM_L3MISS",
+	.pme_code = 0x401e6,
+	.pme_short_desc = "Marked instruction was reloaded from a location beyond the local chiplet",
+	.pme_long_desc = "n/a",
+},
+[ POWER8_PME_PM_MRK_INST_ISSUED ] = {
+	.pme_name = "PM_MRK_INST_ISSUED",
+	.pme_code = 0x10132,
+	.pme_short_desc = "Marked instruction issued",
+	.pme_long_desc = "Marked instruction issued.",
+},
+[ POWER8_PME_PM_MRK_INST_TIMEO ] = {
+	.pme_name = "PM_MRK_INST_TIMEO",
+	.pme_code = 0x40134,
+	.pme_short_desc = "marked Instruction finish timeout (instruction lost)",
+	.pme_long_desc = "marked Instruction finish timeout (instruction lost).",
+},
+[ POWER8_PME_PM_MRK_L1_ICACHE_MISS ] = {
+	.pme_name = "PM_MRK_L1_ICACHE_MISS",
+	.pme_code = 0x101e4,
+	.pme_short_desc = "sampled Instruction suffered an icache Miss",
+	.pme_long_desc = "Marked L1 Icache Miss.",
+},
+[ POWER8_PME_PM_MRK_L1_RELOAD_VALID ] = {
+	.pme_name = "PM_MRK_L1_RELOAD_VALID",
+	.pme_code = 0x101ea,
+	.pme_short_desc = "Marked demand reload",
+	.pme_long_desc = "Marked demand reload.",
+},
 [ POWER8_PME_PM_MRK_L2_RC_DISP ] = {
 	.pme_name = "PM_MRK_L2_RC_DISP",
 	.pme_code = 0x20114,
 	.pme_short_desc = "Marked Instruction RC dispatched in L2",
 	.pme_long_desc = "Marked Instruction RC dispatched in L2.",
 },
+[ POWER8_PME_PM_MRK_L2_RC_DONE ] = {
+	.pme_name = "PM_MRK_L2_RC_DONE",
+	.pme_code = 0x3012a,
+	.pme_short_desc = "Marked RC done",
+	.pme_long_desc = "Marked RC done.",
+},
+[ POWER8_PME_PM_MRK_LARX_FIN ] = {
+	.pme_name = "PM_MRK_LARX_FIN",
+	.pme_code = 0x40116,
+	.pme_short_desc = "Larx finished",
+	.pme_long_desc = "Larx finished .",
+},
+[ POWER8_PME_PM_MRK_LD_MISS_EXPOSED ] = {
+	.pme_name = "PM_MRK_LD_MISS_EXPOSED",
+	.pme_code = 0x1013f,
+	.pme_short_desc = "Marked Load exposed Miss (exposed period ended)",
+	.pme_long_desc = "Marked Load exposed Miss (use edge detect to count #)",
+},
+[ POWER8_PME_PM_MRK_LD_MISS_EXPOSED_CYC ] = {
+	.pme_name = "PM_MRK_LD_MISS_EXPOSED_CYC",
+	.pme_code = 0x1013e,
+	.pme_short_desc = "Marked Load exposed Miss cycles",
+	.pme_long_desc = "Marked Load exposed Miss (use edge detect to count #).",
+},
+[ POWER8_PME_PM_MRK_LD_MISS_L1 ] = {
+	.pme_name = "PM_MRK_LD_MISS_L1",
+	.pme_code = 0x201e2,
+	.pme_short_desc = "Marked DL1 Demand Miss counted at exec time",
+	.pme_long_desc = "Marked DL1 Demand Miss counted at exec time.",
+},
 [ POWER8_PME_PM_MRK_LD_MISS_L1_CYC ] = {
 	.pme_name = "PM_MRK_LD_MISS_L1_CYC",
 	.pme_code = 0x4013e,
 	.pme_short_desc = "Marked ld latency",
 	.pme_long_desc = "Marked ld latency.",
 },
+[ POWER8_PME_PM_MRK_LSU_FIN ] = {
+	.pme_name = "PM_MRK_LSU_FIN",
+	.pme_code = 0x40132,
+	.pme_short_desc = "lsu marked instr finish",
+	.pme_long_desc = "lsu marked instr finish.",
+},
+[ POWER8_PME_PM_MRK_LSU_FLUSH ] = {
+	.pme_name = "PM_MRK_LSU_FLUSH",
+	.pme_code = 0xd180,
+	.pme_short_desc = "Flush: (marked) : All Cases",
+	.pme_long_desc = "Flush: (marked) : All Cases42",
+},
+[ POWER8_PME_PM_MRK_LSU_FLUSH_LRQ ] = {
+	.pme_name = "PM_MRK_LSU_FLUSH_LRQ",
+	.pme_code = 0xd188,
+	.pme_short_desc = "Flush: (marked) LRQ",
+	.pme_long_desc = "Flush: (marked) LRQMarked LRQ flushes",
+},
+[ POWER8_PME_PM_MRK_LSU_FLUSH_SRQ ] = {
+	.pme_name = "PM_MRK_LSU_FLUSH_SRQ",
+	.pme_code = 0xd18a,
+	.pme_short_desc = "Flush: (marked) SRQ",
+	.pme_long_desc = "Flush: (marked) SRQMarked SRQ lhs flushes",
+},
+[ POWER8_PME_PM_MRK_LSU_FLUSH_ULD ] = {
+	.pme_name = "PM_MRK_LSU_FLUSH_ULD",
+	.pme_code = 0xd184,
+	.pme_short_desc = "Flush: (marked) Unaligned Load",
+	.pme_long_desc = "Flush: (marked) Unaligned LoadMarked unaligned load flushes",
+},
+[ POWER8_PME_PM_MRK_LSU_FLUSH_UST ] = {
+	.pme_name = "PM_MRK_LSU_FLUSH_UST",
+	.pme_code = 0xd186,
+	.pme_short_desc = "Flush: (marked) Unaligned Store",
+	.pme_long_desc = "Flush: (marked) Unaligned StoreMarked unaligned store flushes",
+},
+[ POWER8_PME_PM_MRK_LSU_REJECT ] = {
+	.pme_name = "PM_MRK_LSU_REJECT",
+	.pme_code = 0x40164,
+	.pme_short_desc = "LSU marked reject (up to 2 per cycle)",
+	.pme_long_desc = "LSU marked reject (up to 2 per cycle).",
+},
+[ POWER8_PME_PM_MRK_LSU_REJECT_ERAT_MISS ] = {
+	.pme_name = "PM_MRK_LSU_REJECT_ERAT_MISS",
+	.pme_code = 0x30164,
+	.pme_short_desc = "LSU marked reject due to ERAT (up to 2 per cycle)",
+	.pme_long_desc = "LSU marked reject due to ERAT (up to 2 per cycle).",
+},
+[ POWER8_PME_PM_MRK_NTF_FIN ] = {
+	.pme_name = "PM_MRK_NTF_FIN",
+	.pme_code = 0x20112,
+	.pme_short_desc = "Marked next to finish instruction finished",
+	.pme_long_desc = "Marked next to finish instruction finished.",
+},
+[ POWER8_PME_PM_MRK_RUN_CYC ] = {
+	.pme_name = "PM_MRK_RUN_CYC",
+	.pme_code = 0x1d15e,
+	.pme_short_desc = "Marked run cycles",
+	.pme_long_desc = "Marked run cycles.",
+},
+[ POWER8_PME_PM_MRK_SRC_PREF_TRACK_EFF ] = {
+	.pme_name = "PM_MRK_SRC_PREF_TRACK_EFF",
+	.pme_code = 0x1d15a,
+	.pme_short_desc = "Marked src pref track was effective",
+	.pme_long_desc = "Marked src pref track was effective.",
+},
+[ POWER8_PME_PM_MRK_SRC_PREF_TRACK_INEFF ] = {
+	.pme_name = "PM_MRK_SRC_PREF_TRACK_INEFF",
+	.pme_code = 0x3d15a,
+	.pme_short_desc = "Prefetch tracked was ineffective for marked src",
+	.pme_long_desc = "Prefetch tracked was ineffective for marked src.",
+},
+[ POWER8_PME_PM_MRK_SRC_PREF_TRACK_MOD ] = {
+	.pme_name = "PM_MRK_SRC_PREF_TRACK_MOD",
+	.pme_code = 0x4d15c,
+	.pme_short_desc = "Prefetch tracked was moderate for marked src",
+	.pme_long_desc = "Prefetch tracked was moderate for marked src.",
+},
+[ POWER8_PME_PM_MRK_SRC_PREF_TRACK_MOD_L2 ] = {
+	.pme_name = "PM_MRK_SRC_PREF_TRACK_MOD_L2",
+	.pme_code = 0x1d15c,
+	.pme_short_desc = "Marked src Prefetch Tracked was moderate (source L2)",
+	.pme_long_desc = "Marked src Prefetch Tracked was moderate (source L2).",
+},
+[ POWER8_PME_PM_MRK_SRC_PREF_TRACK_MOD_L3 ] = {
+	.pme_name = "PM_MRK_SRC_PREF_TRACK_MOD_L3",
+	.pme_code = 0x3d15c,
+	.pme_short_desc = "Prefetch tracked was moderate (L3 hit) for marked src",
+	.pme_long_desc = "Prefetch tracked was moderate (L3 hit) for marked src.",
+},
 [ POWER8_PME_PM_MRK_STALL_CMPLU_CYC ] = {
 	.pme_name = "PM_MRK_STALL_CMPLU_CYC",
 	.pme_code = 0x3013e,
 	.pme_short_desc = "Marked Group completion Stall",
-	.pme_long_desc = "Marked Group Completion Stall cycles (use edge detect to count).",
+	.pme_long_desc = "Marked Group Completion Stall cycles (use edge detect to count #).",
+},
+[ POWER8_PME_PM_MRK_STCX_FAIL ] = {
+	.pme_name = "PM_MRK_STCX_FAIL",
+	.pme_code = 0x3e158,
+	.pme_short_desc = "marked stcx failed",
+	.pme_long_desc = "marked stcx failed.",
+},
+[ POWER8_PME_PM_MRK_ST_CMPL ] = {
+	.pme_name = "PM_MRK_ST_CMPL",
+	.pme_code = 0x10134,
+	.pme_short_desc = "marked store completed and sent to nest",
+	.pme_long_desc = "Marked store completed.",
+},
+[ POWER8_PME_PM_MRK_ST_CMPL_INT ] = {
+	.pme_name = "PM_MRK_ST_CMPL_INT",
+	.pme_code = 0x30134,
+	.pme_short_desc = "marked store finished with intervention",
+	.pme_long_desc = "marked store complete (data home) with intervention.",
+},
+[ POWER8_PME_PM_MRK_ST_DRAIN_TO_L2DISP_CYC ] = {
+	.pme_name = "PM_MRK_ST_DRAIN_TO_L2DISP_CYC",
+	.pme_code = 0x3f150,
+	.pme_short_desc = "cycles to drain st from core to L2",
+	.pme_long_desc = "cycles to drain st from core to L2.",
+},
+[ POWER8_PME_PM_MRK_ST_FWD ] = {
+	.pme_name = "PM_MRK_ST_FWD",
+	.pme_code = 0x3012c,
+	.pme_short_desc = "Marked st forwards",
+	.pme_long_desc = "Marked st forwards.",
+},
+[ POWER8_PME_PM_MRK_ST_L2DISP_TO_CMPL_CYC ] = {
+	.pme_name = "PM_MRK_ST_L2DISP_TO_CMPL_CYC",
+	.pme_code = 0x1f150,
+	.pme_short_desc = "cycles from L2 rc disp to l2 rc completion",
+	.pme_long_desc = "cycles from L2 rc disp to l2 rc completion.",
+},
+[ POWER8_PME_PM_MRK_ST_NEST ] = {
+	.pme_name = "PM_MRK_ST_NEST",
+	.pme_code = 0x20138,
+	.pme_short_desc = "Marked store sent to nest",
+	.pme_long_desc = "Marked store sent to nest.",
+},
+[ POWER8_PME_PM_MRK_TGT_PREF_TRACK_EFF ] = {
+	.pme_name = "PM_MRK_TGT_PREF_TRACK_EFF",
+	.pme_code = 0x1c15a,
+	.pme_short_desc = "Marked target pref track was effective",
+	.pme_long_desc = "Marked target pref track was effective.",
+},
+[ POWER8_PME_PM_MRK_TGT_PREF_TRACK_INEFF ] = {
+	.pme_name = "PM_MRK_TGT_PREF_TRACK_INEFF",
+	.pme_code = 0x3c15a,
+	.pme_short_desc = "Prefetch tracked was ineffective for marked target",
+	.pme_long_desc = "Prefetch tracked was ineffective for marked target.",
+},
+[ POWER8_PME_PM_MRK_TGT_PREF_TRACK_MOD ] = {
+	.pme_name = "PM_MRK_TGT_PREF_TRACK_MOD",
+	.pme_code = 0x4c15c,
+	.pme_short_desc = "Prefetch tracked was moderate for marked target",
+	.pme_long_desc = "Prefetch tracked was moderate for marked target.",
+},
+[ POWER8_PME_PM_MRK_TGT_PREF_TRACK_MOD_L2 ] = {
+	.pme_name = "PM_MRK_TGT_PREF_TRACK_MOD_L2",
+	.pme_code = 0x1c15c,
+	.pme_short_desc = "Marked target Prefetch Tracked was moderate (source L2)",
+	.pme_long_desc = "Marked target Prefetch Tracked was moderate (source L2).",
+},
+[ POWER8_PME_PM_MRK_TGT_PREF_TRACK_MOD_L3 ] = {
+	.pme_name = "PM_MRK_TGT_PREF_TRACK_MOD_L3",
+	.pme_code = 0x3c15c,
+	.pme_short_desc = "Prefetch tracked was moderate (L3 hit) for marked target",
+	.pme_long_desc = "Prefetch tracked was moderate (L3 hit) for marked target.",
+},
+[ POWER8_PME_PM_MRK_VSU_FIN ] = {
+	.pme_name = "PM_MRK_VSU_FIN",
+	.pme_code = 0x30132,
+	.pme_short_desc = "VSU marked instr finish",
+	.pme_long_desc = "vsu (fpu) marked instr finish.",
+},
+[ POWER8_PME_PM_MULT_MRK ] = {
+	.pme_name = "PM_MULT_MRK",
+	.pme_code = 0x3d15e,
+	.pme_short_desc = "mult marked instr",
+	.pme_long_desc = "mult marked instr.",
+},
+[ POWER8_PME_PM_NESTED_TEND ] = {
+	.pme_name = "PM_NESTED_TEND",
+	.pme_code = 0x20b0,
+	.pme_short_desc = "Completion time nested tend",
+	.pme_long_desc = "Completion time nested tend",
 },
 [ POWER8_PME_PM_NEST_REF_CLK ] = {
 	.pme_name = "PM_NEST_REF_CLK",
 	.pme_code = 0x3006e,
-	.pme_short_desc = "Nest reference clocks",
+	.pme_short_desc = "Multiply by 4 to obtain the number of PB cycles",
 	.pme_long_desc = "Nest reference clocks.",
 },
+[ POWER8_PME_PM_NON_FAV_TBEGIN ] = {
+	.pme_name = "PM_NON_FAV_TBEGIN",
+	.pme_code = 0x20b6,
+	.pme_short_desc = "Dispatch time non favored tbegin",
+	.pme_long_desc = "Dispatch time non favored tbegin",
+},
+[ POWER8_PME_PM_NON_TM_RST_SC ] = {
+	.pme_name = "PM_NON_TM_RST_SC",
+	.pme_code = 0x328084,
+	.pme_short_desc = "non tm snp rst tm sc",
+	.pme_long_desc = "non tm snp rst tm sc",
+},
+[ POWER8_PME_PM_NTCG_ALL_FIN ] = {
+	.pme_name = "PM_NTCG_ALL_FIN",
+	.pme_code = 0x2001a,
+	.pme_short_desc = "Cycles after all instructions have finished to group completed",
+	.pme_long_desc = "Ccycles after all instructions have finished to group completed.",
+},
+[ POWER8_PME_PM_OUTER_TBEGIN ] = {
+	.pme_name = "PM_OUTER_TBEGIN",
+	.pme_code = 0x20ac,
+	.pme_short_desc = "Completion time outer tbegin",
+	.pme_long_desc = "Completion time outer tbegin",
+},
+[ POWER8_PME_PM_OUTER_TEND ] = {
+	.pme_name = "PM_OUTER_TEND",
+	.pme_code = 0x20ae,
+	.pme_short_desc = "Completion time outer tend",
+	.pme_long_desc = "Completion time outer tend",
+},
 [ POWER8_PME_PM_PMC1_OVERFLOW ] = {
 	.pme_name = "PM_PMC1_OVERFLOW",
 	.pme_code = 0x20010,
@@ -969,6 +6416,18 @@ static const pme_power_entry_t power8_pe[] = {
 	.pme_short_desc = "Overflow from counter 2",
 	.pme_long_desc = "Overflow from counter 2.",
 },
+[ POWER8_PME_PM_PMC2_REWIND ] = {
+	.pme_name = "PM_PMC2_REWIND",
+	.pme_code = 0x30020,
+	.pme_short_desc = "PMC2 Rewind Event (did not match condition)",
+	.pme_long_desc = "PMC2 Rewind Event (did not match condition).",
+},
+[ POWER8_PME_PM_PMC2_SAVED ] = {
+	.pme_name = "PM_PMC2_SAVED",
+	.pme_code = 0x10022,
+	.pme_short_desc = "PMC2 Rewind Value saved",
+	.pme_long_desc = "PMC2 Rewind Value saved (matched condition).",
+},
 [ POWER8_PME_PM_PMC3_OVERFLOW ] = {
 	.pme_name = "PM_PMC3_OVERFLOW",
 	.pme_code = 0x40010,
@@ -981,17 +6440,443 @@ static const pme_power_entry_t power8_pe[] = {
 	.pme_short_desc = "Overflow from counter 4",
 	.pme_long_desc = "Overflow from counter 4.",
 },
+[ POWER8_PME_PM_PMC4_REWIND ] = {
+	.pme_name = "PM_PMC4_REWIND",
+	.pme_code = 0x10020,
+	.pme_short_desc = "PMC4 Rewind Event",
+	.pme_long_desc = "PMC4 Rewind Event (did not match condition).",
+},
+[ POWER8_PME_PM_PMC4_SAVED ] = {
+	.pme_name = "PM_PMC4_SAVED",
+	.pme_code = 0x30022,
+	.pme_short_desc = "PMC4 Rewind Value saved (matched condition)",
+	.pme_long_desc = "PMC4 Rewind Value saved (matched condition).",
+},
+[ POWER8_PME_PM_PMC5_OVERFLOW ] = {
+	.pme_name = "PM_PMC5_OVERFLOW",
+	.pme_code = 0x10024,
+	.pme_short_desc = "Overflow from counter 5",
+	.pme_long_desc = "Overflow from counter 5.",
+},
 [ POWER8_PME_PM_PMC6_OVERFLOW ] = {
 	.pme_name = "PM_PMC6_OVERFLOW",
 	.pme_code = 0x30024,
 	.pme_short_desc = "Overflow from counter 6",
 	.pme_long_desc = "Overflow from counter 6.",
 },
-[ POWER8_PME_PM_PPC_CMPL ] = {
-	.pme_name = "PM_PPC_CMPL",
-	.pme_code = 0x40002,
-	.pme_short_desc = "PPC Instructions Finished (completed)",
-	.pme_long_desc = "PPC Instructions Finished (completed).",
+[ POWER8_PME_PM_PREF_TRACKED ] = {
+	.pme_name = "PM_PREF_TRACKED",
+	.pme_code = 0x2005a,
+	.pme_short_desc = "Total number of Prefetch Operations that were tracked",
+	.pme_long_desc = "Total number of Prefetch Operations that were tracked.",
+},
+[ POWER8_PME_PM_PREF_TRACK_EFF ] = {
+	.pme_name = "PM_PREF_TRACK_EFF",
+	.pme_code = 0x1005a,
+	.pme_short_desc = "Prefetch Tracked was effective",
+	.pme_long_desc = "Prefetch Tracked was effective.",
+},
+[ POWER8_PME_PM_PREF_TRACK_INEFF ] = {
+	.pme_name = "PM_PREF_TRACK_INEFF",
+	.pme_code = 0x3005a,
+	.pme_short_desc = "Prefetch tracked was ineffective",
+	.pme_long_desc = "Prefetch tracked was ineffective.",
+},
+[ POWER8_PME_PM_PREF_TRACK_MOD ] = {
+	.pme_name = "PM_PREF_TRACK_MOD",
+	.pme_code = 0x4005a,
+	.pme_short_desc = "Prefetch tracked was moderate",
+	.pme_long_desc = "Prefetch tracked was moderate.",
+},
+[ POWER8_PME_PM_PREF_TRACK_MOD_L2 ] = {
+	.pme_name = "PM_PREF_TRACK_MOD_L2",
+	.pme_code = 0x1005c,
+	.pme_short_desc = "Prefetch Tracked was moderate (source L2)",
+	.pme_long_desc = "Prefetch Tracked was moderate (source L2).",
+},
+[ POWER8_PME_PM_PREF_TRACK_MOD_L3 ] = {
+	.pme_name = "PM_PREF_TRACK_MOD_L3",
+	.pme_code = 0x3005c,
+	.pme_short_desc = "Prefetch tracked was moderate (L3)",
+	.pme_long_desc = "Prefetch tracked was moderate (L3).",
+},
+[ POWER8_PME_PM_PROBE_NOP_DISP ] = {
+	.pme_name = "PM_PROBE_NOP_DISP",
+	.pme_code = 0x40014,
+	.pme_short_desc = "ProbeNops dispatched",
+	.pme_long_desc = "ProbeNops dispatched.",
+},
+[ POWER8_PME_PM_PTE_PREFETCH ] = {
+	.pme_name = "PM_PTE_PREFETCH",
+	.pme_code = 0xe084,
+	.pme_short_desc = "PTE prefetches",
+	.pme_long_desc = "PTE prefetches42",
+},
+[ POWER8_PME_PM_PUMP_CPRED ] = {
+	.pme_name = "PM_PUMP_CPRED",
+	.pme_code = 0x10054,
+	.pme_short_desc = "Pump prediction correct. Counts across all types of pumps for all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate)",
+	.pme_long_desc = "Pump prediction correct. Counts across all types of pumpsfor all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate).",
+},
+[ POWER8_PME_PM_PUMP_MPRED ] = {
+	.pme_name = "PM_PUMP_MPRED",
+	.pme_code = 0x40052,
+	.pme_short_desc = "Pump misprediction. Counts across all types of pumps for all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate)",
+	.pme_long_desc = "Pump Mis prediction Counts across all types of pumpsfor all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate).",
+},
+[ POWER8_PME_PM_RC0_ALLOC ] = {
+	.pme_name = "PM_RC0_ALLOC",
+	.pme_code = 0x16081,
+	.pme_short_desc = "RC mach 0 Busy. Used by PMU to sample ave RC livetime(mach0 used as sample point)",
+	.pme_long_desc = "0.0",
+},
+[ POWER8_PME_PM_RC0_BUSY ] = {
+	.pme_name = "PM_RC0_BUSY",
+	.pme_code = 0x16080,
+	.pme_short_desc = "RC mach 0 Busy. Used by PMU to sample ave RC livetime(mach0 used as sample point)",
+	.pme_long_desc = "RC mach 0 Busy. Used by PMU to sample ave RC livetime(mach0 used as sample point)",
+},
+[ POWER8_PME_PM_RC_LIFETIME_EXC_1024 ] = {
+	.pme_name = "PM_RC_LIFETIME_EXC_1024",
+	.pme_code = 0x200301ea,
+	.pme_short_desc = "Number of times the RC machine for a sampled instruction was active for more than 1024 cycles",
+	.pme_long_desc = "Reload latency exceeded 1024 cyc",
+},
+[ POWER8_PME_PM_RC_LIFETIME_EXC_2048 ] = {
+	.pme_name = "PM_RC_LIFETIME_EXC_2048",
+	.pme_code = 0x200401ec,
+	.pme_short_desc = "Number of times the RC machine for a sampled instruction was active for more than 2048 cycles",
+	.pme_long_desc = "Threshold counter exceeded a value of 2048",
+},
+[ POWER8_PME_PM_RC_LIFETIME_EXC_256 ] = {
+	.pme_name = "PM_RC_LIFETIME_EXC_256",
+	.pme_code = 0x200101e8,
+	.pme_short_desc = "Number of times the RC machine for a sampled instruction was active for more than 256 cycles",
+	.pme_long_desc = "Threshold counter exceed a count of 256",
+},
+[ POWER8_PME_PM_RC_LIFETIME_EXC_32 ] = {
+	.pme_name = "PM_RC_LIFETIME_EXC_32",
+	.pme_code = 0x200201e6,
+	.pme_short_desc = "Number of times the RC machine for a sampled instruction was active for more than 32 cycles",
+	.pme_long_desc = "Reload latency exceeded 32 cyc",
+},
+[ POWER8_PME_PM_RC_USAGE ] = {
+	.pme_name = "PM_RC_USAGE",
+	.pme_code = 0x36088,
+	.pme_short_desc = "Continuous 16 cycle(2to1) window where this signals rotates thru sampling each L2 RC machine busy. PMU uses this wave to then do 16 cyc count to sample total number of machs running",
+	.pme_long_desc = "Continuous 16 cycle(2to1) window where this signals rotates thru sampling each L2 RC machine busy. PMU uses this wave to then do 16 cyc count to sample total number of machs running",
+},
+[ POWER8_PME_PM_RD_CLEARING_SC ] = {
+	.pme_name = "PM_RD_CLEARING_SC",
+	.pme_code = 0x34808e,
+	.pme_short_desc = "rd clearing sc",
+	.pme_long_desc = "rd clearing sc",
+},
+[ POWER8_PME_PM_RD_FORMING_SC ] = {
+	.pme_name = "PM_RD_FORMING_SC",
+	.pme_code = 0x34808c,
+	.pme_short_desc = "rd forming sc",
+	.pme_long_desc = "rd forming sc",
+},
+[ POWER8_PME_PM_RD_HIT_PF ] = {
+	.pme_name = "PM_RD_HIT_PF",
+	.pme_code = 0x428086,
+	.pme_short_desc = "rd machine hit l3 pf machine",
+	.pme_long_desc = "rd machine hit l3 pf machine",
+},
+[ POWER8_PME_PM_REAL_SRQ_FULL ] = {
+	.pme_name = "PM_REAL_SRQ_FULL",
+	.pme_code = 0x20004,
+	.pme_short_desc = "Out of real srq entries",
+	.pme_long_desc = "Out of real srq entries.",
+},
+[ POWER8_PME_PM_RUN_CYC ] = {
+	.pme_name = "PM_RUN_CYC",
+	.pme_code = 0x600f4,
+	.pme_short_desc = "Run_cycles",
+	.pme_long_desc = "Run_cycles.",
+},
+[ POWER8_PME_PM_RUN_CYC_SMT2_MODE ] = {
+	.pme_name = "PM_RUN_CYC_SMT2_MODE",
+	.pme_code = 0x3006c,
+	.pme_short_desc = "Cycles run latch is set and core is in SMT2 mode",
+	.pme_long_desc = "Cycles run latch is set and core is in SMT2 mode.",
+},
+[ POWER8_PME_PM_RUN_CYC_SMT2_SHRD_MODE ] = {
+	.pme_name = "PM_RUN_CYC_SMT2_SHRD_MODE",
+	.pme_code = 0x2006a,
+	.pme_short_desc = "cycles this threads run latch is set and the core is in SMT2 shared mode",
+	.pme_long_desc = "Cycles run latch is set and core is in SMT2-shared mode.",
+},
+[ POWER8_PME_PM_RUN_CYC_SMT2_SPLIT_MODE ] = {
+	.pme_name = "PM_RUN_CYC_SMT2_SPLIT_MODE",
+	.pme_code = 0x1006a,
+	.pme_short_desc = "Cycles run latch is set and core is in SMT2-split mode",
+	.pme_long_desc = "Cycles run latch is set and core is in SMT2-split mode.",
+},
+[ POWER8_PME_PM_RUN_CYC_SMT4_MODE ] = {
+	.pme_name = "PM_RUN_CYC_SMT4_MODE",
+	.pme_code = 0x2006c,
+	.pme_short_desc = "cycles this threads run latch is set and the core is in SMT4 mode",
+	.pme_long_desc = "Cycles run latch is set and core is in SMT4 mode.",
+},
+[ POWER8_PME_PM_RUN_CYC_SMT8_MODE ] = {
+	.pme_name = "PM_RUN_CYC_SMT8_MODE",
+	.pme_code = 0x4006c,
+	.pme_short_desc = "Cycles run latch is set and core is in SMT8 mode",
+	.pme_long_desc = "Cycles run latch is set and core is in SMT8 mode.",
+},
+[ POWER8_PME_PM_RUN_CYC_ST_MODE ] = {
+	.pme_name = "PM_RUN_CYC_ST_MODE",
+	.pme_code = 0x1006c,
+	.pme_short_desc = "Cycles run latch is set and core is in ST mode",
+	.pme_long_desc = "Cycles run latch is set and core is in ST mode.",
+},
+[ POWER8_PME_PM_RUN_INST_CMPL ] = {
+	.pme_name = "PM_RUN_INST_CMPL",
+	.pme_code = 0x500fa,
+	.pme_short_desc = "Run_Instructions",
+	.pme_long_desc = "Run_Instructions.",
+},
+[ POWER8_PME_PM_RUN_PURR ] = {
+	.pme_name = "PM_RUN_PURR",
+	.pme_code = 0x400f4,
+	.pme_short_desc = "Run_PURR",
+	.pme_long_desc = "Run_PURR.",
+},
+[ POWER8_PME_PM_RUN_SPURR ] = {
+	.pme_name = "PM_RUN_SPURR",
+	.pme_code = 0x10008,
+	.pme_short_desc = "Run SPURR",
+	.pme_long_desc = "Run SPURR.",
+},
+[ POWER8_PME_PM_SEC_ERAT_HIT ] = {
+	.pme_name = "PM_SEC_ERAT_HIT",
+	.pme_code = 0xf082,
+	.pme_short_desc = "secondary ERAT Hit",
+	.pme_long_desc = "secondary ERAT Hit42",
+},
+[ POWER8_PME_PM_SHL_CREATED ] = {
+	.pme_name = "PM_SHL_CREATED",
+	.pme_code = 0x508c,
+	.pme_short_desc = "Store-Hit-Load Table Entry Created",
+	.pme_long_desc = "Store-Hit-Load Table Entry Created",
+},
+[ POWER8_PME_PM_SHL_ST_CONVERT ] = {
+	.pme_name = "PM_SHL_ST_CONVERT",
+	.pme_code = 0x508e,
+	.pme_short_desc = "Store-Hit-Load Table Read Hit with entry Enabled",
+	.pme_long_desc = "Store-Hit-Load Table Read Hit with entry Enabled",
+},
+[ POWER8_PME_PM_SHL_ST_DISABLE ] = {
+	.pme_name = "PM_SHL_ST_DISABLE",
+	.pme_code = 0x5090,
+	.pme_short_desc = "Store-Hit-Load Table Read Hit with entry Disabled (entry was disabled due to the entry shown to not prevent the flush)",
+	.pme_long_desc = "Store-Hit-Load Table Read Hit with entry Disabled (entry was disabled due to the entry shown to not prevent the flush)",
+},
+[ POWER8_PME_PM_SN0_ALLOC ] = {
+	.pme_name = "PM_SN0_ALLOC",
+	.pme_code = 0x26085,
+	.pme_short_desc = "SN mach 0 Busy. Used by PMU to sample ave RC livetime(mach0 used as sample point)",
+	.pme_long_desc = "0.0",
+},
+[ POWER8_PME_PM_SN0_BUSY ] = {
+	.pme_name = "PM_SN0_BUSY",
+	.pme_code = 0x26084,
+	.pme_short_desc = "SN mach 0 Busy. Used by PMU to sample ave RC livetime(mach0 used as sample point)",
+	.pme_long_desc = "SN mach 0 Busy. Used by PMU to sample ave RC livetime(mach0 used as sample point)",
+},
+[ POWER8_PME_PM_SNOOP_TLBIE ] = {
+	.pme_name = "PM_SNOOP_TLBIE",
+	.pme_code = 0xd0b2,
+	.pme_short_desc = "TLBIE snoop",
+	.pme_long_desc = "TLBIE snoopSnoop TLBIE",
+},
+[ POWER8_PME_PM_SNP_TM_HIT_M ] = {
+	.pme_name = "PM_SNP_TM_HIT_M",
+	.pme_code = 0x338088,
+	.pme_short_desc = "snp tm st hit m mu",
+	.pme_long_desc = "snp tm st hit m mu",
+},
+[ POWER8_PME_PM_SNP_TM_HIT_T ] = {
+	.pme_name = "PM_SNP_TM_HIT_T",
+	.pme_code = 0x33808a,
+	.pme_short_desc = "snp tm_st_hit t tn te",
+	.pme_long_desc = "snp tm_st_hit t tn te",
+},
+[ POWER8_PME_PM_SN_USAGE ] = {
+	.pme_name = "PM_SN_USAGE",
+	.pme_code = 0x4608c,
+	.pme_short_desc = "Continuous 16 cycle(2to1) window where this signals rotates thru sampling each L2 SN machine busy. PMU uses this wave to then do 16 cyc count to sample total number of machs running",
+	.pme_long_desc = "Continuous 16 cycle(2to1) window where this signals rotates thru sampling each L2 SN machine busy. PMU uses this wave to then do 16 cyc count to sample total number of machs running",
+},
+[ POWER8_PME_PM_STALL_END_GCT_EMPTY ] = {
+	.pme_name = "PM_STALL_END_GCT_EMPTY",
+	.pme_code = 0x10028,
+	.pme_short_desc = "Count ended because GCT went empty",
+	.pme_long_desc = "Count ended because GCT went empty.",
+},
+[ POWER8_PME_PM_STCX_FAIL ] = {
+	.pme_name = "PM_STCX_FAIL",
+	.pme_code = 0x1e058,
+	.pme_short_desc = "stcx failed",
+	.pme_long_desc = "stcx failed .",
+},
+[ POWER8_PME_PM_STCX_LSU ] = {
+	.pme_name = "PM_STCX_LSU",
+	.pme_code = 0xc090,
+	.pme_short_desc = "STCX executed reported at sent to nest",
+	.pme_long_desc = "STCX executed reported at sent to nest42",
+},
+[ POWER8_PME_PM_ST_CAUSED_FAIL ] = {
+	.pme_name = "PM_ST_CAUSED_FAIL",
+	.pme_code = 0x717080,
+	.pme_short_desc = "Non TM St caused any thread to fail",
+	.pme_long_desc = "Non TM St caused any thread to fail",
+},
+[ POWER8_PME_PM_ST_CMPL ] = {
+	.pme_name = "PM_ST_CMPL",
+	.pme_code = 0x20016,
+	.pme_short_desc = "Store completion count",
+	.pme_long_desc = "Store completion count.",
+},
+[ POWER8_PME_PM_ST_FIN ] = {
+	.pme_name = "PM_ST_FIN",
+	.pme_code = 0x200f0,
+	.pme_short_desc = "Store Instructions Finished",
+	.pme_long_desc = "Store Instructions Finished (store sent to nest).",
+},
+[ POWER8_PME_PM_ST_FWD ] = {
+	.pme_name = "PM_ST_FWD",
+	.pme_code = 0x20018,
+	.pme_short_desc = "Store forwards that finished",
+	.pme_long_desc = "Store forwards that finished.",
+},
+[ POWER8_PME_PM_ST_MISS_L1 ] = {
+	.pme_name = "PM_ST_MISS_L1",
+	.pme_code = 0x300f0,
+	.pme_short_desc = "Store Missed L1",
+	.pme_long_desc = "Store Missed L1.",
+},
+[ POWER8_PME_PM_SUSPENDED ] = {
+	.pme_name = "PM_SUSPENDED",
+	.pme_code = 0x0,
+	.pme_short_desc = "Counter OFF",
+	.pme_long_desc = "Counter OFF.",
+},
+[ POWER8_PME_PM_SWAP_CANCEL ] = {
+	.pme_name = "PM_SWAP_CANCEL",
+	.pme_code = 0x3090,
+	.pme_short_desc = "SWAP cancel , rtag not available",
+	.pme_long_desc = "SWAP cancel , rtag not available",
+},
+[ POWER8_PME_PM_SWAP_CANCEL_GPR ] = {
+	.pme_name = "PM_SWAP_CANCEL_GPR",
+	.pme_code = 0x3092,
+	.pme_short_desc = "SWAP cancel , rtag not available for gpr",
+	.pme_long_desc = "SWAP cancel , rtag not available for gpr",
+},
+[ POWER8_PME_PM_SWAP_COMPLETE ] = {
+	.pme_name = "PM_SWAP_COMPLETE",
+	.pme_code = 0x308c,
+	.pme_short_desc = "swap cast in completed",
+	.pme_long_desc = "swap cast in completed",
+},
+[ POWER8_PME_PM_SWAP_COMPLETE_GPR ] = {
+	.pme_name = "PM_SWAP_COMPLETE_GPR",
+	.pme_code = 0x308e,
+	.pme_short_desc = "swap cast in completed fpr gpr",
+	.pme_long_desc = "swap cast in completed fpr gpr",
+},
+[ POWER8_PME_PM_SYNC_MRK_BR_LINK ] = {
+	.pme_name = "PM_SYNC_MRK_BR_LINK",
+	.pme_code = 0x15152,
+	.pme_short_desc = "Marked Branch and link branch that can cause a synchronous interrupt",
+	.pme_long_desc = "Marked Branch and link branch that can cause a synchronous interrupt.",
+},
+[ POWER8_PME_PM_SYNC_MRK_BR_MPRED ] = {
+	.pme_name = "PM_SYNC_MRK_BR_MPRED",
+	.pme_code = 0x1515c,
+	.pme_short_desc = "Marked Branch mispredict that can cause a synchronous interrupt",
+	.pme_long_desc = "Marked Branch mispredict that can cause a synchronous interrupt.",
+},
+[ POWER8_PME_PM_SYNC_MRK_FX_DIVIDE ] = {
+	.pme_name = "PM_SYNC_MRK_FX_DIVIDE",
+	.pme_code = 0x15156,
+	.pme_short_desc = "Marked fixed point divide that can cause a synchronous interrupt",
+	.pme_long_desc = "Marked fixed point divide that can cause a synchronous interrupt.",
+},
+[ POWER8_PME_PM_SYNC_MRK_L2HIT ] = {
+	.pme_name = "PM_SYNC_MRK_L2HIT",
+	.pme_code = 0x15158,
+	.pme_short_desc = "Marked L2 Hits that can throw a synchronous interrupt",
+	.pme_long_desc = "Marked L2 Hits that can throw a synchronous interrupt.",
+},
+[ POWER8_PME_PM_SYNC_MRK_L2MISS ] = {
+	.pme_name = "PM_SYNC_MRK_L2MISS",
+	.pme_code = 0x1515a,
+	.pme_short_desc = "Marked L2 Miss that can throw a synchronous interrupt",
+	.pme_long_desc = "Marked L2 Miss that can throw a synchronous interrupt.",
+},
+[ POWER8_PME_PM_SYNC_MRK_L3MISS ] = {
+	.pme_name = "PM_SYNC_MRK_L3MISS",
+	.pme_code = 0x15154,
+	.pme_short_desc = "Marked L3 misses that can throw a synchronous interrupt",
+	.pme_long_desc = "Marked L3 misses that can throw a synchronous interrupt.",
+},
+[ POWER8_PME_PM_SYNC_MRK_PROBE_NOP ] = {
+	.pme_name = "PM_SYNC_MRK_PROBE_NOP",
+	.pme_code = 0x15150,
+	.pme_short_desc = "Marked probeNops which can cause synchronous interrupts",
+	.pme_long_desc = "Marked probeNops which can cause synchronous interrupts.",
+},
+[ POWER8_PME_PM_SYS_PUMP_CPRED ] = {
+	.pme_name = "PM_SYS_PUMP_CPRED",
+	.pme_code = 0x30050,
+	.pme_short_desc = "Initial and Final Pump Scope was system pump for all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate)",
+	.pme_long_desc = "Initial and Final Pump Scope and data sourced across this scope was system pump for all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate).",
+},
+[ POWER8_PME_PM_SYS_PUMP_MPRED ] = {
+	.pme_name = "PM_SYS_PUMP_MPRED",
+	.pme_code = 0x30052,
+	.pme_short_desc = "Final Pump Scope (system) mispredicted. Either the original scope was too small (Chip/Group) or the original scope was System and it should have been smaller. Counts for all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate)",
+	.pme_long_desc = "Final Pump Scope(system) to get data sourced, ended up larger than Initial Pump Scope(Chip/Group) OR Final Pump Scope(system) got data from source that was at smaller scope(Chip/group) Final pump was system pump and initial pump was chip or group or",
+},
+[ POWER8_PME_PM_SYS_PUMP_MPRED_RTY ] = {
+	.pme_name = "PM_SYS_PUMP_MPRED_RTY",
+	.pme_code = 0x40050,
+	.pme_short_desc = "Final Pump Scope (system) ended up larger than Initial Pump Scope (Chip/Group) for all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate)",
+	.pme_long_desc = "Final Pump Scope(system) to get data sourced, ended up larger than Initial Pump Scope (Chip or Group) for all data types excluding data prefetch (demand load,inst prefetch,inst fetch,xlate).",
+},
+[ POWER8_PME_PM_TABLEWALK_CYC ] = {
+	.pme_name = "PM_TABLEWALK_CYC",
+	.pme_code = 0x10026,
+	.pme_short_desc = "Cycles when a tablewalk (I or D) is active",
+	.pme_long_desc = "Tablewalk Active.",
+},
+[ POWER8_PME_PM_TABLEWALK_CYC_PREF ] = {
+	.pme_name = "PM_TABLEWALK_CYC_PREF",
+	.pme_code = 0xe086,
+	.pme_short_desc = "tablewalk qualified for pte prefetches",
+	.pme_long_desc = "tablewalk qualified for pte prefetches42",
+},
+[ POWER8_PME_PM_TABORT_TRECLAIM ] = {
+	.pme_name = "PM_TABORT_TRECLAIM",
+	.pme_code = 0x20b2,
+	.pme_short_desc = "Completion time tabortnoncd, tabortcd, treclaim",
+	.pme_long_desc = "Completion time tabortnoncd, tabortcd, treclaim",
+},
+[ POWER8_PME_PM_TB_BIT_TRANS ] = {
+	.pme_name = "PM_TB_BIT_TRANS",
+	.pme_code = 0x300f8,
+	.pme_short_desc = "timebase event",
+	.pme_long_desc = "timebase event.",
+},
+[ POWER8_PME_PM_TEND_PEND_CYC ] = {
+	.pme_name = "PM_TEND_PEND_CYC",
+	.pme_code = 0xe0ba,
+	.pme_short_desc = "TEND latency per thread",
+	.pme_long_desc = "TEND latency per thread42",
 },
 [ POWER8_PME_PM_THRD_ALL_RUN_CYC ] = {
 	.pme_name = "PM_THRD_ALL_RUN_CYC",
@@ -999,11 +6884,587 @@ static const pme_power_entry_t power8_pe[] = {
 	.pme_short_desc = "All Threads in Run_cycles (was both threads in run_cycles)",
 	.pme_long_desc = "All Threads in Run_cycles (was both threads in run_cycles).",
 },
+[ POWER8_PME_PM_THRD_CONC_RUN_INST ] = {
+	.pme_name = "PM_THRD_CONC_RUN_INST",
+	.pme_code = 0x300f4,
+	.pme_short_desc = "PPC Instructions Finished when both threads in run_cycles",
+	.pme_long_desc = "Concurrent Run Instructions.",
+},
+[ POWER8_PME_PM_THRD_GRP_CMPL_BOTH_CYC ] = {
+	.pme_name = "PM_THRD_GRP_CMPL_BOTH_CYC",
+	.pme_code = 0x10012,
+	.pme_short_desc = "Cycles group completed on both completion slots by any thread",
+	.pme_long_desc = "Two threads finished same cycle (gated by run latch).",
+},
+[ POWER8_PME_PM_THRD_PRIO_0_1_CYC ] = {
+	.pme_name = "PM_THRD_PRIO_0_1_CYC",
+	.pme_code = 0x40bc,
+	.pme_short_desc = "Cycles thread running at priority level 0 or 1",
+	.pme_long_desc = "Cycles thread running at priority level 0 or 1",
+},
+[ POWER8_PME_PM_THRD_PRIO_2_3_CYC ] = {
+	.pme_name = "PM_THRD_PRIO_2_3_CYC",
+	.pme_code = 0x40be,
+	.pme_short_desc = "Cycles thread running at priority level 2 or 3",
+	.pme_long_desc = "Cycles thread running at priority level 2 or 3",
+},
+[ POWER8_PME_PM_THRD_PRIO_4_5_CYC ] = {
+	.pme_name = "PM_THRD_PRIO_4_5_CYC",
+	.pme_code = 0x5080,
+	.pme_short_desc = "Cycles thread running at priority level 4 or 5",
+	.pme_long_desc = "Cycles thread running at priority level 4 or 5",
+},
+[ POWER8_PME_PM_THRD_PRIO_6_7_CYC ] = {
+	.pme_name = "PM_THRD_PRIO_6_7_CYC",
+	.pme_code = 0x5082,
+	.pme_short_desc = "Cycles thread running at priority level 6 or 7",
+	.pme_long_desc = "Cycles thread running at priority level 6 or 7",
+},
+[ POWER8_PME_PM_THRD_REBAL_CYC ] = {
+	.pme_name = "PM_THRD_REBAL_CYC",
+	.pme_code = 0x3098,
+	.pme_short_desc = "cycles rebalance was active",
+	.pme_long_desc = "cycles rebalance was active",
+},
+[ POWER8_PME_PM_THRESH_EXC_1024 ] = {
+	.pme_name = "PM_THRESH_EXC_1024",
+	.pme_code = 0x301ea,
+	.pme_short_desc = "Threshold counter exceeded a value of 1024",
+	.pme_long_desc = "Threshold counter exceeded a value of 1024.",
+},
+[ POWER8_PME_PM_THRESH_EXC_128 ] = {
+	.pme_name = "PM_THRESH_EXC_128",
+	.pme_code = 0x401ea,
+	.pme_short_desc = "Threshold counter exceeded a value of 128",
+	.pme_long_desc = "Threshold counter exceeded a value of 128.",
+},
+[ POWER8_PME_PM_THRESH_EXC_2048 ] = {
+	.pme_name = "PM_THRESH_EXC_2048",
+	.pme_code = 0x401ec,
+	.pme_short_desc = "Threshold counter exceeded a value of 2048",
+	.pme_long_desc = "Threshold counter exceeded a value of 2048.",
+},
+[ POWER8_PME_PM_THRESH_EXC_256 ] = {
+	.pme_name = "PM_THRESH_EXC_256",
+	.pme_code = 0x101e8,
+	.pme_short_desc = "Threshold counter exceed a count of 256",
+	.pme_long_desc = "Threshold counter exceed a count of 256.",
+},
+[ POWER8_PME_PM_THRESH_EXC_32 ] = {
+	.pme_name = "PM_THRESH_EXC_32",
+	.pme_code = 0x201e6,
+	.pme_short_desc = "Threshold counter exceeded a value of 32",
+	.pme_long_desc = "Threshold counter exceeded a value of 32.",
+},
+[ POWER8_PME_PM_THRESH_EXC_4096 ] = {
+	.pme_name = "PM_THRESH_EXC_4096",
+	.pme_code = 0x101e6,
+	.pme_short_desc = "Threshold counter exceed a count of 4096",
+	.pme_long_desc = "Threshold counter exceed a count of 4096.",
+},
+[ POWER8_PME_PM_THRESH_EXC_512 ] = {
+	.pme_name = "PM_THRESH_EXC_512",
+	.pme_code = 0x201e8,
+	.pme_short_desc = "Threshold counter exceeded a value of 512",
+	.pme_long_desc = "Threshold counter exceeded a value of 512.",
+},
+[ POWER8_PME_PM_THRESH_EXC_64 ] = {
+	.pme_name = "PM_THRESH_EXC_64",
+	.pme_code = 0x301e8,
+	.pme_short_desc = "IFU non-branch finished",
+	.pme_long_desc = "Threshold counter exceeded a value of 64.",
+},
+[ POWER8_PME_PM_THRESH_MET ] = {
+	.pme_name = "PM_THRESH_MET",
+	.pme_code = 0x101ec,
+	.pme_short_desc = "threshold exceeded",
+	.pme_long_desc = "threshold exceeded.",
+},
 [ POWER8_PME_PM_THRESH_NOT_MET ] = {
 	.pme_name = "PM_THRESH_NOT_MET",
 	.pme_code = 0x4016e,
 	.pme_short_desc = "Threshold counter did not meet threshold",
 	.pme_long_desc = "Threshold counter did not meet threshold.",
 },
+[ POWER8_PME_PM_TLBIE_FIN ] = {
+	.pme_name = "PM_TLBIE_FIN",
+	.pme_code = 0x30058,
+	.pme_short_desc = "tlbie finished",
+	.pme_long_desc = "tlbie finished.",
+},
+[ POWER8_PME_PM_TLB_MISS ] = {
+	.pme_name = "PM_TLB_MISS",
+	.pme_code = 0x20066,
+	.pme_short_desc = "TLB Miss (I + D)",
+	.pme_long_desc = "TLB Miss (I + D).",
+},
+[ POWER8_PME_PM_TM_BEGIN_ALL ] = {
+	.pme_name = "PM_TM_BEGIN_ALL",
+	.pme_code = 0x20b8,
+	.pme_short_desc = "Tm any tbegin",
+	.pme_long_desc = "Tm any tbegin",
+},
+[ POWER8_PME_PM_TM_CAM_OVERFLOW ] = {
+	.pme_name = "PM_TM_CAM_OVERFLOW",
+	.pme_code = 0x318082,
+	.pme_short_desc = "l3 tm cam overflow during L2 co of SC",
+	.pme_long_desc = "l3 tm cam overflow during L2 co of SC",
+},
+[ POWER8_PME_PM_TM_CAP_OVERFLOW ] = {
+	.pme_name = "PM_TM_CAP_OVERFLOW",
+	.pme_code = 0x74708c,
+	.pme_short_desc = "TM Footprint Capactiy Overflow",
+	.pme_long_desc = "TM Footprint Capactiy Overflow",
+},
+[ POWER8_PME_PM_TM_END_ALL ] = {
+	.pme_name = "PM_TM_END_ALL",
+	.pme_code = 0x20ba,
+	.pme_short_desc = "Tm any tend",
+	.pme_long_desc = "Tm any tend",
+},
+[ POWER8_PME_PM_TM_FAIL_CONF_NON_TM ] = {
+	.pme_name = "PM_TM_FAIL_CONF_NON_TM",
+	.pme_code = 0x3086,
+	.pme_short_desc = "TEXAS fail reason @ completion",
+	.pme_long_desc = "TEXAS fail reason @ completion",
+},
+[ POWER8_PME_PM_TM_FAIL_CON_TM ] = {
+	.pme_name = "PM_TM_FAIL_CON_TM",
+	.pme_code = 0x3088,
+	.pme_short_desc = "TEXAS fail reason @ completion",
+	.pme_long_desc = "TEXAS fail reason @ completion",
+},
+[ POWER8_PME_PM_TM_FAIL_DISALLOW ] = {
+	.pme_name = "PM_TM_FAIL_DISALLOW",
+	.pme_code = 0xe0b2,
+	.pme_short_desc = "TM fail disallow",
+	.pme_long_desc = "TM fail disallow42",
+},
+[ POWER8_PME_PM_TM_FAIL_FOOTPRINT_OVERFLOW ] = {
+	.pme_name = "PM_TM_FAIL_FOOTPRINT_OVERFLOW",
+	.pme_code = 0x3084,
+	.pme_short_desc = "TEXAS fail reason @ completion",
+	.pme_long_desc = "TEXAS fail reason @ completion",
+},
+[ POWER8_PME_PM_TM_FAIL_NON_TX_CONFLICT ] = {
+	.pme_name = "PM_TM_FAIL_NON_TX_CONFLICT",
+	.pme_code = 0xe0b8,
+	.pme_short_desc = "Non transactional conflict from LSU whtver gets repoted to texas",
+	.pme_long_desc = "Non transactional conflict from LSU whtver gets repoted to texas42",
+},
+[ POWER8_PME_PM_TM_FAIL_SELF ] = {
+	.pme_name = "PM_TM_FAIL_SELF",
+	.pme_code = 0x308a,
+	.pme_short_desc = "TEXAS fail reason @ completion",
+	.pme_long_desc = "TEXAS fail reason @ completion",
+},
+[ POWER8_PME_PM_TM_FAIL_TLBIE ] = {
+	.pme_name = "PM_TM_FAIL_TLBIE",
+	.pme_code = 0xe0b4,
+	.pme_short_desc = "TLBIE hit bloom filter",
+	.pme_long_desc = "TLBIE hit bloom filter42",
+},
+[ POWER8_PME_PM_TM_FAIL_TX_CONFLICT ] = {
+	.pme_name = "PM_TM_FAIL_TX_CONFLICT",
+	.pme_code = 0xe0b6,
+	.pme_short_desc = "Transactional conflict from LSU, whatever gets reported to texas",
+	.pme_long_desc = "Transactional conflict from LSU, whatever gets reported to texas 42",
+},
+[ POWER8_PME_PM_TM_FAV_CAUSED_FAIL ] = {
+	.pme_name = "PM_TM_FAV_CAUSED_FAIL",
+	.pme_code = 0x727086,
+	.pme_short_desc = "TM Load (fav) caused another thread to fail",
+	.pme_long_desc = "TM Load (fav) caused another thread to fail",
+},
+[ POWER8_PME_PM_TM_LD_CAUSED_FAIL ] = {
+	.pme_name = "PM_TM_LD_CAUSED_FAIL",
+	.pme_code = 0x717082,
+	.pme_short_desc = "Non TM Ld caused any thread to fail",
+	.pme_long_desc = "Non TM Ld caused any thread to fail",
+},
+[ POWER8_PME_PM_TM_LD_CONF ] = {
+	.pme_name = "PM_TM_LD_CONF",
+	.pme_code = 0x727084,
+	.pme_short_desc = "TM Load (fav or non-fav) ran into conflict (failed)",
+	.pme_long_desc = "TM Load (fav or non-fav) ran into conflict (failed)",
+},
+[ POWER8_PME_PM_TM_RST_SC ] = {
+	.pme_name = "PM_TM_RST_SC",
+	.pme_code = 0x328086,
+	.pme_short_desc = "tm snp rst tm sc",
+	.pme_long_desc = "tm snp rst tm sc",
+},
+[ POWER8_PME_PM_TM_SC_CO ] = {
+	.pme_name = "PM_TM_SC_CO",
+	.pme_code = 0x318080,
+	.pme_short_desc = "l3 castout tm Sc line",
+	.pme_long_desc = "l3 castout tm Sc line",
+},
+[ POWER8_PME_PM_TM_ST_CAUSED_FAIL ] = {
+	.pme_name = "PM_TM_ST_CAUSED_FAIL",
+	.pme_code = 0x73708a,
+	.pme_short_desc = "TM Store (fav or non-fav) caused another thread to fail",
+	.pme_long_desc = "TM Store (fav or non-fav) caused another thread to fail",
+},
+[ POWER8_PME_PM_TM_ST_CONF ] = {
+	.pme_name = "PM_TM_ST_CONF",
+	.pme_code = 0x737088,
+	.pme_short_desc = "TM Store (fav or non-fav) ran into conflict (failed)",
+	.pme_long_desc = "TM Store (fav or non-fav) ran into conflict (failed)",
+},
+[ POWER8_PME_PM_TM_TBEGIN ] = {
+	.pme_name = "PM_TM_TBEGIN",
+	.pme_code = 0x20bc,
+	.pme_short_desc = "Tm nested tbegin",
+	.pme_long_desc = "Tm nested tbegin",
+},
+[ POWER8_PME_PM_TM_TRANS_RUN_CYC ] = {
+	.pme_name = "PM_TM_TRANS_RUN_CYC",
+	.pme_code = 0x10060,
+	.pme_short_desc = "run cycles in transactional state",
+	.pme_long_desc = "run cycles in transactional state.",
+},
+[ POWER8_PME_PM_TM_TRANS_RUN_INST ] = {
+	.pme_name = "PM_TM_TRANS_RUN_INST",
+	.pme_code = 0x30060,
+	.pme_short_desc = "Instructions completed in transactional state",
+	.pme_long_desc = "Instructions completed in transactional state.",
+},
+[ POWER8_PME_PM_TM_TRESUME ] = {
+	.pme_name = "PM_TM_TRESUME",
+	.pme_code = 0x3080,
+	.pme_short_desc = "Tm resume",
+	.pme_long_desc = "Tm resume",
+},
+[ POWER8_PME_PM_TM_TSUSPEND ] = {
+	.pme_name = "PM_TM_TSUSPEND",
+	.pme_code = 0x20be,
+	.pme_short_desc = "Tm suspend",
+	.pme_long_desc = "Tm suspend",
+},
+[ POWER8_PME_PM_TM_TX_PASS_RUN_CYC ] = {
+	.pme_name = "PM_TM_TX_PASS_RUN_CYC",
+	.pme_code = 0x2e012,
+	.pme_short_desc = "cycles spent in successful transactions",
+	.pme_long_desc = "run cycles spent in successful transactions.",
+},
+[ POWER8_PME_PM_TM_TX_PASS_RUN_INST ] = {
+	.pme_name = "PM_TM_TX_PASS_RUN_INST",
+	.pme_code = 0x4e014,
+	.pme_short_desc = "run instructions spent in successful transactions.",
+	.pme_long_desc = "run instructions spent in successful transactions.",
+},
+[ POWER8_PME_PM_UP_PREF_L3 ] = {
+	.pme_name = "PM_UP_PREF_L3",
+	.pme_code = 0xe08c,
+	.pme_short_desc = "Micropartition prefetch",
+	.pme_long_desc = "Micropartition prefetch42",
+},
+[ POWER8_PME_PM_UP_PREF_POINTER ] = {
+	.pme_name = "PM_UP_PREF_POINTER",
+	.pme_code = 0xe08e,
+	.pme_short_desc = "Micrpartition pointer prefetches",
+	.pme_long_desc = "Micrpartition pointer prefetches42",
+},
+[ POWER8_PME_PM_VSU0_16FLOP ] = {
+	.pme_name = "PM_VSU0_16FLOP",
+	.pme_code = 0xa0a4,
+	.pme_short_desc = "Sixteen flops operation (SP vector versions of fdiv,fsqrt)",
+	.pme_long_desc = "Sixteen flops operation (SP vector versions of fdiv,fsqrt)",
+},
+[ POWER8_PME_PM_VSU0_1FLOP ] = {
+	.pme_name = "PM_VSU0_1FLOP",
+	.pme_code = 0xa080,
+	.pme_short_desc = "one flop (fadd, fmul, fsub, fcmp, fsel, fabs, fnabs, fres, fsqrte, fneg) operation finished",
+	.pme_long_desc = "one flop (fadd, fmul, fsub, fcmp, fsel, fabs, fnabs, fres, fsqrte, fneg) operation finishedDecode into 1,2,4 FLOP according to instr IOP, multiplied by #vector elements according to route( eg x1, x2, x4) Only if instr sends finish to ISU",
+},
+[ POWER8_PME_PM_VSU0_2FLOP ] = {
+	.pme_name = "PM_VSU0_2FLOP",
+	.pme_code = 0xa098,
+	.pme_short_desc = "two flops operation (scalar fmadd, fnmadd, fmsub, fnmsub and DP vector versions of single flop instructions)",
+	.pme_long_desc = "two flops operation (scalar fmadd, fnmadd, fmsub, fnmsub and DP vector versions of single flop instructions)",
+},
+[ POWER8_PME_PM_VSU0_4FLOP ] = {
+	.pme_name = "PM_VSU0_4FLOP",
+	.pme_code = 0xa09c,
+	.pme_short_desc = "four flops operation (scalar fdiv, fsqrt, DP vector version of fmadd, fnmadd, fmsub, fnmsub, SP vector versions of single flop instructions)",
+	.pme_long_desc = "four flops operation (scalar fdiv, fsqrt, DP vector version of fmadd, fnmadd, fmsub, fnmsub, SP vector versions of single flop instructions)",
+},
+[ POWER8_PME_PM_VSU0_8FLOP ] = {
+	.pme_name = "PM_VSU0_8FLOP",
+	.pme_code = 0xa0a0,
+	.pme_short_desc = "eight flops operation (DP vector versions of fdiv,fsqrt and SP vector versions of fmadd,fnmadd,fmsub,fnmsub)",
+	.pme_long_desc = "eight flops operation (DP vector versions of fdiv,fsqrt and SP vector versions of fmadd,fnmadd,fmsub,fnmsub)",
+},
+[ POWER8_PME_PM_VSU0_COMPLEX_ISSUED ] = {
+	.pme_name = "PM_VSU0_COMPLEX_ISSUED",
+	.pme_code = 0xb0a4,
+	.pme_short_desc = "Complex VMX instruction issued",
+	.pme_long_desc = "Complex VMX instruction issued",
+},
+[ POWER8_PME_PM_VSU0_CY_ISSUED ] = {
+	.pme_name = "PM_VSU0_CY_ISSUED",
+	.pme_code = 0xb0b4,
+	.pme_short_desc = "Cryptographic instruction RFC02196 Issued",
+	.pme_long_desc = "Cryptographic instruction RFC02196 Issued",
+},
+[ POWER8_PME_PM_VSU0_DD_ISSUED ] = {
+	.pme_name = "PM_VSU0_DD_ISSUED",
+	.pme_code = 0xb0a8,
+	.pme_short_desc = "64BIT Decimal Issued",
+	.pme_long_desc = "64BIT Decimal Issued",
+},
+[ POWER8_PME_PM_VSU0_DP_2FLOP ] = {
+	.pme_name = "PM_VSU0_DP_2FLOP",
+	.pme_code = 0xa08c,
+	.pme_short_desc = "DP vector version of fmul, fsub, fcmp, fsel, fabs, fnabs, fres ,fsqrte, fneg",
+	.pme_long_desc = "DP vector version of fmul, fsub, fcmp, fsel, fabs, fnabs, fres ,fsqrte, fneg",
+},
+[ POWER8_PME_PM_VSU0_DP_FMA ] = {
+	.pme_name = "PM_VSU0_DP_FMA",
+	.pme_code = 0xa090,
+	.pme_short_desc = "DP vector version of fmadd,fnmadd,fmsub,fnmsub",
+	.pme_long_desc = "DP vector version of fmadd,fnmadd,fmsub,fnmsub",
+},
+[ POWER8_PME_PM_VSU0_DP_FSQRT_FDIV ] = {
+	.pme_name = "PM_VSU0_DP_FSQRT_FDIV",
+	.pme_code = 0xa094,
+	.pme_short_desc = "DP vector versions of fdiv,fsqrt",
+	.pme_long_desc = "DP vector versions of fdiv,fsqrt",
+},
+[ POWER8_PME_PM_VSU0_DQ_ISSUED ] = {
+	.pme_name = "PM_VSU0_DQ_ISSUED",
+	.pme_code = 0xb0ac,
+	.pme_short_desc = "128BIT Decimal Issued",
+	.pme_long_desc = "128BIT Decimal Issued",
+},
+[ POWER8_PME_PM_VSU0_EX_ISSUED ] = {
+	.pme_name = "PM_VSU0_EX_ISSUED",
+	.pme_code = 0xb0b0,
+	.pme_short_desc = "Direct move 32/64b VRFtoGPR RFC02206 Issued",
+	.pme_long_desc = "Direct move 32/64b VRFtoGPR RFC02206 Issued",
+},
+[ POWER8_PME_PM_VSU0_FIN ] = {
+	.pme_name = "PM_VSU0_FIN",
+	.pme_code = 0xa0bc,
+	.pme_short_desc = "VSU0 Finished an instruction",
+	.pme_long_desc = "VSU0 Finished an instruction",
+},
+[ POWER8_PME_PM_VSU0_FMA ] = {
+	.pme_name = "PM_VSU0_FMA",
+	.pme_code = 0xa084,
+	.pme_short_desc = "two flops operation (fmadd, fnmadd, fmsub, fnmsub) Scalar instructions only!",
+	.pme_long_desc = "two flops operation (fmadd, fnmadd, fmsub, fnmsub) Scalar instructions only!",
+},
+[ POWER8_PME_PM_VSU0_FPSCR ] = {
+	.pme_name = "PM_VSU0_FPSCR",
+	.pme_code = 0xb098,
+	.pme_short_desc = "Move to/from FPSCR type instruction issued on Pipe 0",
+	.pme_long_desc = "Move to/from FPSCR type instruction issued on Pipe 0",
+},
+[ POWER8_PME_PM_VSU0_FSQRT_FDIV ] = {
+	.pme_name = "PM_VSU0_FSQRT_FDIV",
+	.pme_code = 0xa088,
+	.pme_short_desc = "four flops operation (fdiv,fsqrt) Scalar Instructions only!",
+	.pme_long_desc = "four flops operation (fdiv,fsqrt) Scalar Instructions only!",
+},
+[ POWER8_PME_PM_VSU0_PERMUTE_ISSUED ] = {
+	.pme_name = "PM_VSU0_PERMUTE_ISSUED",
+	.pme_code = 0xb090,
+	.pme_short_desc = "Permute VMX Instruction Issued",
+	.pme_long_desc = "Permute VMX Instruction Issued",
+},
+[ POWER8_PME_PM_VSU0_SCALAR_DP_ISSUED ] = {
+	.pme_name = "PM_VSU0_SCALAR_DP_ISSUED",
+	.pme_code = 0xb088,
+	.pme_short_desc = "Double Precision scalar instruction issued on Pipe0",
+	.pme_long_desc = "Double Precision scalar instruction issued on Pipe0",
+},
+[ POWER8_PME_PM_VSU0_SIMPLE_ISSUED ] = {
+	.pme_name = "PM_VSU0_SIMPLE_ISSUED",
+	.pme_code = 0xb094,
+	.pme_short_desc = "Simple VMX instruction issued",
+	.pme_long_desc = "Simple VMX instruction issued",
+},
+[ POWER8_PME_PM_VSU0_SINGLE ] = {
+	.pme_name = "PM_VSU0_SINGLE",
+	.pme_code = 0xa0a8,
+	.pme_short_desc = "FPU single precision",
+	.pme_long_desc = "FPU single precision",
+},
+[ POWER8_PME_PM_VSU0_SQ ] = {
+	.pme_name = "PM_VSU0_SQ",
+	.pme_code = 0xb09c,
+	.pme_short_desc = "Store Vector Issued",
+	.pme_long_desc = "Store Vector Issued",
+},
+[ POWER8_PME_PM_VSU0_STF ] = {
+	.pme_name = "PM_VSU0_STF",
+	.pme_code = 0xb08c,
+	.pme_short_desc = "FPU store (SP or DP) issued on Pipe0",
+	.pme_long_desc = "FPU store (SP or DP) issued on Pipe0",
+},
+[ POWER8_PME_PM_VSU0_VECTOR_DP_ISSUED ] = {
+	.pme_name = "PM_VSU0_VECTOR_DP_ISSUED",
+	.pme_code = 0xb080,
+	.pme_short_desc = "Double Precision vector instruction issued on Pipe0",
+	.pme_long_desc = "Double Precision vector instruction issued on Pipe0",
+},
+[ POWER8_PME_PM_VSU0_VECTOR_SP_ISSUED ] = {
+	.pme_name = "PM_VSU0_VECTOR_SP_ISSUED",
+	.pme_code = 0xb084,
+	.pme_short_desc = "Single Precision vector instruction issued (executed)",
+	.pme_long_desc = "Single Precision vector instruction issued (executed)",
+},
+[ POWER8_PME_PM_VSU1_16FLOP ] = {
+	.pme_name = "PM_VSU1_16FLOP",
+	.pme_code = 0xa0a6,
+	.pme_short_desc = "Sixteen flops operation (SP vector versions of fdiv,fsqrt)",
+	.pme_long_desc = "Sixteen flops operation (SP vector versions of fdiv,fsqrt)",
+},
+[ POWER8_PME_PM_VSU1_1FLOP ] = {
+	.pme_name = "PM_VSU1_1FLOP",
+	.pme_code = 0xa082,
+	.pme_short_desc = "one flop (fadd, fmul, fsub, fcmp, fsel, fabs, fnabs, fres, fsqrte, fneg) operation finished",
+	.pme_long_desc = "one flop (fadd, fmul, fsub, fcmp, fsel, fabs, fnabs, fres, fsqrte, fneg) operation finished",
+},
+[ POWER8_PME_PM_VSU1_2FLOP ] = {
+	.pme_name = "PM_VSU1_2FLOP",
+	.pme_code = 0xa09a,
+	.pme_short_desc = "two flops operation (scalar fmadd, fnmadd, fmsub, fnmsub and DP vector versions of single flop instructions)",
+	.pme_long_desc = "two flops operation (scalar fmadd, fnmadd, fmsub, fnmsub and DP vector versions of single flop instructions)",
+},
+[ POWER8_PME_PM_VSU1_4FLOP ] = {
+	.pme_name = "PM_VSU1_4FLOP",
+	.pme_code = 0xa09e,
+	.pme_short_desc = "four flops operation (scalar fdiv, fsqrt, DP vector version of fmadd, fnmadd, fmsub, fnmsub, SP vector versions of single flop instructions)",
+	.pme_long_desc = "four flops operation (scalar fdiv, fsqrt, DP vector version of fmadd, fnmadd, fmsub, fnmsub, SP vector versions of single flop instructions)",
+},
+[ POWER8_PME_PM_VSU1_8FLOP ] = {
+	.pme_name = "PM_VSU1_8FLOP",
+	.pme_code = 0xa0a2,
+	.pme_short_desc = "eight flops operation (DP vector versions of fdiv,fsqrt and SP vector versions of fmadd,fnmadd,fmsub,fnmsub)",
+	.pme_long_desc = "eight flops operation (DP vector versions of fdiv,fsqrt and SP vector versions of fmadd,fnmadd,fmsub,fnmsub)",
+},
+[ POWER8_PME_PM_VSU1_COMPLEX_ISSUED ] = {
+	.pme_name = "PM_VSU1_COMPLEX_ISSUED",
+	.pme_code = 0xb0a6,
+	.pme_short_desc = "Complex VMX instruction issued",
+	.pme_long_desc = "Complex VMX instruction issued",
+},
+[ POWER8_PME_PM_VSU1_CY_ISSUED ] = {
+	.pme_name = "PM_VSU1_CY_ISSUED",
+	.pme_code = 0xb0b6,
+	.pme_short_desc = "Cryptographic instruction RFC02196 Issued",
+	.pme_long_desc = "Cryptographic instruction RFC02196 Issued",
+},
+[ POWER8_PME_PM_VSU1_DD_ISSUED ] = {
+	.pme_name = "PM_VSU1_DD_ISSUED",
+	.pme_code = 0xb0aa,
+	.pme_short_desc = "64BIT Decimal Issued",
+	.pme_long_desc = "64BIT Decimal Issued",
+},
+[ POWER8_PME_PM_VSU1_DP_2FLOP ] = {
+	.pme_name = "PM_VSU1_DP_2FLOP",
+	.pme_code = 0xa08e,
+	.pme_short_desc = "DP vector version of fmul, fsub, fcmp, fsel, fabs, fnabs, fres ,fsqrte, fneg",
+	.pme_long_desc = "DP vector version of fmul, fsub, fcmp, fsel, fabs, fnabs, fres ,fsqrte, fneg",
+},
+[ POWER8_PME_PM_VSU1_DP_FMA ] = {
+	.pme_name = "PM_VSU1_DP_FMA",
+	.pme_code = 0xa092,
+	.pme_short_desc = "DP vector version of fmadd,fnmadd,fmsub,fnmsub",
+	.pme_long_desc = "DP vector version of fmadd,fnmadd,fmsub,fnmsub",
+},
+[ POWER8_PME_PM_VSU1_DP_FSQRT_FDIV ] = {
+	.pme_name = "PM_VSU1_DP_FSQRT_FDIV",
+	.pme_code = 0xa096,
+	.pme_short_desc = "DP vector versions of fdiv,fsqrt",
+	.pme_long_desc = "DP vector versions of fdiv,fsqrt",
+},
+[ POWER8_PME_PM_VSU1_DQ_ISSUED ] = {
+	.pme_name = "PM_VSU1_DQ_ISSUED",
+	.pme_code = 0xb0ae,
+	.pme_short_desc = "128BIT Decimal Issued",
+	.pme_long_desc = "128BIT Decimal Issued",
+},
+[ POWER8_PME_PM_VSU1_EX_ISSUED ] = {
+	.pme_name = "PM_VSU1_EX_ISSUED",
+	.pme_code = 0xb0b2,
+	.pme_short_desc = "Direct move 32/64b VRFtoGPR RFC02206 Issued",
+	.pme_long_desc = "Direct move 32/64b VRFtoGPR RFC02206 Issued",
+},
+[ POWER8_PME_PM_VSU1_FIN ] = {
+	.pme_name = "PM_VSU1_FIN",
+	.pme_code = 0xa0be,
+	.pme_short_desc = "VSU1 Finished an instruction",
+	.pme_long_desc = "VSU1 Finished an instruction",
+},
+[ POWER8_PME_PM_VSU1_FMA ] = {
+	.pme_name = "PM_VSU1_FMA",
+	.pme_code = 0xa086,
+	.pme_short_desc = "two flops operation (fmadd, fnmadd, fmsub, fnmsub) Scalar instructions only!",
+	.pme_long_desc = "two flops operation (fmadd, fnmadd, fmsub, fnmsub) Scalar instructions only!",
+},
+[ POWER8_PME_PM_VSU1_FPSCR ] = {
+	.pme_name = "PM_VSU1_FPSCR",
+	.pme_code = 0xb09a,
+	.pme_short_desc = "Move to/from FPSCR type instruction issued on Pipe 0",
+	.pme_long_desc = "Move to/from FPSCR type instruction issued on Pipe 0",
+},
+[ POWER8_PME_PM_VSU1_FSQRT_FDIV ] = {
+	.pme_name = "PM_VSU1_FSQRT_FDIV",
+	.pme_code = 0xa08a,
+	.pme_short_desc = "four flops operation (fdiv,fsqrt) Scalar Instructions only!",
+	.pme_long_desc = "four flops operation (fdiv,fsqrt) Scalar Instructions only!",
+},
+[ POWER8_PME_PM_VSU1_PERMUTE_ISSUED ] = {
+	.pme_name = "PM_VSU1_PERMUTE_ISSUED",
+	.pme_code = 0xb092,
+	.pme_short_desc = "Permute VMX Instruction Issued",
+	.pme_long_desc = "Permute VMX Instruction Issued",
+},
+[ POWER8_PME_PM_VSU1_SCALAR_DP_ISSUED ] = {
+	.pme_name = "PM_VSU1_SCALAR_DP_ISSUED",
+	.pme_code = 0xb08a,
+	.pme_short_desc = "Double Precision scalar instruction issued on Pipe1",
+	.pme_long_desc = "Double Precision scalar instruction issued on Pipe1",
+},
+[ POWER8_PME_PM_VSU1_SIMPLE_ISSUED ] = {
+	.pme_name = "PM_VSU1_SIMPLE_ISSUED",
+	.pme_code = 0xb096,
+	.pme_short_desc = "Simple VMX instruction issued",
+	.pme_long_desc = "Simple VMX instruction issued",
+},
+[ POWER8_PME_PM_VSU1_SINGLE ] = {
+	.pme_name = "PM_VSU1_SINGLE",
+	.pme_code = 0xa0aa,
+	.pme_short_desc = "FPU single precision",
+	.pme_long_desc = "FPU single precision",
+},
+[ POWER8_PME_PM_VSU1_SQ ] = {
+	.pme_name = "PM_VSU1_SQ",
+	.pme_code = 0xb09e,
+	.pme_short_desc = "Store Vector Issued",
+	.pme_long_desc = "Store Vector Issued",
+},
+[ POWER8_PME_PM_VSU1_STF ] = {
+	.pme_name = "PM_VSU1_STF",
+	.pme_code = 0xb08e,
+	.pme_short_desc = "FPU store (SP or DP) issued on Pipe1",
+	.pme_long_desc = "FPU store (SP or DP) issued on Pipe1",
+},
+[ POWER8_PME_PM_VSU1_VECTOR_DP_ISSUED ] = {
+	.pme_name = "PM_VSU1_VECTOR_DP_ISSUED",
+	.pme_code = 0xb082,
+	.pme_short_desc = "Double Precision vector instruction issued on Pipe1",
+	.pme_long_desc = "Double Precision vector instruction issued on Pipe1",
+},
+[ POWER8_PME_PM_VSU1_VECTOR_SP_ISSUED ] = {
+	.pme_name = "PM_VSU1_VECTOR_SP_ISSUED",
+	.pme_code = 0xb086,
+	.pme_short_desc = "Single Precision vector instruction issued (executed)",
+	.pme_long_desc = "Single Precision vector instruction issued (executed)",
+},
 };
 #endif
diff --git a/src/libpfm4/lib/pfmlib_arm_armv8.c b/src/libpfm4/lib/pfmlib_arm_armv8.c
new file mode 100644
index 0000000..c38bd9b
--- /dev/null
+++ b/src/libpfm4/lib/pfmlib_arm_armv8.c
@@ -0,0 +1,116 @@
+/*
+ * pfmlib_arm_armv8.c : support for ARMv8 processors
+ *
+ * Copyright (c) 2014 Google Inc. All rights reserved
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+#include <sys/types.h>
+#include <string.h>
+#include <stdlib.h>
+
+/* private headers */
+#include "pfmlib_priv.h"			/* library private */
+#include "pfmlib_arm_priv.h"
+
+#include "events/arm_cortex_a57_events.h"    /* A57 event tables */
+#include "events/arm_cortex_a53_events.h"    /* A53 event tables */
+
+static int
+pfm_arm_detect_cortex_a57(void *this)
+{
+	int ret;
+
+	ret = pfm_arm_detect(this);
+	if (ret != PFM_SUCCESS)
+		return PFM_ERR_NOTSUPP;
+
+	if ((pfm_arm_cfg.implementer == 0x41) && /* ARM */
+		(pfm_arm_cfg.part == 0xd07)) { /* Cortex A57 */
+			return PFM_SUCCESS;
+	}
+	return PFM_ERR_NOTSUPP;
+}
+
+static int
+pfm_arm_detect_cortex_a53(void *this)
+{
+	int ret;
+
+	ret = pfm_arm_detect(this);
+	if (ret != PFM_SUCCESS)
+		return PFM_ERR_NOTSUPP;
+
+	if ((pfm_arm_cfg.implementer == 0x41) && /* ARM */
+		(pfm_arm_cfg.part == 0xd03)) { /* Cortex A53 */
+			return PFM_SUCCESS;
+	}
+	return PFM_ERR_NOTSUPP;
+}
+
+/* ARM Cortex A57 support */
+pfmlib_pmu_t arm_cortex_a57_support={
+	.desc			= "ARM Cortex A57",
+	.name			= "arm_ac57",
+	.pmu			= PFM_PMU_ARM_CORTEX_A57,
+	.pme_count		= LIBPFM_ARRAY_SIZE(arm_cortex_a57_pe),
+	.type			= PFM_PMU_TYPE_CORE,
+	.pe			= arm_cortex_a57_pe,
+
+	.pmu_detect		= pfm_arm_detect_cortex_a57,
+	.max_encoding		= 1,
+	.num_cntrs		= 6,
+
+	.get_event_encoding[PFM_OS_NONE] = pfm_arm_get_encoding,
+	 PFMLIB_ENCODE_PERF(pfm_arm_get_perf_encoding),
+	.get_event_first	= pfm_arm_get_event_first,
+	.get_event_next		= pfm_arm_get_event_next,
+	.event_is_valid		= pfm_arm_event_is_valid,
+	.validate_table		= pfm_arm_validate_table,
+	.get_event_info		= pfm_arm_get_event_info,
+	.get_event_attr_info	= pfm_arm_get_event_attr_info,
+	 PFMLIB_VALID_PERF_PATTRS(pfm_arm_perf_validate_pattrs),
+	.get_event_nattrs	= pfm_arm_get_event_nattrs,
+};
+
+/* ARM Cortex A53 support */
+pfmlib_pmu_t arm_cortex_a53_support={
+	.desc			= "ARM Cortex A53",
+	.name			= "arm_ac53",
+	.pmu			= PFM_PMU_ARM_CORTEX_A53,
+	.pme_count		= LIBPFM_ARRAY_SIZE(arm_cortex_a53_pe),
+	.type			= PFM_PMU_TYPE_CORE,
+	.pe			= arm_cortex_a53_pe,
+
+	.pmu_detect		= pfm_arm_detect_cortex_a53,
+	.max_encoding		= 1,
+	.num_cntrs		= 6,
+
+	.get_event_encoding[PFM_OS_NONE] = pfm_arm_get_encoding,
+	 PFMLIB_ENCODE_PERF(pfm_arm_get_perf_encoding),
+	.get_event_first	= pfm_arm_get_event_first,
+	.get_event_next		= pfm_arm_get_event_next,
+	.event_is_valid		= pfm_arm_event_is_valid,
+	.validate_table		= pfm_arm_validate_table,
+	.get_event_info		= pfm_arm_get_event_info,
+	.get_event_attr_info	= pfm_arm_get_event_attr_info,
+	 PFMLIB_VALID_PERF_PATTRS(pfm_arm_perf_validate_pattrs),
+	.get_event_nattrs	= pfm_arm_get_event_nattrs,
+};
diff --git a/src/libpfm4/lib/pfmlib_arm_priv.h b/src/libpfm4/lib/pfmlib_arm_priv.h
index ef367b7..227508b 100644
--- a/src/libpfm4/lib/pfmlib_arm_priv.h
+++ b/src/libpfm4/lib/pfmlib_arm_priv.h
@@ -86,6 +86,9 @@ extern int pfm_arm_get_perf_encoding(void *this, pfmlib_event_desc_t *e);
 #define ARMV7_A15_ATTRS	(_ARM_ATTR_K|_ARM_ATTR_U|_ARM_ATTR_HV)
 #define ARMV7_A15_PLM	(PFM_PLM0|PFM_PLM3|PFM_PLMH)
 
+#define ARMV8_ATTRS	(_ARM_ATTR_K|_ARM_ATTR_U|_ARM_ATTR_HV)
+#define ARMV8_PLM	(PFM_PLM0|PFM_PLM3|PFM_PLMH)
+
 static inline int
 arm_has_plm(void *this, pfmlib_event_desc_t *e)
 {
diff --git a/src/libpfm4/lib/pfmlib_common.c b/src/libpfm4/lib/pfmlib_common.c
index 8e4b1a1..ebe20da 100644
--- a/src/libpfm4/lib/pfmlib_common.c
+++ b/src/libpfm4/lib/pfmlib_common.c
@@ -199,7 +199,14 @@ static pfmlib_pmu_t *pfmlib_pmus[]=
 	&arm_cortex_a15_support,
 	&arm_1176_support,
 	&arm_qcom_krait_support,
+	&arm_cortex_a57_support,
+	&arm_cortex_a53_support,
 #endif
+#ifdef CONFIG_PFMLIB_ARCH_ARM64
+	&arm_cortex_a57_support,
+	&arm_cortex_a53_support,
+#endif
+
 #ifdef CONFIG_PFMLIB_ARCH_S390X
 	&s390x_cpum_cf_support,
 	&s390x_cpum_sf_support,
diff --git a/src/libpfm4/lib/pfmlib_priv.h b/src/libpfm4/lib/pfmlib_priv.h
index 715c4b0..5678cc0 100644
--- a/src/libpfm4/lib/pfmlib_priv.h
+++ b/src/libpfm4/lib/pfmlib_priv.h
@@ -332,6 +332,8 @@ extern pfmlib_pmu_t arm_cortex_a9_support;
 extern pfmlib_pmu_t arm_cortex_a15_support;
 extern pfmlib_pmu_t arm_1176_support;
 extern pfmlib_pmu_t arm_qcom_krait_support;
+extern pfmlib_pmu_t arm_cortex_a57_support;
+extern pfmlib_pmu_t arm_cortex_a53_support;
 extern pfmlib_pmu_t mips_74k_support;
 extern pfmlib_pmu_t s390x_cpum_cf_support;
 extern pfmlib_pmu_t s390x_cpum_sf_support;
diff --git a/src/libpfm4/perf_examples/syst_count.c b/src/libpfm4/perf_examples/syst_count.c
index df2ed0a..0d53078 100644
--- a/src/libpfm4/perf_examples/syst_count.c
+++ b/src/libpfm4/perf_examples/syst_count.c
@@ -182,18 +182,11 @@ setup_cpu(int cpu, int cfd)
 				if (errno == EACCES)
 					err(1, "you need to be root to run system-wide on this machine");
 
-				warn("cannot attach event %s to CPU%ds, skipping it", fds[j].name, cpu);
-				goto error;
+				warn("cannot attach event %s to CPU%ds, aborting", fds[j].name, cpu);
+				exit(1);
 			}
 		}
 	}
-	return;
-error:
-	for (i=0; i < j; i++) {
-		if (fds[i].fd > -1)
-			close(fds[i].fd);
-		fds[i].fd = -1;
-	}
 }
 
 void start_cpu(int c)
diff --git a/src/libpfm4/tests/Makefile b/src/libpfm4/tests/Makefile
index 7076fb7..7dd82c3 100644
--- a/src/libpfm4/tests/Makefile
+++ b/src/libpfm4/tests/Makefile
@@ -39,6 +39,10 @@ ifeq ($(CONFIG_PFMLIB_ARCH_ARM),y)
 SRCS += validate_arm.c
 endif
 
+ifeq ($(CONFIG_PFMLIB_ARCH_ARM64),y)
+SRCS += validate_arm64.c
+endif
+
 ifeq ($(CONFIG_PFMLIB_ARCH_POWERPC),y)
 SRCS += validate_power.c
 endif
diff --git a/src/libpfm4/tests/validate_arm.c b/src/libpfm4/tests/validate_arm.c
index fe97aa9..44eefd4 100644
--- a/src/libpfm4/tests/validate_arm.c
+++ b/src/libpfm4/tests/validate_arm.c
@@ -159,6 +159,76 @@ static const test_event_t arm_test_events[]={
 	  .codes[0] = 0x480000ff,
 	  .fstr = "qcom_krait::CPU_CYCLES:k=0:u=1:hv=0",
 	},
+	{ SRC_LINE,
+	  .name = "arm_ac57::CPU_CYCLES",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000011,
+	  .fstr = "arm_ac57::CPU_CYCLES:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac57::CPU_CYCLES:k",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x88000011,
+	  .fstr = "arm_ac57::CPU_CYCLES:k=1:u=0:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac57::CPU_CYCLES:k:u",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000011,
+	  .fstr = "arm_ac57::CPU_CYCLES:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac57::INST_RETIRED",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000008,
+	  .fstr = "arm_ac57::INST_RETIRED:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac53::CPU_CYCLES",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000011,
+	  .fstr = "arm_ac53::CPU_CYCLES:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac53::CPU_CYCLES:k",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x88000011,
+	  .fstr = "arm_ac53::CPU_CYCLES:k=1:u=0:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac53::CPU_CYCLES:k:u",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000011,
+	  .fstr = "arm_ac53::CPU_CYCLES:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac53::INST_RETIRED",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000008,
+	  .fstr = "arm_ac53::INST_RETIRED:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac53::LD_RETIRED",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000006,
+	  .fstr = "arm_ac53::LD_RETIRED:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac53::ST_RETIRED",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000007,
+	  .fstr = "arm_ac53::ST_RETIRED:k=1:u=1:hv=0",
+	},
 };
 #define NUM_TEST_EVENTS (int)(sizeof(arm_test_events)/sizeof(test_event_t))
 
diff --git a/src/libpfm4/tests/validate_arm64.c b/src/libpfm4/tests/validate_arm64.c
new file mode 100644
index 0000000..61400ac
--- /dev/null
+++ b/src/libpfm4/tests/validate_arm64.c
@@ -0,0 +1,180 @@
+/*
+ * validate_arm64.c - validate ARM64 event tables + encodings
+ *
+ * Copyright (c) 2014 Google, Inc
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+#include <sys/types.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <inttypes.h>
+#include <stdarg.h>
+#include <errno.h>
+#include <unistd.h>
+#include <string.h>
+
+#include <perfmon/pfmlib.h>
+
+#define MAX_ENCODING	1
+#define SRC_LINE	.line = __LINE__
+
+typedef struct {
+	const char *name;
+	const char *fstr;
+	uint64_t codes[MAX_ENCODING];
+	int ret, count, line;
+} test_event_t;
+
+static const test_event_t arm64_test_events[]={
+	{ SRC_LINE,
+	  .name = "arm_ac57::CPU_CYCLES",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000011,
+	  .fstr = "arm_ac57::CPU_CYCLES:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac57::CPU_CYCLES:k",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x88000011,
+	  .fstr = "arm_ac57::CPU_CYCLES:k=1:u=0:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac57::CPU_CYCLES:k:u",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000011,
+	  .fstr = "arm_ac57::CPU_CYCLES:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac57::INST_RETIRED",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000008,
+	  .fstr = "arm_ac57::INST_RETIRED:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac53::CPU_CYCLES",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000011,
+	  .fstr = "arm_ac53::CPU_CYCLES:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac53::CPU_CYCLES:k",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x88000011,
+	  .fstr = "arm_ac53::CPU_CYCLES:k=1:u=0:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac53::CPU_CYCLES:k:u",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000011,
+	  .fstr = "arm_ac53::CPU_CYCLES:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac53::INST_RETIRED",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000008,
+	  .fstr = "arm_ac53::INST_RETIRED:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac53::LD_RETIRED",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000006,
+	  .fstr = "arm_ac53::LD_RETIRED:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac53::ST_RETIRED",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000007,
+	  .fstr = "arm_ac53::ST_RETIRED:k=1:u=1:hv=0",
+	},
+};
+#define NUM_TEST_EVENTS (int)(sizeof(arm64_test_events)/sizeof(test_event_t))
+
+static int check_test_events(FILE *fp)
+{
+	const test_event_t *e;
+	char *fstr;
+	uint64_t *codes;
+	int count, i, j;
+	int ret, errors = 0;
+
+	for (i = 0, e = arm64_test_events; i < NUM_TEST_EVENTS; i++, e++) {
+		codes = NULL;
+		count = 0;
+		fstr = NULL;
+		ret = pfm_get_event_encoding(e->name, PFM_PLM0 | PFM_PLM3, &fstr, NULL, &codes, &count);
+		if (ret != e->ret) {
+			fprintf(fp,"Line %d, Event%d %s, ret=%s(%d) expected %s(%d)\n", e->line, i, e->name, pfm_strerror(ret), ret, pfm_strerror(e->ret), e->ret);
+			errors++;
+		} else {
+			if (ret != PFM_SUCCESS) {
+				if (fstr) {
+					fprintf(fp,"Line %d, Event%d %s, expected fstr NULL but it is not\n", e->line, i, e->name);
+					errors++;
+				}
+				if (count != 0) {
+					fprintf(fp,"Line %d, Event%d %s, expected count=0 instead of %d\n", e->line, i, e->name, count);
+					errors++;
+				}
+				if (codes) {
+					fprintf(fp,"Line %d, Event%d %s, expected codes[] NULL but it is not\n", e->line, i, e->name);
+					errors++;
+				}
+			} else {
+				if (count != e->count) {
+					fprintf(fp,"Line %d, Event%d %s, count=%d expected %d\n", e->line, i, e->name, count, e->count);
+					errors++;
+				}
+				for (j=0; j < count; j++) {
+					if (codes[j] != e->codes[j]) {
+						fprintf(fp,"Line %d, Event%d %s, codes[%d]=%#"PRIx64" expected %#"PRIx64"\n", e->line, i, e->name, j, codes[j], e->codes[j]);
+						errors++;
+					}
+				}
+				if (e->fstr && strcmp(fstr, e->fstr)) {
+					fprintf(fp,"Line %d, Event%d %s, fstr=%s expected %s\n", e->line, i, e->name, fstr, e->fstr);
+					errors++;
+				}
+			}
+		}
+		if (codes)
+			free(codes);
+		if (fstr)
+			free(fstr);
+	}
+	printf("\t %d ARM64 events: %d errors\n", i, errors);
+	return errors;
+}
+
+int
+validate_arch(FILE *fp)
+{
+	return check_test_events(fp);
+}
-- 
2.1.0

From 04865a316fd64931cdc125d40fd250ace21f5bed Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Fri, 27 Jun 2014 18:19:58 -0400
Subject: [PATCH 17/24] Update libpfm4

Catches a haswell table update.
We are in line with libpfm commit:
commit 234d9223fdafeb4052d1e6d9919d0e9aa7068171
Author: Stephane Eranian <eranian@gmail.com>
Date:   Tue Jun 24 15:07:26 2014 +0200

    showevtinfo: allow listing of encoding for any PMU

    This patch forces LIBPFM_ENCODE_INACTIVE=1 for showevtinfo
    to allow showevtinfo -E to work for any target PMU and
    not just the host PMU.

    Showevtinfo does not actually program events, it just
    lists events and encodings.

    Signed-off-by: Stephane Eranian <eranian@gmail.com>

diff --git a/src/libpfm4/docs/man3/libpfm_arm_ac7.3 b/src/libpfm4/docs/man3/libpfm_arm_ac7.3
new file mode 100644
index 0000000..89d06e9
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_arm_ac7.3
@@ -0,0 +1,35 @@
+.TH LIBPFM 3  "August, 2012" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_arm_ac7 - support for Arm Cortex A7 PMU
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: arm_ac7
+.B PMU desc: ARM Cortex A7
+.sp
+.SH DESCRIPTION
+The library supports the ARM Cortex A7 core PMU.
+
+This PMU supports 4 counters and privilege levels filtering.
+
+.SH MODIFIERS
+The following modifiers are supported on ARM Cortex A7:
+.TP
+.B u
+Measure at the user level. This corresponds to \fBPFM_PLM3\fR.
+This is a boolean modifier.
+.TP
+.B k
+Measure at the kernel level. This corresponds to \fBPFM_PLM0\fR.
+This is a boolean modifier.
+.TP
+.B hv
+Measure at the hypervisor level. This corresponds to \fBPFM_PLMH\fR.
+This is a boolean modifier.
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.PP
diff --git a/src/libpfm4/examples/showevtinfo.c b/src/libpfm4/examples/showevtinfo.c
index 3723da3..45763ec 100644
--- a/src/libpfm4/examples/showevtinfo.c
+++ b/src/libpfm4/examples/showevtinfo.c
@@ -67,6 +67,35 @@ static const char *srcs[PFM_ATTR_CTRL_MAX]={
 	[PFM_ATTR_CTRL_PERF_EVENT] = "perf_event",
 };
 
+#ifdef PFMLIB_WINDOWS
+int set_env_var(const char *var, const char *value, int ov)
+{
+	size_t len;
+	char *str;
+	int ret;
+
+	len = strlen(var) + 1 + strlen(value) + 1;
+
+	str = malloc(len);
+	if (!str)
+		return PFM_ERR_NOMEM;
+
+	sprintf(str, "%s=%s", var, value);
+
+	ret = putenv(str);
+
+	free(str);
+
+	return ret ? PFM_ERR_INVAL : PFM_SUCCESS;
+}
+#else
+static inline int
+set_env_var(const char *var, const char *value, int ov)
+{
+	return setenv(var, value, ov);
+}
+#endif
+
 static int
 event_has_pname(char *s)
 {
@@ -790,6 +819,12 @@ main(int argc, char **argv)
 				errx(1, "unknown option error");
 		}
 	}
+	/* to allow encoding of events from non detected PMU models */
+	ret = set_env_var("LIBPFM_ENCODE_INACTIVE", "1", 1);
+	if (ret != PFM_SUCCESS)
+		errx(1, "cannot force inactive encoding");
+
+
 	ret = pfm_initialize();
 	if (ret != PFM_SUCCESS)
 		errx(1, "cannot initialize libpfm: %s", pfm_strerror(ret));
diff --git a/src/libpfm4/include/perfmon/pfmlib.h b/src/libpfm4/include/perfmon/pfmlib.h
index a7ec026..0169511 100644
--- a/src/libpfm4/include/perfmon/pfmlib.h
+++ b/src/libpfm4/include/perfmon/pfmlib.h
@@ -240,6 +240,8 @@ typedef enum {
 	PFM_PMU_ARM_CORTEX_A57,		/* ARM Cortex A57 (ARMv8) */
 	PFM_PMU_ARM_CORTEX_A53,		/* ARM Cortex A53 (ARMv8) */
 
+	PFM_PMU_ARM_CORTEX_A7,		/* ARM Cortex A7 */
+
 	/* MUST ADD NEW PMU MODELS HERE */
 
 	PFM_PMU_MAX			/* end marker */
diff --git a/src/libpfm4/lib/Makefile b/src/libpfm4/lib/Makefile
index 5aaf4b3..14a6d0d 100644
--- a/src/libpfm4/lib/Makefile
+++ b/src/libpfm4/lib/Makefile
@@ -279,6 +279,7 @@ INC_ARM=events/arm_cortex_a8_events.h		\
         events/arm_cortex_a9_events.h
 
 INC_ARM=pfmlib_arm_priv.h			\
+	events/arm_cortex_a7_events.h		\
 	events/arm_cortex_a8_events.h		\
 	events/arm_cortex_a9_events.h		\
 	events/arm_cortex_a15_events.h		\
diff --git a/src/libpfm4/lib/events/arm_cortex_a7_events.h b/src/libpfm4/lib/events/arm_cortex_a7_events.h
new file mode 100644
index 0000000..f7197f9
--- /dev/null
+++ b/src/libpfm4/lib/events/arm_cortex_a7_events.h
@@ -0,0 +1,231 @@
+/*
+ * Copyright (c) 2014 by Vince Weaver <vincent.weaver@maine.edu>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Cortex A7 MPCore
+ * based on Table 11-5 from the "Cortex-A7 MPCore Technical Reference Manual"
+ */
+static const arm_entry_t arm_cortex_a7_pe[]={
+	{.name = "SW_INCR",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x00,
+	 .desc = "Incremented on writes to the Software Increment Register"
+	},
+	{.name = "L1I_CACHE_REFILL",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x01,
+	 .desc = "Level 1 instruction cache refill"
+	},
+	{.name = "L1I_TLB_REFILL",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x02,
+	 .desc = "Level 1 instruction TLB refill"
+	},
+	{.name = "L1D_CACHE_REFILL",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x03,
+	 .desc = "Level 1 data cache refill"
+	},
+	{.name = "L1D_CACHE_ACCESS",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x04,
+	 .desc = "Level 1 data cache access"
+	},
+	{.name = "L1D_TLB_REFILL",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x05,
+	 .desc = "Level 1 data TLB refill"
+	},
+	{.name = "DATA_READS",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x06,
+	 .desc = "Data reads architecturally executed"
+	},
+	{.name = "DATA_WRITES",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x07,
+	 .desc = "Data writes architecturally executed"
+	},
+	{.name = "INST_RETIRED",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x08,
+	 .desc = "Instruction architecturally executed"
+	},
+	{.name = "EXCEPTION_TAKEN",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x09,
+	 .desc = "Exception taken"
+	},
+	{.name = "EXCEPTION_RETURN",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x0a,
+	 .desc = "Instruction architecturally executed"
+	},
+	{.name = "CID_WRITE_RETIRED",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x0b,
+	 .desc = "Change to ContextID retired"
+	},
+	{.name = "SW_CHANGE_PC",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x0c,
+	 .desc = "Software change of PC"
+	},
+	{.name = "IMMEDIATE_BRANCHES",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x0d,
+	 .desc = "Immediate branch architecturally executed"
+	},
+	{.name = "PROCEDURE_RETURNS",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x0e,
+	 .desc = "Procedure returns architecturally executed"
+	},
+	{.name = "UNALIGNED_LOAD_STORE",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x0f,
+	 .desc = "Unaligned load-store"
+	},
+	{.name = "BRANCH_MISPRED",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x10,
+	 .desc = "Branches mispredicted/not predicted"
+	},
+	{.name = "CPU_CYCLES",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x11,
+	 .desc = "Cycles"
+	},
+	{.name = "BRANCH_PRED",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x12,
+	 .desc = "Predictable branch speculatively executed"
+	},
+	{.name = "DATA_MEM_ACCESS",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x13,
+	 .desc = "Data memory access"
+	},
+	{.name = "L1I_CACHE_ACCESS",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x14,
+	 .desc = "Level 1 instruction cache access"
+	},
+	{.name = "L1D_CACHE_EVICTION",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x15,
+	 .desc = "Level 1 data cache eviction"
+	},
+	{.name = "L2D_CACHE_ACCESS",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x16,
+	 .desc = "Level 2 data cache access"
+	},
+	{.name = "L2D_CACHE_REFILL",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x17,
+	 .desc = "Level 2 data cache refill"
+	},
+	{.name = "L2D_CACHE_WB",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x18,
+	 .desc = "Level 2 data cache WriteBack"
+	},
+	{.name = "BUS_ACCESS",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x19,
+	 .desc = "Bus accesses"
+	},
+	{.name = "BUS_CYCLES",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x1d,
+	 .desc = "Bus cycle"
+	},
+	{.name = "BUS_READ_ACCESS",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x60,
+	 .desc = "Bus read access"
+	},
+	{.name = "BUS_WRITE_ACCESS",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x61,
+	 .desc = "Bus write access"
+	},
+	{.name = "IRQ_EXCEPTION_TAKEN",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x86,
+	 .desc = "IRQ Exception Taken"
+	},
+	{.name = "FIQ_EXCEPTION_TAKEN",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0x87,
+	 .desc = "FIQ Exception Taken"
+	},
+	{.name = "EXTERNAL_MEMORY_REQUEST",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0xc0,
+	 .desc = "External memory request"
+	},
+	{.name = "NONCACHE_EXTERNAL_MEMORY_REQUEST",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0xc1,
+	 .desc = "Non-cacheable xternal memory request"
+	},
+	{.name = "PREFETCH_LINEFILL",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0xc2,
+	 .desc = "Linefill due to prefetch"
+	},
+	{.name = "PREFETCH_LINEFILL_DROPPED",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0xc3,
+	 .desc = "Prefetch linefill dropped"
+	},
+	{.name = "ENTERING_READ_ALLOC",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0xc4,
+	 .desc = "Entering read allocate mode"
+	},
+	{.name = "READ_ALLOC",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0xc5,
+	 .desc = "Read allocate mode"
+	},
+	/* 0xc6 is Reserved */
+	{.name = "ETM_EXT_OUT_0",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0xc7,
+	 .desc = "ETM Ext Out[0]"
+	},
+	{.name = "ETM_EXT_OUT_1",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0xc8,
+	 .desc = "ETM Ext Out[1]"
+	},
+	{.name = "DATA_WRITE_STALL",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0xc9,
+	 .desc = "Data write operation that stalls pipeline due to full store buffer"
+	},
+	{.name = "DATA_SNOOPED",
+	 .modmsk = ARMV7_A7_ATTRS,
+	 .code = 0xca,
+	 .desc = "Data snooped from other processor"
+	},
+};
diff --git a/src/libpfm4/lib/events/intel_hsw_events.h b/src/libpfm4/lib/events/intel_hsw_events.h
index 028f295..c51120c 100644
--- a/src/libpfm4/lib/events/intel_hsw_events.h
+++ b/src/libpfm4/lib/events/intel_hsw_events.h
@@ -310,6 +310,12 @@ static const intel_x86_umask_t hsw_cycle_activity[]={
      .ucntmsk= 0x4,
      .uflags = INTEL_X86_NCOMBO,
    },
+   { .uname  = "STALL_L1D_PENDING",
+     .udesc  = "Executions stalls due to pending L1D load cache misses",
+     .ucode  = 0x0c00 | (0xc << INTEL_X86_CMASK_BIT),
+     .ucntmsk= 0x4,
+     .uflags = INTEL_X86_NCOMBO,
+   },
    { .uname  = "STALLS_L2_PENDING",
      .udesc  = "Execution stalls due to L2 pending loads (must use with HT off only)",
      .ucode  = 0x0500 | (0x5 << INTEL_X86_CMASK_BIT),
diff --git a/src/libpfm4/lib/events/intel_ivbep_unc_cbo_events.h b/src/libpfm4/lib/events/intel_ivbep_unc_cbo_events.h
index 318521d..3827e03 100644
--- a/src/libpfm4/lib/events/intel_ivbep_unc_cbo_events.h
+++ b/src/libpfm4/lib/events/intel_ivbep_unc_cbo_events.h
@@ -187,7 +187,7 @@ static const intel_x86_umask_t ivbep_unc_c_llc_lookup[]={
      .ucode = 0x1100,
    },
    { .uname  = "NID",
-     .udesc  = "Match a given RTID destination NID",
+     .udesc  = "Match a given RTID destination NID (must provide nf=X modifier)",
      .umodmsk_req = _SNBEP_UNC_ATTR_NF1,
      .grpid  = 1,
      .ucode = 0x4100,
@@ -218,7 +218,7 @@ static const intel_x86_umask_t ivbep_unc_c_llc_victims[]={
      .grpid  = 0,
    },
    { .uname  = "NID",
-     .udesc  = "Victimized Lines matching the NID filter",
+     .udesc  = "Victimized Lines matching the NID filter (must provide nf=X modifier)",
      .ucode = 0x4000,
      .uflags = INTEL_X86_GRP_DFL_NONE,
      .umodmsk_req = _SNBEP_UNC_ATTR_NF1,
@@ -536,7 +536,7 @@ static const intel_x86_umask_t ivbep_unc_c_tor_inserts[]={
     .uflags = INTEL_X86_NCOMBO | INTEL_X86_EXCL_GRP_GT,
   },
   { .uname = "NID_ALL",
-    .udesc  = "Number of NID-matched transactions inserted into the TOR",
+    .udesc  = "Number of NID-matched transactions inserted into the TOR (must provide nf=X modifier)",
     .ucode  = 0x4800,
     .grpid  = 0,
     .umodmsk_req = _SNBEP_UNC_ATTR_NF1,
diff --git a/src/libpfm4/lib/events/intel_snbep_unc_cbo_events.h b/src/libpfm4/lib/events/intel_snbep_unc_cbo_events.h
index ae10b61..430a47c 100644
--- a/src/libpfm4/lib/events/intel_snbep_unc_cbo_events.h
+++ b/src/libpfm4/lib/events/intel_snbep_unc_cbo_events.h
@@ -162,6 +162,12 @@
    }
 
 static const intel_x86_umask_t snbep_unc_c_llc_lookup[]={
+   { .uname  = "ANY",
+     .udesc  = "Any request",
+     .grpid  = 0,
+     .uflags = INTEL_X86_NCOMBO,
+     .ucode = 0x1f00,
+   },
    { .uname  = "DATA_READ",
      .udesc  = "Data read requests",
      .grpid  = 0,
@@ -181,7 +187,7 @@ static const intel_x86_umask_t snbep_unc_c_llc_lookup[]={
      .ucode = 0x900,
    },
    { .uname  = "NID",
-     .udesc  = "Match a given RTID destination NID",
+     .udesc  = "Match a given RTID destination NID (must provide nf=X modifier)",
      .uflags = INTEL_X86_NCOMBO | INTEL_X86_GRP_DFL_NONE,
      .umodmsk_req = _SNBEP_UNC_ATTR_NF,
      .grpid  = 1,
@@ -208,7 +214,9 @@ static const intel_x86_umask_t snbep_unc_c_llc_victims[]={
      .ucode = 0x800,
    },
    { .uname  = "NID",
-     .udesc  = "Victimized Lines matching the NID filter",
+     .udesc  = "Victimized Lines matching the NID filter (must provide nf=X modifier)",
+     .uflags = INTEL_X86_NCOMBO,
+     .umodmsk_req = _SNBEP_UNC_ATTR_NF,
      .ucode = 0x4000,
    },
 };
@@ -438,7 +446,7 @@ static const intel_x86_umask_t snbep_unc_c_tor_inserts[]={
     .uflags = INTEL_X86_NCOMBO,
   },
   { .uname = "NID_ALL",
-    .udesc  = "Number of NID-matched transactions inserted into the TOR",
+    .udesc  = "Number of NID-matched transactions inserted into the TOR (must provide nf=X modifier)",
     .ucode  = 0x4800,
     .grpid  = 0,
     .umodmsk_req = _SNBEP_UNC_ATTR_NF,
@@ -633,9 +641,10 @@ static const intel_x86_entry_t intel_snbep_unc_c_pe[]={
   },
   { .name   = "UNC_C_LLC_VICTIMS",
     .desc   = "Lines victimized",
-    .modmsk = SNBEP_UNC_CBO_ATTRS,
+    .modmsk = SNBEP_UNC_CBO_NID_ATTRS,
     .cntmsk = 0x3,
     .code = 0x37,
+    .flags = INTEL_X86_NO_AUTOENCODE,
     .numasks = LIBPFM_ARRAY_SIZE(snbep_unc_c_llc_victims),
     .ngrp = 1,
     .umasks = snbep_unc_c_llc_victims,
diff --git a/src/libpfm4/lib/pfmlib_arm_armv7_pmuv1.c b/src/libpfm4/lib/pfmlib_arm_armv7_pmuv1.c
index 5fb14ca..c930781 100644
--- a/src/libpfm4/lib/pfmlib_arm_armv7_pmuv1.c
+++ b/src/libpfm4/lib/pfmlib_arm_armv7_pmuv1.c
@@ -33,12 +33,30 @@
 #include "pfmlib_priv.h"			/* library private */
 #include "pfmlib_arm_priv.h"
 
-#include "events/arm_cortex_a8_events.h"        /* event tables */
+#include "events/arm_cortex_a7_events.h"        /* event tables */
+#include "events/arm_cortex_a8_events.h"
 #include "events/arm_cortex_a9_events.h"
 #include "events/arm_cortex_a15_events.h"
 #include "events/arm_qcom_krait_events.h"
 
 static int
+pfm_arm_detect_cortex_a7(void *this)
+{
+
+	int ret;
+
+	ret = pfm_arm_detect(this);
+	if (ret != PFM_SUCCESS)
+		return PFM_ERR_NOTSUPP;
+
+	if ((pfm_arm_cfg.implementer == 0x41) && /* ARM */
+			(pfm_arm_cfg.part == 0xc07)) { /* Cortex-A7 */
+		return PFM_SUCCESS;
+	}
+	return PFM_ERR_NOTSUPP;
+}
+
+static int
 pfm_arm_detect_cortex_a8(void *this)
 {
 
@@ -112,6 +130,32 @@ pfm_arm_detect_krait(void *this)
 }
 
 
+/* Cortex A7 support */
+pfmlib_pmu_t arm_cortex_a7_support={
+	.desc			= "ARM Cortex A7",
+	.name			= "arm_ac7",
+	.pmu			= PFM_PMU_ARM_CORTEX_A7,
+	.pme_count		= LIBPFM_ARRAY_SIZE(arm_cortex_a7_pe),
+	.type			= PFM_PMU_TYPE_CORE,
+	.pe			= arm_cortex_a7_pe,
+
+	.pmu_detect		= pfm_arm_detect_cortex_a7,
+	.max_encoding		= 1,
+	.num_cntrs		= 4,
+	.supported_plm		= ARMV7_A7_PLM,
+
+	.get_event_encoding[PFM_OS_NONE] = pfm_arm_get_encoding,
+	 PFMLIB_ENCODE_PERF(pfm_arm_get_perf_encoding),
+	.get_event_first	= pfm_arm_get_event_first,
+	.get_event_next		= pfm_arm_get_event_next,
+	.event_is_valid		= pfm_arm_event_is_valid,
+	.validate_table		= pfm_arm_validate_table,
+	.get_event_info		= pfm_arm_get_event_info,
+	.get_event_attr_info	= pfm_arm_get_event_attr_info,
+	 PFMLIB_VALID_PERF_PATTRS(pfm_arm_perf_validate_pattrs),
+	.get_event_nattrs	= pfm_arm_get_event_nattrs,
+};
+
 /* Cortex A8 support */
 pfmlib_pmu_t arm_cortex_a8_support={
 	.desc			= "ARM Cortex A8",
diff --git a/src/libpfm4/lib/pfmlib_arm_priv.h b/src/libpfm4/lib/pfmlib_arm_priv.h
index 227508b..81a9df9 100644
--- a/src/libpfm4/lib/pfmlib_arm_priv.h
+++ b/src/libpfm4/lib/pfmlib_arm_priv.h
@@ -86,6 +86,9 @@ extern int pfm_arm_get_perf_encoding(void *this, pfmlib_event_desc_t *e);
 #define ARMV7_A15_ATTRS	(_ARM_ATTR_K|_ARM_ATTR_U|_ARM_ATTR_HV)
 #define ARMV7_A15_PLM	(PFM_PLM0|PFM_PLM3|PFM_PLMH)
 
+#define ARMV7_A7_ATTRS	(_ARM_ATTR_K|_ARM_ATTR_U|_ARM_ATTR_HV)
+#define ARMV7_A7_PLM	(PFM_PLM0|PFM_PLM3|PFM_PLMH)
+
 #define ARMV8_ATTRS	(_ARM_ATTR_K|_ARM_ATTR_U|_ARM_ATTR_HV)
 #define ARMV8_PLM	(PFM_PLM0|PFM_PLM3|PFM_PLMH)
 
diff --git a/src/libpfm4/lib/pfmlib_common.c b/src/libpfm4/lib/pfmlib_common.c
index ebe20da..a16e4f5 100644
--- a/src/libpfm4/lib/pfmlib_common.c
+++ b/src/libpfm4/lib/pfmlib_common.c
@@ -194,6 +194,7 @@ static pfmlib_pmu_t *pfmlib_pmus[]=
 #endif
 
 #ifdef CONFIG_PFMLIB_ARCH_ARM
+	&arm_cortex_a7_support,
 	&arm_cortex_a8_support,
 	&arm_cortex_a9_support,
 	&arm_cortex_a15_support,
diff --git a/src/libpfm4/lib/pfmlib_priv.h b/src/libpfm4/lib/pfmlib_priv.h
index 5678cc0..aa974e0 100644
--- a/src/libpfm4/lib/pfmlib_priv.h
+++ b/src/libpfm4/lib/pfmlib_priv.h
@@ -327,6 +327,7 @@ extern pfmlib_pmu_t perf_event_raw_support;
 extern pfmlib_pmu_t intel_wsm_sp_support;
 extern pfmlib_pmu_t intel_wsm_dp_support;
 extern pfmlib_pmu_t intel_wsm_unc_support;
+extern pfmlib_pmu_t arm_cortex_a7_support;
 extern pfmlib_pmu_t arm_cortex_a8_support;
 extern pfmlib_pmu_t arm_cortex_a9_support;
 extern pfmlib_pmu_t arm_cortex_a15_support;
diff --git a/src/libpfm4/tests/validate_arm.c b/src/libpfm4/tests/validate_arm.c
index 44eefd4..db0439f 100644
--- a/src/libpfm4/tests/validate_arm.c
+++ b/src/libpfm4/tests/validate_arm.c
@@ -45,6 +45,35 @@ typedef struct {
 
 static const test_event_t arm_test_events[]={
 	{ SRC_LINE,
+	  .name = "arm_ac7::CPU_CYCLES",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000011,
+	  .fstr = "arm_ac7::CPU_CYCLES:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac7::CPU_CYCLES:k",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x88000011,
+	  .fstr = "arm_ac7::CPU_CYCLES:k=1:u=0:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac7::CPU_CYCLES:k:u",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000011,
+	  .fstr = "arm_ac7::CPU_CYCLES:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_ac7::INST_RETIRED",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000008,
+	  .fstr = "arm_ac7::INST_RETIRED:k=1:u=1:hv=0",
+	},
+
+	{ SRC_LINE,
 	  .name = "arm_ac8::NEON_CYCLES",
 	  .ret  = PFM_SUCCESS,
 	  .count = 1,
diff --git a/src/libpfm4/tests/validate_x86.c b/src/libpfm4/tests/validate_x86.c
index 2edacd5..b5da6a6 100644
--- a/src/libpfm4/tests/validate_x86.c
+++ b/src/libpfm4/tests/validate_x86.c
@@ -1254,6 +1254,14 @@ static const test_event_t x86_test_events[]={
 	  .fstr = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:STATE_MESIF:e=0:i=0:t=0:tf=0",
 	},
 	{ SRC_LINE,
+	  .name = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:ANY",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x1f34,
+	  .codes[1] = 0x7c0000,
+	  .fstr = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:ANY:STATE_MESIF:e=0:i=0:t=0:tf=0",
+	},
+	{ SRC_LINE,
 	  .name = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:nf=1",
 	  .ret  = PFM_ERR_ATTR,
 	},
@@ -1262,6 +1270,10 @@ static const test_event_t x86_test_events[]={
 	  .ret  = PFM_ERR_ATTR,
 	},
 	{ SRC_LINE,
+	  .name = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:NID",
+	  .ret  = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
 	  .name = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:NID:STATE_M",
 	  .ret  = PFM_ERR_ATTR,
 	},
-- 
2.1.0

From e009d1cd38f25df9838fef332d05a9c14728f00f Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Wed, 23 Jul 2014 09:46:52 -0400
Subject: [PATCH 18/24] Update libpfm4

Brings us in line with
----------------------
commit 60cdc9bfae9e9c7d5294010fa135cccc9d014d10
Author: James Ralph <ralph@icl.utk.edu>
Date:   Wed Jul 23 09:52:26 2014 +0200

    add RAPL support for more Haswell models

    This patch adds RAPL support for Haswell models:
      - 60
      - 69
      - 71

    Signed-off-by: James Ralph <ralph@icl.utk.edu>
-----------------------

diff --git a/src/libpfm4/lib/events/intel_ivb_events.h b/src/libpfm4/lib/events/intel_ivb_events.h
index 4e1b600..dac8163 100644
--- a/src/libpfm4/lib/events/intel_ivb_events.h
+++ b/src/libpfm4/lib/events/intel_ivb_events.h
@@ -170,6 +170,12 @@ static const intel_x86_umask_t ivb_br_misp_exec[]={
      .ucode = 0x8800,
      .uflags= INTEL_X86_NCOMBO,
    },
+   { .uname  = "TAKEN_RETURN_NEAR",
+     .udesc  = "All taken mispredicted indirect branches that have a return mnemonic",
+     .ucode = 0x8800,
+     .uequiv ="TAKEN_NEAR_RETURN",
+     .uflags= INTEL_X86_NCOMBO,
+   },
    { .uname  = "TAKEN_DIRECT_NEAR_CALL",
      .udesc  = "All taken mispredicted non-indirect calls",
      .ucode = 0x9000,
diff --git a/src/libpfm4/lib/pfmlib_intel_rapl.c b/src/libpfm4/lib/pfmlib_intel_rapl.c
index 1215731..4eb67ef 100644
--- a/src/libpfm4/lib/pfmlib_intel_rapl.c
+++ b/src/libpfm4/lib/pfmlib_intel_rapl.c
@@ -83,7 +83,10 @@ pfm_rapl_detect(void *this)
 	switch(pfm_intel_x86_cfg.model) {
 		case 42: /* Sandy Bridge */
 		case 58: /* Ivy Bridge */
+		case 60: /* Haswell */
+		case 69: /* Haswell */
 		case 70: /* Haswell */
+		case 71: /* Haswell */
 			 /* already setup by default */
 			  break;
 		case 45: /* Sandy Bridg-EP  */
-- 
2.1.0

From 5d9ed8d5d9e9e28658dec1da8521a301eff7b086 Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Wed, 30 Jul 2014 12:41:30 -0400
Subject: [PATCH 19/24] Libpfm4 update: catch the cpu= modifier update

Inline with:
commit c9482351a6ce2cf39433527fdad41a78fed2b6f2
Author: Stephane Eranian <eranian@gmail.com>
Date:   Fri Apr 18 14:11:36 2014 +0200

    activate perf_event_ext cpu= modifier

    Enable cpu=X  perf_events modifier on events.
    The cpu number is returned in the pfm_perf_encode_arg.cpu
    field. If modifier not set in event string, then field has
    value -1.

    This is an indicative information of where the user
    wants the event to be programmed. This is useful
    only in system-wide mode. The library does not
    program the event with perf_events. The
    user program still has to invoke the perf_event_open()
    syscall.

diff --git a/src/libpfm4/include/perfmon/pfmlib_perf_event.h b/src/libpfm4/include/perfmon/pfmlib_perf_event.h
index d4620f2..8b3dae2 100644
--- a/src/libpfm4/include/perfmon/pfmlib_perf_event.h
+++ b/src/libpfm4/include/perfmon/pfmlib_perf_event.h
@@ -37,7 +37,7 @@ typedef struct {
 	char **fstr;			/* out/in: fully qualified event string */
 	size_t size;			/* sizeof struct */
 	int idx;			/* out: opaque event identifier */
-	int cpu;			/* out: cpu to program */
+	int cpu;			/* out: cpu to program, -1 = not set */
 	int flags;			/* out: perf_event_open() flags */
 	int pad0;			/* explicit 64-bit mode padding */
 } pfm_perf_encode_arg_t;
diff --git a/src/libpfm4/lib/pfmlib_perf_event.c b/src/libpfm4/lib/pfmlib_perf_event.c
index 4458d98..dbc5dd9 100644
--- a/src/libpfm4/lib/pfmlib_perf_event.c
+++ b/src/libpfm4/lib/pfmlib_perf_event.c
@@ -25,6 +25,7 @@
 #include <unistd.h>
 #include <string.h>
 #include <stdlib.h>
+#include <limits.h>
 #include <perfmon/pfmlib_perf_event.h>
 
 #include "pfmlib_priv.h"
@@ -67,6 +68,7 @@ static const pfmlib_attr_desc_t perf_event_ext_mods[]={
 	PFM_ATTR_B("excl", "exclusive access"),    	/* exclusive PMU access */
 	PFM_ATTR_B("mg", "monitor guest execution"),	/* monitor guest level */
 	PFM_ATTR_B("mh", "monitor host execution"),	/* monitor host level */
+	PFM_ATTR_I("cpu", "CPU to program"),		/* CPU to program */
 	PFM_ATTR_NULL /* end-marker to avoid exporting number of entries */
 };
 
@@ -84,6 +86,7 @@ pfmlib_perf_event_encode(void *this, const char *str, int dfl_plm, void *data)
 	uint64_t ival;
 	int has_plm = 0, has_vmx_plm = 0;
 	int i, plm = 0, ret, vmx_plm = 0;
+	int cpu = -1;
 
 	sz = pfmlib_check_struct(uarg, uarg->size, PFM_PERF_ENCODE_ABI0, sz);
 	if (!sz)
@@ -203,6 +206,11 @@ pfmlib_perf_event_encode(void *this, const char *str, int dfl_plm, void *data)
 			vmx_plm |= PFM_PLM0;
 			has_vmx_plm = 1;
 			break;
+		case PERF_ATTR_CPU:
+			if (ival >= INT_MAX)
+				return PFM_ERR_ATTR_VAL;
+			cpu = (int)ival;
+			break;
 		}
 	}
 	/*
@@ -251,6 +259,9 @@ pfmlib_perf_event_encode(void *this, const char *str, int dfl_plm, void *data)
 	 */
 	arg.idx = pfmlib_pidx2idx(e.pmu, e.event);
 
+	/* propagate cpu */
+	arg.cpu = cpu;
+
 	/* propagate our changes, that overwrites attr->size */
 	memcpy(uarg->attr, attr, asz);
 
diff --git a/src/libpfm4/lib/pfmlib_perf_event_priv.h b/src/libpfm4/lib/pfmlib_perf_event_priv.h
index 0063c77..ee2afc7 100644
--- a/src/libpfm4/lib/pfmlib_perf_event_priv.h
+++ b/src/libpfm4/lib/pfmlib_perf_event_priv.h
@@ -35,6 +35,7 @@
 #define PERF_ATTR_EX	6	/* exclusive event */
 #define PERF_ATTR_MG	7	/* monitor guest execution */
 #define PERF_ATTR_MH	8	/* monitor host execution */
+#define PERF_ATTR_CPU	9	/* CPU to program */
 
 #define _PERF_ATTR_U  (1 << PERF_ATTR_U)
 #define _PERF_ATTR_K  (1 << PERF_ATTR_K)
@@ -45,6 +46,7 @@
 #define _PERF_ATTR_EX (1 << PERF_ATTR_EX)
 #define _PERF_ATTR_MG (1 << PERF_ATTR_MG)
 #define _PERF_ATTR_MH (1 << PERF_ATTR_MH)
+#define _PERF_ATTR_CPU (1 << PERF_ATTR_CPU)
 
 #define PERF_PLM_ALL (PFM_PLM0|PFM_PLM3|PFM_PLMH)
 
diff --git a/src/libpfm4/perf_examples/perf_util.c b/src/libpfm4/perf_examples/perf_util.c
index a5635d5..2fb5d4a 100644
--- a/src/libpfm4/perf_examples/perf_util.c
+++ b/src/libpfm4/perf_examples/perf_util.c
@@ -97,6 +97,7 @@ perf_setup_argv_events(const char **argv, perf_event_desc_t **fds, int *num_fds)
 		fd[num].name = strdup(*argv);
 		fd[num].group_leader = group_leader;
 		fd[num].idx = arg.idx;
+		fd[num].cpu = arg.cpu;
 
 		num++;
 		argv++;
diff --git a/src/libpfm4/perf_examples/perf_util.h b/src/libpfm4/perf_examples/perf_util.h
index 04704bd..4571500 100644
--- a/src/libpfm4/perf_examples/perf_util.h
+++ b/src/libpfm4/perf_examples/perf_util.h
@@ -41,6 +41,7 @@ typedef struct {
 	int fd;
 	int max_fds;
 	int idx; /* opaque libpfm event identifier */
+	int cpu; /* cpu to program */
 	char *fstr; /* fstr from library, must be freed */
 } perf_event_desc_t;
 
-- 
2.1.0

From 9eb767c56286d2c289dc8eeac936383efbebc268 Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Wed, 27 Aug 2014 14:47:47 -0400
Subject: [PATCH 20/24] Libpfm update

Lines up with
commit b87efb1f04ec0ced87a7df5ebcb0ad9b6ee54407
Author: Stephane Eranian <eranian@gmail.com>
Date:   Tue Aug 19 18:34:24 2014 +0200

    syst_smpl: fix bug in read id code

    The return value of read() was chedked incorrectly.

    Signed-off-by: Stephane Eranian <eranian@gmail.com>

diff --git a/src/libpfm4/lib/pfmlib_common.c b/src/libpfm4/lib/pfmlib_common.c
index a16e4f5..f4bdb78 100644
--- a/src/libpfm4/lib/pfmlib_common.c
+++ b/src/libpfm4/lib/pfmlib_common.c
@@ -586,7 +586,7 @@ pfmlib_build_fstr(pfmlib_event_desc_t *e, char **fstr)
 	if (*fstr)
 		sprintf(*fstr, "%s::%s", e->pmu->name, e->fstr);
 
-	return fstr ? PFM_SUCCESS : PFM_ERR_NOMEM;
+	return *fstr ? PFM_SUCCESS : PFM_ERR_NOMEM;
 }
 
 static int
diff --git a/src/libpfm4/perf_examples/syst_smpl.c b/src/libpfm4/perf_examples/syst_smpl.c
index c54bfe6..0e0eb94 100755
--- a/src/libpfm4/perf_examples/syst_smpl.c
+++ b/src/libpfm4/perf_examples/syst_smpl.c
@@ -218,7 +218,7 @@ setup_cpu(int cpu, int fd)
 			err(1, "cannot allocated memory");
 
 		sret = read(fds[0].fd, val, sz);
-		if (sret == (ssize_t)sz)
+		if (sret != (ssize_t)sz)
 			err(1, "cannot read id %zu", sizeof(val));
 
 		for(i=0; i < num_fds; i++) {
-- 
2.1.0

From 8a2f6325331f0f791a658b095f3f2ec04ab4597c Mon Sep 17 00:00:00 2001
From: James Ralph <ralph@icl.utk.edu>
Date: Thu, 11 Sep 2014 14:35:40 -0400
Subject: [PATCH 21/24] Update libpfm4: catches HSW updates

Current with
------------
commit 70ecfb02bf0e8c94b6ee5694626ca269bfbed4d2
Author: Stephane Eranian <eranian@gmail.com>
Date:   Thu Sep 11 17:50:32 2014 +0200

    remove duplicated offcore_Response:LLC_MISS_LOCAL from Haswell
offcore

    The umask was present twice in the event table.

    Signed-off-by: Stephane Eranian <eranian@gmail.com>
------------

diff --git a/src/libpfm4/docs/man3/libpfm_intel_hsw.3 b/src/libpfm4/docs/man3/libpfm_intel_hsw.3
index fb36acf..f67db2b 100644
--- a/src/libpfm4/docs/man3/libpfm_intel_hsw.3
+++ b/src/libpfm4/docs/man3/libpfm_intel_hsw.3
@@ -7,9 +7,11 @@ libpfm_intel_hsw - support for Intel Haswell core PMU
 .sp
 .B PMU name: hsw
 .B PMU desc: Intel Haswell
+.B PMU name: hsw_ep
+.B PMU desc: Intel Haswell-EP
 .sp
 .SH DESCRIPTION
-The library supports the Intel Haswell core PMU. It should be noted that
+The library supports the Intel Haswell and Haswell-EP core PMU. It should be noted that
 this PMU model only covers each core's PMU and not the socket level
 PMU.
 
diff --git a/src/libpfm4/include/perfmon/pfmlib.h b/src/libpfm4/include/perfmon/pfmlib.h
index 0169511..43ec178 100644
--- a/src/libpfm4/include/perfmon/pfmlib.h
+++ b/src/libpfm4/include/perfmon/pfmlib.h
@@ -242,6 +242,8 @@ typedef enum {
 
 	PFM_PMU_ARM_CORTEX_A7,		/* ARM Cortex A7 */
 
+	PFM_PMU_INTEL_HSW_EP,		/* Intel Haswell EP */
+
 	/* MUST ADD NEW PMU MODELS HERE */
 
 	PFM_PMU_MAX			/* end marker */
diff --git a/src/libpfm4/lib/events/intel_hsw_events.h b/src/libpfm4/lib/events/intel_hsw_events.h
index c51120c..0087f01 100644
--- a/src/libpfm4/lib/events/intel_hsw_events.h
+++ b/src/libpfm4/lib/events/intel_hsw_events.h
@@ -322,6 +322,12 @@ static const intel_x86_umask_t hsw_cycle_activity[]={
      .ucntmsk= 0xf,
      .uflags = INTEL_X86_NCOMBO,
    },
+   { .uname  = "CYCLES_NO_EXECUTE",
+     .udesc  = "Cycles during which no instructions were executed in the execution stage of the pipeline",
+     .ucode  = 0x0400 | (0x4 << INTEL_X86_CMASK_BIT),
+     .ucntmsk= 0xf,
+     .uflags = INTEL_X86_NCOMBO,
+   },
 };
 
 static const intel_x86_umask_t hsw_dtlb_load_misses[]={
@@ -904,6 +910,11 @@ static const intel_x86_umask_t hsw_longest_lat_cache[]={
 };
 
 static const intel_x86_umask_t hsw_machine_clears[]={
+  { .uname = "CYCLES",
+    .udesc  = "Cycles there was a Nuke. Account for both thread-specific and All Thread Nukes",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
   { .uname = "MEMORY_ORDERING",
     .udesc  = "Number of Memory Ordering Machine Clears detected",
     .ucode  = 0x200,
@@ -950,6 +961,24 @@ static const intel_x86_umask_t hsw_mem_load_uops_l3_miss_retired[]={
     .ucode  = 0x100,
     .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_DFL,
   },
+   { .uname  = "REMOTE_DRAM",
+     .udesc  = "Number of retired load uops that missed L3 but were service by remote RAM, snoop not needed, snoop miss, snoop hit data not forwarded (Precise Event)",
+     .ucode = 0x400,
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "REMOTE_HITM",
+     .udesc  = "Number of retired load uops whose data sources was remote HITM (Precise Event)",
+     .ucode = 0x1000,
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
+   { .uname  = "REMOTE_FWD",
+     .udesc  = "Load uops that miss in the L3 whose data source was forwarded from a remote cache (Precise Event)",
+     .ucode = 0x2000,
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
 };
 
 static const intel_x86_umask_t hsw_mem_load_uops_retired[]={
@@ -1020,11 +1049,6 @@ static const intel_x86_umask_t hsw_mem_uops_retired[]={
     .ucode  = 0x2100,
     .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
   },
-  { .uname = "LOCK_STORES",
-    .udesc  = "Store uops with locked access retired",
-    .ucode  = 0x2200,
-    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
-  },
   { .uname = "SPLIT_LOADS",
     .udesc  = "Line-splitted load uops retired",
     .ucode  = 0x4100,
@@ -1494,34 +1518,151 @@ static const intel_x86_umask_t hsw_offcore_response[]={
    { .uname  = "LLC_HITM",
      .udesc  = "Supplier: counts L3 hits in M-state (initial lookup)",
      .ucode = 1ULL << (18+8),
+     .umodel = PFM_PMU_INTEL_HSW,
      .grpid = 1,
    },
    { .uname  = "LLC_HITE",
      .udesc  = "Supplier: counts L3 hits in E-state",
      .ucode = 1ULL << (19+8),
+     .umodel = PFM_PMU_INTEL_HSW,
      .grpid = 1,
    },
    { .uname  = "LLC_HITS",
      .udesc  = "Supplier: counts L3 hits in S-state",
      .ucode = 1ULL << (20+8),
+     .umodel = PFM_PMU_INTEL_HSW,
      .grpid = 1,
    },
    { .uname  = "LLC_HITF",
      .udesc  = "Supplier: counts L3 hits in F-state",
      .ucode = 1ULL << (21+8),
-     .grpid = 1,
-   },
-   { .uname  = "LLC_MISS_LOCAL",
-     .udesc  = "Supplier: counts L3 misses to local DRAM",
-     .ucode = 1ULL << (22+8),
+     .umodel = PFM_PMU_INTEL_HSW,
      .grpid = 1,
    },
    { .uname  = "LLC_HITMESF",
      .udesc  = "Supplier: counts L3 hits in any state (M, E, S, F)",
      .ucode  = 0xfULL << (18+8),
      .uequiv = "LLC_HITM:LLC_HITE:LLC_HITS:LLC_HITF",
+     .umodel = PFM_PMU_INTEL_HSW,
      .grpid  = 1,
    },
+   { .uname  = "LLC_HIT",
+     .udesc  = "Alias for LLC_HITMESF",
+     .ucode  = 0xfULL << (18+8),
+     .uequiv = "LLC_HITM:LLC_HITE:LLC_HITS:LLC_HITF",
+     .umodel = PFM_PMU_INTEL_HSW,
+     .grpid  = 1,
+   },
+   { .uname  = "L3_HITM",
+     .udesc  = "Supplier: counts L3 hits in M-state (initial lookup)",
+     .ucode = 1ULL << (18+8),
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .grpid = 1,
+   },
+   { .uname  = "L3_HITE",
+     .udesc  = "Supplier: counts L3 hits in E-state",
+     .ucode = 1ULL << (19+8),
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .grpid = 1,
+   },
+   { .uname  = "L3_HITS",
+     .udesc  = "Supplier: counts L3 hits in S-state",
+     .ucode = 1ULL << (20+8),
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .grpid = 1,
+   },
+   { .uname  = "L3_HITF",
+     .udesc  = "Supplier: counts L3 hits in F-state",
+     .ucode = 1ULL << (21+8),
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .grpid = 1,
+   },
+   { .uname  = "L3_HIT",
+     .udesc  = "Supplier: counts L3 hits in M, E, S, F state",
+     .ucode = 0xfULL << (18+8),
+     .uequiv = "L3_HITM:L3_HITE:L3_HITS:L3_HITF",
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .grpid = 1,
+   },
+   { .uname  = "L4_HIT_LOCAL_L4",
+     .udesc  = "Supplier: counts L4 hits to local L4 cache",
+     .ucode = 0x1ULL << (22+8),
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .grpid = 1,
+   },
+   { .uname  = "L4_HIT_REMOTE_HOP0_L4",
+     .udesc  = "Supplier: counts L4 hits to remote L4 cache with 0 hop",
+     .ucode = 0x1ULL << (23+8),
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .grpid = 1,
+   },
+   { .uname  = "L4_HIT_REMOTE_HOP1_L4",
+     .udesc  = "Supplier: counts L4 hits to remote L4 cache with 1 hop",
+     .ucode = 0x1ULL << (24+8),
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .grpid = 1,
+   },
+   { .uname  = "L4_HIT_REMOTE_HOP2P_L4",
+     .udesc  = "Supplier: counts L4 hits to remote L4 cache with 2P hops",
+     .ucode = 0x1ULL << (25+8),
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .grpid = 1,
+   },
+   { .uname  = "L4_HIT",
+     .udesc  = "Supplier: counts L4 hits",
+     .ucode = 0xfULL << (22+8),
+     .uequiv = "L4_HIT_LOCAL_L4:L4_HIT_REMOTE_HOP0_L4:L4_HIT_REMOTE_HOP1_L4:L4_HIT_REMOTE_HOP2P_L4",
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .grpid = 1,
+   },
+   { .uname  = "LLC_MISS_LOCAL",
+     .udesc  = "Supplier: counts L3 misses to local DRAM",
+     .ucode = 1ULL << (22+8),
+     .umodel = PFM_PMU_INTEL_HSW,
+     .grpid = 1,
+   },
+   { .uname  = "L3_MISS_LOCAL",
+     .udesc  = "Supplier: counts L3 misses to local DRAM",
+     .ucode = 1ULL << (26+8),
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .grpid = 1,
+   },
+   { .uname  = "L3_MISS_REMOTE_HOP0_DRAM",
+     .udesc  = "Supplier: counts L3 misses to remote DRAM with 0 hop",
+     .ucode = 0x1ULL << (27+8),
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .grpid = 1,
+   },
+   { .uname  = "L3_MISS_REMOTE_HOP1_DRAM",
+     .udesc  = "Supplier: counts L3 misses to remote DRAM with 1 hop",
+     .ucode = 0x1ULL << (28+8),
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .grpid = 1,
+   },
+   { .uname  = "L3_MISS_REMOTE_HOP2P_DRAM",
+     .udesc  = "Supplier: counts L3 misses to remote DRAM with 2P hops",
+     .ucode = 0x1ULL << (29+8),
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .grpid = 1,
+   },
+   { .uname  = "L3_MISS",
+     .udesc  = "Supplier: counts L3 misses to local or remote DRAM",
+     .ucode = 0xfULL << (26+8),
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .grpid = 1,
+   },
+   { .uname  = "L3_MISS_REMOTE_DRAM",
+     .udesc  = "Supplier: counts L3 misses to remote DRAM",
+     .ucode = 0x3ULL << (27+8),
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .grpid = 1,
+   },
+   { .uname  = "SPL_HIT",
+     .udesc  = "Supplier: counts L3 misses to remote DRAM",
+     .ucode = 0x1ULL << (30+8),
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .grpid = 1,
+   },
    { .uname  = "SNP_NONE",
      .udesc  = "Snoop: counts number of times no snoop-related information is available",
      .ucode = 1ULL << (31+8),
@@ -1804,6 +1945,36 @@ static const intel_x86_umask_t hsw_page_walker_loads[]={
      .ucode = 0x2400,
      .uflags= INTEL_X86_NCOMBO,
    },
+   { .uname  = "EPT_DTLB_L1",
+     .udesc  = "Number of extended page table walks from the DTLB that hit in the L1D and line fill buffer",
+     .ucode = 0x4100,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "EPT_ITLB_L1",
+     .udesc  = "Number of extended page table walks from the ITLB that hit in the L1D and line fill buffer",
+     .ucode = 0x8100,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "EPT_DTLB_L2",
+     .udesc  = "Number of extended page table walks from the DTLB that hit in the L2",
+     .ucode = 0x4200,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "EPT_ITLB_L2",
+     .udesc  = "Number of extended page table walks from the ITLB that hit in the L2",
+     .ucode = 0x8200,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "EPT_DTLB_L3",
+     .udesc  = "Number of extended page table walks from the DTLB that hit in the L3",
+     .ucode = 0x4400,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "EPT_ITLB_L3",
+     .udesc  = "Number of extended page table walks from the ITLB that hit in the L3",
+     .ucode = 0x8400,
+     .uflags= INTEL_X86_NCOMBO,
+   },
    { .uname  = "DTLB_MEMORY",
      .udesc  = "Number of DTLB page walker loads that hit memory",
      .ucode = 0x1800,
@@ -1814,6 +1985,16 @@ static const intel_x86_umask_t hsw_page_walker_loads[]={
      .ucode = 0x2800,
      .uflags= INTEL_X86_NCOMBO,
    },
+   { .uname  = "EPT_DTLB_MEMORY",
+     .udesc  = "Number of extended page table walks from the DTLB that hit memory",
+     .ucode = 0x4800,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "EPT_ITLB_MEMORY",
+     .udesc  = "Number of extended page table walks from the ITLB that hit memory",
+     .ucode = 0x8800,
+     .uflags= INTEL_X86_NCOMBO,
+   },
 };
 
 static const intel_x86_umask_t hsw_lsd[]={
@@ -1832,6 +2013,14 @@ static const intel_x86_umask_t hsw_dsb2mite_switches[]={
    },
 };
 
+static const intel_x86_umask_t hsw_ept[]={
+   { .uname  = "CYCLES",
+     .udesc  = "Cycles for an extended page table walk",
+     .ucode = 0x0200,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+   },
+};
+
 static const intel_x86_entry_t intel_hsw_pe[]={
   { .name   = "UNHALTED_CORE_CYCLES",
     .desc   = "Count core clock cycles whenever the clock signal on the specific core is running (not halted)",
@@ -2412,21 +2601,30 @@ static const intel_x86_entry_t intel_hsw_pe[]={
   { .name   = "PAGE_WALKER_LOADS",
     .desc   = "Page walker loads",
     .modmsk = INTEL_V4_ATTRS,
-    .cntmsk = 0xff,
+    .cntmsk = 0xf,
     .code = 0xbc,
     .numasks = LIBPFM_ARRAY_SIZE(hsw_page_walker_loads),
     .ngrp = 1,
     .umasks = hsw_page_walker_loads,
   },
-{ .name   = "DSB2MITE_SWITCHES",
-  .desc   = "Number of DSB to MITE switches",
-  .modmsk = INTEL_V4_ATTRS,
-  .cntmsk = 0xff,
-  .code = 0xab,
-  .numasks = LIBPFM_ARRAY_SIZE(hsw_dsb2mite_switches),
-  .ngrp = 1,
-  .umasks = hsw_dsb2mite_switches,
-},
+  { .name   = "DSB2MITE_SWITCHES",
+    .desc   = "Number of DSB to MITE switches",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0xff,
+    .code = 0xab,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_dsb2mite_switches),
+    .ngrp = 1,
+    .umasks = hsw_dsb2mite_switches,
+  },
+  { .name   = "EPT",
+    .desc   = "Extended page table",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0xff,
+    .code = 0x4f,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_ept),
+    .ngrp = 1,
+    .umasks = hsw_ept,
+  },
   { .name   = "OFFCORE_RESPONSE_0",
     .desc   = "Offcore response event (must provide at least one request type and either any_response or any combination of supplier + snoop)",
     .modmsk = INTEL_V4_ATTRS,
diff --git a/src/libpfm4/lib/pfmlib_amd64.c b/src/libpfm4/lib/pfmlib_amd64.c
index 31e2181..98f55b8 100644
--- a/src/libpfm4/lib/pfmlib_amd64.c
+++ b/src/libpfm4/lib/pfmlib_amd64.c
@@ -112,10 +112,14 @@ amd64_get_revision(pfm_amd64_config_t *cfg)
         if (cfg->family == 15) {
                 switch (cfg->model >> 4) {
                 case 0:
-                        if (cfg->model == 5 && cfg->stepping < 2)
+                        if (cfg->model == 5 && cfg->stepping < 2) {
                                 rev = PFM_PMU_AMD64_K8_REVB;
-                        if (cfg->model == 4 && cfg->stepping == 0)
+				break;
+                        }
+                        if (cfg->model == 4 && cfg->stepping == 0) {
                                 rev = PFM_PMU_AMD64_K8_REVB;
+				break;
+                        }
                         rev = PFM_PMU_AMD64_K8_REVC;
 			break;
                 case 1:
diff --git a/src/libpfm4/lib/pfmlib_common.c b/src/libpfm4/lib/pfmlib_common.c
index f4bdb78..81903ff 100644
--- a/src/libpfm4/lib/pfmlib_common.c
+++ b/src/libpfm4/lib/pfmlib_common.c
@@ -98,6 +98,7 @@ static pfmlib_pmu_t *pfmlib_pmus[]=
 	&intel_ivb_unc_cbo3_support,
 	&intel_ivb_ep_support,
 	&intel_hsw_support,
+	&intel_hsw_ep_support,
 	&intel_rapl_support,
 	&intel_snbep_unc_cb0_support,
 	&intel_snbep_unc_cb1_support,
@@ -945,7 +946,7 @@ found_attr:
 		if (type != PFM_ATTR_UMASK && type != PFM_ATTR_RAW_UMASK && !has_val) {
 			if (type != PFM_ATTR_MOD_BOOL)
 				return PFM_ERR_ATTR_VAL;
-			has_val = 1; s = yes; /* no const */
+			s = yes; /* no const */
 			goto handle_bool;
 		}
 
diff --git a/src/libpfm4/lib/pfmlib_intel_hsw.c b/src/libpfm4/lib/pfmlib_intel_hsw.c
index f4975f6..1feae63 100644
--- a/src/libpfm4/lib/pfmlib_intel_hsw.c
+++ b/src/libpfm4/lib/pfmlib_intel_hsw.c
@@ -40,7 +40,6 @@ pfm_hsw_detect(void *this)
 
 	switch (pfm_intel_x86_cfg.model) {
 		case 60: /* Haswell */
-		case 63: /* Haswell */
 		case 69: /* Haswell */
 		case 70: /* Haswell */
 		case 71: /* Haswell */
@@ -52,6 +51,27 @@ pfm_hsw_detect(void *this)
 }
 
 static int
+pfm_hsw_ep_detect(void *this)
+{
+	int ret;
+
+	ret = pfm_intel_x86_detect();
+	if (ret != PFM_SUCCESS)
+		return ret;
+
+	if (pfm_intel_x86_cfg.family != 6)
+		return PFM_ERR_NOTSUPP;
+
+	switch (pfm_intel_x86_cfg.model) {
+		case 63: /* Haswell EP */
+			break;
+		default:
+			return PFM_ERR_NOTSUPP;
+	}
+	return PFM_SUCCESS;
+}
+
+static int
 pfm_hsw_init(void *this)
 {
 	pfm_intel_x86_cfg.arch_version = 4;
@@ -86,3 +106,32 @@ pfmlib_pmu_t intel_hsw_support={
 	.get_event_nattrs	= pfm_intel_x86_get_event_nattrs,
 	.can_auto_encode	= pfm_intel_x86_can_auto_encode,
 };
+
+pfmlib_pmu_t intel_hsw_ep_support={
+	.desc			= "Intel Haswell EP",
+	.name			= "hsw_ep",
+	.pmu			= PFM_PMU_INTEL_HSW_EP,
+	.pme_count		= LIBPFM_ARRAY_SIZE(intel_hsw_pe),
+	.type			= PFM_PMU_TYPE_CORE,
+	.supported_plm		= INTEL_X86_PLM,
+	.num_cntrs		= 8, /* consider with HT off by default */
+	.num_fixed_cntrs	= 3,
+	.max_encoding		= 2, /* offcore_response */
+	.pe			= intel_hsw_pe,
+	.atdesc			= intel_x86_mods,
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK
+				| INTEL_X86_PMU_FL_ECMASK,
+	.pmu_detect		= pfm_hsw_ep_detect,
+	.pmu_init		= pfm_hsw_init,
+	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding,
+	 PFMLIB_ENCODE_PERF(pfm_intel_x86_get_perf_encoding),
+	.get_event_first	= pfm_intel_x86_get_event_first,
+	.get_event_next		= pfm_intel_x86_get_event_next,
+	.event_is_valid		= pfm_intel_x86_event_is_valid,
+	.validate_table		= pfm_intel_x86_validate_table,
+	.get_event_info		= pfm_intel_x86_get_event_info,
+	.get_event_attr_info	= pfm_intel_x86_get_event_attr_info,
+	 PFMLIB_VALID_PERF_PATTRS(pfm_intel_x86_perf_validate_pattrs),
+	.get_event_nattrs	= pfm_intel_x86_get_event_nattrs,
+	.can_auto_encode	= pfm_intel_x86_can_auto_encode,
+};
diff --git a/src/libpfm4/lib/pfmlib_priv.h b/src/libpfm4/lib/pfmlib_priv.h
index aa974e0..129a815 100644
--- a/src/libpfm4/lib/pfmlib_priv.h
+++ b/src/libpfm4/lib/pfmlib_priv.h
@@ -246,6 +246,7 @@ extern pfmlib_pmu_t intel_ivb_unc_cbo2_support;
 extern pfmlib_pmu_t intel_ivb_unc_cbo3_support;
 extern pfmlib_pmu_t intel_ivb_ep_support;
 extern pfmlib_pmu_t intel_hsw_support;
+extern pfmlib_pmu_t intel_hsw_ep_support;
 extern pfmlib_pmu_t intel_rapl_support;
 extern pfmlib_pmu_t intel_snbep_unc_cb0_support;
 extern pfmlib_pmu_t intel_snbep_unc_cb1_support;
diff --git a/src/libpfm4/tests/validate_x86.c b/src/libpfm4/tests/validate_x86.c
index b5da6a6..743cc14 100644
--- a/src/libpfm4/tests/validate_x86.c
+++ b/src/libpfm4/tests/validate_x86.c
@@ -2702,8 +2702,110 @@ static const test_event_t x86_test_events[]={
 	  .codes[0] = 0x25,
 	  .fstr = "ivbep_unc_r3qpi1::UNC_R3_TXR_CYCLES_FULL:e=0:t=0",
 	},
+	{ SRC_LINE,
+	  .name = "hsw_ep::mem_trans_retired:latency_above_threshold:ldlat=3:u",
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5101cd,
+	  .codes[1] = 3,
+	  .fstr = "hsw_ep::MEM_TRANS_RETIRED:LOAD_LATENCY:k=0:u=1:e=0:i=0:c=0:t=0:ldlat=3:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "hsw_ep::mem_trans_retired:latency_above_threshold:ldlat=1000000",
+	  .ret = PFM_ERR_ATTR_VAL,
+	},
+	{ SRC_LINE,
+	  .name = "hsw_ep::mem_trans_retired:load_latency",
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5301cd,
+	  .codes[1] = 3,
+	  .fstr = "hsw_ep::MEM_TRANS_RETIRED:LOAD_LATENCY:k=1:u=1:e=0:i=0:c=0:t=0:ldlat=3:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "hsw_ep::mem_trans_retired:load_latency:ldlat=1000000",
+	  .ret = PFM_ERR_ATTR_VAL,
+	},
+	{ SRC_LINE,
+	  .name = "hsw_ep::mem_trans_retired:latency_above_threshold:ldlat=2:intx=0:intxcp=0",
+	  .ret = PFM_ERR_ATTR_VAL,
+	},
+	{ SRC_LINE,
+	  .name = "hsw_ep::inst_Retired:any_p:intx",
+	  .count = 1,
+	  .codes[0] = 0x1005300c0,
+	  .fstr = "hsw_ep::INST_RETIRED:ANY_P:k=1:u=1:e=0:i=0:c=0:t=0:intx=1:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "hsw_ep::inst_Retired:any_p:intx:intxcp",
+	  .count = 1,
+	  .codes[0] = 0x3005300c0,
+	  .fstr = "hsw_ep::INST_RETIRED:ANY_P:k=1:u=1:e=0:i=0:c=0:t=0:intx=1:intxcp=1",
+	},
+	{ SRC_LINE,
+	  .name = "hsw_ep::inst_Retired:any_p:intx=0:intxcp",
+	  .count = 1,
+	  .codes[0] = 0x2005300c0,
+	  .fstr = "hsw_ep::INST_RETIRED:ANY_P:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=1",
+	},
+	{ SRC_LINE,
+	  .name = "hsw_ep::cycle_activity:cycles_l2_pending",
+	  .ret = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x15301a3,
+	  .fstr = "hsw_ep::CYCLE_ACTIVITY:CYCLES_L2_PENDING:k=1:u=1:e=0:i=0:t=0:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "hsw_ep::cycle_activity:cycles_l2_pending:c=8",
+	  .ret = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "hsw_ep::hle_retired:aborted",
+	  .ret = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x5304c8,
+	  .fstr = "hsw_ep::HLE_RETIRED:ABORTED:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "hsw_ep::mem_load_uops_l3_miss_retired:remote_dram",
+	  .ret = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x5304d3,
+	  .fstr = "hsw_ep::MEM_LOAD_UOPS_L3_MISS_RETIRED:REMOTE_DRAM:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "hsw_ep::offcore_response_0:any_data:L3_miss_local",
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5301b7,
+	  .codes[1] = 0x3f84000091ull,
+	  .fstr = "hsw_ep::OFFCORE_RESPONSE_0:DMND_DATA_RD:PF_DATA_RD:PF_LLC_DATA_RD:L3_MISS_LOCAL:SNP_ANY:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "hsw_ep::offcore_response_0:any_data:LLC_miss_local",
+	  .ret = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "hsw_ep::offcore_response_0:any_data:LLC_miss_remote",
+	  .ret = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "hsw_ep::offcore_response_0:any_data:L3_HIT",
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] =0x5301b7,
+	  .codes[1] =0x3f803c0091ull,
+	  .fstr = "hsw_ep::OFFCORE_RESPONSE_0:DMND_DATA_RD:PF_DATA_RD:PF_LLC_DATA_RD:L3_HITM:L3_HITE:L3_HITS:L3_HITF:SNP_ANY:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "hsw_ep::offcore_response_0:any_data:L4_HIT",
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5301b7,
+	  .codes[1] =0x3f83c00091ull,
+	  .fstr = "hsw_ep::OFFCORE_RESPONSE_0:DMND_DATA_RD:PF_DATA_RD:PF_LLC_DATA_RD:L4_HIT_LOCAL_L4:L4_HIT_REMOTE_HOP0_L4:L4_HIT_REMOTE_HOP1_L4:L4_HIT_REMOTE_HOP2P_L4:SNP_ANY:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
+	},
 };
-
 #define NUM_TEST_EVENTS (int)(sizeof(x86_test_events)/sizeof(test_event_t))
 
 static int
-- 
2.1.0

From e96e89685f7802e046c12b0165370c9920d42eff Mon Sep 17 00:00:00 2001
From: Heike McCraw <mccraw@icl.utk.edu>
Date: Tue, 14 Oct 2014 12:20:04 -0400
Subject: [PATCH 22/24] Update libpfm4

Current with
------------

commit 1ca13380f772dcae481962eedc7a073dde61ca05
Author: William Cohen <wcohen@redhat.com>
Date:   Tue Oct 7 11:49:38 2014 -0400

    Add support for Applied Micro X-Gene processor

	The pmu events for the Applied Micro X-Gene processor are listed on:

	https://github.com/AppliedMicro/ENGLinuxLatest/blob/apm_linux_v3.17-rc4/Documentation/arm64/xgene_pmu.txt

    This patch adds event mappings for the Applied Micro X-Gene processor and identifies the Applied Micro X-Gene processors.

diff --git a/src/libpfm4/README b/src/libpfm4/README
index e74238f..59b705c 100644
--- a/src/libpfm4/README
+++ b/src/libpfm4/README
@@ -48,6 +48,7 @@ The library supports many PMUs. The current version can handle:
 		Intel Sandy Bridge
 		Intel Ivy Bridge
 		Intel Haswell
+		Intel Broadwell
 		Intel Silvermont
 		Intel RAPL (energy consumption)
 		Intel Knights Corner
@@ -58,6 +59,7 @@ The library supports many PMUs. The current version can handle:
 		ARMV7 Cortex A9
 		ARMV7 Cortex A15
 		ARMV8 Cortex A57, A53
+		Applied Micro X-Gene
 		Qualcomm Krait
 
 	- For SPARC
diff --git a/src/libpfm4/docs/Makefile b/src/libpfm4/docs/Makefile
index c7d797e..aa4125e 100644
--- a/src/libpfm4/docs/Makefile
+++ b/src/libpfm4/docs/Makefile
@@ -48,6 +48,7 @@ ARCH_MAN=libpfm_intel_core.3	\
 	 libpfm_intel_ivb.3	\
 	 libpfm_intel_ivb_unc.3 \
 	 libpfm_intel_hsw.3	\
+	 libpfm_intel_bdw.3	\
 	 libpfm_intel_rapl.3	\
 	 libpfm_intel_slm.3	\
 	 libpfm_intel_snbep_unc_cbo.3 \
@@ -76,7 +77,8 @@ endif
 endif
 
 ifeq ($(CONFIG_PFMLIB_ARCH_ARM),y)
-ARCH_MAN += libpfm_arm_ac57.3 \
+ARCH_MAN += libpfm_arm_xgene.3 \
+	    libpfm_arm_ac57.3 \
 	    libpfm_arm_ac53.3 \
 	    libpfm_arm_ac15.3 \
 	    libpfm_arm_ac8.3 \
@@ -85,7 +87,8 @@ ARCH_MAN += libpfm_arm_ac57.3 \
 endif
 
 ifeq ($(CONFIG_PFMLIB_ARCH_ARM64),y)
-ARCH_MAN += libpfm_arm_ac57.3 \
+ARCH_MAN += libpfm_arm_xgene.3 \
+	    libpfm_arm_ac57.3 \
 	    libpfm_arm_ac53.3
 endif
 
diff --git a/src/libpfm4/docs/man3/libpfm_arm_xgene.3 b/src/libpfm4/docs/man3/libpfm_arm_xgene.3
new file mode 100644
index 0000000..a0a84bc
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_arm_xgene.3
@@ -0,0 +1,39 @@
+.TH LIBPFM 4  "May, 2014" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_arm_ac57 - support for Applied Micro X-Gene PMU
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: arm_xgene
+.B PMU desc: Applied Micro X-Gene
+.sp
+.SH DESCRIPTION
+The library supports the Applied Micro X-Gene PMU.
+
+This PMU supports 6 counters and privilege levels filtering.
+It can operate in both 32 and 64 bit modes.
+
+.SH MODIFIERS
+The following modifiers are supported on Applied Micro X-Gene:
+.TP
+.B u
+Measure at the user level. This corresponds to \fBPFM_PLM3\fR.
+This is a boolean modifier.
+.TP
+.B k
+Measure at the kernel level. This corresponds to \fBPFM_PLM0\fR.
+This is a boolean modifier.
+.TP
+.B hv
+Measure at the hypervisor level. This corresponds to \fBPFM_PLMH\fR.
+This is a boolean modifier.
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.nf
+William Cohen <wcohen@redhat.com>
+.if
+.PP
diff --git a/src/libpfm4/docs/man3/libpfm_intel_bdw.3 b/src/libpfm4/docs/man3/libpfm_intel_bdw.3
new file mode 100644
index 0000000..85d4c71
--- /dev/null
+++ b/src/libpfm4/docs/man3/libpfm_intel_bdw.3
@@ -0,0 +1,105 @@
+.TH LIBPFM 3  "October, 2014" "" "Linux Programmer's Manual"
+.SH NAME
+libpfm_intel_bdw - support for Intel Broadwell core PMU
+.SH SYNOPSIS
+.nf
+.B #include <perfmon/pfmlib.h>
+.sp
+.B PMU name: bdw
+.B PMU desc: Intel Broadwell
+.sp
+.SH DESCRIPTION
+The library supports the Intel Broadwell core PMU. It should be noted that
+this PMU model only covers each core's PMU and not the socket level
+PMU.
+
+On Broadwell, the number of generic counters depends on the Hyperthreading (HT) mode.
+When HT is on, then only 4 generic counters are available. When HT is off, then 8 generic
+counters are available. The \fBpfm_get_pmu_info()\fR function returns the maximum number
+of generic counters in \fBnum_cntrs\fr.
+
+.SH MODIFIERS
+The following modifiers are supported on Intel Broadwell processors:
+.TP
+.B u
+Measure at user level which includes privilege levels 1, 2, 3. This corresponds to \fBPFM_PLM3\fR.
+This is a boolean modifier.
+.TP
+.B k
+Measure at kernel level which includes privilege level 0. This corresponds to \fBPFM_PLM0\fR.
+This is a boolean modifier.
+.TP
+.B i
+Invert the meaning of the event. The counter will now count cycles in which the event is \fBnot\fR
+occurring. This is a boolean modifier
+.TP
+.B e
+Enable edge detection, i.e., count only when there is a state transition from no occurrence of the event
+to at least one occurrence. This modifier must be combined with a counter mask modifier (m) with a value greater or equal to one.
+This is a boolean modifier.
+.TP
+.B c
+Set the counter mask value. The mask acts as a threshold. The counter will count the number of cycles
+in which the number of occurrences of the event is greater or equal to the threshold. This is an integer
+modifier with values in the range [0:255].
+.TP
+.B t
+Measure on both threads at the same time assuming hyper-threading is enabled. This is a boolean modifier.
+.TP
+.B ldlat
+Pass a latency threshold to the MEM_TRANS_RETIRED:LOAD_LATENCY event.
+This is an integer attribute that must be in the range [3:65535]. It is required
+for this event.  Note that the event must be used with precise sampling (PEBS).
+.TP
+.B intx
+Monitor the event only when executing inside a transactional memory region (in tx). Event
+does not count otherwise. This is a boolean modifiers. Default value is 0.
+.TP
+.B intxcp
+Do not count occurrences of the event when they are inside an aborted transactional memory
+region. This is a boolean modifier. Default value is 0.
+
+.SH OFFCORE_RESPONSE events
+Intel Broadwell provides two offcore_response events. They are called OFFCORE_RESPONSE_0 and OFFCORE_RESPONSE_1.
+
+Those events need special treatment in the performance monitoring infrastructure
+because each event uses an extra register to store some settings. Thus, in
+case multiple offcore_response events are monitored simultaneously, the kernel needs
+to manage the sharing of that extra register.
+
+The offcore_response events are exposed as a normal events by the library. The extra
+settings are exposed as regular umasks. The library takes care of encoding the
+events according to the underlying kernel interface.
+
+On Intel Broadwell, the umasks are divided into three categories: request, supplier
+and snoop. The user must provide at least one umask for each category. The categories
+are shown in the umask descriptions.
+
+There is also the special response umask called \fBANY_RESPONSE\fR. When this umask
+is used then it overrides any supplier and snoop umasks. In other words, users can
+specify either \fBANY_RESPONSE\fR \fBOR\fR any combinations of supplier + snoops.
+
+In case no supplier or snoop is specified, the library defaults to using
+\fBANY_RESPONSE\fR.
+
+For instance, the following are valid event selections:
+.TP
+.B OFFCORE_RESPONSE_0:DMND_DATA_RD:ANY_RESPONSE
+.TP
+.B OFFCORE_RESPONSE_0:ANY_REQUEST
+.TP
+.B OFFCORE_RESPONSE_0:ANY_RFO:LLC_HITM:SNOOP_ANY
+
+.P
+But the following are illegal:
+
+.TP
+.B OFFCORE_RESPONSE_0:ANY_RFO:LLC_HITM:ANY_RESPONSE
+.TP
+.B OFFCORE_RESPONSE_0:ANY_RFO:LLC_HITM:SNOOP_ANY:ANY_RESPONSE
+
+.SH AUTHORS
+.nf
+Stephane Eranian <eranian@gmail.com>
+.if
+.PP
diff --git a/src/libpfm4/include/perfmon/pfmlib.h b/src/libpfm4/include/perfmon/pfmlib.h
index 43ec178..34d2524 100644
--- a/src/libpfm4/include/perfmon/pfmlib.h
+++ b/src/libpfm4/include/perfmon/pfmlib.h
@@ -243,6 +243,9 @@ typedef enum {
 	PFM_PMU_ARM_CORTEX_A7,		/* ARM Cortex A7 */
 
 	PFM_PMU_INTEL_HSW_EP,		/* Intel Haswell EP */
+	PFM_PMU_INTEL_BDW,		/* Intel Broadwell EP */
+
+	PFM_PMU_ARM_XGENE,		/* Applied Micro X-Gene (ARMv8) */
 
 	/* MUST ADD NEW PMU MODELS HERE */
 
diff --git a/src/libpfm4/lib/Makefile b/src/libpfm4/lib/Makefile
index 14a6d0d..db127a4 100644
--- a/src/libpfm4/lib/Makefile
+++ b/src/libpfm4/lib/Makefile
@@ -60,6 +60,7 @@ SRCS   += pfmlib_amd64.c pfmlib_intel_core.c pfmlib_intel_x86.c \
 	  pfmlib_intel_snb.c pfmlib_intel_snb_unc.c \
 	  pfmlib_intel_ivb.c pfmlib_intel_ivb_unc.c \
 	  pfmlib_intel_hsw.c \
+	  pfmlib_intel_bdw.c \
 	  pfmlib_intel_rapl.c \
 	  pfmlib_intel_snbep_unc.c \
 	  pfmlib_intel_snbep_unc_cbo.c \
@@ -229,6 +230,7 @@ INC_X86= pfmlib_intel_x86_priv.h	\
 	events/intel_snb_unc_events.h	\
 	events/intel_ivb_events.h	\
 	events/intel_hsw_events.h	\
+	events/intel_bdw_events.h	\
 	pfmlib_intel_snbep_unc_priv.h	\
 	events/intel_snbep_unc_cbo_events.h \
 	events/intel_snbep_unc_ha_events.h \
@@ -276,7 +278,8 @@ INC_SPARC=events/sparc_ultra12_events.h		\
 INC_CELL=events/cell_events.h
 
 INC_ARM=events/arm_cortex_a8_events.h		\
-        events/arm_cortex_a9_events.h
+        events/arm_cortex_a9_events.h		\
+        events/arm_arm_xgene_events.h
 
 INC_ARM=pfmlib_arm_priv.h			\
 	events/arm_cortex_a7_events.h		\
diff --git a/src/libpfm4/lib/events/arm_xgene_events.h b/src/libpfm4/lib/events/arm_xgene_events.h
new file mode 100644
index 0000000..9486a11
--- /dev/null
+++ b/src/libpfm4/lib/events/arm_xgene_events.h
@@ -0,0 +1,528 @@
+/*
+ * Copyright (c) 2014 Red Hat Inc. All rights reserved
+ * Contributed by William Cohen <wcohen@redhat.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Applied Micro X-Gene
+ * based on https://github.com/AppliedMicro/ENGLinuxLatest/blob/apm_linux_v3.17-rc4/Documentation/arm64/xgene_pmu.txt
+ */
+
+static const arm_entry_t arm_xgene_pe[]={
+	{.name = "SW_INCR",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x00,
+	 .desc = "Instruction architecturally executed (condition check pass) software increment"
+	},
+	{.name = "L1I_CACHE_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x01,
+	 .desc = "Level 1 instruction cache refill"
+	},
+	{.name = "L1I_TLB_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x02,
+	 .desc = "Level 1 instruction TLB refill"
+	},
+	{.name = "L1D_CACHE_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x03,
+	 .desc = "Level 1 data cache refill"
+	},
+	{.name = "L1D_CACHE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x04,
+	 .desc = "Level 1 data cache access"
+	},
+	{.name = "L1D_TLB_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x05,
+	 .desc = "Level 1 data TLB refill"
+	},
+	{.name = "INST_RETIRED",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x08,
+	 .desc = "Instruction architecturally executed"
+	},
+	{.name = "EXCEPTION_TAKEN",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x09,
+	 .desc = "Exception taken"
+	},
+	{.name = "EXCEPTION_RETURN",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x0a,
+	 .desc = "Instruction architecturally executed (condition check pass) - Exception return"
+	},
+	{.name = "CID_WRITE_RETIRED",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x0b,
+	 .desc = "Instruction architecturally executed (condition check pass) - Write to CONTEXTIDR",
+	},
+	{.name = "BRANCH_MISPRED",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x10,
+	 .desc = "Mispredicted or not predicted branch speculatively executed"
+	},
+	{.name = "CPU_CYCLES",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x11,
+	 .desc = "Cycles"
+	},
+	{.name = "BRANCH_PRED",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x12,
+	 .desc = "Predictable branch speculatively executed"
+	},
+	{.name = "DATA_MEM_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x13,
+	 .desc = "Data memory access"
+	},
+	{.name = "L1I_CACHE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x14,
+	 .desc = "Level 1 instruction cache access"
+	},
+	{.name = "L2D_CACHE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x16,
+	 .desc = "Level 2 data cache access"
+	},
+	{.name = "L2D_CACHE_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x17,
+	 .desc = "Level 2 data cache refill"
+	},
+	{.name = "L2D_CACHE_WB",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x18,
+	 .desc = "Level 2 data cache WriteBack"
+	},
+	{.name = "BUS_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x19,
+	 .desc = "Bus access"
+	},
+	{.name = "LOCAL_MEMORY_ERROR",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x1a,
+	 .desc = "Local memory error"
+	},
+	{.name = "INST_SPEC_EXEC",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x1b,
+	 .desc = "Instruction speculatively executed"
+	},
+	{.name = "TTBR_WRITE_RETIRED",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x1c,
+	 .desc = "Instruction architecturally executed (condition check pass)  Write to translation table base"
+	},
+	{.name = "L1D_READ_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x40,
+	 .desc = "Level 1 data cache read access"
+	},
+	{.name = "L1D_WRITE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x41,
+	 .desc = "Level 1 data cache write access"
+	},
+	{.name = "L1D_READ_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x42,
+	 .desc = "Level 1 data cache read refill"
+	},
+	{.name = "L1D_INVALIDATE",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x48,
+	 .desc = "Level 1 data cache invalidate"
+	},
+	{.name = "L1D_TLB_READ_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x4c,
+	 .desc = "Level 1 data TLB read refill"
+	},
+	{.name = "L1D_TLB_WRITE_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x4d,
+	 .desc = "Level 1 data TLB write refill"
+	},
+	{.name = "L2D_READ_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x50,
+	 .desc = "Level 2 data cache read access"
+	},
+	{.name = "L2D_WRITE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x51,
+	 .desc = "Level 2 data cache write access"
+	},
+	{.name = "L2D_READ_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x52,
+	 .desc = "Level 2 data cache read refill"
+	},
+	{.name = "L2D_WRITE_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x53,
+	 .desc = "Level 2 data cache write refill"
+	},
+	{.name = "L2D_WB_VICTIM",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x56,
+	 .desc = "Level 2 data cache writeback victim"
+	},
+	{.name = "L2D_WB_CLEAN_COHERENCY",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x57,
+	 .desc = "Level 2 data cache writeback cleaning and coherency"
+	},
+	{.name = "L2D_INVALIDATE",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x58,
+	 .desc = "Level 2 data cache invalidate"
+	},
+	{.name = "BUS_READ_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x60,
+	 .desc = "Bus read access"
+	},
+	{.name = "BUS_WRITE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x61,
+	 .desc = "Bus write access"
+	},
+	{.name = "BUS_NORMAL_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x62,
+	 .desc = "Bus normal access"
+	},
+	{.name = "BUS_NOT_NORMAL_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x63,
+	 .desc = "Bus not normal access"
+	},
+	{.name = "BUS_NORMAL_ACCESS_2",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x64,
+	 .desc = "Bus normal access"
+	},
+	{.name = "BUS_PERIPH_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x65,
+	 .desc = "Bus peripheral access"
+	},
+	{.name = "DATA_MEM_READ_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x66,
+	 .desc = "Data memory read access"
+	},
+	{.name = "DATA_MEM_WRITE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x67,
+	 .desc = "Data memory write access"
+	},
+	{.name = "UNALIGNED_READ_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x68,
+	 .desc = "Unaligned read access"
+	},
+	{.name = "UNALIGNED_WRITE_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x69,
+	 .desc = "Unaligned read access"
+	},
+	{.name = "UNALIGNED_ACCESS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x6a,
+	 .desc = "Unaligned access"
+	},
+	{.name = "INST_SPEC_EXEC_LDREX",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x6c,
+	 .desc = "Exclusive operation speculatively executed - Load exclusive"
+	},
+	{.name = "INST_SPEC_EXEC_STREX_PASS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x6d,
+	 .desc = "Exclusive operation speculative executed - Store exclusive pass"
+	},
+	{.name = "INST_SPEC_EXEC_STREX_FAIL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x6e,
+	 .desc = "Exclusive operation speculative executed - Store exclusive fail"
+	},
+	{.name = "INST_SPEC_EXEC_STREX",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x6f,
+	 .desc = "Exclusive operation speculatively executed - Store exclusive"
+	},
+	{.name = "INST_SPEC_EXEC_LOAD",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x70,
+	 .desc = "Load instruction speculatively executed"
+	},
+	{.name = "INST_SPEC_EXEC_STORE",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x71,
+	 .desc = "Store instruction speculatively executed"
+	},
+	{.name = "INST_SPEC_EXEC_LOAD_STORE",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x72,
+	 .desc = "Load or store instruction speculatively executed"
+	},
+	{.name = "INST_SPEC_EXEC_INTEGER_INST",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x73,
+	 .desc = "Integer data processing instruction speculatively executed"
+	},
+	{.name = "INST_SPEC_EXEC_SIMD",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x74,
+	 .desc = "Advanced SIMD instruction speculatively executed"
+	},
+	{.name = "INST_SPEC_EXEC_VFP",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x75,
+	 .desc = "VFP instruction speculatively executed"
+	},
+	{.name = "INST_SPEC_EXEC_SOFT_PC",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x76,
+	 .desc = "Software change of the PC instruction speculatively executed"
+	},
+	{.name = "BRANCH_SPEC_EXEC_IMM_BRANCH",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x78,
+	 .desc = "Immediate branch speculatively executed"
+	},
+	{.name = "BRANCH_SPEC_EXEC_RET",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x79,
+	 .desc = "Return branch speculatively executed"
+	},
+	{.name = "BRANCH_SPEC_EXEC_IND",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x7a,
+	 .desc = "Indirect branch speculatively executed"
+	},
+	{.name = "BARRIER_SPEC_EXEC_ISB",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x7c,
+	 .desc = "ISB barrier speculatively executed"
+	},
+	{.name = "BARRIER_SPEC_EXEC_DSB",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x7d,
+	 .desc = "DSB barrier speculatively executed"
+	},
+	{.name = "BARRIER_SPEC_EXEC_DMB",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x7e,
+	 .desc = "DMB barrier speculatively executed"
+	},
+	{.name = "EXCEPTION_UNDEF",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x81,
+	 .desc = "Exception taken, other synchronous"
+	},
+	{.name = "EXCEPTION_SVC",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x82,
+	 .desc = "Exception taken, supervisor call"
+	},
+	{.name = "EXCEPTION_PABORT",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x83,
+	 .desc = "Exception taken, instruction abort"
+	},
+	{.name = "EXCEPTION_DABORT",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x84,
+	 .desc = "Exception taken, data abort or SError"
+	},
+	{.name = "EXCEPTION_IRQ",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x86,
+	 .desc = "Exception taken, irq"
+	},
+	{.name = "EXCEPTION_FIQ",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x87,
+	 .desc = "Exception taken, fiq"
+	},
+	{.name = "EXCEPTION_HVC",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x8a,
+	 .desc = "Exception taken, hypervisor call"
+	},
+	{.name = "EXCEPTION_TRAP_PABORT",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x8b,
+	 .desc = "Exception taken, instruction abort not taken locally"
+	},
+	{.name = "EXCEPTION_TRAP_DABORT",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x8c,
+	 .desc = "Exception taken, data abort or SError not taken locally"
+	},
+	{.name = "EXCEPTION_TRAP_OTHER",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x8d,
+	 .desc = "Exception taken, other traps not taken locally"
+	},
+	{.name = "EXCEPTION_TRAP_IRQ",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x8e,
+	 .desc = "Exception taken, irq not taken locally"
+	},
+	{.name = "EXCEPTION_TRAP_FIQ",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x8f,
+	 .desc = "Exception taken, fiq not taken locally"
+	},
+	{.name = "RC_LD_SPEC",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x90,
+	 .desc = "Release consistency instruction speculatively executed (load-acquire)",
+	},
+	{.name = "RC_ST_SPEC",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x91,
+	 .desc = "Release consistency instruction speculatively executed (store-release)",
+	},
+	{.name = "INST_SPEC_EXEC_NOP",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x100,
+	 .desc = "Operation speculatively executed - NOP",
+	},
+	{.name = "FSU_CLOCK_OFF",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x101,
+	 .desc = "FSU clocking gated off cycle",
+	},
+	{.name = "BTB_MISPREDICT",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x102,
+	 .desc = "BTB misprediction",
+	},
+	{.name = "ITB_MISS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x103,
+	 .desc = "ITB miss",
+	},
+	{.name = "DTB_MISS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x104,
+	 .desc = "DTB miss",
+	},
+	{.name = "L1D_CACHE_LATE_MISS",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x105,
+	 .desc = "L1 data cache late miss",
+	},
+	{.name = "L1D_CACHE_PREFETCH",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x106,
+	 .desc = "L1 data cache prefetch request",
+	},
+	{.name = "L2_CACHE_PREFETCH",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x107,
+	 .desc = "L2 data prefetch request",
+	},
+	{.name = "STALLED_CYCLES_FRONTEND",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x108,
+	 .desc = "Decode starved for instruction cycle",
+	},
+	{.name = "STALLED_CYCLES_BACKEND",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x109,
+	 .desc = "Op dispatch stalled cycle",
+	},
+	{.name = "IXA_NO_ISSUE",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x10A,
+	 .desc = "IXA Op non-issue",
+	},
+	{.name = "IXB_NO_ISSUE",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x10B,
+	 .desc = "IXB Op non-issue",
+	},
+	{.name = "BX_NO_ISSUE",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x10C,
+	 .desc = "BX Op non-issue",
+	},
+	{.name = "LX_NO_ISSUE",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x10D,
+	 .desc = "LX Op non-issue",
+	},
+	{.name = "SX_NO_ISSUE",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x10E,
+	 .desc = "SX Op non-issue",
+	},
+	{.name = "FX_NO_ISSUE",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x10F,
+	 .desc = "FX Op non-issue",
+	},
+	{.name = "WAIT_CYCLES",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x110,
+	 .desc = "Wait state cycle",
+	},
+	{.name = "L1_STAGE2_TLB_REFILL",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x111,
+	 .desc = "L1 stage-2 TLB refill",
+	},
+	{.name = "PAGE_WALK_L0_STAGE1_HIT",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x112,
+	 .desc = "Page Walk Cache level-0 stage-1 hit",
+	},
+	{.name = "PAGE_WALK_L1_STAGE1_HIT",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x113,
+	 .desc = "Page Walk Cache level-1 stage-1 hit",
+	},
+	{.name = "PAGE_WALK_L2_STAGE1_HIT",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x114,
+	 .desc = "Page Walk Cache level-2 stage-1 hit",
+	},
+	{.name = "PAGE_WALK_L1_STAGE2_HIT",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x115,
+	 .desc = "Page Walk Cache level-1 stage-2 hit",
+	},
+	{.name = "PAGE_WALK_L2_STAGE2_HIT",
+	 .modmsk = ARMV8_ATTRS,
+	 .code = 0x116,
+	 .desc = "Page Walk Cache level-2 stage-2 hit",
+	},
+	/* END Applied Micro X-Gene specific events */
+};
diff --git a/src/libpfm4/lib/events/intel_bdw_events.h b/src/libpfm4/lib/events/intel_bdw_events.h
new file mode 100644
index 0000000..b7d6749
--- /dev/null
+++ b/src/libpfm4/lib/events/intel_bdw_events.h
@@ -0,0 +1,2485 @@
+/*
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * This file is part of libpfm, a performance monitoring support library for
+ * applications on Linux.
+ *
+ * PMU: bdw (Intel Haswell)
+ */
+
+static const intel_x86_umask_t bdw_baclears[]={
+  { .uname = "ANY",
+    .udesc  = "Number of front-end re-steers due to BPU misprediction",
+    .ucode  = 0x1f00,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t bdw_br_inst_exec[]={
+  { .uname = "NONTAKEN_CONDITIONAL",
+    .udesc  = "All macro conditional nontaken branch instructions",
+    .ucode  = 0x4100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NONTAKEN_COND",
+    .udesc  = "All macro conditional nontaken branch instructions",
+    .ucode  = 0x4100,
+    .uequiv = "NONTAKEN_CONDITIONAL",
+    .uflags = INTEL_X86_NCOMBO,
+  },
+
+  { .uname = "TAKEN_CONDITIONAL",
+    .udesc  = "Taken speculative and retired macro-conditional branches",
+    .ucode  = 0x8100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "TAKEN_COND",
+    .udesc  = "Taken speculative and retired macro-conditional branches",
+    .ucode  = 0x8100,
+    .uequiv = "TAKEN_CONDITIONAL",
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "TAKEN_DIRECT_JUMP",
+    .udesc  = "Taken speculative and retired macro-conditional branch instructions excluding calls and indirects",
+    .ucode  = 0x8200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "TAKEN_INDIRECT_JUMP_NON_CALL_RET",
+    .udesc  = "Taken speculative and retired indirect branches excluding calls and returns",
+    .ucode  = 0x8400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "TAKEN_INDIRECT_NEAR_RETURN",
+    .udesc  = "Taken speculative and retired indirect branches with return mnemonic",
+    .ucode  = 0x8800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "TAKEN_DIRECT_NEAR_CALL",
+    .udesc  = "Taken speculative and retired direct near calls",
+    .ucode  = 0x9000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_CONDITIONAL",
+    .udesc  = "Speculative and retired macro-conditional branches",
+    .ucode  = 0xc100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_COND",
+    .udesc  = "Speculative and retired macro-conditional branches",
+    .ucode  = 0xc100,
+    .uequiv = "ALL_CONDITIONAL",
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ANY_COND",
+    .udesc  = "Speculative and retired macro-conditional branches",
+    .ucode  = 0xc100,
+    .uequiv = "ALL_CONDITIONAL",
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_DIRECT_JMP",
+    .udesc  = "Speculative and retired macro-unconditional branches excluding calls and indirects",
+    .ucode  = 0xc200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_INDIRECT_JUMP_NON_CALL_RET",
+    .udesc  = "Speculative and retired indirect branches excluding calls and returns",
+    .ucode  = 0xc400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_INDIRECT_NEAR_RETURN",
+    .udesc  = "Speculative and retired indirect return branches",
+    .ucode  = 0xc800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_DIRECT_NEAR_CALL",
+    .udesc  = "Speculative and retired direct near calls",
+    .ucode  = 0xd000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "TAKEN_INDIRECT_NEAR_CALL",
+    .udesc  = "All indirect calls, including both register and memory indirect",
+    .ucode  = 0xa000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_BRANCHES",
+    .udesc  = "All branch instructions executed",
+    .ucode  = 0xff00,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t bdw_br_inst_retired[]={
+  { .uname = "CONDITIONAL",
+    .udesc  = "Counts all taken and not taken macro conditional branch instructions",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "COND",
+    .udesc  = "Counts all taken and not taken macro conditional branch instructions",
+    .ucode  = 0x100,
+    .uequiv = "CONDITIONAL",
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "NEAR_CALL",
+    .udesc  = "Counts all macro direct and indirect near calls",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "ALL_BRANCHES",
+    .udesc  = "Counts all taken and not taken macro branches including far branches (architectural event)",
+    .ucode  = 0x0,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL | INTEL_X86_PEBS,
+  },
+  { .uname = "NEAR_RETURN",
+    .udesc  = "Counts the number of near ret instructions retired",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "NOT_TAKEN",
+    .udesc  = "Counts all not taken macro branch instructions retired",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "NEAR_TAKEN",
+    .udesc  = "Counts the number of near branch taken instructions retired",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "FAR_BRANCH",
+    .udesc  = "Counts the number of far branch instructions retired",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+};
+
+static const intel_x86_umask_t bdw_br_misp_exec[]={
+  { .uname = "NONTAKEN_CONDITIONAL",
+    .udesc  = "Not taken speculative and retired mispredicted macro conditional branches",
+    .ucode  = 0x4100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NONTAKEN_COND",
+    .udesc  = "Not taken speculative and retired mispredicted macro conditional branches",
+    .ucode  = 0x4100,
+    .uequiv = "NONTAKEN_CONDITIONAL",
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "TAKEN_CONDITIONAL",
+    .udesc  = "Taken speculative and retired mispredicted macro conditional branches",
+    .ucode  = 0x8100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "TAKEN_COND",
+    .udesc  = "Taken speculative and retired mispredicted macro conditional branches",
+    .ucode  = 0x8100,
+    .uequiv = "TAKEN_CONDITIONAL",
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "TAKEN_INDIRECT_JUMP_NON_CALL_RET",
+    .udesc  = "Taken speculative and retired mispredicted indirect branches excluding calls and returns",
+    .ucode  = 0x8400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "TAKEN_RETURN_NEAR",
+    .udesc  = "Taken speculative and retired mispredicted indirect branches with return mnemonic",
+    .ucode  = 0x8800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_CONDITIONAL",
+    .udesc  = "Speculative and retired mispredicted macro conditional branches",
+    .ucode  = 0xc100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ANY_COND",
+    .udesc  = "Speculative and retired mispredicted macro conditional branches",
+    .ucode  = 0xc100,
+    .uequiv = "ALL_CONDITIONAL",
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_INDIRECT_JUMP_NON_CALL_RET",
+    .udesc  = "All mispredicted indirect branches that are not calls nor returns",
+    .ucode  = 0xc400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_BRANCHES",
+    .udesc  = "Speculative and retired mispredicted macro conditional branches",
+    .ucode  = 0xff00,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "TAKEN_INDIRECT_NEAR_CALL",
+    .udesc  = "Taken speculative and retired mispredicted indirect calls",
+    .ucode  = 0xa000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_br_misp_retired[]={
+  { .uname = "CONDITIONAL",
+    .udesc  = "All mispredicted macro conditional branch instructions",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "COND",
+    .udesc  = "All mispredicted macro conditional branch instructions",
+    .ucode  = 0x100,
+    .uequiv = "CONDITIONAL",
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "ALL_BRANCHES",
+    .udesc  = "All mispredicted macro branches (architectural event)",
+    .ucode  = 0x0, /* architectural encoding */
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_DFL,
+  },
+  { .uname = "NEAR_TAKEN",
+    .udesc  = "number of near branch instructions retired that were mispredicted and taken",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+};
+
+static const intel_x86_umask_t bdw_cpl_cycles[]={
+  { .uname = "RING0",
+    .udesc  = "Unhalted core cycles when the thread is in ring 0",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RING123",
+    .udesc  = "Unhalted core cycles when thread is in rings 1, 2, or 3",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RING0_TRANS",
+    .udesc  = "Number of intervals between processor halts while thread is in ring 0",
+    .ucode  = 0x100 | INTEL_X86_MOD_EDGE | (1 << INTEL_X86_CMASK_BIT), /* edge=1 cnt=1 */
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_E | _INTEL_X86_ATTR_C,
+  },
+};
+
+static const intel_x86_umask_t bdw_cpu_clk_thread_unhalted[]={
+  { .uname = "REF_XCLK",
+    .udesc  = "Cases when the core is unhalted at 100Mhz",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname  = "REF_P",
+    .udesc  = "Cycles when the core is unhalted (count at 100 Mhz)",
+    .ucode = 0x100,
+    .uequiv = "REF_XCLK",
+    .uflags= INTEL_X86_NCOMBO,
+  },
+  { .uname  = "THREAD_P",
+    .udesc  = "Cycles when thread is not halted",
+    .ucode = 0x000,
+    .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t bdw_cycle_activity[]={
+   { .uname  = "CYCLES_L2_PENDING",
+     .udesc  = "Cycles with pending L2 miss loads (must use with HT off only)",
+     .ucode  = 0x0100 | (0x1 << INTEL_X86_CMASK_BIT),
+     .uflags = INTEL_X86_NCOMBO,
+     .ucntmsk= 0xf,
+   },
+   { .uname  = "CYCLES_LDM_PENDING",
+     .udesc  = "Cycles with pending memory loads",
+     .ucode  = 0x0200 | (0x2 << INTEL_X86_CMASK_BIT),
+     .uflags = INTEL_X86_NCOMBO,
+   },
+   { .uname  = "CYCLES_L1D_PENDING",
+     .udesc  = "Cycles with pending L1D load cache misses",
+     .ucode  = 0x0800 | (0x8 << INTEL_X86_CMASK_BIT),
+     .ucntmsk= 0x4,
+     .uflags = INTEL_X86_NCOMBO,
+   },
+   { .uname  = "STALL_L1D_PENDING",
+     .udesc  = "Executions stalls due to pending L1D load cache misses",
+     .ucode  = 0x0c00 | (0xc << INTEL_X86_CMASK_BIT),
+     .ucntmsk= 0x4,
+     .uflags = INTEL_X86_NCOMBO,
+   },
+   { .uname  = "STALLS_L2_PENDING",
+     .udesc  = "Execution stalls due to L2 pending loads (must use with HT off only)",
+     .ucode  = 0x0500 | (0x5 << INTEL_X86_CMASK_BIT),
+     .ucntmsk= 0xf,
+     .uflags = INTEL_X86_NCOMBO,
+   },
+   { .uname  = "CYCLES_NO_EXECUTE",
+     .udesc  = "Cycles during which no instructions were executed in the execution stage of the pipeline",
+     .ucode  = 0x0400 | (0x4 << INTEL_X86_CMASK_BIT),
+     .ucntmsk= 0xf,
+     .uflags = INTEL_X86_NCOMBO,
+   },
+};
+
+static const intel_x86_umask_t bdw_dtlb_load_misses[]={
+  { .uname = "MISS_CAUSES_A_WALK",
+    .udesc  = "Misses in all DTLB levels that cause page walks",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WALK_COMPLETED_4K",
+    .udesc  = "Misses in all TLB levels causes a page walk that completes (4K)",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WALK_COMPLETED",
+    .udesc  = "Misses in all TLB levels causes a page walk of any page size that completes",
+    .ucode  = 0xe00,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WALK_DURATION",
+    .udesc  = "Cycles when PMH is busy with page walks",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "STLB_HIT_4K",
+    .udesc  = "Misses that miss the DTLB and hit the STLB (4K)",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "STLB_HIT",
+    .udesc  = "Number of cache load STLB hits. No page walk",
+    .ucode  = 0x6000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_itlb_misses[]={
+  { .uname = "MISS_CAUSES_A_WALK",
+    .udesc  = "Misses in all DTLB levels that cause page walks",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WALK_COMPLETED_4K",
+    .udesc  = "Misses in all TLB levels causes a page walk that completes (4K)",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WALK_COMPLETED",
+    .udesc  = "Misses in all TLB levels causes a page walk of any page size that completes",
+    .ucode  = 0xe00,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "WALK_DURATION",
+    .udesc  = "Cycles when PMH is busy with page walks",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "STLB_HIT_4K",
+    .udesc  = "Misses that miss the DTLB and hit the STLB (4K)",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "STLB_HIT",
+    .udesc  = "Number of cache load STLB hits. No page walk",
+    .ucode  = 0x6000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_fp_assist[]={
+  { .uname = "X87_OUTPUT",
+    .udesc  = "Number of X87 FP assists due to output values",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "X87_INPUT",
+    .udesc  = "Number of X87 FP assists due to input values",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SIMD_OUTPUT",
+    .udesc  = "Number of SIMD FP assists due to output values",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SIMD_INPUT",
+    .udesc  = "Number of SIMD FP assists due to input values",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ANY",
+    .udesc  = "Cycles with any input/output SEE or FP assists",
+    .ucode  = 0x1e00 | (1 << INTEL_X86_CMASK_BIT), /* cnt=1 */
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "ALL",
+    .udesc  = "Cycles with any input and output SSE or FP assist",
+    .ucode  = 0x1e00 | (1 << INTEL_X86_CMASK_BIT), /* cnt=1 */
+    .uequiv = "ANY",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+};
+
+static const intel_x86_umask_t bdw_icache[]={
+  { .uname = "MISSES",
+    .udesc  = "Number of Instruction Cache, Streaming Buffer and Victim Cache Misses. Includes Uncacheable accesses",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t bdw_idq[]={
+  { .uname = "EMPTY",
+    .udesc  = "Cycles the Instruction Decode Queue (IDQ) is empty",
+    .ucode  = 0x200,
+    .ucntmsk= 0xf,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MITE_UOPS",
+    .udesc  = "Number of uops delivered to Instruction Decode Queue (IDQ) from MITE path",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "DSB_UOPS",
+    .udesc  = "Number of uops delivered to Instruction Decode Queue (IDQ) from Decode Stream Buffer (DSB) path",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MS_DSB_UOPS",
+    .udesc  = "Uops initiated by Decode Stream Buffer (DSB) that are being delivered to Instruction Decode Queue (IDQ) while Microcode Sequencer (MS) is busy",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MS_MITE_UOPS",
+    .udesc  = "Uops initiated by MITE and delivered to Instruction Decode Queue (IDQ) while Microcode Sequencer (MS) is busy",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MS_UOPS",
+    .udesc  = "Number of Uops were delivered into Instruction Decode Queue (IDQ) from MS, initiated by Decode Stream Buffer (DSB) or MITE",
+    .ucode  = 0x3000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MS_UOPS_CYCLES",
+    .udesc  = "Number of cycles that Uops were delivered into Instruction Decode Queue (IDQ) when MS_Busy, initiated by Decode Stream Buffer (DSB) or MITE",
+    .ucode  = 0x3000 | (1 << INTEL_X86_CMASK_BIT), /* cnt=1 */
+    .uequiv = "MS_UOPS:c=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "MITE_UOPS_CYCLES",
+    .udesc  = "Cycles when uops are being delivered to Instruction Decode Queue (IDQ) from MITE path",
+    .ucode  = 0x400 | (1 << INTEL_X86_CMASK_BIT), /* cnt=1 */
+    .uequiv = "MITE_UOPS:c=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "DSB_UOPS_CYCLES",
+    .udesc  = "Cycles when uops are being delivered to Instruction Decode Queue (IDQ) from Decode Stream Buffer (DSB) path",
+    .ucode  = 0x800 | (1 << INTEL_X86_CMASK_BIT), /* cnt=1 */
+    .uequiv = "DSB_UOPS:c=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "MS_DSB_UOPS_CYCLES",
+    .udesc  = "Cycles when uops initiated by Decode Stream Buffer (DSB) are being delivered to Instruction Decode Queue (IDQ) while Microcode Sequencer (MS) is busy",
+    .ucode  = 0x1000 | (1 << INTEL_X86_CMASK_BIT), /* cnt=1 */
+    .uequiv = "MS_DSB_UOPS:c=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "MS_DSB_OCCUR",
+    .udesc  = "Deliveries to Instruction Decode Queue (IDQ) initiated by Decode Stream Buffer (DSB) while Microcode Sequencer (MS) is busy",
+    .ucode  = 0x1000 | INTEL_X86_MOD_EDGE | (1 << INTEL_X86_CMASK_BIT), /* edge=1 cnt=1 */
+    .uequiv = "MS_DSB_UOPS:c=1:e=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_E | _INTEL_X86_ATTR_C,
+  },
+  { .uname = "ALL_DSB_CYCLES_4_UOPS",
+    .udesc  = "Cycles Decode Stream Buffer (DSB) is delivering 4 Uops",
+    .ucode  = 0x1800 | (4 << INTEL_X86_CMASK_BIT), /* cnt=4 */
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "ALL_DSB_CYCLES_ANY_UOPS",
+    .udesc  = "Cycles Decode Stream Buffer (DSB) is delivering any Uop",
+    .ucode  = 0x1800 | (1 << INTEL_X86_CMASK_BIT), /* cnt=1 */
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "ALL_MITE_CYCLES_4_UOPS",
+    .udesc  = "Cycles MITE is delivering 4 Uops",
+    .ucode  = 0x2400 | (4 << INTEL_X86_CMASK_BIT), /* cnt=4 */
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "ALL_MITE_CYCLES_ANY_UOPS",
+    .udesc  = "Cycles MITE is delivering any Uop",
+    .ucode  = 0x2400 | (1 << INTEL_X86_CMASK_BIT), /* cnt=1 */
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "ALL_MITE_UOPS",
+    .udesc  = "Number of uops delivered to Instruction Decode Queue (IDQ) from any path",
+    .ucode  = 0x3c00,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_idq_uops_not_delivered[]={
+  { .uname = "CORE",
+    .udesc  = "Count number of non-delivered uops to Resource Allocation Table (RAT)",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t bdw_inst_retired[]={
+  { .uname = "ANY_P",
+    .udesc  = "Number of instructions retired. General Counter - architectural event",
+    .ucode  = 0x000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "ALL",
+    .udesc  = "Precise instruction retired event with HW to reduce effect of PEBS shadow in IP distribution (Precise Event)",
+    .ucode  = 0x100,
+    .uequiv = "PREC_DIST",
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "TOTAL_CYCLES",
+    .udesc  = "Number of cycles using always true condition",
+    .ucode  = 0x100 | INTEL_X86_MOD_INV | (10 << INTEL_X86_CMASK_BIT), /* inv=1 cnt=10 */
+    .uequiv = "PREC_DIST:i=1:c=10",
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+    .modhw  = _INTEL_X86_ATTR_I | _INTEL_X86_ATTR_C,
+  },
+  { .uname = "PREC_DIST",
+    .udesc  = "Precise instruction retired event with HW to reduce effect of PEBS shadow in IP distribution (Precise event)",
+    .ucode  = 0x100,
+    .ucntmsk= 0x2,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "X87",
+    .udesc  = "NUmber of FPU operations retired (instructions with no exceptions)",
+    .ucode  = 0x200,
+    .ucntmsk= 0x2,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_int_misc[]={
+  { .uname = "RECOVERY_CYCLES",
+    .udesc  = "Number of cycles waiting for Machine Clears  except JEClear",
+    .ucode  = 0x300,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RECOVERY_STALLS_COUNT",
+    .udesc  = "Number of occurrences waiting for Machine Clears",
+    .ucode  = 0x300 | INTEL_X86_MOD_EDGE | (1 << INTEL_X86_CMASK_BIT), /* edge=1 cnt=1 */
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_E | _INTEL_X86_ATTR_C,
+  },
+};
+
+static const intel_x86_umask_t bdw_itlb[]={
+  { .uname = "ITLB_FLUSH",
+    .udesc  = "Flushing of the Instruction TLB (ITLB) pages independent of page size",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t bdw_l1d[]={
+  { .uname = "REPLACEMENT",
+    .udesc  = "L1D Data line replacements",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t bdw_l1d_pend_miss[]={
+  { .uname = "PENDING",
+    .udesc  = "Cycles with L1D load misses outstanding",
+    .ucode  = 0x100,
+    .ucntmsk = 0x4,
+    .uflags = INTEL_X86_DFL,
+  },
+  { .uname = "PENDING_CYCLES",
+    .udesc  = "Cycles with L1D load misses outstanding",
+    .ucode  = 0x100 | (1 << INTEL_X86_CMASK_BIT), /* cnt=1 */
+    .uequiv = "PENDING:c=1",
+    .ucntmsk = 0x4,
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_C,
+  },
+  { .uname = "OCCURRENCES",
+    .udesc  = "Number L1D miss outstanding",
+    .ucode  = 0x100 | INTEL_X86_MOD_EDGE | (1 << INTEL_X86_CMASK_BIT), /* edge=1 cnt=1 */
+    .uequiv = "PENDING:c=1:e=1",
+    .ucntmsk = 0x4,
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_E | _INTEL_X86_ATTR_C,
+  },
+  { .uname = "EDGE",
+    .udesc  = "Number L1D miss outstanding",
+    .ucode  = 0x100 | INTEL_X86_MOD_EDGE | (1 << INTEL_X86_CMASK_BIT), /* edge=1 cnt=1 */
+    .uequiv = "PENDING:c=1:e=1",
+    .ucntmsk = 0x4,
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_E | _INTEL_X86_ATTR_C,
+  },
+};
+
+static const intel_x86_umask_t bdw_l2_demand_rqsts[]={
+  { .uname = "WB_HIT",
+    .udesc  = "WB requests that hit L2 cache",
+    .ucode  = 0x5000,
+    .uflags = INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t bdw_l2_lines_in[]={
+  { .uname = "I",
+    .udesc  = "L2 cache lines in I state filling L2",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "S",
+    .udesc  = "L2 cache lines in S state filling L2",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "E",
+    .udesc  = "L2 cache lines in E state filling L2",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL",
+    .udesc  = "L2 cache lines filling L2",
+    .ucode  = 0x700,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "ANY",
+    .udesc  = "L2 cache lines filling L2",
+    .uequiv = "ALL",
+    .ucode  = 0x700,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_l2_lines_out[]={
+  { .uname = "DEMAND_CLEAN",
+    .udesc  = "Number of clean L2 cachelines evicted by demand",
+    .ucode  = 0x500,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t bdw_l2_rqsts[]={
+  { .uname = "DEMAND_DATA_RD_MISS",
+    .udesc  = "Demand Data Read requests that miss L2 cache",
+    .ucode  = 0x2100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "DEMAND_DATA_RD_HIT",
+    .udesc  = "Demand Data Read requests that hit L2 cache",
+    .ucode  = 0x4100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "DEMAND_RFO_MISS",
+    .udesc  = "RFO requests that miss L2 cache",
+    .ucode  = 0x2200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RFO_MISS",
+    .udesc  = "RFO requests that miss L2 cache",
+    .ucode  = 0x2200,
+    .uequiv = "DEMAND_RFO_MISS",
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "DEMAND_RFO_HIT",
+    .udesc  = "RFO requests that hit L2 cache",
+    .ucode  = 0x4200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RFO_HIT",
+    .udesc  = "RFO requests that hit L2 cache",
+    .ucode  = 0x4200,
+    .uequiv = "DEMAND_RFO_HIT",
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "CODE_RD_MISS",
+    .udesc  = "L2 cache misses when fetching instructions",
+    .ucode  = 0x2400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_DEMAND_MISS",
+    .udesc  = "All demand requests that miss the L2 cache",
+    .ucode  = 0x2700,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "CODE_RD_HIT",
+    .udesc  = "L2 cache hits when fetching instructions, code reads",
+    .ucode  = 0x4400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "L2_PF_MISS",
+    .udesc  = "Requests from the L2 hardware prefetchers that miss L2 cache",
+    .ucode  = 0x3000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MISS",
+    .udesc  = "All requests that miss the L2 cache",
+    .ucode  = 0x3f00,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "L2_PF_HIT",
+    .udesc  = "Requests from the L2 hardware prefetchers that hit L2 cache",
+    .ucode  = 0x5000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_DEMAND_DATA_RD",
+    .udesc  = "Any data read request to L2 cache",
+    .ucode  = 0xe100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_RFO",
+    .udesc  = "Any data RFO request to L2 cache",
+    .ucode  = 0xe200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_CODE_RD",
+    .udesc  = "Any code read request to L2 cache",
+    .ucode  = 0xe400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_DEMAND_REFERENCES",
+    .udesc  = "All demand requests to L2 cache ",
+    .ucode  = 0xe700,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_PF",
+    .udesc  = "Any L2 HW prefetch request to L2 cache",
+    .ucode  = 0xf800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "REFERENCES",
+    .udesc  = "All requests to L2 cache",
+    .ucode  = 0xff00,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t bdw_l2_trans[]={
+  { .uname = "DEMAND_DATA_RD",
+    .udesc  = "Demand Data Read requests that access L2 cache",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RFO",
+    .udesc  = "RFO requests that access L2 cache",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "CODE_RD",
+    .udesc  = "L2 cache accesses when fetching instructions",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_PF",
+    .udesc  = "L2 or L3 HW prefetches that access L2 cache, including rejects",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "L1D_WB",
+    .udesc  = "L1D writebacks that access L2 cache",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "L2_FILL",
+    .udesc  = "L2 fill requests that access L2 cache",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "L2_WB",
+    .udesc  = "L2 writebacks that access L2 cache",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_REQUESTS",
+    .udesc  = "Transactions accessing L2 pipe",
+    .ucode  = 0x8000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t bdw_ld_blocks[]={
+  { .uname = "STORE_FORWARD",
+    .udesc  = "Counts the number of loads blocked by overlapping with store buffer entries that cannot be forwarded",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "NO_SR",
+    .udesc  = "number of times that split load operations are temporarily blocked because all resources for handling the split accesses are in use",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_ld_blocks_partial[]={
+  { .uname = "ADDRESS_ALIAS",
+    .udesc  = "False dependencies in MOB due to partial compare on address",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t bdw_load_hit_pre[]={
+  { .uname = "HW_PF",
+    .udesc  = "Non software-prefetch load dispatches that hit FB allocated for hardware prefetch",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t bdw_lock_cycles[]={
+  { .uname = "SPLIT_LOCK_UC_LOCK_DURATION",
+    .udesc  = "Cycles in which the L1D and L2 are locked, due to a UC lock or split lock",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "CACHE_LOCK_DURATION",
+    .udesc  = "cycles that the L1D is locked",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_longest_lat_cache[]={
+  { .uname = "MISS",
+    .udesc  = "Core-originated cacheable demand requests missed LLC - architectural event",
+    .ucode  = 0x4100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "REFERENCE",
+    .udesc  = "Core-originated cacheable demand requests that refer to LLC - architectural event",
+    .ucode  = 0x4f00,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_machine_clears[]={
+  { .uname = "CYCLES",
+    .udesc  = "Cycles there was a Nuke. Account for both thread-specific and All Thread Nukes",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MEMORY_ORDERING",
+    .udesc  = "Number of Memory Ordering Machine Clears detected",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SMC",
+    .udesc  = "Number of Self-modifying code (SMC) Machine Clears detected",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MASKMOV",
+    .udesc  = "This event counts the number of executed Intel AVX masked load operations that refer to an illegal address range with the mask bits set to 0",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_mem_load_uops_l3_hit_retired[]={
+  { .uname = "XSNP_MISS",
+    .udesc  = "Retired load uops which data sources were L3 hit and cross-core snoop missed in on-pkg core cache",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "XSNP_HIT",
+    .udesc  = "Retired load uops which data sources were L3 and cross-core snoop hits in on-pkg core cache",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "XSNP_HITM",
+    .udesc  = "Load had HitM Response from a core on same socket (shared L3). (Non PEBS",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "XSNP_NONE",
+    .udesc  = "Retired load uops which data sources were hits in L3 without snoops required",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+};
+
+static const intel_x86_umask_t bdw_mem_load_uops_l3_miss_retired[]={
+  { .uname = "LOCAL_DRAM",
+    .udesc  = "Retired load uops missing L3 cache but hitting local memory",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t bdw_mem_load_uops_retired[]={
+  { .uname = "L1_HIT",
+    .udesc  = "Retired load uops with L1 cache hits as data source",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "L2_HIT",
+    .udesc  = "Retired load uops with L2 cache hits as data source",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "L3_HIT",
+    .udesc  = "Retired load uops with L3 cache hits as data source",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "L1_MISS",
+    .udesc  = "Retired load uops which missed the L1D",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "L2_MISS",
+    .udesc  = "Retired load uops which missed the L2. Unknown data source excluded",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "L3_MISS",
+    .udesc  = "Retired load uops which missed the L3",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "HIT_LFB",
+    .udesc  = "Retired load uops which missed L1 but hit line fill buffer (LFB)",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+};
+
+static const intel_x86_umask_t bdw_mem_trans_retired[]={
+  { .uname  = "LOAD_LATENCY",
+    .udesc  = "Memory load instructions retired above programmed clocks, minimum threshold value is 3 (Precise Event and ldlat required)",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_LDLAT | INTEL_X86_DFL,
+  },
+  { .uname  = "LATENCY_ABOVE_THRESHOLD",
+    .udesc  = "Memory load instructions retired above programmed clocks, minimum threshold value is 3 (Precise Event and ldlat required)",
+    .ucode  = 0x100,
+    .uequiv = "LOAD_LATENCY",
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_LDLAT | INTEL_X86_NO_AUTOENCODE,
+  },
+};
+
+static const intel_x86_umask_t bdw_mem_uops_retired[]={
+  { .uname = "STLB_MISS_LOADS",
+    .udesc  = "Load uops with true STLB miss retired to architected path",
+    .ucode  = 0x1100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "STLB_MISS_STORES",
+    .udesc  = "Store uops with true STLB miss retired to architected path",
+    .ucode  = 0x1200,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "LOCK_LOADS",
+    .udesc  = "Load uops with locked access retired",
+    .ucode  = 0x2100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "SPLIT_LOADS",
+    .udesc  = "Line-splitted load uops retired",
+    .ucode  = 0x4100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "SPLIT_STORES",
+    .udesc  = "Line-splitted store uops retired",
+    .ucode  = 0x4200,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "ALL_LOADS",
+    .udesc  = "All load uops retired",
+    .ucode  = 0x8100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "ALL_STORES",
+    .udesc  = "All store uops retired",
+    .ucode  = 0x8200,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+};
+
+static const intel_x86_umask_t bdw_misalign_mem_ref[]={
+  { .uname = "LOADS",
+    .udesc  = "Speculative cache-line split load uops dispatched to the L1D",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "STORES",
+    .udesc  = "Speculative cache-line split store-address uops dispatched to L1D",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_move_elimination[]={
+  { .uname = "INT_ELIMINATED",
+    .udesc  = "Number of integer Move Elimination candidate uops that were eliminated",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SIMD_ELIMINATED",
+    .udesc  = "Number of SIMD Move Elimination candidate uops that were eliminated",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "INT_NOT_ELIMINATED",
+    .udesc  = "Number of integer Move Elimination candidate uops that were not eliminated",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SIMD_NOT_ELIMINATED",
+    .udesc  = "Number of SIMD Move Elimination candidate uops that were not eliminated",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_offcore_requests[]={
+  { .uname  = "DEMAND_DATA_RD",
+    .udesc  = "Demand data read requests sent to uncore (use with HT off only)",
+    .ucode = 0x100,
+    .uflags= INTEL_X86_NCOMBO,
+  },
+  { .uname = "DEMAND_CODE_RD",
+    .udesc  = "Demand code read requests sent to uncore (use with HT off only)",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "DEMAND_RFO",
+    .udesc  = "Demand RFOs requests sent to uncore (use with HT off only)",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ALL_DATA_RD",
+    .udesc  = "Data read requests sent to uncore (use with HT off only)",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_other_assists[]={
+  { .uname = "AVX_TO_SSE",
+    .udesc  = "Number of transitions from AVX-256 to legacy SSE when penalty applicable",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SSE_TO_AVX",
+    .udesc  = "Number of transitions from legacy SSE to AVX-256 when penalty applicable",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ANY_WB_ASSIST",
+    .udesc  = "Number of times any microcode assist is invoked by HW upon uop writeback",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_resource_stalls[]={
+  { .uname = "ANY",
+    .udesc  = "Cycles Allocation is stalled due to Resource Related reason",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "ALL",
+    .udesc  = "Cycles Allocation is stalled due to Resource Related reason",
+    .ucode  = 0x100,
+    .uequiv = "ANY",
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "RS",
+    .udesc  = "Stall cycles caused by absence of eligible entries in Reservation Station (RS)",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SB",
+    .udesc  = "Cycles Allocator is stalled due to Store Buffer full (not including draining from synch)",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ROB",
+    .udesc  = "ROB full stall cycles",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_rob_misc_events[]={
+  { .uname = "LBR_INSERTS",
+    .udesc  = "Count each time an new Last Branch Record (LBR) is inserted",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+};
+
+static const intel_x86_umask_t bdw_rs_events[]={
+  { .uname = "EMPTY_CYCLES",
+    .udesc  = "Cycles the Reservation Station (RS) is empty for this thread",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_DFL,
+  },
+  { .uname = "EMPTY_END",
+    .udesc  = "Number of times the reservation station (RS) was empty",
+    .ucode  = 0x100 | INTEL_X86_MOD_INV |  (1 << INTEL_X86_CMASK_BIT) | INTEL_X86_MOD_EDGE, /* inv=1, cmask=1,edge=1 */
+    .modhw  = _INTEL_X86_ATTR_I | _INTEL_X86_ATTR_C | _INTEL_X86_ATTR_E,
+  },
+};
+
+static const intel_x86_umask_t bdw_tlb_flush[]={
+  { .uname = "DTLB_THREAD",
+    .udesc  = "Count number of DTLB flushes of thread-specific entries",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "STLB_ANY",
+    .udesc  = "Count number of any STLB flushes",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_uops_executed[]={
+  { .uname = "CORE",
+    .udesc  = "Number of uops executed from any thread",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_DFL,
+  },
+  { .uname = "STALL_CYCLES",
+    .udesc  = "Number of cycles with no uops executed",
+    .ucode  = 0x200 | INTEL_X86_MOD_INV | (1 << INTEL_X86_CMASK_BIT), /* inv=1 cnt=1 */
+    .uequiv = "CORE:c=1:i=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_I | _INTEL_X86_ATTR_C,
+  },
+};
+
+static const intel_x86_umask_t bdw_uops_executed_port[]={
+  { .uname = "PORT_0",
+    .udesc  = "Cycles which a Uop is executed on port 0",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "PORT_1",
+    .udesc  = "Cycles which a Uop is executed on port 1",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "PORT_2",
+    .udesc  = "Cycles which a Uop is executed on port 2",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "PORT_3",
+    .udesc  = "Cycles which a Uop is executed on port 3",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "PORT_4",
+    .udesc  = "Cycles which a Uop is executed on port 4",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "PORT_5",
+    .udesc  = "Cycles which a Uop is executed on port 5",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "PORT_6",
+    .udesc  = "Cycles which a Uop is executed on port 6",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "PORT_7",
+    .udesc  = "Cycles which a Uop is executed on port 7",
+    .ucode  = 0x8000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "PORT_0_CORE",
+    .udesc  = "tbd",
+    .ucode  = 0x100 | INTEL_X86_MOD_ANY, /* any=1 */
+    .uequiv = "PORT_0:t=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_T,
+  },
+  { .uname = "PORT_1_CORE",
+    .udesc  = "tbd",
+    .ucode  = 0x200 | INTEL_X86_MOD_ANY, /* any=1 */
+    .uequiv = "PORT_1:t=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_T,
+  },
+  { .uname = "PORT_2_CORE",
+    .udesc  = "tbd",
+    .ucode  = 0x400 | INTEL_X86_MOD_ANY, /* any=1 */
+    .uequiv = "PORT_2:t=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_T,
+  },
+  { .uname = "PORT_3_CORE",
+    .udesc  = "tbd",
+    .ucode  = 0x800 | INTEL_X86_MOD_ANY, /* any=1 */
+    .uequiv = "PORT_3:t=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_T,
+  },
+  { .uname = "PORT_4_CORE",
+    .udesc  = "tbd",
+    .ucode  = 0x1000 | INTEL_X86_MOD_ANY, /* any=1 */
+    .uequiv = "PORT_4:t=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_T,
+  },
+  { .uname = "PORT_5_CORE",
+    .udesc  = "tbd",
+    .ucode  = 0x2000 | INTEL_X86_MOD_ANY, /* any=1 */
+    .uequiv = "PORT_5:t=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_T,
+  },
+  { .uname = "PORT_6_CORE",
+    .udesc  = "tbd",
+    .ucode  = 0x4000 | INTEL_X86_MOD_ANY, /* any=1 */
+    .uequiv = "PORT_6:t=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_T,
+  },
+  { .uname = "PORT_7_CORE",
+    .udesc  = "tbd",
+    .ucode  = 0x8000 | INTEL_X86_MOD_ANY, /* any=1 */
+    .uequiv = "PORT_7:t=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_T,
+  },
+};
+
+static const intel_x86_umask_t bdw_uops_issued[]={
+  { .uname = "ANY",
+    .udesc  = "Number of Uops issued by the Resource Allocation Table (RAT) to the Reservation Station (RS)",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "ALL",
+    .udesc  = "Number of Uops issued by the Resource Allocation Table (RAT) to the Reservation Station (RS)",
+    .ucode  = 0x100,
+    .uequiv = "ANY",
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "FLAGS_MERGE",
+    .udesc  = "Number of flags-merge uops being allocated. Such uops adds delay",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SLOW_LEA",
+    .udesc  = "Number of slow LEA or similar uops allocated. Such uop has 3 sources regardless if result of LEA instruction or not",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "SINGLE_MUL",
+    .udesc  = "Number of Multiply packed/scalar single precision uops allocated",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "STALL_CYCLES",
+    .udesc  = "Counts the number of cycles no uops issued by this thread",
+    .ucode  = 0x100 | INTEL_X86_MOD_INV | (1 << INTEL_X86_CMASK_BIT), /* inv=1 cnt=1 */
+    .uequiv = "ANY:c=1:i=1",
+    .uflags = INTEL_X86_NCOMBO,
+    .ucntmsk = 0xf,
+    .modhw  = _INTEL_X86_ATTR_I | _INTEL_X86_ATTR_C,
+  },
+  { .uname = "CORE_STALL_CYCLES",
+    .udesc  = "Counts the number of cycles no uops issued on this core",
+    .ucode  = 0x100 | INTEL_X86_MOD_ANY | INTEL_X86_MOD_INV | (1 << INTEL_X86_CMASK_BIT), /* any=1 inv=1 cnt=1 */
+    .uequiv = "ANY:c=1:i=1:t=1",
+    .ucntmsk = 0xf,
+    .uflags = INTEL_X86_NCOMBO,
+    .modhw  = _INTEL_X86_ATTR_T | _INTEL_X86_ATTR_I | _INTEL_X86_ATTR_C,
+  },
+};
+
+static const intel_x86_umask_t bdw_uops_retired[]={
+  { .uname = "ALL",
+    .udesc  = "All uops that actually retired",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS | INTEL_X86_DFL,
+  },
+  { .uname = "ANY",
+    .udesc  = "All uops that actually retired",
+    .ucode  = 0x100,
+    .uequiv = "ALL",
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "RETIRE_SLOTS",
+    .udesc  = "number of retirement slots used non PEBS",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "STALL_CYCLES",
+    .udesc  = "Cycles no executable uops retired (Precise Event)",
+    .ucode  = 0x100 | INTEL_X86_MOD_INV | (1 << INTEL_X86_CMASK_BIT), /* inv=1 cnt=1 */
+    .uequiv = "ALL:i=1:c=1",
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+    .modhw  = _INTEL_X86_ATTR_I | _INTEL_X86_ATTR_C,
+  },
+  { .uname = "TOTAL_CYCLES",
+    .udesc  = "Number of cycles using always true condition applied to PEBS uops retired event",
+    .ucode  = 0x100 | INTEL_X86_MOD_INV | (10 << INTEL_X86_CMASK_BIT), /* inv=1 cnt=10 */
+    .uequiv = "ALL:i=1:c=10",
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+    .modhw  = _INTEL_X86_ATTR_I | _INTEL_X86_ATTR_C,
+  },
+  { .uname = "CORE_STALL_CYCLES",
+    .udesc  = "Cycles no executable uops retired on core (Precise Event)",
+    .ucode  = 0x100 | INTEL_X86_MOD_INV | (1 << INTEL_X86_CMASK_BIT), /* inv=1 cnt=1 */
+    .uequiv = "ALL:i=1:c=1:t=1",
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+    .modhw  = _INTEL_X86_ATTR_I | _INTEL_X86_ATTR_C,
+  },
+  { .uname = "STALL_OCCURRENCES",
+    .udesc  = "Number of transitions from stalled to unstalled execution (Precise Event)",
+    .ucode  = 0x100 | INTEL_X86_MOD_INV | INTEL_X86_MOD_EDGE| (1 << INTEL_X86_CMASK_BIT), /* inv=1 edge=1 cnt=1 */
+    .uequiv = "ALL:c=1:i=1:e=1",
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+    .modhw  = _INTEL_X86_ATTR_I | _INTEL_X86_ATTR_C | _INTEL_X86_ATTR_E,
+  },
+};
+
+static const intel_x86_umask_t bdw_offcore_response[]={
+   { .uname  = "DMND_DATA_RD",
+     .udesc  = "Request: number of demand and DCU prefetch data reads of full and partial cachelines as well as demand data page table entry cacheline reads. Does not count L2 data read prefetches or instruction fetches",
+     .ucode = 1ULL << (0 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "DMND_RFO",
+     .udesc  = "Request: number of demand and DCU prefetch reads for ownership (RFO) requests generated by a write to data cacheline. Does not count L2 RFO prefetches",
+     .ucode = 1ULL << (1 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "DMND_IFETCH",
+     .udesc  = "Request: number of demand and DCU prefetch instruction cacheline reads. Does not count L2 code read prefetches",
+     .ucode = 1ULL << (2 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "WB",
+     .udesc  = "Request: number of writebacks (modified to exclusive) transactions",
+     .ucode = 1ULL << (3 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PF_DATA_RD",
+     .udesc  = "Request: number of data cacheline reads generated by L2 prefetchers",
+     .ucode = 1ULL << (4 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PF_RFO",
+     .udesc  = "Request: number of RFO requests generated by L2 prefetchers",
+     .ucode = 1ULL << (5 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PF_IFETCH",
+     .udesc  = "Request: number of code reads generated by L2 prefetchers",
+     .ucode = 1ULL << (6 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PF_LLC_DATA_RD",
+     .udesc  = "Request: number of L3 prefetcher requests to L2 for loads",
+     .ucode = 1ULL << (7 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PF_LLC_RFO",
+     .udesc  = "Request: number of RFO requests generated by L2 prefetcher",
+     .ucode = 1ULL << (8 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PF_LLC_IFETCH",
+     .udesc  = "Request: number of L2 prefetcher requests to L3 for instruction fetches",
+     .ucode = 1ULL << (9 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "BUS_LOCKS",
+     .udesc  = "Request: number bus lock and split lock requests",
+     .ucode = 1ULL << (10 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "STRM_ST",
+     .udesc  = "Request: number of streaming store requests",
+     .ucode = 1ULL << (11 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "OTHER",
+     .udesc  = "Request: counts one of the following transaction types, including L3 invalidate, I/O, full or partial writes, WC or non-temporal stores, CLFLUSH, Fences, lock, unlock, split lock",
+     .ucode = 1ULL << (15+8),
+     .grpid = 0,
+   },
+   { .uname  = "ANY_IFETCH",
+     .udesc  = "Request: combination of PF_IFETCH | DMND_IFETCH | PF_LLC_IFETCH",
+     .uequiv = "PF_IFETCH:DMND_IFETCH:PF_LLC_IFETCH",
+     .ucode = 0x24100,
+     .grpid = 0,
+   },
+   { .uname  = "ANY_REQUEST",
+     .udesc  = "Request: combination of all request umasks",
+     .uequiv = "DMND_DATA_RD:DMND_RFO:DMND_IFETCH:WB:PF_DATA_RD:PF_RFO:PF_IFETCH:PF_LLC_DATA_RD:PF_LLC_RFO:PF_LLC_IFETCH:BUS_LOCKS:STRM_ST:OTHER",
+     .ucode = 0x8fff00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+     .grpid = 0,
+   },
+   { .uname  = "ANY_DATA",
+     .udesc  = "Request: combination of DMND_DATA | PF_DATA_RD | PF_LLC_DATA_RD",
+     .uequiv = "DMND_DATA_RD:PF_DATA_RD:PF_LLC_DATA_RD",
+     .ucode = 0x9100,
+     .grpid = 0,
+   },
+   { .uname  = "ANY_RFO",
+     .udesc  = "Request: combination of DMND_RFO | PF_RFO | PF_LLC_RFO",
+     .uequiv = "DMND_RFO:PF_RFO:PF_LLC_RFO",
+     .ucode = 0x10300,
+     .grpid = 0,
+   },
+
+   { .uname  = "ANY_RESPONSE",
+     .udesc  = "Response: count any response type",
+     .ucode = 1ULL << (16+8),
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL | INTEL_X86_EXCL_GRP_GT,
+     .grpid = 1,
+   },
+   { .uname  = "NO_SUPP",
+     .udesc  = "Supplier: counts number of times supplier information is not available",
+     .ucode = 1ULL << (17+8),
+     .grpid = 1,
+   },
+   { .uname  = "LLC_HITM",
+     .udesc  = "Supplier: counts L3 hits in M-state (initial lookup)",
+     .ucode = 1ULL << (18+8),
+     .umodel = PFM_PMU_INTEL_BDW,
+     .grpid = 1,
+   },
+   { .uname  = "LLC_HITE",
+     .udesc  = "Supplier: counts L3 hits in E-state",
+     .ucode = 1ULL << (19+8),
+     .umodel = PFM_PMU_INTEL_BDW,
+     .grpid = 1,
+   },
+   { .uname  = "LLC_HITS",
+     .udesc  = "Supplier: counts L3 hits in S-state",
+     .ucode = 1ULL << (20+8),
+     .umodel = PFM_PMU_INTEL_BDW,
+     .grpid = 1,
+   },
+   { .uname  = "LLC_HITF",
+     .udesc  = "Supplier: counts L3 hits in F-state",
+     .ucode = 1ULL << (21+8),
+     .umodel = PFM_PMU_INTEL_BDW,
+     .grpid = 1,
+   },
+   { .uname  = "LLC_HITMESF",
+     .udesc  = "Supplier: counts L3 hits in any state (M, E, S, F)",
+     .ucode  = 0xfULL << (18+8),
+     .uequiv = "LLC_HITM:LLC_HITE:LLC_HITS:LLC_HITF",
+     .umodel = PFM_PMU_INTEL_BDW,
+     .grpid  = 1,
+   },
+   { .uname  = "LLC_HIT",
+     .udesc  = "Alias for LLC_HITMESF",
+     .ucode  = 0xfULL << (18+8),
+     .uequiv = "LLC_HITM:LLC_HITE:LLC_HITS:LLC_HITF",
+     .umodel = PFM_PMU_INTEL_BDW,
+     .grpid  = 1,
+   },
+   { .uname  = "LLC_MISS_LOCAL",
+     .udesc  = "Supplier: counts L3 misses to local DRAM",
+     .ucode = 1ULL << (22+8),
+     .umodel = PFM_PMU_INTEL_BDW,
+     .grpid = 1,
+   },
+   { .uname  = "SNP_NONE",
+     .udesc  = "Snoop: counts number of times no snoop-related information is available",
+     .ucode = 1ULL << (31+8),
+     .grpid = 2,
+   },
+   { .uname  = "SNP_NOT_NEEDED",
+     .udesc  = "Snoop: counts the number of times no snoop was needed to satisfy the request",
+     .ucode = 1ULL << (32+8),
+     .grpid = 2,
+   },
+   { .uname  = "SNP_MISS",
+     .udesc  = "Snoop: counts number of times a snoop was needed and it missed all snooped caches",
+     .ucode = 1ULL << (33+8),
+     .grpid = 2,
+   },
+   { .uname  = "SNP_NO_FWD",
+     .udesc  = "Snoop: counts number of times a snoop was needed and it hit in at leas one snooped cache",
+     .ucode = 1ULL << (34+8),
+     .grpid = 2,
+   },
+   { .uname  = "SNP_FWD",
+     .udesc  = "Snoop: counts number of times a snoop was needed and data was forwarded from a remote socket",
+     .ucode = 1ULL << (35+8),
+     .grpid = 2,
+   },
+   { .uname  = "HITM",
+     .udesc  = "Snoop: counts number of times a snoop was needed and it hitM-ed in local or remote cache",
+     .ucode = 1ULL << (36+8),
+     .grpid = 2,
+   },
+   { .uname  = "NON_DRAM",
+     .udesc  = "Snoop:  counts number of times target was a non-DRAM system address. This includes MMIO transactions",
+     .ucode = 1ULL << (37+8),
+     .grpid = 2,
+   },
+   { .uname  = "SNP_ANY",
+     .udesc  = "Snoop: any snoop reason",
+     .ucode = 0x7fULL << (31+8),
+     .uequiv = "SNP_NONE:SNP_NOT_NEEDED:SNP_MISS:SNP_NO_FWD:SNP_FWD:HITM:NON_DRAM",
+     .uflags= INTEL_X86_DFL,
+     .grpid = 2,
+   },
+};
+
+static const intel_x86_umask_t bdw_hle_retired[]={
+  { .uname = "START",
+    .udesc  = "Number of times an HLE execution started",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "COMMIT",
+    .udesc  = "Number of times an HLE execution successfully committed",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED",
+    .udesc  = "Number of times an HLE execution aborted due to any reasons (multiple categories may count as one) (Precise Event)",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "ABORTED_MISC1",
+    .udesc  = "Number of times an HLE execution aborted due to various memory events",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED_MISC2",
+    .udesc  = "Number of times an HLE execution aborted due to uncommon conditions",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED_MISC3",
+    .udesc  = "Number of times an HLE execution aborted due to HLE-unfriendly instructions",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED_MISC4",
+    .udesc  = "Number of times an HLE execution aborted due to incompatible memory type",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED_MISC5",
+    .udesc  = "Number of times an HLE execution aborted due to none of the other 4 reasons (e.g., interrupt)",
+    .ucode  = 0x8000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_rtm_retired[]={
+  { .uname = "START",
+    .udesc  = "Number of times an RTM execution started",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
+  },
+  { .uname = "COMMIT",
+    .udesc  = "Number of times an RTM execution successfully committed",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED",
+    .udesc  = "Number of times an RTM execution aborted due to any reasons (multiple categories may count as one) (Precise Event)",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+  },
+  { .uname = "ABORTED_MISC1",
+    .udesc  = "Number of times an RTM execution aborted due to various memory events",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED_MISC2",
+    .udesc  = "Number of times an RTM execution aborted due to uncommon conditions",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED_MISC3",
+    .udesc  = "Number of times an RTM execution aborted due to RTM-unfriendly instructions",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED_MISC4",
+    .udesc  = "Number of times an RTM execution aborted due to incompatible memory type",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORTED_MISC5",
+    .udesc  = "Number of times an RTM execution aborted due to none of the other 4 reasons (e.g., interrupt)",
+    .ucode  = 0x8000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_tx_mem[]={
+  { .uname = "ABORT_CONFLICT",
+    .udesc  = "Number of times a transactional abort was signaled due to data conflict on a transactionally accessed address",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORT_CAPACITY",
+    .udesc  = "Number of times a transactional abort was signaled due to data capacity limitation",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORT_HLE_STORE_TO_ELIDED_LOCK",
+    .udesc  = "Number of times a HLE transactional execution aborted due to a non xrelease prefixed instruction writing to an elided lock in the elision buffer",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORT_HLE_ELISION_BUFFER_NOT_EMPTY",
+    .udesc  = "Number of times a HLE transactional execution aborted due to NoAllocatedElisionBuffer being non-zero",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORT_HLE_ELISION_BUFFER_MISMATCH",
+    .udesc  = "Number of times a HLE transaction execution aborted due to xrelease lock not satisfying the address and value requirements in the elision buffer",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORT_HLE_ELISION_BUFFER_UNSUPPORTED_ALIGNMENT",
+    .udesc  = "Number of times a HLE transaction execution aborted due to an unsupported read alignment from the elision buffer",
+    .ucode  = 0x2000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "ABORT_HLE_ELISION_BUFFER_FULL",
+    .udesc  = "Number of times a HLE clock could not be elided due to ElisionBufferAvailable being zero",
+    .ucode  = 0x4000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_tx_exec[]={
+  { .uname = "MISC1",
+    .udesc  = "Number of times a class of instructions that may cause a transactional abort was executed. Since this is the count of execution, it may not always cause a transactional abort",
+    .ucode  = 0x100,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MISC2",
+    .udesc  = "Number of times a class of instructions that may cause a transactional abort was executed inside a transactional region",
+    .ucode  = 0x200,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MISC3",
+    .udesc  = "Number of times an instruction execution caused the supported nest count to be exceeded",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MISC4",
+    .udesc  = "Number of times an instruction a xbegin instruction was executed inside HLE transactional region",
+    .ucode  = 0x800,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "MISC5",
+    .udesc  = "Number of times an instruction with HLE xacquire prefix was executed inside a RTM transactional region",
+    .ucode  = 0x1000,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+};
+
+static const intel_x86_umask_t bdw_offcore_requests_outstanding[]={
+   { .uname  = "ALL_DATA_RD_CYCLES",
+     .udesc  = "Cycles with cacheable data read transactions in the superQ (use with HT off only)",
+     .uequiv = "ALL_DATA_RD:c=1",
+     .ucode = 0x800 | (0x1 << INTEL_X86_CMASK_BIT),
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "DEMAND_CODE_RD_CYCLES",
+     .udesc  = "Cycles with demand code reads transactions in the superQ (use with HT off only)",
+     .uequiv = "DEMAND_CODE_RD:c=1",
+     .ucode = 0x200 | (0x1 << INTEL_X86_CMASK_BIT),
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "DEMAND_DATA_RD_CYCLES",
+     .udesc  = "Cycles with demand data read transactions in the superQ (use with HT off only)",
+     .uequiv = "DEMAND_DATA_RD:c=1",
+     .ucode = 0x100 | (0x1 << INTEL_X86_CMASK_BIT),
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "ALL_DATA_RD",
+     .udesc  = "Cacheable data read transactions in the superQ every cycle (use with HT off only)",
+     .ucode = 0x800,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "DEMAND_CODE_RD",
+     .udesc  = "Code read transactions in the superQ every cycle (use with HT off only)",
+     .ucode = 0x200,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "DEMAND_DATA_RD",
+     .udesc  = "Demand data read transactions in the superQ every cycle (use with HT off only)",
+     .ucode = 0x100,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "DEMAND_RFO",
+     .udesc  = "Outstanding RFO (store) transactions in the superQ every cycle (use with HT off only)",
+     .ucode = 0x400,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "DEMAND_RFO_CYCLES",
+     .udesc  = "Cycles with outstanding RFO (store) transactions in the superQ (use with HT off only)",
+     .uequiv = "DEMAND_RFO:c=1",
+     .ucode = 0x400 | (0x1 << INTEL_X86_CMASK_BIT),
+     .uflags= INTEL_X86_NCOMBO,
+   },
+};
+
+static const intel_x86_umask_t bdw_ild_stall[]={
+   { .uname  = "LCP",
+     .udesc  = "Stall caused by changing prefix length of the instruction",
+     .ucode = 0x100,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+   },
+};
+
+static const intel_x86_umask_t bdw_page_walker_loads[]={
+   { .uname  = "DTLB_L1",
+     .udesc  = "Number of DTLB page walker loads that hit in the L1D and line fill buffer",
+     .ucode = 0x1100,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "ITLB_L1",
+     .udesc  = "Number of ITLB page walker loads that hit in the L1I and line fill buffer",
+     .ucode = 0x2100,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "DTLB_L2",
+     .udesc  = "Number of DTLB page walker loads that hit in the L2",
+     .ucode = 0x1200,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "ITLB_L2",
+     .udesc  = "Number of ITLB page walker loads that hit in the L2",
+     .ucode = 0x2200,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "DTLB_L3",
+     .udesc  = "Number of DTLB page walker loads that hit in the L3",
+     .ucode = 0x1400,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "ITLB_L3",
+     .udesc  = "Number of ITLB page walker loads that hit in the L3",
+     .ucode = 0x2400,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "DTLB_MEMORY",
+     .udesc  = "Number of DTLB page walker loads that hit memory",
+     .ucode = 0x1800,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "ITLB_MEMORY",
+     .udesc  = "Number of ITLB page walker loads that hit memory",
+     .ucode = 0x2800,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+};
+
+static const intel_x86_umask_t bdw_lsd[]={
+   { .uname  = "UOPS",
+     .udesc  = "Number of uops delivered by the Loop Stream Detector (LSD)",
+     .ucode = 0x100,
+     .uflags= INTEL_X86_DFL,
+   },
+};
+
+static const intel_x86_umask_t bdw_dsb2mite_switches[]={
+   { .uname  = "PENALTY_CYCLES",
+     .udesc  = "Number of DSB to MITE switch true penalty cycles",
+     .ucode = 0x0200,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+   },
+};
+
+static const intel_x86_umask_t bdw_ept[]={
+   { .uname  = "CYCLES",
+     .udesc  = "Cycles for an extended page table walk",
+     .ucode = 0x0200,
+     .uequiv = "WALK_CYCLES",
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "WALK_CYCLES",
+     .udesc  = "Cycles for an extended page table walk",
+     .ucode = 0x0200,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+   },
+};
+
+static const intel_x86_umask_t bdw_arith[]={
+   { .uname  = "FPU_DIV_ACTIVE",
+     .udesc  = "Cycles when divider is busy execuing divide operations",
+     .ucode = 0x0100,
+     .uflags= INTEL_X86_DFL,
+   },
+};
+
+static const intel_x86_entry_t intel_bdw_pe[]={
+  { .name   = "UNHALTED_CORE_CYCLES",
+    .desc   = "Count core clock cycles whenever the clock signal on the specific core is running (not halted)",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0x20000000full,
+    .code = 0x3c,
+  },
+  { .name   = "UNHALTED_REFERENCE_CYCLES",
+    .desc   = "Unhalted reference cycles",
+    .modmsk = INTEL_FIXED3_ATTRS,
+    .cntmsk = 0x400000000ull,
+    .code = 0x0300, /* pseudo encoding */
+    .flags = INTEL_X86_FIXED,
+  },
+  { .name   = "INSTRUCTION_RETIRED",
+    .desc   = "Number of instructions at retirement",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0x10000000full,
+    .code = 0xc0,
+  },
+  { .name   = "INSTRUCTIONS_RETIRED",
+    .desc   = "This is an alias for INSTRUCTION_RETIRED",
+    .modmsk = INTEL_V4_ATTRS,
+    .equiv = "INSTRUCTION_RETIRED",
+    .cntmsk = 0x10000000full,
+    .code = 0xc0,
+  },
+  { .name   = "BRANCH_INSTRUCTIONS_RETIRED",
+    .desc   = "Count branch instructions at retirement. Specifically, this event counts the retirement of the last micro-op of a branch instruction",
+    .modmsk = INTEL_V4_ATTRS,
+    .equiv = "BR_INST_RETIRED:ALL_BRANCHES",
+    .cntmsk = 0xff,
+    .code = 0xc4,
+  },
+  { .name   = "MISPREDICTED_BRANCH_RETIRED",
+    .desc   = "Count mispredicted branch instructions at retirement. Specifically, this event counts at retirement of the last micro-op of a branch instruction in the architectural path of the execution and experienced misprediction in the branch prediction hardware",
+    .modmsk = INTEL_V4_ATTRS,
+    .equiv = "BR_MISP_RETIRED:ALL_BRANCHES",
+    .cntmsk = 0xff,
+    .code = 0xc5,
+  },
+  { .name = "BACLEARS",
+    .desc   = "Branch re-steered",
+    .code = 0xe6,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_baclears),
+    .umasks  = bdw_baclears
+  },
+  { .name = "BR_INST_EXEC",
+    .desc   = "Branch instructions executed",
+    .code = 0x88,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_br_inst_exec),
+    .umasks  = bdw_br_inst_exec
+  },
+  { .name = "BR_INST_RETIRED",
+    .desc   = "Branch instructions retired (Precise Event)",
+    .code = 0xc4,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_br_inst_retired),
+    .umasks  = bdw_br_inst_retired
+  },
+  { .name = "BR_MISP_EXEC",
+    .desc   = "Mispredicted branches executed",
+    .code = 0x89,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_br_misp_exec),
+    .umasks  = bdw_br_misp_exec
+  },
+  { .name = "BR_MISP_RETIRED",
+    .desc   = "Mispredicted retired branches (Precise Event)",
+    .code = 0xc5,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_br_misp_retired),
+    .umasks  = bdw_br_misp_retired
+  },
+  { .name = "CPL_CYCLES",
+    .desc   = "Unhalted core cycles at a specific ring level",
+    .code = 0x5c,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_cpl_cycles),
+    .umasks  = bdw_cpl_cycles
+  },
+  { .name = "CPU_CLK_THREAD_UNHALTED",
+    .desc   = "Count core clock cycles whenever the clock signal on the specific core is running (not halted)",
+    .code = 0x3c,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_cpu_clk_thread_unhalted),
+    .umasks  = bdw_cpu_clk_thread_unhalted
+  },
+  { .name = "CPU_CLK_UNHALTED",
+    .desc   = "Count core clock cycles whenever the clock signal on the specific core is running (not halted)",
+    .code = 0x3c,
+    .cntmsk = 0xff,
+    .modmsk = INTEL_V4_ATTRS,
+    .equiv = "CPU_CLK_THREAD_UNHALTED",
+  },
+  { .name = "CYCLE_ACTIVITY",
+    .desc   = "Stalled cycles",
+    .code = 0xa3,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS & ~_INTEL_X86_ATTR_C,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_cycle_activity),
+    .umasks  = bdw_cycle_activity
+  },
+  { .name = "DTLB_LOAD_MISSES",
+    .desc   = "Data TLB load misses",
+    .code = 0x8,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_dtlb_load_misses),
+    .umasks  = bdw_dtlb_load_misses
+  },
+  { .name = "DTLB_STORE_MISSES",
+    .desc = "Data TLB store misses",
+    .code = 0x49,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_dtlb_load_misses),
+    .umasks  = bdw_dtlb_load_misses /* shared */
+  },
+  { .name = "FP_ASSIST",
+    .desc = "X87 floating-point assists",
+    .code = 0xca,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_fp_assist),
+    .umasks  = bdw_fp_assist
+  },
+  { .name = "HLE_RETIRED",
+    .desc = "HLE execution (Precise Event)",
+    .code = 0xc8,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_hle_retired),
+    .umasks  = bdw_hle_retired
+  },
+  { .name = "ICACHE",
+    .desc = "Instruction Cache",
+    .code = 0x80,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_icache),
+    .umasks  = bdw_icache
+  },
+  { .name = "IDQ",
+    .desc   = "IDQ operations",
+    .code = 0x79,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_idq),
+    .umasks  = bdw_idq
+  },
+  { .name = "IDQ_UOPS_NOT_DELIVERED",
+    .desc   = "Uops not delivered",
+    .code = 0x9c,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_idq_uops_not_delivered),
+    .umasks  = bdw_idq_uops_not_delivered
+  },
+  { .name = "INST_RETIRED",
+    .desc = "Number of instructions retired (Precise Event)",
+    .code = 0xc0,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_inst_retired),
+    .umasks  = bdw_inst_retired
+  },
+  { .name = "INT_MISC",
+    .desc = "Miscellaneous interruptions",
+    .code = 0xd,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_int_misc),
+    .umasks  = bdw_int_misc
+  },
+  { .name = "ITLB",
+    .desc   = "Instruction TLB",
+    .code = 0xae,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_itlb),
+    .umasks  = bdw_itlb
+  },
+  { .name = "ITLB_MISSES",
+    .desc = "Instruction TLB misses",
+    .code = 0x85,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_itlb_misses),
+    .umasks  = bdw_itlb_misses
+  },
+  { .name = "L1D",
+    .desc   = "L1D cache",
+    .code = 0x51,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_l1d),
+    .umasks  = bdw_l1d
+  },
+  { .name = "L1D_PEND_MISS",
+    .desc   = "L1D pending misses",
+    .code = 0x48,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_l1d_pend_miss),
+    .umasks  = bdw_l1d_pend_miss
+  },
+  { .name = "L2_DEMAND_RQSTS",
+    .desc = "Demand Data Read requests to L2",
+    .code = 0x27,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_l2_demand_rqsts),
+    .umasks  = bdw_l2_demand_rqsts
+  },
+  { .name = "L2_LINES_IN",
+    .desc   = "L2 lines allocated",
+    .code = 0xf1,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_l2_lines_in),
+    .umasks  = bdw_l2_lines_in
+  },
+  { .name = "L2_LINES_OUT",
+    .desc   = "L2 lines evicted",
+    .code = 0xf2,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_l2_lines_out),
+    .umasks  = bdw_l2_lines_out
+  },
+  { .name = "L2_RQSTS",
+    .desc   = "L2 requests",
+    .code = 0x24,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_l2_rqsts),
+    .umasks  = bdw_l2_rqsts
+  },
+  { .name = "L2_TRANS",
+    .desc   = "L2 transactions",
+    .code = 0xf0,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_l2_trans),
+    .umasks  = bdw_l2_trans
+  },
+  { .name = "LD_BLOCKS",
+    .desc   = "Blocking loads",
+    .code = 0x3,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_ld_blocks),
+    .umasks  = bdw_ld_blocks
+  },
+  { .name = "LD_BLOCKS_PARTIAL",
+    .desc   = "Partial load blocks",
+    .code = 0x7,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_ld_blocks_partial),
+    .umasks  = bdw_ld_blocks_partial
+  },
+  { .name = "LOAD_HIT_PRE",
+    .desc   = "Load dispatches",
+    .code = 0x4c,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_load_hit_pre),
+    .umasks  = bdw_load_hit_pre
+  },
+  { .name = "LOCK_CYCLES",
+    .desc   = "Locked cycles in L1D and L2",
+    .code = 0x63,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_lock_cycles),
+    .umasks  = bdw_lock_cycles
+  },
+  { .name = "LONGEST_LAT_CACHE",
+    .desc   = "L3 cache",
+    .code = 0x2e,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_longest_lat_cache),
+    .umasks  = bdw_longest_lat_cache
+  },
+  { .name = "MACHINE_CLEARS",
+    .desc   = "Machine clear asserted",
+    .code = 0xc3,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_machine_clears),
+    .umasks  = bdw_machine_clears
+  },
+  { .name = "MEM_LOAD_UOPS_L3_HIT_RETIRED",
+    .desc   = "L3 hit load uops retired (Precise Event)",
+    .code = 0xd2,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_mem_load_uops_l3_hit_retired),
+    .umasks  = bdw_mem_load_uops_l3_hit_retired
+  },
+  { .name = "MEM_LOAD_UOPS_LLC_HIT_RETIRED",
+    .desc   = "L3 hit load uops retired (Precise Event)",
+    .equiv = "MEM_LOAD_UOPS_L3_HIT_RETIRED",
+    .code = 0xd2,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_mem_load_uops_l3_hit_retired),
+    .umasks  = bdw_mem_load_uops_l3_hit_retired
+  },
+  { .name = "MEM_LOAD_UOPS_L3_MISS_RETIRED",
+    .desc   = "Load uops retired that missed the L3 (Precise Event)",
+    .code = 0xd3,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_mem_load_uops_l3_miss_retired),
+    .umasks  = bdw_mem_load_uops_l3_miss_retired
+  },
+  { .name = "MEM_LOAD_UOPS_LLC_MISS_RETIRED",
+    .desc   = "Load uops retired that missed the L3 (Precise Event)",
+    .equiv = "MEM_LOAD_UOPS_L3_MISS_RETIRED",
+    .code = 0xd3,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_mem_load_uops_l3_miss_retired),
+    .umasks  = bdw_mem_load_uops_l3_miss_retired
+  },
+  { .name = "MEM_LOAD_UOPS_RETIRED",
+    .desc = "Retired load uops (Precise Event)",
+    .code = 0xd1,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_mem_load_uops_retired),
+    .umasks  = bdw_mem_load_uops_retired
+  },
+  { .name = "MEM_TRANS_RETIRED",
+    .desc   = "Memory transactions retired (Precise Event)",
+    .code = 0xcd,
+    .cntmsk = 0x8,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS | _INTEL_X86_ATTR_LDLAT,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_mem_trans_retired),
+    .umasks  = bdw_mem_trans_retired
+  },
+  { .name = "MEM_UOPS_RETIRED",
+    .desc = "Memory uops retired (Precise Event)",
+    .code = 0xd0,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_mem_uops_retired),
+    .umasks  = bdw_mem_uops_retired
+  },
+  { .name = "MISALIGN_MEM_REF",
+    .desc = "Misaligned memory references",
+    .code = 0x5,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_misalign_mem_ref),
+    .umasks  = bdw_misalign_mem_ref
+  },
+  { .name = "MOVE_ELIMINATION",
+    .desc = "Move Elimination",
+    .code = 0x58,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_move_elimination),
+    .umasks  = bdw_move_elimination
+  },
+  { .name = "OFFCORE_REQUESTS",
+    .desc = "Demand Data Read requests sent to uncore",
+    .code = 0xb0,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_offcore_requests),
+    .umasks  = bdw_offcore_requests
+  },
+  { .name = "OTHER_ASSISTS",
+    .desc = "Software assist",
+    .code = 0xc1,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_other_assists),
+    .umasks  = bdw_other_assists
+  },
+  { .name = "RESOURCE_STALLS",
+    .desc = "Cycles Allocation is stalled due to Resource Related reason",
+    .code = 0xa2,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_resource_stalls),
+    .umasks  = bdw_resource_stalls
+  },
+  { .name = "ROB_MISC_EVENTS",
+    .desc = "ROB miscellaneous events",
+    .code = 0xcc,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_rob_misc_events),
+    .umasks  = bdw_rob_misc_events
+  },
+  { .name = "RS_EVENTS",
+    .desc = "Reservation Station",
+    .code = 0x5e,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_rs_events),
+    .umasks  = bdw_rs_events
+  },
+  { .name = "RTM_RETIRED",
+    .desc = "Restricted Transaction Memory execution (Precise Event)",
+    .code = 0xc9,
+    .cntmsk = 0xf,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_rtm_retired),
+    .umasks  = bdw_rtm_retired
+  },
+  { .name = "TLB_FLUSH",
+    .desc   = "TLB flushes",
+    .code = 0xbd,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_tlb_flush),
+    .umasks  = bdw_tlb_flush
+  },
+  { .name = "UOPS_EXECUTED",
+    .desc   = "Uops executed",
+    .code = 0xb1,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_uops_executed),
+    .umasks  = bdw_uops_executed
+  },
+  { .name = "LSD",
+    .desc   = "Loop stream detector",
+    .code = 0xa8,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_lsd),
+    .umasks  = bdw_lsd,
+  },
+
+  { .name = "UOPS_EXECUTED_PORT",
+    .desc   = "Uops dispatch to specific ports",
+    .code = 0xa1,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_uops_executed_port),
+    .umasks  = bdw_uops_executed_port
+  },
+  { .name = "UOPS_ISSUED",
+    .desc   = "Uops issued",
+    .code = 0xe,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_uops_issued),
+    .umasks  = bdw_uops_issued
+  },
+  { .name = "ARITH",
+    .desc   = "Arithmetic uop",
+    .code = 0x14,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_arith),
+    .umasks  = bdw_arith
+  },
+  { .name = "UOPS_RETIRED",
+    .desc = "Uops retired (Precise Event)",
+    .code = 0xc2,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .flags = INTEL_X86_PEBS,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_uops_retired),
+    .umasks  = bdw_uops_retired
+  },
+  { .name = "TX_MEM",
+    .desc = "Transactional memory aborts",
+    .code = 0x54,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_tx_mem),
+    .umasks  = bdw_tx_mem,
+  },
+  { .name = "TX_EXEC",
+    .desc = "Transactional execution",
+    .code = 0x5d,
+    .cntmsk = 0xff,
+    .ngrp = 1,
+    .modmsk = INTEL_V4_ATTRS,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_tx_exec),
+    .umasks  = bdw_tx_exec
+  },
+  { .name   = "OFFCORE_REQUESTS_OUTSTANDING",
+    .desc   = "Outstanding offcore requests",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0xff,
+    .code = 0x60,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_offcore_requests_outstanding),
+    .ngrp = 1,
+    .umasks = bdw_offcore_requests_outstanding,
+  },
+  { .name   = "ILD_STALL",
+    .desc   = "Instruction Length Decoder stalls",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0xff,
+    .code = 0x87,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_ild_stall),
+    .ngrp = 1,
+    .umasks = bdw_ild_stall,
+  },
+  { .name   = "PAGE_WALKER_LOADS",
+    .desc   = "Page walker loads",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0xf,
+    .code = 0xbc,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_page_walker_loads),
+    .ngrp = 1,
+    .umasks = bdw_page_walker_loads,
+  },
+  { .name   = "DSB2MITE_SWITCHES",
+    .desc   = "Number of DSB to MITE switches",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0xff,
+    .code = 0xab,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_dsb2mite_switches),
+    .ngrp = 1,
+    .umasks = bdw_dsb2mite_switches,
+  },
+  { .name   = "EPT",
+    .desc   = "Extended page table",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0xff,
+    .code = 0x4f,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_ept),
+    .ngrp = 1,
+    .umasks = bdw_ept,
+  },
+  { .name   = "OFFCORE_RESPONSE_0",
+    .desc   = "Offcore response event (must provide at least one request type and either any_response or any combination of supplier + snoop)",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0xf,
+    .code = 0x1b7,
+    .flags= INTEL_X86_NHM_OFFCORE,
+    .numasks = LIBPFM_ARRAY_SIZE(bdw_offcore_response),
+    .ngrp = 3,
+    .umasks = bdw_offcore_response,
+  },
+  { .name   = "OFFCORE_RESPONSE_1",
+    .desc   = "Offcore response event (must provide at least one request type and either any_response or any combination of supplier + snoop)",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0xf,
+    .code = 0x1bb,
+    .flags= INTEL_X86_NHM_OFFCORE,
+    .numasks =  LIBPFM_ARRAY_SIZE(bdw_offcore_response),
+    .ngrp = 3,
+    .umasks = bdw_offcore_response, /* identical to actual umasks list for this event */
+  },
+};
diff --git a/src/libpfm4/lib/events/intel_hsw_events.h b/src/libpfm4/lib/events/intel_hsw_events.h
index 0087f01..b6fd56f 100644
--- a/src/libpfm4/lib/events/intel_hsw_events.h
+++ b/src/libpfm4/lib/events/intel_hsw_events.h
@@ -322,6 +322,12 @@ static const intel_x86_umask_t hsw_cycle_activity[]={
      .ucntmsk= 0xf,
      .uflags = INTEL_X86_NCOMBO,
    },
+   { .uname  = "STALLS_LDM_PENDING",
+     .udesc  = "Execution stalls due to memory subsystem",
+     .ucode  = 0x0600 | (0x6 << INTEL_X86_CMASK_BIT),
+     .ucntmsk= 0xf,
+     .uflags = INTEL_X86_NCOMBO,
+   },
    { .uname  = "CYCLES_NO_EXECUTE",
      .udesc  = "Cycles during which no instructions were executed in the execution stage of the pipeline",
      .ucode  = 0x0400 | (0x4 << INTEL_X86_CMASK_BIT),
@@ -1621,12 +1627,19 @@ static const intel_x86_umask_t hsw_offcore_response[]={
      .umodel = PFM_PMU_INTEL_HSW,
      .grpid = 1,
    },
-   { .uname  = "L3_MISS_LOCAL",
+   { .uname  = "L3_MISS_LOCAL_DRAM",
      .udesc  = "Supplier: counts L3 misses to local DRAM",
      .ucode = 1ULL << (26+8),
      .umodel = PFM_PMU_INTEL_HSW_EP,
      .grpid = 1,
    },
+   { .uname  = "L3_MISS_LOCAL",
+     .udesc  = "Supplier: Alias to L3_MISS_LOCAL_DRAM",
+     .ucode = 1ULL << (26+8),
+     .umodel = PFM_PMU_INTEL_HSW_EP,
+     .uequiv = "L3_MISS_LOCAL_DRAM",
+     .grpid = 1,
+   },
    { .uname  = "L3_MISS_REMOTE_HOP0_DRAM",
      .udesc  = "Supplier: counts L3 misses to remote DRAM with 0 hop",
      .ucode = 0x1ULL << (27+8),
diff --git a/src/libpfm4/lib/pfmlib_amd64.c b/src/libpfm4/lib/pfmlib_amd64.c
index 98f55b8..1383804 100644
--- a/src/libpfm4/lib/pfmlib_amd64.c
+++ b/src/libpfm4/lib/pfmlib_amd64.c
@@ -347,6 +347,20 @@ pfm_amd64_detect(void *this)
 	return PFM_SUCCESS;
 }
 
+int
+pfm_amd64_family_detect(void *this)
+{
+	struct pfmlib_pmu *pmu = this;
+	int ret;
+
+	ret = pfm_amd64_detect(this);
+	if (ret != PFM_SUCCESS)
+		return ret;
+
+	ret = pfm_amd64_cfg.revision;
+	return ret == pmu->cpu_family ? PFM_SUCCESS : PFM_ERR_NOTSUPP;
+}
+
 static int
 amd64_add_defaults(void *this, pfmlib_event_desc_t *e, unsigned int msk, uint64_t *umask)
 {
diff --git a/src/libpfm4/lib/pfmlib_amd64_fam10h.c b/src/libpfm4/lib/pfmlib_amd64_fam10h.c
index 8627e46..60df01d 100644
--- a/src/libpfm4/lib/pfmlib_amd64_fam10h.c
+++ b/src/libpfm4/lib/pfmlib_amd64_fam10h.c
@@ -29,16 +29,6 @@
 #include "events/amd64_events_fam10h.h"
 
 #define DEFINE_FAM10H_REV(d, n, r, pmuid) \
-static int							\
-pfm_amd64_fam10h_##n##_detect(void *this)			\
-{								\
-	int ret;						\
-	ret = pfm_amd64_detect(this);				\
-	if (ret != PFM_SUCCESS)					\
-		return ret;					\
-	ret = pfm_amd64_cfg.revision;				\
-	return ret == pmuid ? PFM_SUCCESS : PFM_ERR_NOTSUPP;	\
-}								\
 pfmlib_pmu_t amd64_fam10h_##n##_support={			\
 	.desc			= "AMD64 Fam10h "#d,		\
 	.name			= "amd64_fam10h_"#n,		\
@@ -53,7 +43,8 @@ pfmlib_pmu_t amd64_fam10h_##n##_support={			\
 	.atdesc			= amd64_mods,			\
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK,	\
 								\
-	.pmu_detect		= pfm_amd64_fam10h_##n##_detect,\
+	.cpu_family		= pmuid,			\
+	.pmu_detect		= pfm_amd64_family_detect,	\
 	.get_event_encoding[PFM_OS_NONE] = pfm_amd64_get_encoding,\
 	 PFMLIB_ENCODE_PERF(pfm_amd64_get_perf_encoding),	\
 	.get_event_first	= pfm_amd64_get_event_first,	\
diff --git a/src/libpfm4/lib/pfmlib_amd64_fam11h.c b/src/libpfm4/lib/pfmlib_amd64_fam11h.c
index 2ae2fbc..6917e9c 100644
--- a/src/libpfm4/lib/pfmlib_amd64_fam11h.c
+++ b/src/libpfm4/lib/pfmlib_amd64_fam11h.c
@@ -29,16 +29,6 @@
 #include "events/amd64_events_fam11h.h"
 
 #define DEFINE_FAM11H_REV(d, n, r, pmuid) \
-static int							\
-pfm_amd64_fam11h_##n##_detect(void *this)			\
-{								\
-	int ret;						\
-	ret = pfm_amd64_detect(this);				\
-	if (ret != PFM_SUCCESS)					\
-		return ret;					\
-	ret = pfm_amd64_cfg.revision;				\
-	return ret == pmuid ? PFM_SUCCESS : PFM_ERR_NOTSUPP;	\
-}								\
 pfmlib_pmu_t amd64_fam11h_##n##_support={			\
 	.desc			= "AMD64 Fam11h "#d,		\
 	.name			= "amd64_fam11h_"#n,		\
@@ -53,7 +43,8 @@ pfmlib_pmu_t amd64_fam11h_##n##_support={			\
 	.atdesc			= amd64_mods,			\
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK,	\
 								\
-	.pmu_detect		= pfm_amd64_fam11h_##n##_detect,\
+	.cpu_family		= pmuid,			\
+	.pmu_detect		= pfm_amd64_family_detect,	\
 	.get_event_encoding[PFM_OS_NONE] = pfm_amd64_get_encoding,\
 	 PFMLIB_ENCODE_PERF(pfm_amd64_get_perf_encoding),	\
 	.get_event_first	= pfm_amd64_get_event_first,	\
diff --git a/src/libpfm4/lib/pfmlib_amd64_fam12h.c b/src/libpfm4/lib/pfmlib_amd64_fam12h.c
index 12f0b79..bd84167 100644
--- a/src/libpfm4/lib/pfmlib_amd64_fam12h.c
+++ b/src/libpfm4/lib/pfmlib_amd64_fam12h.c
@@ -29,16 +29,6 @@
 #include "events/amd64_events_fam12h.h"
 
 #define DEFINE_FAM12H_REV(d, n, r, pmuid) \
-static int							\
-pfm_amd64_fam12h_##n##_detect(void *this)			\
-{								\
-	int ret;						\
-	ret = pfm_amd64_detect(this);				\
-	if (ret != PFM_SUCCESS)					\
-		return ret;					\
-	ret = pfm_amd64_cfg.revision;				\
-	return ret == pmuid ? PFM_SUCCESS : PFM_ERR_NOTSUPP;	\
-}								\
 pfmlib_pmu_t amd64_fam12h_##n##_support={			\
 	.desc			= "AMD64 Fam12h "#d,		\
 	.name			= "amd64_fam12h_"#n,		\
@@ -53,7 +43,8 @@ pfmlib_pmu_t amd64_fam12h_##n##_support={			\
 	.atdesc			= amd64_mods,			\
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK,	\
 								\
-	.pmu_detect		= pfm_amd64_fam12h_##n##_detect,\
+	.cpu_family		= pmuid,			\
+	.pmu_detect		= pfm_amd64_family_detect,	\
 	.get_event_encoding[PFM_OS_NONE] = pfm_amd64_get_encoding,\
 	 PFMLIB_ENCODE_PERF(pfm_amd64_get_perf_encoding),	\
 	.get_event_first	= pfm_amd64_get_event_first,	\
diff --git a/src/libpfm4/lib/pfmlib_amd64_fam14h.c b/src/libpfm4/lib/pfmlib_amd64_fam14h.c
index ef3ea89..2f1fcb8 100644
--- a/src/libpfm4/lib/pfmlib_amd64_fam14h.c
+++ b/src/libpfm4/lib/pfmlib_amd64_fam14h.c
@@ -29,16 +29,6 @@
 #include "events/amd64_events_fam14h.h"
 
 #define DEFINE_FAM14H_REV(d, n, r, pmuid) \
-static int							\
-pfm_amd64_fam14h_##n##_detect(void *this)			\
-{								\
-	int ret;						\
-	ret = pfm_amd64_detect(this);				\
-	if (ret != PFM_SUCCESS)					\
-		return ret;					\
-	ret = pfm_amd64_cfg.revision;				\
-	return ret == pmuid ? PFM_SUCCESS : PFM_ERR_NOTSUPP;	\
-}								\
 pfmlib_pmu_t amd64_fam14h_##n##_support={			\
 	.desc			= "AMD64 Fam14h "#d,		\
 	.name			= "amd64_fam14h_"#n,		\
@@ -53,7 +43,8 @@ pfmlib_pmu_t amd64_fam14h_##n##_support={			\
 	.atdesc			= amd64_mods,			\
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK,	\
 								\
-	.pmu_detect		= pfm_amd64_fam14h_##n##_detect,\
+	.cpu_family		= pmuid,			\
+	.pmu_detect		= pfm_amd64_family_detect,	\
 	.get_event_encoding[PFM_OS_NONE] = pfm_amd64_get_encoding,\
 	 PFMLIB_ENCODE_PERF(pfm_amd64_get_perf_encoding),	\
 	.get_event_first	= pfm_amd64_get_event_first,	\
diff --git a/src/libpfm4/lib/pfmlib_amd64_fam15h.c b/src/libpfm4/lib/pfmlib_amd64_fam15h.c
index b752d87..4d14f46 100644
--- a/src/libpfm4/lib/pfmlib_amd64_fam15h.c
+++ b/src/libpfm4/lib/pfmlib_amd64_fam15h.c
@@ -29,21 +29,6 @@
 #include "events/amd64_events_fam15h.h"
 #include "events/amd64_events_fam15h_nb.h"
 
-static int
-pfm_amd64_fam15h_detect(void *this)
-{
-	int ret;
-
-	ret = pfm_amd64_detect(this);
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	if (pfm_amd64_cfg.revision == PFM_PMU_AMD64_FAM15H_INTERLAGOS)
-		return PFM_SUCCESS;
-
-	return PFM_ERR_NOTSUPP;
-}
-
 pfmlib_pmu_t amd64_fam15h_interlagos_support={
 	.desc			= "AMD64 Fam15h Interlagos",
 	.name			= "amd64_fam15h_interlagos",
@@ -57,7 +42,8 @@ pfmlib_pmu_t amd64_fam15h_interlagos_support={
 	.pe			= amd64_fam15h_pe,
 	.atdesc			= amd64_mods,
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK,
-	.pmu_detect		= pfm_amd64_fam15h_detect,
+	.cpu_family		= PFM_PMU_AMD64_FAM15H_INTERLAGOS,
+	.pmu_detect		= pfm_amd64_family_detect,
 	.get_event_encoding[PFM_OS_NONE] = pfm_amd64_get_encoding,
 	 PFMLIB_ENCODE_PERF(pfm_amd64_get_perf_encoding),
 	.get_event_first	= pfm_amd64_get_event_first,
@@ -84,7 +70,8 @@ pfmlib_pmu_t amd64_fam15h_nb_support={
 	.pe			= amd64_fam15h_nb_pe,
 	.atdesc			= amd64_mods,
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK,
-	.pmu_detect		= pfm_amd64_fam15h_detect,
+	.cpu_family		= PFM_PMU_AMD64_FAM15H_INTERLAGOS,
+	.pmu_detect		= pfm_amd64_family_detect,
 	.get_event_encoding[PFM_OS_NONE] = pfm_amd64_get_encoding,
 	 PFMLIB_ENCODE_PERF(pfm_amd64_get_perf_encoding),
 	.get_event_first	= pfm_amd64_get_event_first,
diff --git a/src/libpfm4/lib/pfmlib_amd64_k7.c b/src/libpfm4/lib/pfmlib_amd64_k7.c
index 18e8531..1601ad2 100644
--- a/src/libpfm4/lib/pfmlib_amd64_k7.c
+++ b/src/libpfm4/lib/pfmlib_amd64_k7.c
@@ -28,18 +28,6 @@
 #include "pfmlib_amd64_priv.h"
 #include "events/amd64_events_k7.h"
 
-static int
-pfm_amd64_k7_detect(void *this)
-{
-	int ret;
-
-	ret = pfm_amd64_detect(this);
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	ret = pfm_amd64_cfg.revision;
-	return ret == PFM_PMU_AMD64_K7 ? PFM_SUCCESS : PFM_ERR_NOTSUPP;
-}
 
 pfmlib_pmu_t amd64_k7_support={
 	.desc			= "AMD64 K7",
@@ -55,7 +43,8 @@ pfmlib_pmu_t amd64_k7_support={
 	.atdesc			= amd64_mods,
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK,
 
-	.pmu_detect		= pfm_amd64_k7_detect,
+	.cpu_family		= PFM_PMU_AMD64_K7,
+	.pmu_detect		= pfm_amd64_family_detect,
 
 	.get_event_encoding[PFM_OS_NONE] = pfm_amd64_get_encoding,
 	 PFMLIB_ENCODE_PERF(pfm_amd64_get_perf_encoding),
diff --git a/src/libpfm4/lib/pfmlib_amd64_k8.c b/src/libpfm4/lib/pfmlib_amd64_k8.c
index 1d5fa9a..9c2872b 100644
--- a/src/libpfm4/lib/pfmlib_amd64_k8.c
+++ b/src/libpfm4/lib/pfmlib_amd64_k8.c
@@ -29,16 +29,6 @@
 #include "events/amd64_events_k8.h"
 
 #define DEFINE_K8_REV(d, n, r, pmuid) \
-static int							\
-pfm_amd64_k8_##n##_detect(void *this)				\
-{								\
-	int ret;						\
-	ret = pfm_amd64_detect(this);				\
-	if (ret != PFM_SUCCESS)					\
-		return ret;					\
-	ret = pfm_amd64_cfg.revision;				\
-	return ret == pmuid ? PFM_SUCCESS : PFM_ERR_NOTSUPP;	\
-};								\
 pfmlib_pmu_t amd64_k8_##n##_support={				\
 	.desc			= "AMD64 K8 "#d,		\
 	.name			= "amd64_k8_"#n,		\
@@ -53,7 +43,8 @@ pfmlib_pmu_t amd64_k8_##n##_support={				\
 	.atdesc			= amd64_mods,			\
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK,	\
 								\
-	.pmu_detect		= pfm_amd64_k8_##n##_detect,	\
+	.cpu_family		= pmuid,			\
+	.pmu_detect		= pfm_amd64_family_detect,	\
 	.get_event_encoding[PFM_OS_NONE] = pfm_amd64_get_encoding, \
 	 PFMLIB_ENCODE_PERF(pfm_amd64_get_perf_encoding),	\
 	.get_event_first	= pfm_amd64_get_event_first,	\
diff --git a/src/libpfm4/lib/pfmlib_amd64_priv.h b/src/libpfm4/lib/pfmlib_amd64_priv.h
index 14c9526..66ca49e 100644
--- a/src/libpfm4/lib/pfmlib_amd64_priv.h
+++ b/src/libpfm4/lib/pfmlib_amd64_priv.h
@@ -213,4 +213,5 @@ extern int pfm_amd64_get_num_events(void *this);
 extern int pfm_amd64_get_perf_encoding(void *this, pfmlib_event_desc_t *e);
 extern void pfm_amd64_perf_validate_pattrs(void *this, pfmlib_event_desc_t *e);
 extern void pfm_amd64_nb_perf_validate_pattrs(void *this, pfmlib_event_desc_t *e);
+extern int pfm_amd64_family_detect(void *this);
 #endif /* __PFMLIB_AMD64_PRIV_H__ */
diff --git a/src/libpfm4/lib/pfmlib_arm_armv8.c b/src/libpfm4/lib/pfmlib_arm_armv8.c
index c38bd9b..3619508 100644
--- a/src/libpfm4/lib/pfmlib_arm_armv8.c
+++ b/src/libpfm4/lib/pfmlib_arm_armv8.c
@@ -32,6 +32,7 @@
 
 #include "events/arm_cortex_a57_events.h"    /* A57 event tables */
 #include "events/arm_cortex_a53_events.h"    /* A53 event tables */
+#include "events/arm_xgene_events.h"         /* Applied Micro X-Gene tables */
 
 static int
 pfm_arm_detect_cortex_a57(void *this)
@@ -65,6 +66,22 @@ pfm_arm_detect_cortex_a53(void *this)
 	return PFM_ERR_NOTSUPP;
 }
 
+static int
+pfm_arm_detect_xgene(void *this)
+{
+	int ret;
+
+	ret = pfm_arm_detect(this);
+	if (ret != PFM_SUCCESS)
+		return PFM_ERR_NOTSUPP;
+
+	if ((pfm_arm_cfg.implementer == 0x50) && /* Applied Micro */
+		(pfm_arm_cfg.part == 0x000)) { /* Applied Micro X-Gene */
+			return PFM_SUCCESS;
+	}
+	return PFM_ERR_NOTSUPP;
+}
+
 /* ARM Cortex A57 support */
 pfmlib_pmu_t arm_cortex_a57_support={
 	.desc			= "ARM Cortex A57",
@@ -114,3 +131,28 @@ pfmlib_pmu_t arm_cortex_a53_support={
 	 PFMLIB_VALID_PERF_PATTRS(pfm_arm_perf_validate_pattrs),
 	.get_event_nattrs	= pfm_arm_get_event_nattrs,
 };
+
+/* Applied Micro X-Gene support */
+pfmlib_pmu_t arm_xgene_support={
+	.desc			= "Applied Micro X-Gene",
+	.name			= "arm_xgene",
+	.pmu			= PFM_PMU_ARM_XGENE,
+	.pme_count		= LIBPFM_ARRAY_SIZE(arm_xgene_pe),
+	.type			= PFM_PMU_TYPE_CORE,
+	.pe			= arm_xgene_pe,
+
+	.pmu_detect		= pfm_arm_detect_xgene,
+	.max_encoding		= 1,
+	.num_cntrs		= 6,
+
+	.get_event_encoding[PFM_OS_NONE] = pfm_arm_get_encoding,
+	 PFMLIB_ENCODE_PERF(pfm_arm_get_perf_encoding),
+	.get_event_first	= pfm_arm_get_event_first,
+	.get_event_next		= pfm_arm_get_event_next,
+	.event_is_valid		= pfm_arm_event_is_valid,
+	.validate_table		= pfm_arm_validate_table,
+	.get_event_info		= pfm_arm_get_event_info,
+	.get_event_attr_info	= pfm_arm_get_event_attr_info,
+	 PFMLIB_VALID_PERF_PATTRS(pfm_arm_perf_validate_pattrs),
+	.get_event_nattrs	= pfm_arm_get_event_nattrs,
+};
diff --git a/src/libpfm4/lib/pfmlib_common.c b/src/libpfm4/lib/pfmlib_common.c
index 81903ff..d399d47 100644
--- a/src/libpfm4/lib/pfmlib_common.c
+++ b/src/libpfm4/lib/pfmlib_common.c
@@ -99,6 +99,7 @@ static pfmlib_pmu_t *pfmlib_pmus[]=
 	&intel_ivb_ep_support,
 	&intel_hsw_support,
 	&intel_hsw_ep_support,
+	&intel_bdw_support,
 	&intel_rapl_support,
 	&intel_snbep_unc_cb0_support,
 	&intel_snbep_unc_cb1_support,
@@ -203,10 +204,12 @@ static pfmlib_pmu_t *pfmlib_pmus[]=
 	&arm_qcom_krait_support,
 	&arm_cortex_a57_support,
 	&arm_cortex_a53_support,
+	&arm_xgene_support,
 #endif
 #ifdef CONFIG_PFMLIB_ARCH_ARM64
 	&arm_cortex_a57_support,
 	&arm_cortex_a53_support,
+	&arm_xgene_support,
 #endif
 
 #ifdef CONFIG_PFMLIB_ARCH_S390X
diff --git a/src/libpfm4/lib/pfmlib_intel_atom.c b/src/libpfm4/lib/pfmlib_intel_atom.c
index efdc670..5ce95a3 100644
--- a/src/libpfm4/lib/pfmlib_intel_atom.c
+++ b/src/libpfm4/lib/pfmlib_intel_atom.c
@@ -37,32 +37,14 @@
 #include "pfmlib_intel_x86_priv.h"
 #include "events/intel_atom_events.h"
 
-static int
-pfm_intel_atom_detect(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-	/*
-	 * Atom : family 6 model 28
-	 */
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
-
-	switch(pfm_intel_x86_cfg.model) {
-	case 28: /* Pineview/Silverthorne */
-	case 38: /* Lincroft */
-	case 39: /* Penwell */
-	case 53: /* Cloverview */
-	case 54: /* Cedarview */
-		break;
-	default:
-		return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
+static const int atom_models[] = {
+	28, /* Pineview/Silverthorne */
+	38, /* Lincroft */
+	39, /* Penwell */
+	53, /* Cloverview */
+	54, /* Cedarview */
+	0
+};
 
 static int
 pfm_intel_atom_init(void *this)
@@ -85,7 +67,9 @@ pfmlib_pmu_t intel_atom_support={
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK,
 	.supported_plm		= INTEL_X86_PLM,
 
-	.pmu_detect		= pfm_intel_atom_detect,
+	.cpu_family		= 6,
+	.cpu_models		= atom_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 	.pmu_init		= pfm_intel_atom_init,
 
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding,
diff --git a/src/libpfm4/lib/pfmlib_intel_bdw.c b/src/libpfm4/lib/pfmlib_intel_bdw.c
new file mode 100644
index 0000000..99be478
--- /dev/null
+++ b/src/libpfm4/lib/pfmlib_intel_bdw.c
@@ -0,0 +1,70 @@
+/*
+ * pfmlib_intel_bdw.c : Intel Broadwell core PMU
+ *
+ * Copyright (c) 2014 Google, Inc
+ * Contributed by Stephane Eranian <eranian@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ * of the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+ * PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
+ * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+/* private headers */
+#include "pfmlib_priv.h"
+#include "pfmlib_intel_x86_priv.h"
+#include "events/intel_bdw_events.h"
+
+static const int bdw_models[] = {
+	61, /* Broadwell Core-M */
+	0
+};
+
+static int
+pfm_bdw_init(void *this)
+{
+	pfm_intel_x86_cfg.arch_version = 4;
+	return PFM_SUCCESS;
+}
+
+pfmlib_pmu_t intel_bdw_support={
+	.desc			= "Intel Broadwell",
+	.name			= "bdw",
+	.pmu			= PFM_PMU_INTEL_BDW,
+	.pme_count		= LIBPFM_ARRAY_SIZE(intel_bdw_pe),
+	.type			= PFM_PMU_TYPE_CORE,
+	.supported_plm		= INTEL_X86_PLM,
+	.num_cntrs		= 8, /* consider with HT off by default */
+	.num_fixed_cntrs	= 3,
+	.max_encoding		= 2, /* offcore_response */
+	.pe			= intel_bdw_pe,
+	.atdesc			= intel_x86_mods,
+	.flags			= PFMLIB_PMU_FL_RAW_UMASK
+				| INTEL_X86_PMU_FL_ECMASK,
+	.cpu_family		= 6,
+	.cpu_models		= bdw_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
+	.pmu_init		= pfm_bdw_init,
+	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding,
+	 PFMLIB_ENCODE_PERF(pfm_intel_x86_get_perf_encoding),
+	.get_event_first	= pfm_intel_x86_get_event_first,
+	.get_event_next		= pfm_intel_x86_get_event_next,
+	.event_is_valid		= pfm_intel_x86_event_is_valid,
+	.validate_table		= pfm_intel_x86_validate_table,
+	.get_event_info		= pfm_intel_x86_get_event_info,
+	.get_event_attr_info	= pfm_intel_x86_get_event_attr_info,
+	 PFMLIB_VALID_PERF_PATTRS(pfm_intel_x86_perf_validate_pattrs),
+	.get_event_nattrs	= pfm_intel_x86_get_event_nattrs,
+	.can_auto_encode	= pfm_intel_x86_can_auto_encode,
+};
diff --git a/src/libpfm4/lib/pfmlib_intel_core.c b/src/libpfm4/lib/pfmlib_intel_core.c
index 351168c..2eb42fa 100644
--- a/src/libpfm4/lib/pfmlib_intel_core.c
+++ b/src/libpfm4/lib/pfmlib_intel_core.c
@@ -33,28 +33,12 @@
 #include "pfmlib_intel_x86_priv.h"
 #include "events/intel_core_events.h"
 
-static int
-pfm_core_detect(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
-
-	switch(pfm_intel_x86_cfg.model) {
-		case 15: /* Merom */
-		case 23: /* Penryn */
-		case 29: /* Dunnington */
-			  break;
-		default:
-			return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
+static const int core_models[] = {
+	15, /* Merom */
+	23, /* Penryn */
+	29, /* Dunnington */
+	0
+};
 
 static int
 pfm_core_init(void *this)
@@ -78,7 +62,9 @@ pfmlib_pmu_t intel_core_support={
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK
 				| INTEL_X86_PMU_FL_ECMASK,
 
-	.pmu_detect		= pfm_core_detect,
+	.cpu_family		= 6,
+	.cpu_models		= core_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 	.pmu_init		= pfm_core_init,
 
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding,
diff --git a/src/libpfm4/lib/pfmlib_intel_hsw.c b/src/libpfm4/lib/pfmlib_intel_hsw.c
index 1feae63..3018eeb 100644
--- a/src/libpfm4/lib/pfmlib_intel_hsw.c
+++ b/src/libpfm4/lib/pfmlib_intel_hsw.c
@@ -26,50 +26,18 @@
 #include "pfmlib_intel_x86_priv.h"
 #include "events/intel_hsw_events.h"
 
-static int
-pfm_hsw_detect(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
-
-	switch (pfm_intel_x86_cfg.model) {
-		case 60: /* Haswell */
-		case 69: /* Haswell */
-		case 70: /* Haswell */
-		case 71: /* Haswell */
-			break;
-		default:
-			return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
-
-static int
-pfm_hsw_ep_detect(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
+static const int hsw_models[] = {
+	60, /* Haswell */
+	69, /* Haswell */
+	70, /* Haswell */
+	71, /* Haswell */
+	0
+};
 
-	switch (pfm_intel_x86_cfg.model) {
-		case 63: /* Haswell EP */
-			break;
-		default:
-			return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
+static const int hsw_ep_models[] = {
+	63, /* Haswell */
+	0
+};
 
 static int
 pfm_hsw_init(void *this)
@@ -92,7 +60,9 @@ pfmlib_pmu_t intel_hsw_support={
 	.atdesc			= intel_x86_mods,
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK
 				| INTEL_X86_PMU_FL_ECMASK,
-	.pmu_detect		= pfm_hsw_detect,
+	.cpu_family		= 6,
+	.cpu_models		= hsw_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 	.pmu_init		= pfm_hsw_init,
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding,
 	 PFMLIB_ENCODE_PERF(pfm_intel_x86_get_perf_encoding),
@@ -121,7 +91,9 @@ pfmlib_pmu_t intel_hsw_ep_support={
 	.atdesc			= intel_x86_mods,
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK
 				| INTEL_X86_PMU_FL_ECMASK,
-	.pmu_detect		= pfm_hsw_ep_detect,
+	.cpu_family		= 6,
+	.cpu_models		= hsw_ep_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 	.pmu_init		= pfm_hsw_init,
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding,
 	 PFMLIB_ENCODE_PERF(pfm_intel_x86_get_perf_encoding),
diff --git a/src/libpfm4/lib/pfmlib_intel_ivb.c b/src/libpfm4/lib/pfmlib_intel_ivb.c
index e11b6b7..696c88b 100644
--- a/src/libpfm4/lib/pfmlib_intel_ivb.c
+++ b/src/libpfm4/lib/pfmlib_intel_ivb.c
@@ -27,54 +27,22 @@
 #include "events/intel_ivb_events.h"
 
 static int
-pfm_ivb_detect(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
-
-	switch (pfm_intel_x86_cfg.model) {
-		case 58: /* IvyBridge (Core i3/i5/i7 3xxx) */
-			break;
-		default:
-			return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
-
-static int
-pfm_ivbep_detect(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
-
-	switch (pfm_intel_x86_cfg.model) {
-		case 62: /* IvyTown */
-			break;
-		default:
-			return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
-
-static int
 pfm_ivb_init(void *this)
 {
 	pfm_intel_x86_cfg.arch_version = 3;
 	return PFM_SUCCESS;
 }
 
+static const int ivb_models[] = {
+	58, /* IvyBridge (Core i3/i5/i7 3xxx) */
+	0
+};
+
+static const int ivbep_models[] = {
+	62, /* Ivytown */
+	0
+};
+
 pfmlib_pmu_t intel_ivb_support={
 	.desc			= "Intel Ivy Bridge",
 	.name			= "ivb",
@@ -89,7 +57,9 @@ pfmlib_pmu_t intel_ivb_support={
 	.atdesc			= intel_x86_mods,
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK
 				| INTEL_X86_PMU_FL_ECMASK,
-	.pmu_detect		= pfm_ivb_detect,
+	.cpu_family		= 6,
+	.cpu_models		= ivb_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 	.pmu_init		= pfm_ivb_init,
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding,
 	 PFMLIB_ENCODE_PERF(pfm_intel_x86_get_perf_encoding),
@@ -118,7 +88,9 @@ pfmlib_pmu_t intel_ivb_ep_support={
 	.atdesc			= intel_x86_mods,
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK
 				| INTEL_X86_PMU_FL_ECMASK,
-	.pmu_detect		= pfm_ivbep_detect,
+	.cpu_family		= 6,
+	.cpu_models		= ivbep_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 	.pmu_init		= pfm_ivb_init,
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding,
 	 PFMLIB_ENCODE_PERF(pfm_intel_x86_get_perf_encoding),
diff --git a/src/libpfm4/lib/pfmlib_intel_knc.c b/src/libpfm4/lib/pfmlib_intel_knc.c
index 4537d0a..e65667e 100644
--- a/src/libpfm4/lib/pfmlib_intel_knc.c
+++ b/src/libpfm4/lib/pfmlib_intel_knc.c
@@ -26,26 +26,10 @@
 #include "pfmlib_intel_x86_priv.h"		/* architecture private */
 #include "events/intel_knc_events.h"
 
-static int
-pfm_knc_detect(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	if (pfm_intel_x86_cfg.family != 11)
-		return PFM_ERR_NOTSUPP;
-
-	switch (pfm_intel_x86_cfg.model) {
-		case 1: /* Knights Corner */
-			break;
-		default:
-			return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
+static const int knc_models[] = {
+	1, /* Knights Corner */
+	0
+};
 
 pfmlib_pmu_t intel_knc_support={
 	.desc			= "Intel Knights Corner",
@@ -59,7 +43,9 @@ pfmlib_pmu_t intel_knc_support={
 	.atdesc			= intel_x86_mods,
 	.supported_plm		= INTEL_X86_PLM,
 
-	.pmu_detect		= pfm_knc_detect,
+	.cpu_family		= 11,
+	.cpu_models		= knc_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding,
 	 PFMLIB_ENCODE_PERF(pfm_intel_x86_get_perf_encoding),
diff --git a/src/libpfm4/lib/pfmlib_intel_nhm.c b/src/libpfm4/lib/pfmlib_intel_nhm.c
index 55e3f1e..87ce5cf 100644
--- a/src/libpfm4/lib/pfmlib_intel_nhm.c
+++ b/src/libpfm4/lib/pfmlib_intel_nhm.c
@@ -34,49 +34,17 @@ static int pfm_nhm_offcore_encode(void *this, pfmlib_event_desc_t *e, uint64_t *
 
 #include "events/intel_nhm_events.h"
 
-static int
-pfm_nhm_detect(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
-
-	switch(pfm_intel_x86_cfg.model) {
-		case 26:
-		case 30:
-		case 31:
-			break;
-		default:
-			return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
-
-static int
-pfm_nhm_ex_detect(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
+static const int nhm_models[] = {
+	26,
+	30,
+	31,
+	0
+};
 
-	switch(pfm_intel_x86_cfg.model) {
-		case 46:
-			break;
-		default:
-			return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
+static const int nhm_ex_models[] = {
+	46,
+	0
+};
 
 static int
 pfm_nhm_init(void *this)
@@ -152,7 +120,9 @@ pfmlib_pmu_t intel_nhm_support={
 	.atdesc			= intel_x86_mods,
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK
 				| INTEL_X86_PMU_FL_ECMASK,
-	.pmu_detect		= pfm_nhm_detect,
+	.cpu_family		= 6,
+	.cpu_models		= nhm_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 	.pmu_init		= pfm_nhm_init,
 
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding,
@@ -183,7 +153,9 @@ pfmlib_pmu_t intel_nhm_ex_support={
 	.atdesc			= intel_x86_mods,
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK
 				| INTEL_X86_PMU_FL_ECMASK,
-	.pmu_detect		= pfm_nhm_ex_detect,
+	.cpu_family		= 6,
+	.cpu_models		= nhm_ex_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 	.pmu_init		= pfm_nhm_init,
 
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding,
diff --git a/src/libpfm4/lib/pfmlib_intel_nhm_unc.c b/src/libpfm4/lib/pfmlib_intel_nhm_unc.c
index c315259..fbf1b19 100644
--- a/src/libpfm4/lib/pfmlib_intel_nhm_unc.c
+++ b/src/libpfm4/lib/pfmlib_intel_nhm_unc.c
@@ -65,49 +65,18 @@ static const pfmlib_attr_desc_t nhm_unc_mods[]={
 	PFM_ATTR_NULL
 };
 
-static int
-pfm_nhm_unc_detect(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
-
-	switch(pfm_intel_x86_cfg.model) {
-		case 26: /* Nehalem */
-		case 30:
-		case 31:
-			  break;
-		default:
-			return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
-
-static int
-pfm_wsm_unc_detect(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
+static const int nhm_models[] = {
+	26,
+	30,
+	31,
+	0
+};
 
-	switch (pfm_intel_x86_cfg.model) {
-		case 37: /* Westmere */
-		case 44:
-			  break;
-		default:
-			return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
+static const int wsm_dp_models[] = {
+	44, /* Westmere-EP, Gulftown */
+	47, /* Westmere E7 */
+	0,
+};
 
 static int
 pfm_nhm_unc_get_encoding(void *this, pfmlib_event_desc_t *e)
@@ -329,7 +298,9 @@ pfmlib_pmu_t intel_nhm_unc_support={
 	.atdesc			= nhm_unc_mods,
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK,
 
-	.pmu_detect		= pfm_nhm_unc_detect,
+	.cpu_family		= 6,
+	.cpu_models		= nhm_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 
 	.get_event_encoding[PFM_OS_NONE] = pfm_nhm_unc_get_encoding,
 	 PFMLIB_ENCODE_PERF(pfm_intel_nhm_unc_get_perf_encoding),
@@ -359,7 +330,9 @@ pfmlib_pmu_t intel_wsm_unc_support={
 	.atdesc			= nhm_unc_mods,
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK,
 
-	.pmu_detect		= pfm_wsm_unc_detect,
+	.cpu_family		= 6,
+	.cpu_models		= wsm_dp_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 
 	.get_event_encoding[PFM_OS_NONE] = pfm_nhm_unc_get_encoding,
 	 PFMLIB_ENCODE_PERF(pfm_intel_nhm_unc_get_perf_encoding),
diff --git a/src/libpfm4/lib/pfmlib_intel_p6.c b/src/libpfm4/lib/pfmlib_intel_p6.c
index e5292cd..fa33874 100644
--- a/src/libpfm4/lib/pfmlib_intel_p6.c
+++ b/src/libpfm4/lib/pfmlib_intel_p6.c
@@ -30,96 +30,31 @@
 #include "events/intel_ppro_events.h"		/* Pentium Pro */
 #include "events/intel_pm_events.h"		/* Pentium M */
 
-static int
-pfm_p6_detect_pii(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
-
-	switch (pfm_intel_x86_cfg.model) {
-		case 3: /* Pentium II */
-		case 5: /* Pentium II Deschutes */
-		case 6: /* Pentium II Mendocino */
-			break;
-		default:
-			return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
-
-static int
-pfm_p6_detect_ppro(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
-
-	switch (pfm_intel_x86_cfg.model) {
-		case 1: /* Pentium Pro */
-			break;
-		default:
-			return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
-
-
-static int
-pfm_p6_detect_piii(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
-
-	switch (pfm_intel_x86_cfg.model) {
-		case 7: /* Pentium III Katmai */
-		case 8: /* Pentium III Coppermine */
-		case 10:/* Pentium III Cascades */
-		case 11:/* Pentium III Tualatin */
-			break;
-		default:
-			return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
-
-static int
-pfm_p6_detect_pm(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
-
-	switch (pfm_intel_x86_cfg.model) {
-		case 9: /* Pentium M */
-		case 13:/* Pentium M */
-			break;
-		default:
-			return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
+static const int pii_models[] = {
+	3, /* Pentium II */
+	5, /* Pentium II Deschutes */
+	6, /* Pentium II Mendocino */
+	0
+};
+
+static const int ppro_models[] = {
+	1, /* Pentium Pro */
+	0
+};
+
+static const int piii_models[] = {
+	7, /* Pentium III Katmai */
+	8, /* Pentium III Coppermine */
+	10,/* Pentium III Cascades */
+	11,/* Pentium III Tualatin */
+	0
+};
+
+static const int pm_models[] = {
+	9, /* Pentium M */
+	13, /* Pentium III Coppermine */
+	0
+};
 
 /* Pentium II support */
 pfmlib_pmu_t intel_pii_support={
@@ -132,7 +67,9 @@ pfmlib_pmu_t intel_pii_support={
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK,
 	.type			= PFM_PMU_TYPE_CORE,
 	.supported_plm		= INTEL_X86_PLM,
-	.pmu_detect		= pfm_p6_detect_pii,
+	.cpu_family		= 6,
+	.cpu_models		= pii_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 	.num_cntrs		= 2,
 	.max_encoding		= 1,
 
@@ -160,7 +97,9 @@ pfmlib_pmu_t intel_p6_support={
 	.type			= PFM_PMU_TYPE_CORE,
 	.supported_plm		= INTEL_X86_PLM,
 
-	.pmu_detect		= pfm_p6_detect_piii,
+	.cpu_family		= 6,
+	.cpu_models		= piii_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 	.num_cntrs		= 2,
 	.max_encoding		= 1,
 
@@ -188,7 +127,9 @@ pfmlib_pmu_t intel_ppro_support={
 	.type			= PFM_PMU_TYPE_CORE,
 	.supported_plm		= INTEL_X86_PLM,
 
-	.pmu_detect		= pfm_p6_detect_ppro,
+	.cpu_family		= 6,
+	.cpu_models		= ppro_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 	.num_cntrs		= 2,
 	.max_encoding		= 1,
 
@@ -215,7 +156,9 @@ pfmlib_pmu_t intel_pm_support={
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK,
 	.supported_plm		= INTEL_X86_PLM,
 
-	.pmu_detect		= pfm_p6_detect_pm,
+	.cpu_family		= 6,
+	.cpu_models		= pm_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 	.pme_count		= LIBPFM_ARRAY_SIZE(intel_pm_pe),
 	.type			= PFM_PMU_TYPE_CORE,
 	.num_cntrs		= 2,
diff --git a/src/libpfm4/lib/pfmlib_intel_slm.c b/src/libpfm4/lib/pfmlib_intel_slm.c
index ba61450..47e16c8 100644
--- a/src/libpfm4/lib/pfmlib_intel_slm.c
+++ b/src/libpfm4/lib/pfmlib_intel_slm.c
@@ -29,26 +29,11 @@
 #include "pfmlib_intel_x86_priv.h"
 #include "events/intel_slm_events.h"
 
-static int
-pfm_intel_slm_detect(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
-
-	switch(pfm_intel_x86_cfg.model) {
-	case 55: /* Silvermont */
-	case 77: /* Silvermont Avoton */
-		break;
-	default:
-		return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
+static const int slm_models[] = {
+	55, /* Silvermont */
+	77, /* Silvermont Avoton */
+	0
+};
 
 static int
 pfm_intel_slm_init(void *this)
@@ -72,7 +57,9 @@ pfmlib_pmu_t intel_slm_support={
 				| INTEL_X86_PMU_FL_ECMASK,
 	.supported_plm		= INTEL_X86_PLM,
 
-	.pmu_detect		= pfm_intel_slm_detect,
+	.cpu_family		= 6,
+	.cpu_models		= slm_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 	.pmu_init		= pfm_intel_slm_init,
 
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding,
diff --git a/src/libpfm4/lib/pfmlib_intel_snb.c b/src/libpfm4/lib/pfmlib_intel_snb.c
index 5e928ce..b57fdf4 100644
--- a/src/libpfm4/lib/pfmlib_intel_snb.c
+++ b/src/libpfm4/lib/pfmlib_intel_snb.c
@@ -27,47 +27,15 @@
 #include "events/intel_snb_events.h"
 #include "events/intel_snbep_events.h"
 
-static int
-pfm_snb_detect(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
-
-	switch (pfm_intel_x86_cfg.model) {
-		case 42: /* Sandy Bridge (Core i7 26xx, 25xx) */
-			break;
-		default:
-			return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
-
-static int
-pfm_snb_ep_detect(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
+static const int snb_models[] = {
+	42, /* Sandy Bridge (Core i7 26xx, 25xx) */
+	0
+};
 
-	switch (pfm_intel_x86_cfg.model) {
-		case 45: /* Sandy Bridge EP */
-			break;
-		default:
-			return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
+static const int snb_ep_models[] = {
+	45, /* Sandy Bridge EP */
+	0
+};
 
 static int
 pfm_snb_init(void *this)
@@ -90,7 +58,9 @@ pfmlib_pmu_t intel_snb_support={
 	.atdesc			= intel_x86_mods,
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK
 				| INTEL_X86_PMU_FL_ECMASK,
-	.pmu_detect		= pfm_snb_detect,
+	.cpu_family		= 6,
+	.cpu_models		= snb_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 	.pmu_init		= pfm_snb_init,
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding,
 	 PFMLIB_ENCODE_PERF(pfm_intel_x86_get_perf_encoding),
@@ -119,7 +89,9 @@ pfmlib_pmu_t intel_snb_ep_support={
 	.atdesc			= intel_x86_mods,
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK
 				| INTEL_X86_PMU_FL_ECMASK,
-	.pmu_detect		= pfm_snb_ep_detect,
+	.cpu_family		= 6,
+	.cpu_models		= snb_ep_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 	.pmu_init		= pfm_snb_init,
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding,
 	 PFMLIB_ENCODE_PERF(pfm_intel_x86_get_perf_encoding),
diff --git a/src/libpfm4/lib/pfmlib_intel_snb_unc.c b/src/libpfm4/lib/pfmlib_intel_snb_unc.c
index b76c5c0..edae361 100644
--- a/src/libpfm4/lib/pfmlib_intel_snb_unc.c
+++ b/src/libpfm4/lib/pfmlib_intel_snb_unc.c
@@ -30,26 +30,10 @@
 
 #include "events/intel_snb_unc_events.h"
 
-static int
-pfm_snb_unc_detect(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
-
-	switch (pfm_intel_x86_cfg.model) {
-		case 42: /* Sandy Bridge (Core i7 26xx, 25xx) */
-			break;
-		default:
-			return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
+static const int snb_models[] = {
+	42, /* Sandy Bridge (Core i7 26xx, 25xx) */
+	0
+};
 
 #define SNB_UNC_CBOX(n, p) \
 pfmlib_pmu_t intel_snb_unc_cbo##n##_support={ \
@@ -66,7 +50,9 @@ pfmlib_pmu_t intel_snb_unc_cbo##n##_support={ \
 	.atdesc			= intel_x86_mods, \
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK\
 				| PFMLIB_PMU_FL_NO_SMPL,\
-	.pmu_detect		= pfm_snb_unc_detect, \
+	.cpu_family		= 6,\
+	.cpu_models		= snb_models, \
+	.pmu_detect		= pfm_intel_x86_model_detect,\
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding, \
 	 PFMLIB_ENCODE_PERF(pfm_intel_nhm_unc_get_perf_encoding), \
 	 PFMLIB_OS_DETECT(pfm_intel_x86_perf_detect), \
diff --git a/src/libpfm4/lib/pfmlib_intel_wsm.c b/src/libpfm4/lib/pfmlib_intel_wsm.c
index d27d7c7..2b581b4 100644
--- a/src/libpfm4/lib/pfmlib_intel_wsm.c
+++ b/src/libpfm4/lib/pfmlib_intel_wsm.c
@@ -26,48 +26,16 @@
 #include "pfmlib_intel_x86_priv.h"
 #include "events/intel_wsm_events.h"
 
-static int
-pfm_wsm_sp_detect(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
-
-	switch (pfm_intel_x86_cfg.model) {
-		case 37: /* Clarkdale */
-			break;
-		default:
-			return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
-
-static int
-pfm_wsm_dp_detect(void *this)
-{
-	int ret;
-
-	ret = pfm_intel_x86_detect();
-	if (ret != PFM_SUCCESS)
-		return ret;
-
-	if (pfm_intel_x86_cfg.family != 6)
-		return PFM_ERR_NOTSUPP;
+static const int wsm_models[] = {
+	37, /* Clarkdale */
+	0,
+};
 
-	switch (pfm_intel_x86_cfg.model) {
-		case 44: /* Westmere-EP, Gulftown */
-		case 47: /* Westmere E7 */
-			break;
-		default:
-			return PFM_ERR_NOTSUPP;
-	}
-	return PFM_SUCCESS;
-}
+static const int wsm_dp_models[] = {
+	44, /* Westmere-EP, Gulftown */
+	47, /* Westmere E7 */
+	0,
+};
 
 static int
 pfm_wsm_init(void *this)
@@ -90,7 +58,9 @@ pfmlib_pmu_t intel_wsm_sp_support={
 	.atdesc			= intel_x86_mods,
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK
 				| INTEL_X86_PMU_FL_ECMASK,
-	.pmu_detect		= pfm_wsm_sp_detect,
+	.cpu_family		= 6,
+	.cpu_models		= wsm_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 	.pmu_init		= pfm_wsm_init,
 
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding,
@@ -121,7 +91,9 @@ pfmlib_pmu_t intel_wsm_dp_support={
 	.atdesc			= intel_x86_mods,
 	.flags			= PFMLIB_PMU_FL_RAW_UMASK
 				| INTEL_X86_PMU_FL_ECMASK,
-	.pmu_detect		= pfm_wsm_dp_detect,
+	.cpu_family		= 6,
+	.cpu_models		= wsm_dp_models,
+	.pmu_detect		= pfm_intel_x86_model_detect,
 	.pmu_init		= pfm_wsm_init,
 
 	.get_event_encoding[PFM_OS_NONE] = pfm_intel_x86_get_encoding,
diff --git a/src/libpfm4/lib/pfmlib_intel_x86.c b/src/libpfm4/lib/pfmlib_intel_x86.c
index cfa1730..81a2258 100644
--- a/src/libpfm4/lib/pfmlib_intel_x86.c
+++ b/src/libpfm4/lib/pfmlib_intel_x86.c
@@ -173,6 +173,26 @@ pfm_intel_x86_detect(void)
 	return PFM_SUCCESS;
 }
 
+int pfm_intel_x86_model_detect(void *this)
+{
+	pfmlib_pmu_t *pmu = this;
+	const int *p;
+	int ret;
+
+	ret = pfm_intel_x86_detect();
+	if (ret != PFM_SUCCESS)
+		return ret;
+
+	if (pfm_intel_x86_cfg.family != pmu->cpu_family)
+		return PFM_ERR_NOTSUPP;
+
+	for (p = pmu->cpu_models; *p; p++) {
+		if (*p == pfm_intel_x86_cfg.model)
+			return PFM_SUCCESS;
+	}
+	return PFM_ERR_NOTSUPP;
+}
+
 int
 pfm_intel_x86_add_defaults(void *this, pfmlib_event_desc_t *e,
 			   unsigned int msk,
diff --git a/src/libpfm4/lib/pfmlib_intel_x86_priv.h b/src/libpfm4/lib/pfmlib_intel_x86_priv.h
index 3b077b1..2a85a13 100644
--- a/src/libpfm4/lib/pfmlib_intel_x86_priv.h
+++ b/src/libpfm4/lib/pfmlib_intel_x86_priv.h
@@ -340,5 +340,6 @@ extern int pfm_intel_x86_get_perf_encoding(void *this, pfmlib_event_desc_t *e);
 extern int pfm_intel_nhm_unc_get_perf_encoding(void *this, pfmlib_event_desc_t *e);
 extern void pfm_intel_x86_perf_validate_pattrs(void *this, pfmlib_event_desc_t *e);
 extern int pfm_intel_x86_can_auto_encode(void *this, int pidx, int uidx);
+extern int pfm_intel_x86_model_detect(void *this);
 
 #endif /* __PFMLIB_INTEL_X86_PRIV_H__ */
diff --git a/src/libpfm4/lib/pfmlib_priv.h b/src/libpfm4/lib/pfmlib_priv.h
index 129a815..8731ac6 100644
--- a/src/libpfm4/lib/pfmlib_priv.h
+++ b/src/libpfm4/lib/pfmlib_priv.h
@@ -116,6 +116,9 @@ typedef struct pfmlib_pmu {
 
 	const pfmlib_attr_desc_t *atdesc;	/* pointer to attrs table */
 
+	const int	cpu_family;		/* cpu family number for detection */
+	const int	*cpu_models;		/* cpu model numbers for detection (zero terminated) */
+
 	int 		 (*pmu_detect)(void *this);
 	int 		 (*pmu_init)(void *this);	/* optional */
 	void		 (*pmu_terminate)(void *this); /* optional */
@@ -247,6 +250,7 @@ extern pfmlib_pmu_t intel_ivb_unc_cbo3_support;
 extern pfmlib_pmu_t intel_ivb_ep_support;
 extern pfmlib_pmu_t intel_hsw_support;
 extern pfmlib_pmu_t intel_hsw_ep_support;
+extern pfmlib_pmu_t intel_bdw_support;
 extern pfmlib_pmu_t intel_rapl_support;
 extern pfmlib_pmu_t intel_snbep_unc_cb0_support;
 extern pfmlib_pmu_t intel_snbep_unc_cb1_support;
@@ -336,6 +340,7 @@ extern pfmlib_pmu_t arm_1176_support;
 extern pfmlib_pmu_t arm_qcom_krait_support;
 extern pfmlib_pmu_t arm_cortex_a57_support;
 extern pfmlib_pmu_t arm_cortex_a53_support;
+extern pfmlib_pmu_t arm_xgene_support;
 extern pfmlib_pmu_t mips_74k_support;
 extern pfmlib_pmu_t s390x_cpum_cf_support;
 extern pfmlib_pmu_t s390x_cpum_sf_support;
diff --git a/src/libpfm4/tests/validate_arm64.c b/src/libpfm4/tests/validate_arm64.c
index 61400ac..f4593de 100644
--- a/src/libpfm4/tests/validate_arm64.c
+++ b/src/libpfm4/tests/validate_arm64.c
@@ -114,6 +114,34 @@ static const test_event_t arm64_test_events[]={
 	  .codes[0] = 0x8000007,
 	  .fstr = "arm_ac53::ST_RETIRED:k=1:u=1:hv=0",
 	},
+	{ SRC_LINE,
+	  .name = "arm_xgene::CPU_CYCLES",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000011,
+	  .fstr = "arm_xgene::CPU_CYCLES:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_xgene::CPU_CYCLES:k",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x88000011,
+	  .fstr = "arm_xgene::CPU_CYCLES:k=1:u=0:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_xgene::CPU_CYCLES:k:u",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000011,
+	  .fstr = "arm_xgene::CPU_CYCLES:k=1:u=1:hv=0",
+	},
+	{ SRC_LINE,
+	  .name = "arm_xgene::INST_RETIRED",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x8000008,
+	  .fstr = "arm_xgene::INST_RETIRED:k=1:u=1:hv=0",
+	},
 };
 #define NUM_TEST_EVENTS (int)(sizeof(arm64_test_events)/sizeof(test_event_t))
 
diff --git a/src/libpfm4/tests/validate_x86.c b/src/libpfm4/tests/validate_x86.c
index 743cc14..fb6bc20 100644
--- a/src/libpfm4/tests/validate_x86.c
+++ b/src/libpfm4/tests/validate_x86.c
@@ -2779,7 +2779,7 @@ static const test_event_t x86_test_events[]={
 	  .count = 2,
 	  .codes[0] = 0x5301b7,
 	  .codes[1] = 0x3f84000091ull,
-	  .fstr = "hsw_ep::OFFCORE_RESPONSE_0:DMND_DATA_RD:PF_DATA_RD:PF_LLC_DATA_RD:L3_MISS_LOCAL:SNP_ANY:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
+	  .fstr = "hsw_ep::OFFCORE_RESPONSE_0:DMND_DATA_RD:PF_DATA_RD:PF_LLC_DATA_RD:L3_MISS_LOCAL_DRAM:SNP_ANY:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
 	},
 	{ SRC_LINE,
 	  .name = "hsw_ep::offcore_response_0:any_data:LLC_miss_local",
@@ -2805,6 +2805,98 @@ static const test_event_t x86_test_events[]={
 	  .codes[1] =0x3f83c00091ull,
 	  .fstr = "hsw_ep::OFFCORE_RESPONSE_0:DMND_DATA_RD:PF_DATA_RD:PF_LLC_DATA_RD:L4_HIT_LOCAL_L4:L4_HIT_REMOTE_HOP0_L4:L4_HIT_REMOTE_HOP1_L4:L4_HIT_REMOTE_HOP2P_L4:SNP_ANY:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
 	},
+	{ SRC_LINE,
+	  .name = "bdw::mem_trans_retired:latency_above_threshold:ldlat=3:u",
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5101cd,
+	  .codes[1] = 3,
+	  .fstr = "bdw::MEM_TRANS_RETIRED:LOAD_LATENCY:k=0:u=1:e=0:i=0:c=0:t=0:ldlat=3:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "bdw::mem_trans_retired:latency_above_threshold:ldlat=1000000",
+	  .ret = PFM_ERR_ATTR_VAL,
+	},
+	{ SRC_LINE,
+	  .name = "bdw::mem_trans_retired:load_latency",
+	  .ret = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5301cd,
+	  .codes[1] = 3,
+	  .fstr = "bdw::MEM_TRANS_RETIRED:LOAD_LATENCY:k=1:u=1:e=0:i=0:c=0:t=0:ldlat=3:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "bdw::mem_trans_retired:load_latency:ldlat=1000000",
+	  .ret = PFM_ERR_ATTR_VAL,
+	},
+	{ SRC_LINE,
+	  .name = "bdw::mem_trans_retired:latency_above_threshold:ldlat=2:intx=0:intxcp=0",
+	  .ret = PFM_ERR_ATTR_VAL,
+	},
+	{ SRC_LINE,
+	  .name = "bdw::inst_Retired:any_p:intx",
+	  .count = 1,
+	  .codes[0] = 0x1005300c0,
+	  .fstr = "bdw::INST_RETIRED:ANY_P:k=1:u=1:e=0:i=0:c=0:t=0:intx=1:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "bdw::inst_Retired:any_p:intx:intxcp",
+	  .count = 1,
+	  .codes[0] = 0x3005300c0,
+	  .fstr = "bdw::INST_RETIRED:ANY_P:k=1:u=1:e=0:i=0:c=0:t=0:intx=1:intxcp=1",
+	},
+	{ SRC_LINE,
+	  .name = "bdw::inst_Retired:any_p:intx=0:intxcp",
+	  .count = 1,
+	  .codes[0] = 0x2005300c0,
+	  .fstr = "bdw::INST_RETIRED:ANY_P:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=1",
+	},
+	{ SRC_LINE,
+	  .name = "bdw::cycle_activity:cycles_l2_pending",
+	  .ret = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x15301a3,
+	  .fstr = "bdw::CYCLE_ACTIVITY:CYCLES_L2_PENDING:k=1:u=1:e=0:i=0:t=0:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "bdw::cycle_activity:cycles_l2_pending:c=8",
+	  .ret = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "bdw::hle_retired:aborted",
+	  .ret = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x5304c8,
+	  .fstr = "bdw::HLE_RETIRED:ABORTED:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "bdw::rtm_retired:aborted",
+	  .ret = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x5304c9,
+	  .fstr = "bdw::RTM_RETIRED:ABORTED:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "bdw::arith:fpu_div_active",
+	  .ret = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x530114,
+	  .fstr = "bdw::ARITH:FPU_DIV_ACTIVE:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "bdw::inst_retired:prec_dist",
+	  .ret = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x5301c0,
+	  .fstr = "bdw::INST_RETIRED:PREC_DIST:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "bdw::rs_events:empty_end",
+	  .ret = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x1d7015e,
+	  .fstr = "bdw::RS_EVENTS:EMPTY_END:k=1:u=1:e=1:i=1:c=1:t=0:intx=0:intxcp=0",
+	},
 };
 #define NUM_TEST_EVENTS (int)(sizeof(x86_test_events)/sizeof(test_event_t))
 
-- 
2.1.0

From 1e8c5d057457f2ee07cc0823c66a77daa72f67e2 Mon Sep 17 00:00:00 2001
From: Heike McCraw <mccraw@icl.utk.edu>
Date: Tue, 9 Dec 2014 16:15:04 -0500
Subject: [PATCH 23/24] Update libpfm4

Current with
------------

commit 7e38ff041cbee37ea6293e165ecf937d8db412b7
Author: Carl Love <cel@us.ibm.com>
Date:   Fri Dec 5 06:43:40 2014 +0100

PPC64 fix long event codes

There are eight Power 8 event codes that do not fit into a u32. The program
used to process the event files and produce the events/power8_events.h file
truncated the event codes to a u32.  The PAPI Power specific struct that
holds the event code is also declared to be a u32. This patch changes the
pme_code field to a u64 and fixes the truncated event codes.

Signed-off-by: Carl Love <cel@us.ibm.com>

diff --git a/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_cbo.3 b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_cbo.3
index b6023b7..7dbd4b1 100644
--- a/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_cbo.3
+++ b/src/libpfm4/docs/man3/libpfm_intel_ivbep_unc_cbo.3
@@ -48,6 +48,16 @@ filtering takes place.
 Thread Filter. This is a 1-bit filter which is used to filter C-Box requests based on logical
 processor (hyper-thread) identification. Possibles values are 0-1. If the filter is not
 specified, then no filtering takes place.
+.TP
+.B nc
+Non-Coherent. This is a 1-bit filter which is used to filter C-Box requests only for the
+TOR_INSERTS and TOR_OCCUPANCY umasks using the OPCODE matcher. If the filter is not
+specified, then no filtering takes place.
+.TP
+.B isoc
+Isochronous. This is a 1-bit filter which is used to filter C-Box requests only for the
+TOR_INSERTS and TOR_OCCUPANCY umasks using the OPCODE matcher. If the filter is not
+specified, then no filtering takes place.
 
 .SH Opcode filtering
 
diff --git a/src/libpfm4/lib/events/intel_bdw_events.h b/src/libpfm4/lib/events/intel_bdw_events.h
index b7d6749..0a6ff38 100644
--- a/src/libpfm4/lib/events/intel_bdw_events.h
+++ b/src/libpfm4/lib/events/intel_bdw_events.h
@@ -21,7 +21,7 @@
  * This file is part of libpfm, a performance monitoring support library for
  * applications on Linux.
  *
- * PMU: bdw (Intel Haswell)
+ * PMU: bdw (Intel Broadwell)
  */
 
 static const intel_x86_umask_t bdw_baclears[]={
diff --git a/src/libpfm4/lib/events/intel_hsw_events.h b/src/libpfm4/lib/events/intel_hsw_events.h
index b6fd56f..1810024 100644
--- a/src/libpfm4/lib/events/intel_hsw_events.h
+++ b/src/libpfm4/lib/events/intel_hsw_events.h
@@ -25,11 +25,11 @@
  */
 
 static const intel_x86_umask_t hsw_baclears[]={
-  { .uname = "ANY",
-    .udesc  = "Number of front-end re-steers due to BPU misprediction",
-    .ucode  = 0x1f00,
-    .uflags = INTEL_X86_NCOMBO | INTEL_X86_DFL,
-  },
+   { .uname  = "ANY",
+     .udesc  = "Counts the number of times the front end is re-steered, mainly when the BPU cannot provide a correct prediction and this is corrected by other branch handling mechanisms at the front end",
+     .ucode = 0x1f00,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+   },
 };
 
 static const intel_x86_umask_t hsw_br_inst_exec[]={
@@ -310,7 +310,7 @@ static const intel_x86_umask_t hsw_cycle_activity[]={
      .ucntmsk= 0x4,
      .uflags = INTEL_X86_NCOMBO,
    },
-   { .uname  = "STALL_L1D_PENDING",
+   { .uname  = "STALLS_L1D_PENDING",
      .udesc  = "Executions stalls due to pending L1D load cache misses",
      .ucode  = 0x0c00 | (0xc << INTEL_X86_CMASK_BIT),
      .ucntmsk= 0x4,
@@ -1429,11 +1429,19 @@ static const intel_x86_umask_t hsw_offcore_response[]={
      .ucode = 1ULL << (1 + 8),
      .grpid = 0,
    },
+
+   { .uname  = "DMND_CODE_RD",
+     .udesc  = "Request: number of demand and DCU prefetch instruction cacheline reads. Does not count L2 code read prefetches",
+     .ucode = 1ULL << (2 + 8),
+     .grpid = 0,
+   },
    { .uname  = "DMND_IFETCH",
      .udesc  = "Request: number of demand and DCU prefetch instruction cacheline reads. Does not count L2 code read prefetches",
      .ucode = 1ULL << (2 + 8),
+     .uequiv = "DMND_CODE_RD",
      .grpid = 0,
    },
+
    { .uname  = "WB",
      .udesc  = "Request: number of writebacks (modified to exclusive) transactions",
      .ucode = 1ULL << (3 + 8),
@@ -1449,30 +1457,52 @@ static const intel_x86_umask_t hsw_offcore_response[]={
      .ucode = 1ULL << (5 + 8),
      .grpid = 0,
    },
+
+   { .uname  = "PF_CODE_RD",
+     .udesc  = "Request: number of code reads generated by L2 prefetchers",
+     .ucode = 1ULL << (6 + 8),
+     .grpid = 0,
+   },
    { .uname  = "PF_IFETCH",
      .udesc  = "Request: number of code reads generated by L2 prefetchers",
      .ucode = 1ULL << (6 + 8),
      .grpid = 0,
+     .uequiv= "PF_CODE_RD",
    },
-   { .uname  = "PF_LLC_DATA_RD",
-     .udesc  = "Request: number of L3 prefetcher requests to L2 for loads",
+
+   { .uname  = "PF_L3_DATA_RD",
+     .udesc  = "Request: number of L2 prefetcher requests to L3 for loads",
      .ucode = 1ULL << (7 + 8),
      .grpid = 0,
    },
-   { .uname  = "PF_LLC_RFO",
+   { .uname  = "PF_L3_RFO",
      .udesc  = "Request: number of RFO requests generated by L2 prefetcher",
      .ucode = 1ULL << (8 + 8),
      .grpid = 0,
    },
-   { .uname  = "PF_LLC_IFETCH",
+
+   { .uname  = "PF_L3_CODE_RD",
+     .udesc  = "Request: number of L2 prefetcher requests to L3 for instruction fetches",
+     .ucode = 1ULL << (9 + 8),
+     .grpid = 0,
+   },
+   { .uname  = "PF_L3_IFETCH",
      .udesc  = "Request: number of L2 prefetcher requests to L3 for instruction fetches",
      .ucode = 1ULL << (9 + 8),
      .grpid = 0,
+     .uequiv= "PF_L3_CODE_RD",
+   },
+
+   { .uname  = "SPLIT_LOCK_UC_LOCK",
+     .udesc  = "Request: number of bus lock and split lock requests",
+     .ucode = 1ULL << (10 + 8),
+     .grpid = 0,
    },
    { .uname  = "BUS_LOCKS",
-     .udesc  = "Request: number bus lock and split lock requests",
+     .udesc  = "Request: number of bus lock and split lock requests",
      .ucode = 1ULL << (10 + 8),
      .grpid = 0,
+     .uequiv= "SPLIT_LOCK_UC_LOCK",
    },
    { .uname  = "STRM_ST",
      .udesc  = "Request: number of streaming store requests",
@@ -1484,29 +1514,35 @@ static const intel_x86_umask_t hsw_offcore_response[]={
      .ucode = 1ULL << (15+8),
      .grpid = 0,
    },
+
+   { .uname  = "ANY_CODE_RD",
+     .udesc  = "Request: combination of PF_CODE_RD | DMND_CODE_RD | PF_L3_CODE_RD",
+     .uequiv = "PF_CODE_RD:DMND_CODE_RD:PF_L3_CODE_RD",
+     .ucode = 0x24400,
+     .grpid = 0,
+   },
    { .uname  = "ANY_IFETCH",
-     .udesc  = "Request: combination of PF_IFETCH | DMND_IFETCH | PF_LLC_IFETCH",
-     .uequiv = "PF_IFETCH:DMND_IFETCH:PF_LLC_IFETCH",
-     .ucode = 0x24100,
+     .udesc  = "Request: combination of PF_CODE_RD | PF_L3_CODE_RD",
+     .ucode = 0x24000,
      .grpid = 0,
    },
    { .uname  = "ANY_REQUEST",
      .udesc  = "Request: combination of all request umasks",
-     .uequiv = "DMND_DATA_RD:DMND_RFO:DMND_IFETCH:WB:PF_DATA_RD:PF_RFO:PF_IFETCH:PF_LLC_DATA_RD:PF_LLC_RFO:PF_LLC_IFETCH:BUS_LOCKS:STRM_ST:OTHER",
+     .uequiv = "DMND_DATA_RD:DMND_RFO:DMND_CODE_RD:WB:PF_DATA_RD:PF_RFO:PF_CODE_RD:PF_L3_DATA_RD:PF_L3_RFO:PF_L3_CODE_RD:SPLIT_LOCK_UC_LOCK:STRM_ST:OTHER",
      .ucode = 0x8fff00,
      .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
      .grpid = 0,
    },
    { .uname  = "ANY_DATA",
-     .udesc  = "Request: combination of DMND_DATA | PF_DATA_RD | PF_LLC_DATA_RD",
-     .uequiv = "DMND_DATA_RD:PF_DATA_RD:PF_LLC_DATA_RD",
+     .udesc  = "Request: combination of DMND_DATA | PF_DATA_RD | PF_L3_DATA_RD",
+     .uequiv = "DMND_DATA_RD:PF_DATA_RD:PF_L3_DATA_RD",
      .ucode = 0x9100,
      .grpid = 0,
    },
    { .uname  = "ANY_RFO",
-     .udesc  = "Request: combination of DMND_RFO | PF_RFO | PF_LLC_RFO",
-     .uequiv = "DMND_RFO:PF_RFO:PF_LLC_RFO",
-     .ucode = 0x10300,
+     .udesc  = "Request: combination of DMND_RFO | PF_RFO | PF_L3_RFO",
+     .uequiv = "DMND_RFO:PF_RFO:PF_L3_RFO",
+     .ucode = 0x12200,
      .grpid = 0,
    },
 
@@ -1521,60 +1557,19 @@ static const intel_x86_umask_t hsw_offcore_response[]={
      .ucode = 1ULL << (17+8),
      .grpid = 1,
    },
-   { .uname  = "LLC_HITM",
-     .udesc  = "Supplier: counts L3 hits in M-state (initial lookup)",
-     .ucode = 1ULL << (18+8),
-     .umodel = PFM_PMU_INTEL_HSW,
-     .grpid = 1,
-   },
-   { .uname  = "LLC_HITE",
-     .udesc  = "Supplier: counts L3 hits in E-state",
-     .ucode = 1ULL << (19+8),
-     .umodel = PFM_PMU_INTEL_HSW,
-     .grpid = 1,
-   },
-   { .uname  = "LLC_HITS",
-     .udesc  = "Supplier: counts L3 hits in S-state",
-     .ucode = 1ULL << (20+8),
-     .umodel = PFM_PMU_INTEL_HSW,
-     .grpid = 1,
-   },
-   { .uname  = "LLC_HITF",
-     .udesc  = "Supplier: counts L3 hits in F-state",
-     .ucode = 1ULL << (21+8),
-     .umodel = PFM_PMU_INTEL_HSW,
-     .grpid = 1,
-   },
-   { .uname  = "LLC_HITMESF",
-     .udesc  = "Supplier: counts L3 hits in any state (M, E, S, F)",
-     .ucode  = 0xfULL << (18+8),
-     .uequiv = "LLC_HITM:LLC_HITE:LLC_HITS:LLC_HITF",
-     .umodel = PFM_PMU_INTEL_HSW,
-     .grpid  = 1,
-   },
-   { .uname  = "LLC_HIT",
-     .udesc  = "Alias for LLC_HITMESF",
-     .ucode  = 0xfULL << (18+8),
-     .uequiv = "LLC_HITM:LLC_HITE:LLC_HITS:LLC_HITF",
-     .umodel = PFM_PMU_INTEL_HSW,
-     .grpid  = 1,
-   },
    { .uname  = "L3_HITM",
      .udesc  = "Supplier: counts L3 hits in M-state (initial lookup)",
      .ucode = 1ULL << (18+8),
-     .umodel = PFM_PMU_INTEL_HSW_EP,
      .grpid = 1,
    },
    { .uname  = "L3_HITE",
      .udesc  = "Supplier: counts L3 hits in E-state",
      .ucode = 1ULL << (19+8),
-     .umodel = PFM_PMU_INTEL_HSW_EP,
      .grpid = 1,
    },
    { .uname  = "L3_HITS",
      .udesc  = "Supplier: counts L3 hits in S-state",
      .ucode = 1ULL << (20+8),
-     .umodel = PFM_PMU_INTEL_HSW_EP,
      .grpid = 1,
    },
    { .uname  = "L3_HITF",
@@ -1584,75 +1579,37 @@ static const intel_x86_umask_t hsw_offcore_response[]={
      .grpid = 1,
    },
    { .uname  = "L3_HIT",
-     .udesc  = "Supplier: counts L3 hits in M, E, S, F state",
-     .ucode = 0xfULL << (18+8),
-     .uequiv = "L3_HITM:L3_HITE:L3_HITS:L3_HITF",
-     .umodel = PFM_PMU_INTEL_HSW_EP,
-     .grpid = 1,
-   },
-   { .uname  = "L4_HIT_LOCAL_L4",
-     .udesc  = "Supplier: counts L4 hits to local L4 cache",
-     .ucode = 0x1ULL << (22+8),
-     .umodel = PFM_PMU_INTEL_HSW_EP,
-     .grpid = 1,
-   },
-   { .uname  = "L4_HIT_REMOTE_HOP0_L4",
-     .udesc  = "Supplier: counts L4 hits to remote L4 cache with 0 hop",
-     .ucode = 0x1ULL << (23+8),
-     .umodel = PFM_PMU_INTEL_HSW_EP,
-     .grpid = 1,
-   },
-   { .uname  = "L4_HIT_REMOTE_HOP1_L4",
-     .udesc  = "Supplier: counts L4 hits to remote L4 cache with 1 hop",
-     .ucode = 0x1ULL << (24+8),
-     .umodel = PFM_PMU_INTEL_HSW_EP,
-     .grpid = 1,
-   },
-   { .uname  = "L4_HIT_REMOTE_HOP2P_L4",
-     .udesc  = "Supplier: counts L4 hits to remote L4 cache with 2P hops",
-     .ucode = 0x1ULL << (25+8),
-     .umodel = PFM_PMU_INTEL_HSW_EP,
-     .grpid = 1,
-   },
-   { .uname  = "L4_HIT",
-     .udesc  = "Supplier: counts L4 hits",
-     .ucode = 0xfULL << (22+8),
-     .uequiv = "L4_HIT_LOCAL_L4:L4_HIT_REMOTE_HOP0_L4:L4_HIT_REMOTE_HOP1_L4:L4_HIT_REMOTE_HOP2P_L4",
-     .umodel = PFM_PMU_INTEL_HSW_EP,
-     .grpid = 1,
-   },
-   { .uname  = "LLC_MISS_LOCAL",
-     .udesc  = "Supplier: counts L3 misses to local DRAM",
-     .ucode = 1ULL << (22+8),
+     .udesc  = "Supplier: counts L3 hits in any state (M, E, S)",
+     .ucode  = 0x7ULL << (18+8),
+     .uequiv = "L3_HITM:L3_HITE:L3_HITS",
      .umodel = PFM_PMU_INTEL_HSW,
-     .grpid = 1,
+     .grpid  = 1,
    },
-   { .uname  = "L3_MISS_LOCAL_DRAM",
-     .udesc  = "Supplier: counts L3 misses to local DRAM",
-     .ucode = 1ULL << (26+8),
+   { .uname  = "L3_HIT",
+     .udesc  = "Supplier: counts L3 hits in any state (M, E, S, F)",
+     .ucode  = 0xfULL << (18+8),
+     .uequiv = "L3_HITM:L3_HITE:L3_HITS:L3_HITF",
      .umodel = PFM_PMU_INTEL_HSW_EP,
-     .grpid = 1,
+     .grpid  = 1,
    },
    { .uname  = "L3_MISS_LOCAL",
-     .udesc  = "Supplier: Alias to L3_MISS_LOCAL_DRAM",
-     .ucode = 1ULL << (26+8),
-     .umodel = PFM_PMU_INTEL_HSW_EP,
-     .uequiv = "L3_MISS_LOCAL_DRAM",
+     .udesc  = "Supplier: counts L3 misses to local DRAM",
+     .ucode = 1ULL << (22+8),
      .grpid = 1,
    },
-   { .uname  = "L3_MISS_REMOTE_HOP0_DRAM",
+   { .uname  = "L3_MISS_REMOTE_HOP0",
      .udesc  = "Supplier: counts L3 misses to remote DRAM with 0 hop",
      .ucode = 0x1ULL << (27+8),
      .umodel = PFM_PMU_INTEL_HSW_EP,
      .grpid = 1,
    },
-   { .uname  = "L3_MISS_REMOTE_HOP1_DRAM",
+   { .uname  = "L3_MISS_REMOTE_HOP1",
      .udesc  = "Supplier: counts L3 misses to remote DRAM with 1 hop",
      .ucode = 0x1ULL << (28+8),
      .umodel = PFM_PMU_INTEL_HSW_EP,
      .grpid = 1,
    },
-   { .uname  = "L3_MISS_REMOTE_HOP2P_DRAM",
+   { .uname  = "L3_MISS_REMOTE_HOP2P",
      .udesc  = "Supplier: counts L3 misses to remote DRAM with 2P hops",
      .ucode = 0x1ULL << (29+8),
      .umodel = PFM_PMU_INTEL_HSW_EP,
@@ -1664,16 +1621,10 @@ static const intel_x86_umask_t hsw_offcore_response[]={
      .umodel = PFM_PMU_INTEL_HSW_EP,
      .grpid = 1,
    },
-   { .uname  = "L3_MISS_REMOTE_DRAM",
-     .udesc  = "Supplier: counts L3 misses to remote DRAM",
-     .ucode = 0x3ULL << (27+8),
-     .umodel = PFM_PMU_INTEL_HSW_EP,
-     .grpid = 1,
-   },
+
    { .uname  = "SPL_HIT",
-     .udesc  = "Supplier: counts L3 misses to remote DRAM",
+     .udesc  = "Supplier: counts L3 supplier hit",
      .ucode = 0x1ULL << (30+8),
-     .umodel = PFM_PMU_INTEL_HSW_EP,
      .grpid = 1,
    },
    { .uname  = "SNP_NONE",
@@ -1701,12 +1652,12 @@ static const intel_x86_umask_t hsw_offcore_response[]={
      .ucode = 1ULL << (35+8),
      .grpid = 2,
    },
-   { .uname  = "HITM",
+   { .uname  = "SNP_HITM",
      .udesc  = "Snoop: counts number of times a snoop was needed and it hitM-ed in local or remote cache",
      .ucode = 1ULL << (36+8),
      .grpid = 2,
    },
-   { .uname  = "NON_DRAM",
+   { .uname  = "SNP_NON_DRAM",
      .udesc  = "Snoop:  counts number of times target was a non-DRAM system address. This includes MMIO transactions",
      .ucode = 1ULL << (37+8),
      .grpid = 2,
@@ -1714,7 +1665,7 @@ static const intel_x86_umask_t hsw_offcore_response[]={
    { .uname  = "SNP_ANY",
      .udesc  = "Snoop: any snoop reason",
      .ucode = 0x7fULL << (31+8),
-     .uequiv = "SNP_NONE:SNP_NOT_NEEDED:SNP_MISS:SNP_NO_FWD:SNP_FWD:HITM:NON_DRAM",
+     .uequiv = "SNP_NONE:SNP_NOT_NEEDED:SNP_MISS:SNP_NO_FWD:SNP_FWD:SNP_HITM:SNP_NON_DRAM",
      .uflags= INTEL_X86_DFL,
      .grpid = 2,
    },
@@ -1812,8 +1763,8 @@ static const intel_x86_umask_t hsw_tx_mem[]={
     .ucode  = 0x100,
     .uflags = INTEL_X86_NCOMBO,
   },
-  { .uname = "ABORT_CAPACITY",
-    .udesc  = "Number of times a transactional abort was signaled due to data capacity limitation",
+  { .uname = "ABORT_CAPACITY_WRITE",
+    .udesc  = "Number of times a transactional abort was signaled due to data capacity limitation for transactional writes",
     .ucode  = 0x200,
     .uflags = INTEL_X86_NCOMBO,
   },
@@ -2034,6 +1985,22 @@ static const intel_x86_umask_t hsw_ept[]={
    },
 };
 
+static const intel_x86_umask_t hsw_arith[]={
+   { .uname  = "DIVIDER_UOPS",
+     .udesc  = "Number of uops executed by divider",
+     .ucode = 0x0200,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+   },
+};
+
+static const intel_x86_umask_t hsw_offcore_requests_buffer[]={
+   { .uname  = "SQ_FULL",
+     .udesc  = "Number of cycles the offcore requests buffer is full",
+     .ucode = 0x0200,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+   },
+};
+
 static const intel_x86_entry_t intel_hsw_pe[]={
   { .name   = "UNHALTED_CORE_CYCLES",
     .desc   = "Count core clock cycles whenever the clock signal on the specific core is running (not halted)",
@@ -2638,6 +2605,24 @@ static const intel_x86_entry_t intel_hsw_pe[]={
     .ngrp = 1,
     .umasks = hsw_ept,
   },
+  { .name   = "ARITH",
+    .desc   = "Counts arithmetic multiply operations",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0xff,
+    .code = 0x14,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_arith),
+    .ngrp = 1,
+    .umasks = hsw_arith,
+  },
+  { .name   = "OFFCORE_REQUESTS_BUFFER",
+    .desc   = "Offcore reqest buffer",
+    .modmsk = INTEL_V4_ATTRS,
+    .cntmsk = 0xff,
+    .code = 0xb2,
+    .numasks = LIBPFM_ARRAY_SIZE(hsw_offcore_requests_buffer),
+    .ngrp = 1,
+    .umasks = hsw_offcore_requests_buffer,
+  },
   { .name   = "OFFCORE_RESPONSE_0",
     .desc   = "Offcore response event (must provide at least one request type and either any_response or any combination of supplier + snoop)",
     .modmsk = INTEL_V4_ATTRS,
diff --git a/src/libpfm4/lib/events/intel_ivbep_unc_cbo_events.h b/src/libpfm4/lib/events/intel_ivbep_unc_cbo_events.h
index 3827e03..cd2448a 100644
--- a/src/libpfm4/lib/events/intel_ivbep_unc_cbo_events.h
+++ b/src/libpfm4/lib/events/intel_ivbep_unc_cbo_events.h
@@ -945,7 +945,7 @@ static const intel_x86_entry_t intel_ivbep_unc_c_pe[]={
     .code = 0x35,
     .cntmsk = 0x3,
     .ngrp = 2,
-    .modmsk = IVBEP_UNC_CBO_NID_ATTRS,
+    .modmsk = IVBEP_UNC_CBO_NID_ATTRS | _SNBEP_UNC_ATTR_ISOC | _SNBEP_UNC_ATTR_NC,
     .flags  = INTEL_X86_NO_AUTOENCODE,
     .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_tor_inserts),
     .umasks  = ivbep_unc_c_tor_inserts
@@ -955,7 +955,7 @@ static const intel_x86_entry_t intel_ivbep_unc_c_pe[]={
     .code = 0x36,
     .cntmsk = 0x1,
     .ngrp = 2,
-    .modmsk = IVBEP_UNC_CBO_NID_ATTRS,
+    .modmsk = IVBEP_UNC_CBO_NID_ATTRS | _SNBEP_UNC_ATTR_ISOC | _SNBEP_UNC_ATTR_NC,
     .flags  = INTEL_X86_NO_AUTOENCODE,
     .numasks = LIBPFM_ARRAY_SIZE(ivbep_unc_c_tor_occupancy),
     .umasks  = ivbep_unc_c_tor_occupancy
diff --git a/src/libpfm4/lib/events/intel_ivbep_unc_ha_events.h b/src/libpfm4/lib/events/intel_ivbep_unc_ha_events.h
index d92ca9e..20beb56 100644
--- a/src/libpfm4/lib/events/intel_ivbep_unc_ha_events.h
+++ b/src/libpfm4/lib/events/intel_ivbep_unc_ha_events.h
@@ -484,7 +484,7 @@ static const intel_x86_umask_t ivbep_unc_h_osb_edr[]={
   },
   { .uname = "READS_REMOTE_S",
     .udesc  = "Reads to remote S",
-    .ucode  = 01000,
+    .ucode  = 0x1000,
   }
 };
 
diff --git a/src/libpfm4/lib/events/power8_events.h b/src/libpfm4/lib/events/power8_events.h
index 3437602..2aee218 100644
--- a/src/libpfm4/lib/events/power8_events.h
+++ b/src/libpfm4/lib/events/power8_events.h
@@ -3862,25 +3862,25 @@ static const pme_power_entry_t power8_pe[] = {
 },
 [ POWER8_PME_PM_L1MISS_LAT_EXC_1024 ] = {
 	.pme_name = "PM_L1MISS_LAT_EXC_1024",
-	.pme_code = 0x200301ea,
+	.pme_code = 0x67200301eaull,
 	.pme_short_desc = "L1 misses that took longer than 1024 cyles to resolve (miss to reload)",
 	.pme_long_desc = "Reload latency exceeded 1024 cyc",
 },
 [ POWER8_PME_PM_L1MISS_LAT_EXC_2048 ] = {
 	.pme_name = "PM_L1MISS_LAT_EXC_2048",
-	.pme_code = 0x200401ec,
+	.pme_code = 0x67200401ecull,
 	.pme_short_desc = "L1 misses that took longer than 2048 cyles to resolve (miss to reload)",
 	.pme_long_desc = "Reload latency exceeded 2048 cyc",
 },
 [ POWER8_PME_PM_L1MISS_LAT_EXC_256 ] = {
 	.pme_name = "PM_L1MISS_LAT_EXC_256",
-	.pme_code = 0x200101e8,
+	.pme_code = 0x67200101e8ull,
 	.pme_short_desc = "L1 misses that took longer than 256 cyles to resolve (miss to reload)",
 	.pme_long_desc = "Reload latency exceeded 256 cyc",
 },
 [ POWER8_PME_PM_L1MISS_LAT_EXC_32 ] = {
 	.pme_name = "PM_L1MISS_LAT_EXC_32",
-	.pme_code = 0x200201e6,
+	.pme_code = 0x67200201e6ull,
 	.pme_short_desc = "L1 misses that took longer than 32 cyles to resolve (miss to reload)",
 	.pme_long_desc = "Reload latency exceeded 32 cyc",
 },
@@ -6538,25 +6538,25 @@ static const pme_power_entry_t power8_pe[] = {
 },
 [ POWER8_PME_PM_RC_LIFETIME_EXC_1024 ] = {
 	.pme_name = "PM_RC_LIFETIME_EXC_1024",
-	.pme_code = 0x200301ea,
+	.pme_code = 0xde200301eaull,
 	.pme_short_desc = "Number of times the RC machine for a sampled instruction was active for more than 1024 cycles",
 	.pme_long_desc = "Reload latency exceeded 1024 cyc",
 },
 [ POWER8_PME_PM_RC_LIFETIME_EXC_2048 ] = {
 	.pme_name = "PM_RC_LIFETIME_EXC_2048",
-	.pme_code = 0x200401ec,
+	.pme_code = 0xde200401ecull,
 	.pme_short_desc = "Number of times the RC machine for a sampled instruction was active for more than 2048 cycles",
 	.pme_long_desc = "Threshold counter exceeded a value of 2048",
 },
 [ POWER8_PME_PM_RC_LIFETIME_EXC_256 ] = {
 	.pme_name = "PM_RC_LIFETIME_EXC_256",
-	.pme_code = 0x200101e8,
+	.pme_code = 0xde200101e8ull,
 	.pme_short_desc = "Number of times the RC machine for a sampled instruction was active for more than 256 cycles",
 	.pme_long_desc = "Threshold counter exceed a count of 256",
 },
 [ POWER8_PME_PM_RC_LIFETIME_EXC_32 ] = {
 	.pme_name = "PM_RC_LIFETIME_EXC_32",
-	.pme_code = 0x200201e6,
+	.pme_code = 0xde200201e6ull,
 	.pme_short_desc = "Number of times the RC machine for a sampled instruction was active for more than 32 cycles",
 	.pme_long_desc = "Reload latency exceeded 32 cyc",
 },
diff --git a/src/libpfm4/lib/pfmlib_intel_snbep_unc.c b/src/libpfm4/lib/pfmlib_intel_snbep_unc.c
index 8fb6472..5ffa638 100644
--- a/src/libpfm4/lib/pfmlib_intel_snbep_unc.c
+++ b/src/libpfm4/lib/pfmlib_intel_snbep_unc.c
@@ -38,11 +38,13 @@ const pfmlib_attr_desc_t snbep_unc_mods[]={
 	PFM_ATTR_I("t", "threshold in range [0-255]"),	/* threshold */
 	PFM_ATTR_I("t", "threshold in range [0-31]"),	/* threshold */
 	PFM_ATTR_I("tf", "thread id filter [0-1]"),	/* thread id */
-	PFM_ATTR_I("cf", "core id filter [0-7]"),	/* core id */
+	PFM_ATTR_I("cf", "core id filter, includes non-thread data in bit 4 [0-15]"),	/* core id (ivbep) */
 	PFM_ATTR_I("nf", "node id bitmask filter [0-255]"),/* nodeid mask filter0 */
 	PFM_ATTR_I("ff", "frequency >= 100Mhz * [0-255]"),/* freq filter */
 	PFM_ATTR_I("addr", "physical address matcher [40 bits]"),/* address matcher */
 	PFM_ATTR_I("nf", "node id bitmask filter [0-255]"),/* nodeid mask filter1 */
+	PFM_ATTR_B("isoc", "match isochronous requests"),   /* isochronous */
+	PFM_ATTR_B("nc", "match non-coherent requests"),   /* non-coherent */
 	PFM_ATTR_NULL
 };
 
@@ -406,7 +408,7 @@ pfm_intel_snbep_unc_get_encoding(void *this, pfmlib_event_desc_t *e)
 					umodmsk |= _SNBEP_UNC_ATTR_TF;
 					break;
 				case SNBEP_UNC_ATTR_CF: /* core id */
-					if (ival > 7)
+					if (ival > 15)
 						return PFM_ERR_ATTR_VAL;
 					reg.cbo.unc_tid = 1;
 					filters[0].cbo_filt.cid = ival;
@@ -445,6 +447,12 @@ pfm_intel_snbep_unc_get_encoding(void *this, pfmlib_event_desc_t *e)
 					addr.ha_addr.hi_addr = (ival >> 26) & ((1ULL << 14)-1);
 					umodmsk |= _SNBEP_UNC_ATTR_A;
 					break;
+				case SNBEP_UNC_ATTR_ISOC: /* isoc filter */
+					filters[1].ivbep_cbo_filt1.isoc = !!ival;
+					break;
+				case SNBEP_UNC_ATTR_NC: /* nc filter */
+					filters[1].ivbep_cbo_filt1.nc = !!ival;
+					break;
 			}
 		}
 	}
@@ -539,9 +547,18 @@ pfm_intel_snbep_unc_get_encoding(void *this, pfmlib_event_desc_t *e)
 		case SNBEP_UNC_ATTR_TF:
 			evt_strcat(e->fstr, ":%s=%lu", snbep_unc_mods[idx].name, reg.cbo.unc_tid);
 			break;
+		case SNBEP_UNC_ATTR_CF:
+			evt_strcat(e->fstr, ":%s=%lu", snbep_unc_mods[idx].name, filters[0].cbo_filt.cid);
+			break;
 		case SNBEP_UNC_ATTR_FF:
 			evt_strcat(e->fstr, ":%s=%lu", snbep_unc_mods[idx].name, (filters[0].val >> (pcu_filt_band*8)) & 0xff);
 			break;
+		case SNBEP_UNC_ATTR_ISOC:
+			evt_strcat(e->fstr, ":%s=%lu", snbep_unc_mods[idx].name, filters[1].ivbep_cbo_filt1.isoc);
+			break;
+		case SNBEP_UNC_ATTR_NC:
+			evt_strcat(e->fstr, ":%s=%lu", snbep_unc_mods[idx].name, filters[1].ivbep_cbo_filt1.nc);
+			break;
 		case SNBEP_UNC_ATTR_NF:
 			if (modmsk_r & _SNBEP_UNC_ATTR_NF)
 				evt_strcat(e->fstr, ":%s=%lu", snbep_unc_mods[idx].name, filters[0].cbo_filt.nid);
diff --git a/src/libpfm4/lib/pfmlib_intel_snbep_unc_priv.h b/src/libpfm4/lib/pfmlib_intel_snbep_unc_priv.h
index d93b5f8..7856bee 100644
--- a/src/libpfm4/lib/pfmlib_intel_snbep_unc_priv.h
+++ b/src/libpfm4/lib/pfmlib_intel_snbep_unc_priv.h
@@ -41,6 +41,8 @@
 #define SNBEP_UNC_ATTR_FF		7
 #define SNBEP_UNC_ATTR_A		8
 #define SNBEP_UNC_ATTR_NF1		9 /* for filter1 */
+#define SNBEP_UNC_ATTR_ISOC	       10 /* isochronous */
+#define SNBEP_UNC_ATTR_NC	       11 /* non-coherent */
 
 #define _SNBEP_UNC_ATTR_I	(1 << SNBEP_UNC_ATTR_I)
 #define _SNBEP_UNC_ATTR_E	(1 << SNBEP_UNC_ATTR_E)
@@ -52,6 +54,8 @@
 #define _SNBEP_UNC_ATTR_FF	(1 << SNBEP_UNC_ATTR_FF)
 #define _SNBEP_UNC_ATTR_A	(1 << SNBEP_UNC_ATTR_A)
 #define _SNBEP_UNC_ATTR_NF1	(1 << SNBEP_UNC_ATTR_NF1)
+#define _SNBEP_UNC_ATTR_ISOC	(1 << SNBEP_UNC_ATTR_ISOC)
+#define _SNBEP_UNC_ATTR_NC	(1 << SNBEP_UNC_ATTR_NC)
 
 #define SNBEP_UNC_IRP_ATTRS \
 	(_SNBEP_UNC_ATTR_E|_SNBEP_UNC_ATTR_T8)
@@ -146,7 +150,7 @@ typedef union {
 		unsigned long unc_umask:8;	/* unit mask */
 		unsigned long unc_res1:1;	/* reserved */
 		unsigned long unc_rst:1;	/* reset */
-		unsigned long unc_edge:1;	/* edge detec */
+		unsigned long unc_edge:1;	/* edge detect */
 		unsigned long unc_tid:1;	/* tid filter enable */
 		unsigned long unc_res2:2;	/* reserved */
 		unsigned long unc_en:1;		/* enable */
diff --git a/src/libpfm4/lib/pfmlib_power_priv.h b/src/libpfm4/lib/pfmlib_power_priv.h
index 725593c..ce44d52 100644
--- a/src/libpfm4/lib/pfmlib_power_priv.h
+++ b/src/libpfm4/lib/pfmlib_power_priv.h
@@ -18,7 +18,7 @@
 *
 */
 typedef struct {
-   unsigned pme_code;
+   uint64_t pme_code;
    const char *pme_name;
    const char *pme_short_desc;
    const char *pme_long_desc;
diff --git a/src/libpfm4/tests/validate_power.c b/src/libpfm4/tests/validate_power.c
index 068d4e6..9f41ed5 100644
--- a/src/libpfm4/tests/validate_power.c
+++ b/src/libpfm4/tests/validate_power.c
@@ -143,6 +143,20 @@ static const test_event_t ppc_test_events[]={
 	  .codes[0] = 0x200f2,
 	  .fstr = "power7::PM_INST_DISP",
 	},
+	{ SRC_LINE,
+	  .name = "power8::PM_L1MISS_LAT_EXC_1024",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0x67200301eaull,
+	  .fstr = "power8::PM_L1MISS_LAT_EXC_1024",
+	},
+	{ SRC_LINE,
+	  .name = "power8::PM_RC_LIFETIME_EXC_32",
+	  .ret  = PFM_SUCCESS,
+	  .count = 1,
+	  .codes[0] = 0xde200201e6ull,
+	  .fstr = "power8::PM_RC_LIFETIME_EXC_32",
+	},
 };
 #define NUM_TEST_EVENTS (int)(sizeof(ppc_test_events)/sizeof(test_event_t))
 
diff --git a/src/libpfm4/tests/validate_x86.c b/src/libpfm4/tests/validate_x86.c
index fb6bc20..e1ed2b7 100644
--- a/src/libpfm4/tests/validate_x86.c
+++ b/src/libpfm4/tests/validate_x86.c
@@ -1251,7 +1251,7 @@ static const test_event_t x86_test_events[]={
 	  .count = 2,
 	  .codes[0] = 0x334,
 	  .codes[1] = 0x7c0000,
-	  .fstr = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:STATE_MESIF:e=0:i=0:t=0:tf=0",
+	  .fstr = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:STATE_MESIF:e=0:i=0:t=0:tf=0:cf=0",
 	},
 	{ SRC_LINE,
 	  .name = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:ANY",
@@ -1259,7 +1259,7 @@ static const test_event_t x86_test_events[]={
 	  .count = 2,
 	  .codes[0] = 0x1f34,
 	  .codes[1] = 0x7c0000,
-	  .fstr = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:ANY:STATE_MESIF:e=0:i=0:t=0:tf=0",
+	  .fstr = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:ANY:STATE_MESIF:e=0:i=0:t=0:tf=0:cf=0",
 	},
 	{ SRC_LINE,
 	  .name = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:nf=1",
@@ -1283,7 +1283,7 @@ static const test_event_t x86_test_events[]={
 	  .count = 2,
 	  .codes[0] = 0x4334,
 	  .codes[1] = 0x7c0c00,
-	  .fstr = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:NID:STATE_MESIF:e=0:i=0:t=0:tf=0:nf=3",
+	  .fstr = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:NID:STATE_MESIF:e=0:i=0:t=0:tf=0:cf=0:nf=3",
 	},
 	{ SRC_LINE,
 	  .name = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:NID:STATE_M:nf=3",
@@ -1291,7 +1291,7 @@ static const test_event_t x86_test_events[]={
 	  .count = 2,
 	  .codes[0] = 0x4334,
 	  .codes[1] = 0x200c00,
-	  .fstr = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:NID:STATE_M:e=0:i=0:t=0:tf=0:nf=3",
+	  .fstr = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:NID:STATE_M:e=0:i=0:t=0:tf=0:cf=0:nf=3",
 	},
 	{ SRC_LINE,
 	  .name = "snbep_unc_cbo0::UNC_C_LLC_LOOKUP:NID:nf=3:tid=1",
@@ -1306,7 +1306,7 @@ static const test_event_t x86_test_events[]={
 	  .ret  = PFM_SUCCESS,
 	  .count = 1,
 	  .codes[0] = 0x1035,
-	  .fstr = "snbep_unc_cbo0::UNC_C_TOR_INSERTS:WB:e=0:i=0:t=0:tf=0",
+	  .fstr = "snbep_unc_cbo0::UNC_C_TOR_INSERTS:WB:e=0:i=0:t=0:tf=0:cf=0",
 	},
 	{ SRC_LINE,
 	  .name = "snbep_unc_cbo0::UNC_C_TOR_INSERTS:OPCODE:OPC_PCIWILF",
@@ -1314,7 +1314,7 @@ static const test_event_t x86_test_events[]={
 	  .count = 2,
 	  .codes[0] = 0x135,
 	  .codes[1] = 0xca000000,
-	  .fstr = "snbep_unc_cbo0::UNC_C_TOR_INSERTS:OPCODE:OPC_PCIWILF:e=0:i=0:t=0:tf=0",
+	  .fstr = "snbep_unc_cbo0::UNC_C_TOR_INSERTS:OPCODE:OPC_PCIWILF:e=0:i=0:t=0:tf=0:cf=0",
 	},
 	{ SRC_LINE,
 	  .name = "snbep_unc_cbo0::UNC_C_TOR_INSERTS:OPCODE:OPC_PCIWILF:nf=1",
@@ -1326,7 +1326,7 @@ static const test_event_t x86_test_events[]={
 	  .count = 2,
 	  .codes[0] = 0x4135,
 	  .codes[1] = 0xcf000400,
-	  .fstr = "snbep_unc_cbo0::UNC_C_TOR_INSERTS:NID_OPCODE:OPC_PCIRDCUR:e=0:i=0:t=0:tf=0:nf=1",
+	  .fstr = "snbep_unc_cbo0::UNC_C_TOR_INSERTS:NID_OPCODE:OPC_PCIRDCUR:e=0:i=0:t=0:tf=0:cf=0:nf=1",
 	},
 	{ SRC_LINE,
 	  .name = "snbep_unc_cbo0::UNC_C_TOR_INSERTS:OPC_RFO:NID_OPCODE:nf=1",
@@ -1334,7 +1334,7 @@ static const test_event_t x86_test_events[]={
 	  .count = 2,
 	  .codes[0] = 0x4135,
 	  .codes[1] = 0xc0000400,
-	  .fstr = "snbep_unc_cbo0::UNC_C_TOR_INSERTS:NID_OPCODE:OPC_RFO:e=0:i=0:t=0:tf=0:nf=1",
+	  .fstr = "snbep_unc_cbo0::UNC_C_TOR_INSERTS:NID_OPCODE:OPC_RFO:e=0:i=0:t=0:tf=0:cf=0:nf=1",
 	},
 	{ SRC_LINE,
 	  .name = "snbep_unc_ha::UNC_H_CLOCKTICKS",
@@ -2080,6 +2080,74 @@ static const test_event_t x86_test_events[]={
 	  .fstr = "hsw::RTM_RETIRED:ABORTED:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
 	},
 	{ SRC_LINE,
+	  .name = "hsw::offcore_response_0:k:intx=1",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x1005201b7,
+	  .codes[1] = 0x18fff,
+	  .fstr = "hsw::OFFCORE_RESPONSE_0:ANY_REQUEST:ANY_RESPONSE:k=1:u=0:e=0:i=0:c=0:t=0:intx=1:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "hsw::offcore_response_0:any_request",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5301b7,
+	  .codes[1] = 0x18fff,
+	  .fstr = "hsw::OFFCORE_RESPONSE_0:DMND_DATA_RD:DMND_RFO:DMND_CODE_RD:WB:PF_DATA_RD:PF_RFO:PF_CODE_RD:PF_L3_DATA_RD:PF_L3_RFO:PF_L3_CODE_RD:SPLIT_LOCK_UC_LOCK:STRM_ST:OTHER:ANY_RESPONSE:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "hsw::offcore_response_0:any_request:any_response:L3_MISS_LOCAL",
+	  .ret  = PFM_ERR_FEATCOMB,
+	},
+	{ SRC_LINE,
+	  .name = "hsw::offcore_response_0:split_lock_uc_lock",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5301b7,
+	  .codes[1] = 0x10400,
+	  .fstr = "hsw::OFFCORE_RESPONSE_0:SPLIT_LOCK_UC_LOCK:ANY_RESPONSE:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "hsw::offcore_response_0:any_ifetch",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5301b7,
+	  .codes[1] = 0x10240,
+	  .fstr = "hsw::OFFCORE_RESPONSE_0:ANY_IFETCH:ANY_RESPONSE:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "hsw::offcore_response_0:L3_HITF",
+	  .ret  = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "hsw::offcore_response_0:LLC_MISS_LOCAL",
+	  .ret  = PFM_ERR_ATTR,
+	},
+	{ SRC_LINE,
+	  .name = "hsw::offcore_response_0:L3_HIT:u",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5101b7,
+	  .codes[1] = 0x3f801c8fffull,
+	  .fstr = "hsw::OFFCORE_RESPONSE_0:ANY_REQUEST:L3_HITM:L3_HITE:L3_HITS:SNP_ANY:k=0:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "hsw::offcore_response_0:ANY_DATA",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5301b7,
+	  .codes[1] = 0x10091,
+	  .fstr = "hsw::OFFCORE_RESPONSE_0:DMND_DATA_RD:PF_DATA_RD:PF_L3_DATA_RD:ANY_RESPONSE:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
+	  .name = "hsw::offcore_response_0:DMND_DATA_RD:L3_HITS:SNP_FWD",
+	  .ret  = PFM_SUCCESS,
+	  .count = 2,
+	  .codes[0] = 0x5301b7,
+	  .codes[1] = 0x800100001,
+	  .fstr = "hsw::OFFCORE_RESPONSE_0:DMND_DATA_RD:L3_HITS:SNP_FWD:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
+	},
+	{ SRC_LINE,
 	  .name = "ivb_unc_cbo0::unc_clockticks",
 	  .ret  = PFM_SUCCESS,
 	  .count = 1,
@@ -2246,7 +2314,7 @@ static const test_event_t x86_test_events[]={
 	  .count = 2,
 	  .codes[0] = 0x334,
 	  .codes[1] = 0x7e0000,
-	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:STATE_MESIF:e=0:t=0:tf=0",
+	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:STATE_MESIF:e=0:t=0:tf=0:cf=0",
 	},
 	{ SRC_LINE,
 	  .name = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:DATA_READ:nf=1",
@@ -2258,7 +2326,7 @@ static const test_event_t x86_test_events[]={
 	  .count = 2,
 	  .codes[0] = 0x1134,
 	  .codes[1] = 0x7e0000,
-	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:ANY:STATE_MESIF:e=0:t=0:tf=0",
+	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:ANY:STATE_MESIF:e=0:t=0:tf=0:cf=0",
 	},
 	{ SRC_LINE,
 	  .name = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:NID:STATE_M",
@@ -2271,7 +2339,7 @@ static const test_event_t x86_test_events[]={
 	  .codes[0] = 0x5134,
 	  .codes[1] = 0x7e0000,
 	  .codes[2] = 0x3,
-	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:ANY:NID:STATE_MESIF:e=0:t=0:tf=0:nf=3",
+	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:ANY:NID:STATE_MESIF:e=0:t=0:tf=0:cf=0:nf=3",
 	},
 	{ SRC_LINE,
 	  .name = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:NID:STATE_M:tid=1",
@@ -2288,7 +2356,7 @@ static const test_event_t x86_test_events[]={
 	  .codes[0] = 0x10c4534,
 	  .codes[1] = 0x7e0001,
 	  .codes[2] = 0x3,
-	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:WRITE:NID:STATE_MESIF:e=1:t=1:tf=1:nf=3",
+	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_LOOKUP:WRITE:NID:STATE_MESIF:e=1:t=1:tf=1:cf=0:nf=3",
 	},
 	{ SRC_LINE,
 	  .name = "ivbep_unc_cbo0::UNC_C_LLC_VICTIMS",
@@ -2307,14 +2375,14 @@ static const test_event_t x86_test_events[]={
 	  .ret  = PFM_SUCCESS,
 	  .count = 1,
 	  .codes[0] = 0x137,
-	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_VICTIMS:STATE_M:e=0:t=0:tf=0",
+	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_VICTIMS:STATE_M:e=0:t=0:tf=0:cf=0",
 	},
 	{ SRC_LINE,
 	  .name = "ivbep_unc_cbo0::UNC_C_LLC_VICTIMS:STATE_M:STATE_S",
 	  .ret  = PFM_SUCCESS,
 	  .count = 1,
 	  .codes[0] = 0x537,
-	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_VICTIMS:STATE_M:STATE_S:e=0:t=0:tf=0",
+	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_VICTIMS:STATE_M:STATE_S:e=0:t=0:tf=0:cf=0",
 	},
 	{ SRC_LINE,
 	  .name = "ivbep_unc_cbo0::UNC_C_LLC_VICTIMS:STATE_M:STATE_S:NID:nf=1",
@@ -2323,7 +2391,7 @@ static const test_event_t x86_test_events[]={
 	  .codes[0] = 0x4537,
 	  .codes[1] = 0x0,
 	  .codes[2] = 0x1,
-	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_VICTIMS:STATE_M:STATE_S:NID:e=0:t=0:tf=0:nf=1",
+	  .fstr = "ivbep_unc_cbo0::UNC_C_LLC_VICTIMS:STATE_M:STATE_S:NID:e=0:t=0:tf=0:cf=0:nf=1",
 	},
 	{ SRC_LINE,
 	  .name = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:OPCODE",
@@ -2334,7 +2402,7 @@ static const test_event_t x86_test_events[]={
 	  .ret  = PFM_SUCCESS,
 	  .count = 1,
 	  .codes[0] = 0x1035,
-	  .fstr = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:WB:e=0:t=0:tf=0",
+	  .fstr = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:WB:e=0:t=0:tf=0:cf=0:isoc=0:nc=0",
 	},
 	{ SRC_LINE,
 	  .name = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:OPCODE:OPC_PCIWILF",
@@ -2343,7 +2411,16 @@ static const test_event_t x86_test_events[]={
 	  .codes[0] = 0x135,
 	  .codes[1] = 0x0,
 	  .codes[2] = 0x19400000ull,
-	  .fstr = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:OPCODE:OPC_PCIWILF:e=0:t=0:tf=0",
+	  .fstr = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:OPCODE:OPC_PCIWILF:e=0:t=0:tf=0:cf=0:isoc=0:nc=0",
+	},
+	{ SRC_LINE,
+	  .name = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:OPCODE:OPC_PCIWILF:isoc=1",
+	  .ret  = PFM_SUCCESS,
+	  .count = 3,
+	  .codes[0] = 0x135,
+	  .codes[1] = 0x0,
+	  .codes[2] = 0x99400000ull,
+	  .fstr = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:OPCODE:OPC_PCIWILF:e=0:t=0:tf=0:cf=0:isoc=1:nc=0",
 	},
 	{ SRC_LINE,
 	  .name = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:OPCODE:OPC_PCIWILF:nf=1",
@@ -2356,7 +2433,7 @@ static const test_event_t x86_test_events[]={
 	  .codes[0] = 0x4135,
 	  .codes[1] = 0x0,
 	  .codes[2] = 0x19e00001ull,
-	  .fstr = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:NID_OPCODE:OPC_PCIRDCUR:e=0:t=0:tf=0:nf=1",
+	  .fstr = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:NID_OPCODE:OPC_PCIRDCUR:e=0:t=0:tf=0:cf=0:nf=1:isoc=0:nc=0",
 	},
 	{ SRC_LINE,
 	  .name = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:OPC_RFO:NID_OPCODE:nf=1",
@@ -2365,14 +2442,14 @@ static const test_event_t x86_test_events[]={
 	  .codes[0] = 0x4135,
 	  .codes[1] = 0x0,
 	  .codes[2] = 0x18000001ull,
-	  .fstr = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:NID_OPCODE:OPC_RFO:e=0:t=0:tf=0:nf=1",
+	  .fstr = "ivbep_unc_cbo0::UNC_C_TOR_INSERTS:NID_OPCODE:OPC_RFO:e=0:t=0:tf=0:cf=0:nf=1:isoc=0:nc=0",
 	},
 	{ SRC_LINE,
 	  .name = "ivbep_unc_cbo0::UNC_C_TOR_OCCUPANCY:MISS_REMOTE",
 	  .ret  = PFM_SUCCESS,
 	  .count = 1,
 	  .codes[0] = 0x8a36,
-	  .fstr = "ivbep_unc_cbo0::UNC_C_TOR_OCCUPANCY:MISS_REMOTE:e=0:t=0:tf=0",
+	  .fstr = "ivbep_unc_cbo0::UNC_C_TOR_OCCUPANCY:MISS_REMOTE:e=0:t=0:tf=0:cf=0:isoc=0:nc=0",
 	},
 	{ SRC_LINE,
 	  .name = "ivbep_unc_pcu::UNC_P_CLOCKTICKS",
@@ -2778,8 +2855,8 @@ static const test_event_t x86_test_events[]={
 	  .ret = PFM_SUCCESS,
 	  .count = 2,
 	  .codes[0] = 0x5301b7,
-	  .codes[1] = 0x3f84000091ull,
-	  .fstr = "hsw_ep::OFFCORE_RESPONSE_0:DMND_DATA_RD:PF_DATA_RD:PF_LLC_DATA_RD:L3_MISS_LOCAL_DRAM:SNP_ANY:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
+	  .codes[1] = 0x3f80400091ull,
+	  .fstr = "hsw_ep::OFFCORE_RESPONSE_0:DMND_DATA_RD:PF_DATA_RD:PF_L3_DATA_RD:L3_MISS_LOCAL:SNP_ANY:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
 	},
 	{ SRC_LINE,
 	  .name = "hsw_ep::offcore_response_0:any_data:LLC_miss_local",
@@ -2795,15 +2872,7 @@ static const test_event_t x86_test_events[]={
 	  .count = 2,
 	  .codes[0] =0x5301b7,
 	  .codes[1] =0x3f803c0091ull,
-	  .fstr = "hsw_ep::OFFCORE_RESPONSE_0:DMND_DATA_RD:PF_DATA_RD:PF_LLC_DATA_RD:L3_HITM:L3_HITE:L3_HITS:L3_HITF:SNP_ANY:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
-	},
-	{ SRC_LINE,
-	  .name = "hsw_ep::offcore_response_0:any_data:L4_HIT",
-	  .ret = PFM_SUCCESS,
-	  .count = 2,
-	  .codes[0] = 0x5301b7,
-	  .codes[1] =0x3f83c00091ull,
-	  .fstr = "hsw_ep::OFFCORE_RESPONSE_0:DMND_DATA_RD:PF_DATA_RD:PF_LLC_DATA_RD:L4_HIT_LOCAL_L4:L4_HIT_REMOTE_HOP0_L4:L4_HIT_REMOTE_HOP1_L4:L4_HIT_REMOTE_HOP2P_L4:SNP_ANY:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
+	  .fstr = "hsw_ep::OFFCORE_RESPONSE_0:DMND_DATA_RD:PF_DATA_RD:PF_L3_DATA_RD:L3_HITM:L3_HITE:L3_HITS:L3_HITF:SNP_ANY:k=1:u=1:e=0:i=0:c=0:t=0:intx=0:intxcp=0",
 	},
 	{ SRC_LINE,
 	  .name = "bdw::mem_trans_retired:latency_above_threshold:ldlat=3:u",
-- 
2.1.0

From 2a502622a68df28b0da9fd081a83eca70c68919e Mon Sep 17 00:00:00 2001
From: Heike McCraw <mccraw@icl.utk.edu>
Date: Tue, 20 Jan 2015 18:14:33 -0500
Subject: [PATCH 24/24] Update libpfm4

Current with
------------

commit c61116d16e8052ca131afde81687290a5f0efd18
Author: Stephane Eranian <eranian@gmail.com>
Date:   Mon Jan 12 19:37:41 2015 +0100

    fix typo is ICACHE:IFETCH_STALL

	No S at the end of STALL.
	Updated description.

	Signed-off-by: Stephane Eranian <eranian@gmail.com>

diff --git a/src/libpfm4/debian/changelog b/src/libpfm4/debian/changelog
index ec0f7eb..1f3e213 100644
--- a/src/libpfm4/debian/changelog
+++ b/src/libpfm4/debian/changelog
@@ -1,3 +1,15 @@
+libpfm4 (6.0) unstable; urgency=low
+  * add Intel Broadwell (desktop) support
+  * add Intel Haswell-EP support (core)
+  * add Applied Micro X-Gene processor support
+  * simplified X86 model detection for Intel processors
+  * Intel SNB, IVB, HSW event table updates
+  * IBM Power8 event table updates
+  * add ARM Cortex A53 support
+  * more bug fixes and minor updates
+
+ -- Stephane Eranian <eranian@gmail.com>  Tue, 30 Dec  2014 16:56:01 +0200
+
 libpfm4 (5.0) unstable; urgency=low
   * Intel IVB-EP uncore PMU support
   * Intel Silvermont support
@@ -11,6 +23,8 @@ libpfm4 (5.0) unstable; urgency=low
   * various IVB, SNB, HSW event table updates
   * more bug fixes
 
+ -- Stephane Eranian <eranian@gmail.com>  Fri, 21 Feb  2014 18:45:01 +0200
+
 libpfm4 (4.0) unstable; urgency=low
   * Intel IVB-EP support
   * Intel IVB updates support
diff --git a/src/libpfm4/include/perfmon/perf_event.h b/src/libpfm4/include/perfmon/perf_event.h
index 244cf51..7a94636 100644
--- a/src/libpfm4/include/perfmon/perf_event.h
+++ b/src/libpfm4/include/perfmon/perf_event.h
@@ -348,6 +348,7 @@ enum perf_event_type {
 	PERF_RECORD_FORK		= 7,
 	PERF_RECORD_READ		= 8,
 	PERF_RECORD_SAMPLE		= 9,
+	PERF_RECORD_MMAP2		= 10,
 	PERF_RECORD_MAX
 };
 
diff --git a/src/libpfm4/lib/events/intel_hsw_events.h b/src/libpfm4/lib/events/intel_hsw_events.h
index 1810024..0f8d4fc 100644
--- a/src/libpfm4/lib/events/intel_hsw_events.h
+++ b/src/libpfm4/lib/events/intel_hsw_events.h
@@ -467,7 +467,12 @@ static const intel_x86_umask_t hsw_icache[]={
   { .uname = "MISSES",
     .udesc  = "Number of Instruction Cache, Streaming Buffer and Victim Cache Misses. Includes Uncacheable accesses",
     .ucode  = 0x200,
-    .uflags = INTEL_X86_DFL,
+    .uflags = INTEL_X86_NCOMBO,
+  },
+  { .uname = "IFETCH_STALL",
+    .udesc  = "Number of cycles where a code-fetch stalled due to L1 instruction cache miss or an iTLB miss",
+    .ucode  = 0x400,
+    .uflags = INTEL_X86_NCOMBO,
   },
 };
 
diff --git a/src/libpfm4/lib/events/intel_ivb_events.h b/src/libpfm4/lib/events/intel_ivb_events.h
index dac8163..78afa96 100644
--- a/src/libpfm4/lib/events/intel_ivb_events.h
+++ b/src/libpfm4/lib/events/intel_ivb_events.h
@@ -993,6 +993,11 @@ static const intel_x86_umask_t ivb_mem_load_uops_retired[]={
      .ucode = 0x4000,
      .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
    },
+   { .uname  = "L1_MISS",
+     .udesc  = "Load miss in nearest-level (L1D) cache (Precise Event)",
+     .ucode = 0x800,
+     .uflags= INTEL_X86_NCOMBO | INTEL_X86_PEBS,
+   },
    { .uname  = "L1_HIT",
      .udesc  = "Load hit in nearest-level (L1D) cache (Precise Event)",
      .ucode = 0x100,
diff --git a/src/libpfm4/lib/events/intel_snb_events.h b/src/libpfm4/lib/events/intel_snb_events.h
index 11937ea..1f4be65 100644
--- a/src/libpfm4/lib/events/intel_snb_events.h
+++ b/src/libpfm4/lib/events/intel_snb_events.h
@@ -478,7 +478,12 @@ static const intel_x86_umask_t snb_icache[]={
    { .uname  = "MISSES",
      .udesc  = "Number of Instruction Cache, Streaming Buffer and Victim Cache Misses. Includes UC accesses",
      .ucode = 0x200,
-     .uflags= INTEL_X86_NCOMBO | INTEL_X86_DFL,
+     .uflags= INTEL_X86_NCOMBO,
+   },
+   { .uname  = "IFETCH_STALL",
+     .udesc  = "Number of cycles wher a code-fetch stalled due to L1 instruction cache miss or iTLB miss",
+     .ucode = 0x400,
+     .uflags= INTEL_X86_NCOMBO,
    },
 };
 
diff --git a/src/libpfm4/lib/pfmlib_arm_armv8.c b/src/libpfm4/lib/pfmlib_arm_armv8.c
index 3619508..5506517 100644
--- a/src/libpfm4/lib/pfmlib_arm_armv8.c
+++ b/src/libpfm4/lib/pfmlib_arm_armv8.c
@@ -143,7 +143,7 @@ pfmlib_pmu_t arm_xgene_support={
 
 	.pmu_detect		= pfm_arm_detect_xgene,
 	.max_encoding		= 1,
-	.num_cntrs		= 6,
+	.num_cntrs		= 4,
 
 	.get_event_encoding[PFM_OS_NONE] = pfm_arm_get_encoding,
 	 PFMLIB_ENCODE_PERF(pfm_arm_get_perf_encoding),
-- 
2.1.0

